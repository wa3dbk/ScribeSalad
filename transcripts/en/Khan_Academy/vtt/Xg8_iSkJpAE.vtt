WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:06.400
In the last couple of videos we first figured out the TOTAL variation in these 9 data points right here

00:00:06.400 --> 00:00:11.533
and we got 30, that's our Total Sum of Squares. Then we asked ourselves,

00:00:11.533 --> 00:00:19.533
how much of that variation is due to variation WITHIN each of these groups, versus variation BETWEEN the groups themselves?

00:00:19.533 --> 00:00:24.933
So, for the variation within the groups we have our Sum of Squares within.

00:00:24.933 --> 00:00:26.933
And there we got 6.

00:00:26.933 --> 00:00:32.533
And then the balance of this, 30, the balance of this variation,

00:00:32.533 --> 00:00:36.333
came from variation between the groups, and we calculated it,

00:00:36.333 --> 00:00:39.867
We got 24.

00:00:39.867 --> 00:00:43.600
What I want to do in this video, is actually use this type of information,

00:00:43.600 --> 00:00:49.267
essentially these statistics we've calculated, to do some inferential statistics,

00:00:49.267 --> 00:00:53.200
to come to some time of conclusion, or maybe not to come to some type of conclusion.

00:00:53.200 --> 00:00:56.867
What I want to do is to put some context around these groups.

00:00:56.867 --> 00:01:00.267
We've been dealing with them abstractly right now, but you can imagine

00:01:00.267 --> 00:01:03.133
these are the results of some type of experiment.

00:01:03.133 --> 00:01:11.867
Let's say that I gave 3 different types of pills or 3 different types of food to people taking a test.

00:01:11.867 --> 00:01:13.933
And these are the scores on the test.

00:01:13.933 --> 00:01:25.333
So this is food 1, food 2, and then this over here is food 3.

00:01:25.333 --> 00:01:33.400
And I want to figure out if the type of food people take going into the test really affect their scores?

00:01:33.400 --> 00:01:40.267
If you look at these means, it looks like they perform best in group 3, than in group 2 or 1.

00:01:40.267 --> 00:01:44.733
But is that difference purely random? Random chance?

00:01:44.733 --> 00:01:50.600
Or can I be pretty confident that it's due to actual differences

00:01:50.600 --> 00:01:56.867
in the population means, of all of the people who would ever take food 3 vs food 2 vs food 1?

00:01:56.867 --> 00:02:03.733
So, my question here is, are the means and the true population means the same?

00:02:03.733 --> 00:02:10.333
This is a sample mean based on 3 samples. But if I knew the true population means--

00:02:10.333 --> 00:02:17.800
So my question is: Is the mean of the population of people taking Food 1 equal to the mean of Food 2?

00:02:17.800 --> 00:02:22.000
Obviously I'll never be able to give that food to every human being that could

00:02:22.000 --> 00:02:25.667
ever live and then make them all take an exam.

00:02:25.667 --> 00:02:30.000
But there is some true mean there, it's just not really measurable.

00:02:30.000 --> 00:02:35.667
So my question is "this" equal to "this" equal to the mean 3, the true population of mean 3.

00:02:35.667 --> 00:02:38.933
And my question is, are these equal?

00:02:38.933 --> 00:02:47.800
Because if they're not equal, that means that the type of food given does have some type of impact

00:02:47.800 --> 00:02:50.067
on how people perform on a test.

00:02:50.067 --> 00:02:55.000
So let's do a little hypothesis test here. Let's say that my null hypothesis

00:02:55.000 --> 00:03:01.267
is that the means are the same. Food doesn't make a difference.

00:03:01.267 --> 00:03:07.200
"food doesn't make a difference"

00:03:07.200 --> 00:03:17.000
and that my Alternate hypothesis is that it does. "It does."

00:03:17.000 --> 00:03:19.000
and the way of thinking about this quantitatively

00:03:19.000 --> 00:03:20.933
is that if it doesn't make a difference,

00:03:20.933 --> 00:03:24.000
the true population means of the groups will be the same.

00:03:24.000 --> 00:03:28.733
The true population mean of the group that took food 1 will be the same

00:03:28.733 --> 00:03:35.400
as the group that took food 2, which will be the same as the group that took food 3.

00:03:35.400 --> 00:03:40.867
If our alternate hypothesis is correct, then these means will not be all the same.

00:03:40.867 --> 00:03:43.067
How can we test this hypothesis?

00:03:43.067 --> 00:03:47.200
So we're going to assume the null hypothesis, which is

00:03:47.200 --> 00:03:49.800
what we always do when we are hypothesis testing,

00:03:49.800 --> 00:03:52.600
we're going to assume our null hypothesis.

00:03:52.600 --> 00:03:56.267
And then essentially figure out, what are the chances

00:03:56.267 --> 00:03:59.267
of getting a certain statistic this extreme?

00:03:59.267 --> 00:04:01.200
And I haven't even defined what that statistic is.

00:04:01.200 --> 00:04:05.267
So we're going to define--we're going to assume our null hypothesis,

00:04:05.267 --> 00:04:08.667
and then we're going to come up with a statistic called the F statistic.

00:04:08.667 --> 00:04:11.933
So our F statistic

00:04:11.933 --> 00:04:16.600
which has an F distribution--and we won't go real deep into the details of

00:04:16.600 --> 00:04:19.067
the F distribution. But you can already start to think of it

00:04:19.067 --> 00:04:23.800
as the ratio of two Chi-squared distributions that may or may not have different degrees of freedom.

00:04:23.800 --> 00:04:31.933
Our F statistic is going to be the ratio of our Sum of Squares between the samples--

00:04:31.933 --> 00:04:37.067
Sum of Squares between

00:04:37.067 --> 00:04:41.733
divided by, our degrees of freedom between

00:04:41.733 --> 00:04:46.333
and this is sometimes called the mean squares between, MSB,

00:04:46.333 --> 00:04:52.333
that, divided by the Sum of Squares within,

00:04:52.333 --> 00:04:56.533
so that's what I had done up here, the SSW in blue,

00:04:56.533 --> 00:05:01.133
divided by the SSW

00:05:01.133 --> 00:05:07.800
divided by the degrees of freedom of the SSwithin, and that was

00:05:07.800 --> 00:05:12.267
m (n-1). Now let's just think about what this is doing right here.

00:05:12.267 --> 00:05:18.333
If this number, the numerator, is much larger than the denominator,

00:05:18.333 --> 00:05:27.333
then that tells us that the variation in this data is due mostly

00:05:27.333 --> 00:05:31.600
to the differences between the actual means

00:05:31.600 --> 00:05:35.933
and its due less to the variation within the means.

00:05:35.933 --> 00:05:40.867
That's if this numerator is much bigger than this denominator over here.

00:05:40.867 --> 00:05:45.733
So that should make us believe that there is a difference

00:05:45.733 --> 00:05:47.200
in the true population mean.

00:05:47.200 --> 00:05:48.733
So if this number is really big,

00:05:48.733 --> 00:05:51.333
it should tell us that there is a lower probability

00:05:51.333 --> 00:05:53.600
that our null hypothesis is correct.

00:05:53.600 --> 00:05:58.533
If this number is really small and our denominator is larger,

00:05:58.533 --> 00:06:02.067
that means that our variation within each sample,

00:06:02.067 --> 00:06:05.467
makes up more of the total variation than our variation between

00:06:05.467 --> 00:06:07.333
the samples. So that means that our variation

00:06:07.333 --> 00:06:12.733
within each of these samples is a bigger percentage of the total variation

00:06:12.733 --> 00:06:15.200
versus the variation between the samples.

00:06:15.200 --> 00:06:17.800
So that would make us believe that "hey! ya know... any difference

00:06:17.800 --> 00:06:21.000
we see between the means is probably just random."

00:06:21.000 --> 00:06:24.400
And that would make it a little harder to reject the null.

00:06:24.400 --> 00:06:26.867
So let's actually calculate it.

00:06:26.867 --> 00:06:34.200
So in this case, our SSbetween, we calculated over here, was 24.

00:06:34.200 --> 00:06:37.933
and we had 2 degrees of freedom.

00:06:37.933 --> 00:06:49.800
And our SSwithin was 6 and we had how many degrees of freedom?

00:06:49.800 --> 00:06:52.667
Also, 6. 6 degrees of freedom.

00:06:52.667 --> 00:06:58.600
So this is going to be 24/2 which is 12, divided by 1.

00:06:58.600 --> 00:07:05.867
Our F statistic that we've calculated is going to be 12.

00:07:05.867 --> 00:07:10.867
F stands for Fischer who is the biologist and statistician who came up with this.

00:07:10.867 --> 00:07:15.267
So our F statistic is going to be 12.

00:07:15.267 --> 00:07:18.067
We're going to see that this is a pretty high number.

00:07:18.067 --> 00:07:19.800
Now, one thing I forgot to mention, with any hypothesis test,

00:07:19.800 --> 00:07:22.267
we're going to need some type of significance level.

00:07:22.267 --> 00:07:24.733
So let's say the significance level that we care about,

00:07:24.733 --> 00:07:28.333
for our hypothesis test, is 10%.

00:07:28.333 --> 00:07:32.267
0.10 -- which means

00:07:32.267 --> 00:07:36.200
that if we assume the null hypothesis, there is

00:07:36.200 --> 00:07:40.067
less than a 10% chance of getting the result we got,

00:07:40.067 --> 00:07:41.667
of getting this F statistic,

00:07:41.667 --> 00:07:44.800
then we will reject the null hypothesis.

00:07:44.800 --> 00:07:48.667
So what we want to do is figure out a critical F statistic value,

00:07:48.667 --> 00:07:54.000
that getting that extreme of a value or greater, is 10%

00:07:54.000 --> 00:07:57.133
and if this is bigger than our critical F statistic value,

00:07:57.133 --> 00:07:59.533
then we're going to reject the null hypothesis,

00:07:59.533 --> 00:08:01.400
if it's less, we can't reject the null.

00:08:01.400 --> 00:08:06.267
So I'm not going to go into a lot of the guts of the F statistic,

00:08:06.267 --> 00:08:09.067
but we can already appreciate that each of these Sum of squares

00:08:09.067 --> 00:08:12.533
has a Chi-squared distribution. "This" has a Chi-squared distribution,

00:08:12.533 --> 00:08:15.200
and "this" has a different Chi-squared distribution

00:08:15.200 --> 00:08:17.533
This is a Chi-squared distribution with 2 degrees of freedom,

00:08:17.533 --> 00:08:21.333
this is a Chi-squared distribution with--And we haven't normalized it and all of that--

00:08:21.333 --> 00:08:24.067
but roughly a Chi squared distribution with 6 degrees of freedom.

00:08:24.067 --> 00:08:29.800
So the F distribution is actually the ratio of two Chi-squared distributions

00:08:29.800 --> 00:08:34.933
And I got this--this is a screenshot from a professor's course at UCLA,

00:08:34.933 --> 00:08:38.533
I hope they don't mind, I need to find us an F table for us to look into.

00:08:38.533 --> 00:08:41.800
But this is what an F distribution looks like.

00:08:41.800 --> 00:08:43.267
And obviously it's going to look different

00:08:43.267 --> 00:08:46.600
depending on the df of the numerator and the denominator.

00:08:46.600 --> 00:08:49.200
There's two df to think about,

00:08:49.200 --> 00:08:52.533
the numerator degrees of freedom and the denominator degrees of freedom

00:08:52.533 --> 00:08:56.933
With that said, let's calculate the critical F statistic,

00:08:56.933 --> 00:09:02.867
for alpha is equal to 0.10,

00:09:02.867 --> 00:09:06.533
and you're actually going to see different F tables for each different alpha,

00:09:06.533 --> 00:09:11.933
where our numerator df is 2, and our denominator df is 6.

00:09:11.933 --> 00:09:17.400
So this table that I got, this whole table is for an alpha of 10%

00:09:17.400 --> 00:09:23.733
or 0.10, and our numerator df was 2 and our denominator

00:09:23.733 --> 00:09:30.133
was 6. So our critical F value is 3.46.

00:09:30.133 --> 00:09:40.000
So our critical F value is 3.46--this value right over here is 3.46

00:09:40.000 --> 00:09:43.533
The value that we got based on our data is much larger than this,

00:09:43.533 --> 00:09:46.267
WAY above it. It's going to have a very, very small p value.

00:09:46.267 --> 00:09:48.000
The probability of getting something this extreme,

00:09:48.000 --> 00:09:50.667
just by chance, assuming the null hypothesis,

00:09:50.667 --> 00:09:54.733
is very low. It's way bigger than our critical F statistic with

00:09:54.733 --> 00:09:56.933
a 10% significance level.

00:09:56.933 --> 00:10:01.733
So because of that we can reject the null hypothesis.

00:10:01.733 --> 00:10:04.400
Which leads us to believe, "you know what, there probably

00:10:04.400 --> 00:10:06.600
IS a difference in the population means."

00:10:06.600 --> 00:10:09.600
Which tells us there probably is a difference in performance

00:10:09.600 --> 00:10:13.467
on an exam if you give them the different foods.

