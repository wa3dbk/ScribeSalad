WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.420
So, I've come here today because you promised me "cache", but I don't see any money.

00:00:03.420 --> 00:00:07.480
I thought you were paying me for these things, but- No, we're not talking about that sort of cash.

00:00:07.480 --> 00:00:12.640
We're actually looking for the cache that is built into our CPUs and they're used in computers

00:00:12.640 --> 00:00:14.880
to try and make things run faster.

00:00:17.120 --> 00:00:21.960
Now, we talked about how the CPU talks to memory, and we spent some time looking at how

00:00:21.960 --> 00:00:25.720
we can build memory chips out of discrete logic circuits.

00:00:25.720 --> 00:00:28.340
While you probably want to build all the memory in your computer system like that,

00:00:28.340 --> 00:00:33.200
there are other ways you can build them to create SIMs as you're using in the late 80s, early 90s.

00:00:33.360 --> 00:00:39.440
And this one is about 256 kilobytes, but you can get DIMMs that are as big as 16 gig these days.

00:00:39.440 --> 00:00:43.400
Now, if you remember back to what Steve Furber was saying about when you build the BBC micro,

00:00:43.640 --> 00:00:50.440
he was talking about how when they built it, they used RAM chips that ran at twice the speed of the CPU.

00:00:50.440 --> 00:00:56.520
So, we got the 8 RAM chips here, and they're connected directly, more or less, to the CPU here.

00:00:56.520 --> 00:01:00.640
The memory ran at 4 megahertz and the CPU ran at 2 megahertz.

00:01:00.640 --> 00:01:03.840
And so the CPU could make its requests and the RAM  would return it very quickly.

00:01:03.840 --> 00:01:08.360
And while the CPU was still processing that, the video circuits could grab the data from memory

00:01:08.360 --> 00:01:13.400
to form the display. So, it was able to multiplex the two and not slow the CPU down,

00:01:13.400 --> 00:01:14.840
unlike some of the systems.

00:01:14.840 --> 00:01:20.080
Now, as time went on, the CPUs got much faster so by the end of 80s, you could get CPUs like this,

00:01:20.080 --> 00:01:24.320
which ran at 8 megahertz and then 16 megahertz, 32 megahertz and so on.

00:01:24.380 --> 00:01:29.320
And now a 3 gigahertz CPU is very easy to get a hold of.

00:01:30.040 --> 00:01:33.760
Unfortunately, the RAM didn't increase speed at the same rate.

00:01:33.760 --> 00:01:38.240
So these days, the RAM runs several orders of magnitude slower than what the CPU runs at.

00:01:38.240 --> 00:01:43.260
So, this leaves us with a problem. Even if the clock speed of the CPU increased, it would still have to wait

00:01:43.260 --> 00:01:46.880
for the memory, so it wouldn't actually appear to get any faster.

00:01:46.880 --> 00:01:51.580
So actually, it is possible to build memory that will work at the speed that the CPU executes at.

00:01:51.580 --> 00:01:55.700
But the problem is it takes more space on the silicon to store each bit of information,

00:01:55.700 --> 00:02:00.780
and so therefore, it costs a lot more to produce the memory compared to the DIMMs,

00:02:00.780 --> 00:02:02.300
the DRAM that we use today.

00:02:02.380 --> 00:02:05.560
So the way we get around this is we split the memory up into two types.

00:02:05.560 --> 00:02:08.280
We have our main memory, which we build out of dynamic RAM.

00:02:08.280 --> 00:02:13.000
But we also have a second type of memory which is actually often built into the CPU as well.

00:02:13.000 --> 00:02:16.360
Now this is much smaller, but it's built out of much faster memory.

00:02:16.360 --> 00:02:22.080
And this is referred to as the cache. Now, the cache is perhaps an old-fashioned English word,

00:02:22.080 --> 00:02:24.840
but it basically just means a small place where we can store things.

00:02:24.840 --> 00:02:30.520
So you might use it to store your hidden treasure if you're a pirate or to store your food for winter.

00:02:30.520 --> 00:02:34.000
Another example where you might come across a cache is with your web browser.

00:02:34.000 --> 00:02:37.940
So the cache on the web browser is used to get around because it takes a relatively long time

00:02:37.940 --> 00:02:41.520
to fetch a piece of information over the Internet compared to accessing something

00:02:41.520 --> 00:02:42.420
on your local machine.

00:02:42.420 --> 00:02:45.320
So what happens is: When you go and fetch a page from the Internet

00:02:45.320 --> 00:02:49.860
the browser will go and get the HTML page, it'll get the CSS files, the images and so on.

00:02:49.860 --> 00:02:56.040
And it's stores or caches a copy onto your local disk that it can then refer if it needs to get it again.

00:02:56.040 --> 00:03:00.280
And the idea is that we can get the data from the local copy a lot quicker than it could

00:03:00.280 --> 00:03:04.200
if it had to go fetch it from the web server somewhere else in the world.

00:03:04.200 --> 00:03:08.100
And it's this same approach that is used by the CPUs. The CPU's got the same problem.

00:03:08.100 --> 00:03:12.880
It can talk to its cache on the CPU very, very quickly, but talking to main memory,

00:03:13.020 --> 00:03:16.940
compared to talking to the cache is a relatively long time.

00:03:16.940 --> 00:03:22.140
So what happens is: Every time it requests a bit of data, it caches a copy locally

00:03:22.140 --> 00:03:27.600
in the cache built onto the CPU, so that when it needs to fetch is again in the near future,

00:03:27.780 --> 00:03:31.460
it can access it from its local copy a lot faster.

00:03:31.460 --> 00:03:35.340
There's some other tricks that it can do as well, because the CPU can say,

00:03:35.340 --> 00:03:39.380
"Well, actually, if I fetch this instruction, there's a very good chance that I'm going to execute

00:03:39.380 --> 00:03:42.140
the next instruction, and the one after that at the same time."

00:03:42.140 --> 00:03:46.360
And so what it can do is, rather than just getting one word of memory at a time,

00:03:46.360 --> 00:03:50.280
it'll say, "Well okay, get me the next 128 bytes of memory."

00:03:50.280 --> 00:03:56.920
And it'll read what we call a cache line, one single lot of 128 bytes from memory into the CPU in one go.

00:03:56.980 --> 00:04:05.320
The idea being that it takes less time to read 128 bytes in one go, than just to read each 128 bytes individually.

00:04:05.320 --> 00:04:08.300
But that's down to the way memory actually store things.

00:04:08.300 --> 00:04:12.120
So, we talked about, in the previous video, how we would have an address, a binary number

00:04:12.840 --> 00:04:16.860
that represents each different bit in the RAM chips.

00:04:17.260 --> 00:04:23.680
But actually, rather than storing it as one big list of bits, it actually stores it as a grid.

00:04:23.680 --> 00:04:27.540
The address that you give it from the CPU gets split up to reference a particular row,

00:04:27.540 --> 00:04:32.180
and a column of that grid to get the particular bit it's interested in.

00:04:32.180 --> 00:04:37.460
Now, the way the RAM chips work: One you've selected a specific row, you can then access

00:04:37.460 --> 00:04:42.540
each of the columns in that relatively quickly, compared to changing to a different row.

00:04:42.740 --> 00:04:47.460
So if we want to get 128 bytes, if they're all in the same row of memory,

00:04:47.460 --> 00:04:51.940
then we can access them very quickly, and so copy them into the CPU's cache much quicker

00:04:51.940 --> 00:04:55.100
than if we were having to select different rows at a time.

00:04:55.460 --> 00:04:58.580
So, how big does the cache on your CPU need to be?

00:04:58.580 --> 00:05:03.680
Well, actually it turns out, you only need a relatively small amount of cache to make a significant difference

00:05:03.680 --> 00:05:07.900
because our programs are often sitting in loops, executing the same set of instructions

00:05:07.900 --> 00:05:09.300
again and again and again.

00:05:09.300 --> 00:05:14.600
So if you've got enough to store that loop, then they can be cached and it'll work fine.

00:05:14.600 --> 00:05:19.400
Or the program's accessing the same block of data and manipulating that in different ways.

00:05:19.400 --> 00:05:23.160
And so if that will fit into the cache, things work relatively fine.

00:05:23.160 --> 00:05:26.780
So we don't need that much. You often use separate caches for the instructions

00:05:26.780 --> 00:05:30.720
and for the data so you don't remove the instruction that you're interested in

00:05:30.720 --> 00:05:33.700
to put a copy of the data that you're going to process in there.

00:05:33.700 --> 00:05:36.240
I mean, you could think about it, that you might have a field full of turnips

00:05:36.240 --> 00:05:40.280
and so you'd have to go and dig them up. But you might also have a cupboard with your turnips

00:05:40.280 --> 00:05:43.800
in the kitchen, so you can make your stew that night without having to go out into the field

00:05:43.800 --> 00:05:49.760
And if you're out working somewhere else, you may even have a turnip in your backpack to eat on the way out.

00:05:50.420 --> 00:05:51.920
Second level turnip cache?

00:05:51.920 --> 00:05:53.120
Yeah! *laughter*

