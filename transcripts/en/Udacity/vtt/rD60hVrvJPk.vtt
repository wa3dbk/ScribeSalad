WEBVTT
Kind: captions
Language: en

00:00:00.080 --> 00:00:05.130
Let's look at the solution to our RAID5
quiz, where we had the five disk array

00:00:05.130 --> 00:00:09.280
with disks similar to what we've
seen in quizzes before, and

00:00:09.280 --> 00:00:12.110
the replacement is 24
hours once the disk fails.

00:00:13.340 --> 00:00:19.390
The data capacity for
RAID5 Is just like for RAID4, 800 GB.

00:00:19.390 --> 00:00:25.080
Effectively, we still sacrifice one
disk worth of capacity to parity.

00:00:25.080 --> 00:00:29.430
It's just that this parity now is
distributed among the five disks.

00:00:29.430 --> 00:00:30.450
The throughput for

00:00:30.450 --> 00:00:34.260
the five disk array however,
is much better than for a RAID4.

00:00:34.260 --> 00:00:39.650
For RAIDs, all of the disks now
have equal amounts of data.

00:00:39.650 --> 00:00:43.540
So we can use all five of
them when we want to read.

00:00:43.540 --> 00:00:48.480
For writes now, we distribute the parity
accesses among all of the disks.

00:00:48.480 --> 00:00:51.800
So all of them can now support writes.

00:00:51.800 --> 00:00:57.718
But we need four accesses so we could
be doing what needs to be done for

00:00:57.718 --> 00:01:01.940
writes at 50 MB per second throughput.

00:01:01.940 --> 00:01:05.239
But what needs to be done for
writes is four accesses.

00:01:05.239 --> 00:01:10.830
We need to read the data and the parity,
and then update the data and the parity.

00:01:10.830 --> 00:01:15.200
So we do four accesses for
every write, which means that our

00:01:15.200 --> 00:01:19.860
write throughput is going to be
one fourth of what we can do.

00:01:20.900 --> 00:01:23.135
Just like before, that means that for

00:01:23.135 --> 00:01:27.520
one-fifth of a second we will be
doing what reads need to do, and for

00:01:27.520 --> 00:01:31.970
the four-fifths of a second will we be
doing what writes need to do in order to

00:01:31.970 --> 00:01:34.410
achieve the same number of reads and
writes.

00:01:34.410 --> 00:01:38.845
Because reads take a quarter
of the time that writes do.

00:01:40.240 --> 00:01:42.390
That means that in our
one-fifth of a second,

00:01:42.390 --> 00:01:46.525
we will do ten megabytes of reads,
and then in the remaining

00:01:46.525 --> 00:01:49.840
four-fifths of that second will
do ten megabytes of writes.

00:01:49.840 --> 00:01:52.940
That way we achieve the same
amount of reads and writes, and

00:01:52.940 --> 00:01:57.190
the overall throughput is
20 megabytes per second.

00:01:57.190 --> 00:01:59.840
This is much better than in RAID4.

00:01:59.840 --> 00:02:07.200
Finally, our MTTF here for RAID5 is
exactly the same as it was for RAID4.

00:02:07.200 --> 00:02:10.850
It is the MTTF of one
disk divided by five.

00:02:10.850 --> 00:02:13.950
This is how long we have
until one of the disks fails.

00:02:13.950 --> 00:02:17.550
Times how many times can we
attempt a repair until we

00:02:17.550 --> 00:02:21.900
finally experience a failure of one of
the remaining four disks in this array.

00:02:21.900 --> 00:02:27.100
So this part here is really the expected
lifetime of the four disks,

00:02:27.100 --> 00:02:28.450
left to their own devices.

00:02:28.450 --> 00:02:30.950
And this is the MTTR.

00:02:30.950 --> 00:02:34.070
And what we get is the same
number here as we did for

00:02:34.070 --> 00:02:38.810
Raid4 which is 20,833,333

00:02:38.810 --> 00:02:43.512
hours which is more
than 2,000 years again.

00:02:43.512 --> 00:02:46.325
So Raid5 has the same data capacity and

00:02:46.325 --> 00:02:52.155
the MTTF as RAID 4, but
has significantly better throughput.

00:02:52.155 --> 00:02:55.595
For reads, it has slightly better
throughput because we can use

00:02:55.595 --> 00:02:58.277
all five disks instead of just four.

00:02:58.277 --> 00:03:01.077
For writes it has a lot
better throughput.

00:03:01.077 --> 00:03:04.667
So that means that we never really
want to use a RAID4 array because we can

00:03:04.667 --> 00:03:09.367
move to a RAID5 array without
sacrificing data capacity,

00:03:09.367 --> 00:03:13.727
without sacrificing the MTTF, but
with improving the throughput.

