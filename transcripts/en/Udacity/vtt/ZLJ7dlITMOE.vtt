WEBVTT
Kind: captions
Language: en

00:00:00.380 --> 00:00:04.220
In the reduce phase, there is more work to be done in pulling the data that

00:00:04.220 --> 00:00:07.730
is needed for each one of these reducers.

00:00:07.730 --> 00:00:12.050
Because, we know that the mappers have been executing

00:00:12.050 --> 00:00:14.780
on different nodes of the computational cluster, and

00:00:14.780 --> 00:00:18.008
they produce their intermediate results as files on

00:00:18.008 --> 00:00:21.880
their local disk. And this worker that is

00:00:21.880 --> 00:00:26.350
carrying out a particular split of the reduce operation

00:00:26.350 --> 00:00:33.610
has to reach out and pull the data from all of the m mappers that have

00:00:33.610 --> 00:00:36.690
stored their intermediate results on their respective local

00:00:36.690 --> 00:00:39.070
disks. So there is remote read that is

00:00:39.070 --> 00:00:44.512
involved. As the first thing in the reduce phase is to pull the data. This is

00:00:44.512 --> 00:00:47.088
part of what I mean by the plumbing

00:00:47.088 --> 00:00:51.412
that the runtime system provides is to recognize that,

00:00:51.412 --> 00:00:57.392
for this reduce operation to work, it needs the mapping results from all the m

00:00:57.392 --> 00:01:03.289
nodes that carried out the map function. And so it is going to do RPC in

00:01:03.289 --> 00:01:09.596
order to get all this data from all the local disks of the nodes on

00:01:09.596 --> 00:01:16.340
which the map was executed. And once it has all the data, it can sort it,

00:01:16.340 --> 00:01:20.583
and then call the reduce function. The reduce function is

00:01:20.583 --> 00:01:23.510
the one that has been written by the domain expert.

00:01:23.510 --> 00:01:26.690
And this is the point at which the domain expertise

00:01:26.690 --> 00:01:29.680
comes in, in saying, well, I've got the data now,

00:01:29.680 --> 00:01:31.620
let me do the processing that I want to do

00:01:31.620 --> 00:01:34.810
for the reduce operation. The sorting that is being done

00:01:34.810 --> 00:01:37.980
as part of the programming framework may be to sort

00:01:37.980 --> 00:01:41.410
the input that is coming in from all of these different

00:01:41.410 --> 00:01:48.440
mappers, so that all the same keys are together in the input data set that is

00:01:48.440 --> 00:01:53.480
going to be given to the reduce function. And once such sorting has been done,

00:01:53.480 --> 00:01:56.422
the programming framework will call the user-supplied

00:01:56.422 --> 00:01:59.860
reduce function for each key with the set

00:01:59.860 --> 00:02:02.940
of intermediate values so that the reduce function

00:02:02.940 --> 00:02:06.730
can do its thing, which is domain specific.

00:02:06.730 --> 00:02:11.860
Each reduce function will then write to the final output file

00:02:11.860 --> 00:02:16.340
specific to the partition that it is dealing with. So, if you think about the

00:02:16.340 --> 00:02:21.680
original example that we started with, if, let's say, this guy is

00:02:21.680 --> 00:02:26.930
accumulating all the instances of the name Kishore, then it

00:02:26.930 --> 00:02:32.230
will write the output file that says oh, I've found so many instances of

00:02:32.230 --> 00:02:35.870
the name Kishore in the input corpus of

00:02:35.870 --> 00:02:39.250
data. And similarly, this guy may be doing

00:02:39.250 --> 00:02:41.990
it for another name like Drew, or Arun,

00:02:41.990 --> 00:02:45.644
and so on. And once each worker has completed

00:02:45.644 --> 00:02:49.970
its work by writing its final output file

00:02:49.970 --> 00:02:52.400
for this partition that it is responsible for,

00:02:52.400 --> 00:02:54.860
then it informs the master, that, yes, I'm

00:02:54.860 --> 00:02:56.510
done with the work that was assigned to me.

00:02:57.620 --> 00:03:00.920
The user program can be woken up when all

00:03:00.920 --> 00:03:03.210
the reducers have indicated to the master that they

00:03:03.210 --> 00:03:05.630
have done the work, and at that point the

00:03:05.630 --> 00:03:08.710
map reduce computation that was initiated by the user

00:03:08.710 --> 00:03:11.800
program is complete. We said that there could be

00:03:11.800 --> 00:03:16.285
m splits of the input dataset, meaning the input

00:03:16.285 --> 00:03:20.230
key-value pairs, and there could be R splits of

00:03:20.230 --> 00:03:23.230
the output that has to be generated by the application

00:03:23.230 --> 00:03:26.290
as a whole. Now, the computational resources that

00:03:26.290 --> 00:03:29.460
are available in the data center, N, may

00:03:29.460 --> 00:03:35.954
be less than the sum m plus R. So there may not be a unique machine to

00:03:35.954 --> 00:03:38.900
assign for each one of the m splits

00:03:38.900 --> 00:03:41.590
that have been made. It is the responsibility

00:03:41.590 --> 00:03:44.670
of the master to manage the machines and

00:03:44.670 --> 00:03:48.890
assign the machines that are available to handing the

00:03:48.890 --> 00:03:52.392
m input data sets as well as the R

00:03:52.392 --> 00:03:55.430
reduce splits that need to be generated. So this is

00:03:55.430 --> 00:03:57.580
part of the heavy lifting that has to be

00:03:57.580 --> 00:04:00.540
done by the runtime. So, for instance, let's say that

00:04:00.540 --> 00:04:05.040
I have only 100 worker nodes available as mappers.

00:04:05.040 --> 00:04:08.600
And I have an input split of 1000, then what

00:04:08.600 --> 00:04:11.610
I'm going to do is, I'm going to assign one split to

00:04:11.610 --> 00:04:14.008
this worker. And when the guy says I'm done with

00:04:14.008 --> 00:04:16.392
it, then I'd say, oh, you're done? Okay, take the next

00:04:16.392 --> 00:04:19.002
split and work on it. Take the next split and work on

00:04:19.002 --> 00:04:24.240
it. So that's how we're going to manage the available resources for carrying

00:04:24.240 --> 00:04:27.334
out the work that needs to be done. So remember that this

00:04:27.334 --> 00:04:30.002
is all done as part of the heavy lifting by the runtime,

00:04:30.002 --> 00:04:33.009
the user doesn't have to worry about it. All that the user

00:04:33.009 --> 00:04:36.749
did was write the map function and write the reduce function, and

00:04:36.749 --> 00:04:39.265
the rest of it is magic so far as the map reduce

00:04:39.265 --> 00:04:42.918
framework is concerned. And similarly, the number of

00:04:42.918 --> 00:04:45.408
R splits specified by the user may be

00:04:45.408 --> 00:04:48.147
more than the number of workers that are

00:04:48.147 --> 00:04:51.433
available to carry that out. And in that

00:04:51.433 --> 00:04:54.565
case, again, the master is going to assign a

00:04:54.565 --> 00:04:57.610
particular split to this worker so that he

00:04:57.610 --> 00:05:01.699
can compute and generate the output file corresponding

00:05:01.699 --> 00:05:04.320
to that split. Once he's done with that and

00:05:04.320 --> 00:05:06.999
notifies the master, then the master will say, okay,

00:05:06.999 --> 00:05:09.336
now that you're done with that, work on the next

00:05:09.336 --> 00:05:11.770
split. And it'll do all the work that is

00:05:11.770 --> 00:05:16.136
associated with plumbing, meaning, bringing the data for the split

00:05:16.136 --> 00:05:19.244
that a particular worker is working on right now,

00:05:19.244 --> 00:05:22.944
sorting it to put all the corresponding keys together, and

00:05:22.944 --> 00:05:26.348
then finally calling the reduce function that has been

00:05:26.348 --> 00:05:29.577
written by the user. That's the kind of work that

00:05:29.577 --> 00:05:34.030
goes on under the covers, in the programming framework of map reduce.

