WEBVTT
Kind: captions
Language: en

00:00:00.530 --> 00:00:02.420
Here's another example.

00:00:02.420 --> 00:00:03.640
You have an image and

00:00:03.640 --> 00:00:07.170
you want your network to say
it's an image with a cat in it.

00:00:07.170 --> 00:00:10.480
it doesn't really matter where the cat
is, it's still an image with a cat.

00:00:11.850 --> 00:00:14.990
If your network has to learn about
kittens in the left corner and

00:00:14.990 --> 00:00:16.760
about kittens in the right corner,

00:00:16.760 --> 00:00:20.420
independently, that's a lot
of work that it has to do.

00:00:20.420 --> 00:00:24.700
How about you telling it instead,
explicitly, that objects and images

00:00:24.700 --> 00:00:28.388
are largely the same whether they're on
the left or on the right of the picture.

00:00:28.388 --> 00:00:31.450
That's what's called
translation invariance,.

00:00:31.450 --> 00:00:33.200
Different positions, same kitten.

00:00:34.480 --> 00:00:36.210
Yet another example.

00:00:36.210 --> 00:00:39.770
Imagine you have a long text
that talks about kittens.

00:00:39.770 --> 00:00:42.580
Does the meaning of kitten
change depending on whether

00:00:42.580 --> 00:00:45.730
it's in the first sentence or
in the second one?

00:00:45.730 --> 00:00:47.290
Mostly not.

00:00:47.290 --> 00:00:50.430
So if you're trying to network on text,
maybe you want the part of

00:00:50.430 --> 00:00:54.150
the network that learns what
a kitten is to be reused

00:00:54.150 --> 00:00:58.110
every time you see the word kitten,
and not have to relearn it every time.

00:00:59.620 --> 00:01:02.580
The way you achieve this in your own
networks is using what is called

00:01:02.580 --> 00:01:03.890
weight sharing.

00:01:03.890 --> 00:01:07.820
When you know that two inputs can
contain the same kind of information,

00:01:07.820 --> 00:01:12.650
then you share the weights and train
the weights jointly for those inputs.

00:01:12.650 --> 00:01:14.510
it is a very important idea.

00:01:14.510 --> 00:01:19.260
Statistical invariants, things that
don't change on average across time or

00:01:19.260 --> 00:01:20.830
space, are everywhere.

00:01:21.840 --> 00:01:23.030
For images,

00:01:23.030 --> 00:01:27.080
the idea of weight sharing will get
us to study convolutional networks.

00:01:27.080 --> 00:01:30.690
For text and sequences in general,
it will lead us to embeddings and

00:01:30.690 --> 00:01:31.940
recurrent neural networks.

