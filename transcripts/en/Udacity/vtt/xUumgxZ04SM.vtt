WEBVTT
Kind: captions
Language: en

00:00:00.008 --> 00:00:03.050
Okay so uh,we've taking a fair amount of load off our

00:00:03.050 --> 00:00:06.450
database. Now if we were to go through that whole solution,

00:00:06.450 --> 00:00:09.390
we'd only be doing database right and we'd very rarely be

00:00:09.390 --> 00:00:11.490
doing a database read at all. And this is a big improvement

00:00:11.490 --> 00:00:14.600
over doing a database read on every page view. So let's

00:00:14.600 --> 00:00:16.980
go back to what our request does. And every request remember

00:00:16.980 --> 00:00:21.110
we, we process the request. You know, this was HTTP, URLs

00:00:21.110 --> 00:00:26.110
and all that stuff. We did the DB query, the database query.

00:00:26.110 --> 00:00:29.980
We collated the results, which for you know, ASCII Chan

00:00:29.980 --> 00:00:32.580
or the blog is, there's not really much involved in

00:00:32.580 --> 00:00:35.320
that at all. And then, we rendered the HTML. So,

00:00:35.320 --> 00:00:37.560
we've improved the database query, but what if we want to improve

00:00:37.560 --> 00:00:40.930
these other, other pieces. Yeah, we can use caching to

00:00:40.930 --> 00:00:44.720
render HTML. That's definitely a technique there, and we can actually

00:00:44.720 --> 00:00:47.380
use another technique for handling all three of these parts

00:00:47.380 --> 00:00:51.280
of the requests, which is adding additional app service and this

00:00:51.280 --> 00:00:55.230
looks something like this. To date conceptually we've basically had

00:00:55.230 --> 00:00:58.280
one program running, that handles all of our requests in

00:00:58.280 --> 00:01:00.700
your blog and an ASCII Chan. We've got the simple

00:01:00.700 --> 00:01:04.750
program you know, requests come in. Responses come back out, but

00:01:04.750 --> 00:01:08.320
if so many requests that one machine can't handle it.

00:01:08.320 --> 00:01:10.739
We can do is we can add multiple machines, to take

00:01:10.739 --> 00:01:13.030
up some of the load. So all of these extra

00:01:13.030 --> 00:01:16.960
requests can go to all of these machines, and these machines

00:01:16.960 --> 00:01:21.300
maybe interacting with the database. They may not be. Presumably

00:01:21.300 --> 00:01:24.450
they have their little caches that we just implemented that

00:01:24.450 --> 00:01:26.907
lives in our program and, and this helps so how

00:01:26.907 --> 00:01:30.920
do we get requests to multiple machines. Well, there's a piece

00:01:30.920 --> 00:01:34.570
of technology that sits between the user and all of

00:01:34.570 --> 00:01:37.760
your app servers called a load balancer. And this is

00:01:37.760 --> 00:01:40.230
a special machine, it's a physical machine just like your

00:01:40.230 --> 00:01:42.100
app server might be or just like your database server might

00:01:42.100 --> 00:01:45.280
be, that's optimized for doing one this, for spreading

00:01:45.280 --> 00:01:49.950
requests across multiple machines. So, what happens is, this load

00:01:49.950 --> 00:01:52.620
balancer has a list of all of the app servers

00:01:52.620 --> 00:01:56.360
that, that are in existence, and requests come in from

00:01:56.360 --> 00:01:58.880
the outside world, many, many, many of them. And the

00:01:58.880 --> 00:02:01.500
load balancer decides which app server to send the request

00:02:01.500 --> 00:02:04.420
to. Send one here, then send one here. Then send

00:02:04.420 --> 00:02:07.020
one here. And it can keep going to that process.

00:02:07.020 --> 00:02:09.030
And the reason this load balancer can handle all this

00:02:09.030 --> 00:02:11.360
traffic while the app servers can't, is the low balancer isn't

00:02:11.360 --> 00:02:15.740
doing anything other than taking in the request, choosing a server,

00:02:15.740 --> 00:02:20.080
and forwarding the connection along. It doesn't have to parse HTTP

00:02:20.080 --> 00:02:23.400
or it may only parse, parse minimal HTTP. It doesn't have

00:02:23.400 --> 00:02:25.530
to, it's not doing database queries, it's not rendering HTML, it's

00:02:25.530 --> 00:02:30.190
not, going to the cache it's, it's doing almost nothing at

00:02:30.190 --> 00:02:32.780
all, other than deciding which server to send a request to.

00:02:32.780 --> 00:02:35.850
You've probably won't ever have to write one of these, but it's

00:02:35.850 --> 00:02:38.530
good to know how they work. And when you're using App Engine,

00:02:38.530 --> 00:02:42.580
Google kind of does all of this for you. They'll automatically create new

00:02:42.580 --> 00:02:46.600
servers running your program and and scale. You can actually go into the

00:02:46.600 --> 00:02:50.130
app engine admin page and see how many servers they are using

00:02:50.130 --> 00:02:52.790
to host your app. Which is pretty cool. Normally this is a

00:02:52.790 --> 00:02:55.370
really challenging thing, and not knowing how to do it the first

00:02:55.370 --> 00:02:57.700
time, this took me a little while to figure out when we were

00:02:57.700 --> 00:03:01.020
scaling Reddit. That doesn't mean I'm not going to make you understand these

00:03:01.020 --> 00:03:04.130
things a little bit deeper. So, there are a couple algorithms a

00:03:04.130 --> 00:03:07.800
load balancer can use to determine which server to send traffic to.

00:03:07.800 --> 00:03:11.020
The simplest one is probably just to randomly choose a server. Now,

00:03:11.020 --> 00:03:13.930
a request comes into the load balancer and the load balancer just

00:03:13.930 --> 00:03:17.290
picks a server and sends a request there which will, you know,

00:03:17.290 --> 00:03:20.420
probably work pretty well. You know, over, over time, if you have

00:03:20.420 --> 00:03:22.890
enough requests, each server should get about the same amount of load.

00:03:22.890 --> 00:03:25.890
Other approach is round robin, and round robin just means a load

00:03:25.890 --> 00:03:29.260
balancer will choose one server at the time. You know, first this guy,

00:03:29.260 --> 00:03:32.270
then this guy, then this guy, then this guy, you know, just,

00:03:32.270 --> 00:03:35.740
in order. That's also a fairly simple algorithm. And then some of the

00:03:35.740 --> 00:03:38.690
balances are really smart and they know what the load is on

00:03:38.690 --> 00:03:42.160
each server, how many requests are outstanding at each server, and it may

00:03:42.160 --> 00:03:44.970
use some sort of load based algorithm just so you know. This guy's

00:03:44.970 --> 00:03:48.080
already handling like five requests and this guy's not doing anything so let's

00:03:48.080 --> 00:03:50.780
send, you know, future requests here until, you know, things

00:03:50.780 --> 00:03:53.640
even out. There's lots of approaches to doing this. What

00:03:53.640 --> 00:03:55.230
I'm going to ask you to do now in the form

00:03:55.230 --> 00:03:59.670
of a quiz is implement a basic round robin algorithm.

