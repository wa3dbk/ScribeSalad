WEBVTT
Kind: captions
Language: en

00:00:00.260 --> 00:00:03.840
That ends the introduction
to discriminative methods.

00:00:03.840 --> 00:00:07.145
So we talked about that basically
the idea is that we're going to

00:00:07.145 --> 00:00:10.568
build a representation and then
somehow we have to train a classifier

00:00:10.568 --> 00:00:13.810
that's going to look at
the division of the boundary.

00:00:13.810 --> 00:00:17.120
The simplest method we showed
was nearest neighbor or KNN.

00:00:17.120 --> 00:00:23.315
Oh, I didn't say, would k of set of,
of say, mm, six be a good idea?

00:00:23.315 --> 00:00:23.924
&gt;&gt; No.

00:00:23.924 --> 00:00:24.777
&gt;&gt; No why not?

00:00:24.777 --> 00:00:27.255
because how does it work?

00:00:27.255 --> 00:00:30.700
You'd find nearest k and
you pick whichever one has the most.

00:00:31.990 --> 00:00:35.200
Why are there nine
Supreme Court justices?

00:00:35.200 --> 00:00:39.250
Because you don't want a decision to
come out four-four, if there were eight.

00:00:39.250 --> 00:00:40.750
So k typically is odd, so

00:00:40.750 --> 00:00:44.150
that you get, you always
a majority one way or the other.

00:00:44.150 --> 00:00:45.040
All right.

00:00:45.040 --> 00:00:49.430
In the next two lessons we'll talk about
some much more sophisticated methods,

00:00:49.430 --> 00:00:52.270
and in particular,
their application to Computer Vision.

