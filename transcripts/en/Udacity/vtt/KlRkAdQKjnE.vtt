WEBVTT
Kind: captions
Language: en

00:00:00.008 --> 00:00:03.160
Now, in order to limit the amount of contention

00:00:03.160 --> 00:00:05.590
on the network when a lock is released, we're

00:00:05.590 --> 00:00:07.760
going to do something that we often do in real

00:00:07.760 --> 00:00:12.840
life. procrastination. So basically, the idea is the following.

00:00:14.050 --> 00:00:17.290
Each processor is going to delay asking for the

00:00:17.290 --> 00:00:19.900
lock, even though they observe that the lock is

00:00:19.900 --> 00:00:23.190
released. Then I will immediately go and try to

00:00:23.190 --> 00:00:25.080
get the lock. They're going to wait for a little bit

00:00:25.080 --> 00:00:29.010
of time. It's sort of like what happens at rush

00:00:29.010 --> 00:00:32.479
hour. If you find that the this traffic is too

00:00:32.479 --> 00:00:34.640
much, you might decide that I don't want to get on

00:00:34.640 --> 00:00:37.640
the highway right now. I'm going to delay a little bit

00:00:37.640 --> 00:00:41.330
so that I don't have to spend as much time

00:00:41.330 --> 00:00:43.190
on the highway. So that's sort of the same thing

00:00:43.190 --> 00:00:45.920
that is being proposed here, and this is what is

00:00:45.920 --> 00:00:50.499
called spinlocks with delay. Let's discuss two different delay alternatives.

00:00:51.700 --> 00:00:55.880
In the first one, you're here. You found that you

00:00:55.880 --> 00:00:59.000
did not get the lock and therefore, you're here locally

00:00:59.000 --> 00:01:03.440
spinning in your cache, waiting for the lock to be

00:01:03.440 --> 00:01:06.400
released. Normally what you would have done, when the lock

00:01:06.400 --> 00:01:08.380
is released, is go back out, break out of this

00:01:08.380 --> 00:01:10.710
loop and go back and check if you can get

00:01:10.710 --> 00:01:12.900
the lock again. But what we're going to do is,

00:01:12.900 --> 00:01:16.790
instead of doing that, when we break out of this loop,

00:01:16.790 --> 00:01:19.610
meaning that the lock has been release, I'm

00:01:19.610 --> 00:01:21.960
not going to immediately go and check to see

00:01:21.960 --> 00:01:23.850
if I can get the lock. I'm doing to

00:01:23.850 --> 00:01:26.600
delay myself by a certain amount of time. And

00:01:26.600 --> 00:01:31.810
you notice that the delay is conditioned by what processor id I

00:01:31.810 --> 00:01:36.570
have. So every processor is waiting for a different amount of

00:01:36.570 --> 00:01:42.300
delay in order to contend for the lock. So since the delay

00:01:42.300 --> 00:01:45.650
is being chosen differently for each processor, even though

00:01:45.650 --> 00:01:48.540
all of them notice that the lock has been released

00:01:48.540 --> 00:01:52.230
simultaneously, only one of them will go and check

00:01:52.230 --> 00:01:55.750
it. And so we are sort of sequentializing the order

00:01:55.750 --> 00:01:59.460
in which the processors that are waiting for the

00:01:59.460 --> 00:02:02.120
lock are going to check whether the lock is available.

00:02:02.120 --> 00:02:04.940
So that is one possible scheme for delaying. Now

00:02:04.940 --> 00:02:07.190
the problem with this is it's a static delay, right?

00:02:07.190 --> 00:02:09.258
So every processor has been preassigned a certain

00:02:09.258 --> 00:02:11.580
amount of delay, which means that even if

00:02:11.580 --> 00:02:14.770
the lock is available, I may not immediately

00:02:14.770 --> 00:02:16.890
go and check because my delay may be very

00:02:16.890 --> 00:02:20.530
high compared to some other processor. And that's

00:02:20.530 --> 00:02:24.660
always an issue when you have static decision

00:02:24.660 --> 00:02:27.700
making. What we can do is instead make

00:02:27.700 --> 00:02:31.100
the decision dynamically, and what we're going to do is,

00:02:32.190 --> 00:02:35.510
when we notice that we don't have the lock,

00:02:37.400 --> 00:02:39.250
we're going to delay ourselves by a certain amount of

00:02:39.250 --> 00:02:41.380
time before we try for the lock again. You

00:02:41.380 --> 00:02:44.930
notice that if you're going to delay checking for whether

00:02:44.930 --> 00:02:47.270
I have the lock or not. It's not super

00:02:47.270 --> 00:02:51.360
critical that, that you spin locally or go to

00:02:51.360 --> 00:02:54.700
memory. But in this example, I'm making it very

00:02:54.700 --> 00:02:57.270
simple by saying that if you don't get the

00:02:57.270 --> 00:02:59.700
lock, just delay a little bit before you try for

00:02:59.700 --> 00:03:05.260
this lock again. And the idea here is this delay

00:03:05.260 --> 00:03:08.470
is, is some small number to start with. But suppose

00:03:08.470 --> 00:03:10.800
I go and check and I find it again to

00:03:10.800 --> 00:03:12.630
be locked. Now, what I'm going to do is the

00:03:12.630 --> 00:03:16.380
next time around, I'm going to increase the delay. That's

00:03:16.380 --> 00:03:19.840
why it's called exponential backoff. So I'm increasing the delay,

00:03:19.840 --> 00:03:22.180
doubling the amount of delay that I'm going to do.

00:03:22.180 --> 00:03:24.610
So that the next time, if I don't find

00:03:24.610 --> 00:03:28.620
the lock to be available, I delay by twice

00:03:28.620 --> 00:03:31.530
the amount from the previous time. And this is

00:03:31.530 --> 00:03:36.580
essentially saying that when the lock is not highly contented

00:03:36.580 --> 00:03:40.550
for, I'm not going to delay myself too much. I'm

00:03:40.550 --> 00:03:42.640
going to immediately go and get it. But on

00:03:42.640 --> 00:03:45.450
the other hand, if I go back again and

00:03:45.450 --> 00:03:47.470
again, and every time I go and check, I find

00:03:47.470 --> 00:03:49.740
it is locked, I'm going to increase the amount of

00:03:49.740 --> 00:03:52.890
delay. Because that's saying that lot of people are contending

00:03:52.890 --> 00:03:55.130
for the lock at the same time. And therefore,

00:03:55.130 --> 00:03:58.530
in order to make sure that we are being sensitive

00:03:58.530 --> 00:04:01.460
to the contention that is there for the lock,

00:04:01.460 --> 00:04:04.880
we increase the amount of delay that we're experiencing. Now

00:04:04.880 --> 00:04:07.200
one nice thing about this simple algorithm that I've shown

00:04:07.200 --> 00:04:12.670
you is that I'm not using the caches at all.

00:04:12.670 --> 00:04:14.990
And, if the, if the processor happens to

00:04:14.990 --> 00:04:19.660
be a non-cache coherent multi-processor, this algorithm will

00:04:19.660 --> 00:04:22.690
still work. Because we're always using test and

00:04:22.690 --> 00:04:27.330
set, and not using just loading from the memory.

00:04:27.330 --> 00:04:30.340
Because if it is not a cache-coherent multiprocessor,

00:04:31.530 --> 00:04:33.620
your private cache is now going to be coherent

00:04:33.620 --> 00:04:35.760
with respect to memory. And so you have

00:04:35.760 --> 00:04:37.720
to execute test and set. But you don't want to

00:04:37.720 --> 00:04:42.510
do it all the time. And this delay makes sure that you can reduce the amount

00:04:42.510 --> 00:04:46.880
of contention on the network. Generally speaking. If

00:04:46.880 --> 00:04:49.720
there's a lot of contention, then static assignment

00:04:49.720 --> 00:04:52.500
of delay may be better than the dynamic

00:04:52.500 --> 00:04:57.220
exponential backoff. But in, in general any kind

00:04:57.220 --> 00:05:00.370
of delay, any kind of procrastination, will help

00:05:00.370 --> 00:05:02.960
a lock algorithm better than the naive spin lock

00:05:02.960 --> 00:05:03.740
that we talked about.

