WEBVTT
Kind: captions
Language: en

00:00:00.520 --> 00:00:03.960
With that out of the way,
let's go back to training models.

00:00:03.960 --> 00:00:07.010
Training logistic regression
using gradient descent is great.

00:00:07.010 --> 00:00:07.640
For one thing,

00:00:07.640 --> 00:00:10.900
you're directly optimizing the error
measure that you care about.

00:00:10.900 --> 00:00:12.060
That's always a great idea.

00:00:12.060 --> 00:00:15.920
And that's why in practice,
a lot of machine learning research

00:00:15.920 --> 00:00:18.239
is about designing the right
last function to optimize.

00:00:19.480 --> 00:00:22.580
But as you might experienced if you've
run the model in the assignments,

00:00:22.580 --> 00:00:23.840
it's got problems.

00:00:23.840 --> 00:00:26.430
The biggest one is that it's
very difficult to scale.

