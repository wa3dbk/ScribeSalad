WEBVTT
Kind: captions
Language: en

00:00:00.590 --> 00:00:05.360
So let's introduce some basic terminologies. In GSM, when

00:00:05.360 --> 00:00:09.190
we talk about cache, what we mean is physical memory.

00:00:09.190 --> 00:00:12.130
We're not talking about the processor caches. We're talking

00:00:12.130 --> 00:00:15.670
about physical memory that is the dynamic random access memory

00:00:15.670 --> 00:00:18.250
or DRAM for short. Which is the physical memory.

00:00:18.250 --> 00:00:21.180
That's what we mean when we use the term cache.

00:00:21.180 --> 00:00:23.690
And there is a sense of community to handle page

00:00:23.690 --> 00:00:25.960
faults of a particular node. So we'll get to that.

00:00:25.960 --> 00:00:28.530
In a minute. And I mentioned that we are

00:00:28.530 --> 00:00:30.960
going to use peer memories as a supplement for the

00:00:30.960 --> 00:00:33.980
disc. In other words, we can imagine that the

00:00:33.980 --> 00:00:37.180
physical memory at every node to be split into two

00:00:37.180 --> 00:00:40.580
parts. One part is what we'll call local and

00:00:40.580 --> 00:00:45.330
local contains the working set of the currently executing processes

00:00:45.330 --> 00:00:47.330
at this node. So this is the stuff that

00:00:47.330 --> 00:00:51.000
this node needs in order to keep all the processes

00:00:51.000 --> 00:00:54.430
running on this node happy. Now, the global is

00:00:54.430 --> 00:00:57.260
similar to a disk. This global part is where

00:00:57.260 --> 00:01:00.600
community service comes in, that is, I'm saying that

00:01:00.600 --> 00:01:02.980
out of my total physical memory, this is the

00:01:02.980 --> 00:01:05.190
part that I need to keep all the processes

00:01:05.190 --> 00:01:07.860
happy in my node, and this is the part

00:01:07.860 --> 00:01:11.990
that I'm willing to use a space for holding

00:01:11.990 --> 00:01:16.700
pages that are swapped out from my fellow citizens

00:01:16.700 --> 00:01:20.190
on the local data network. And this split of local

00:01:20.190 --> 00:01:23.340
and global is dynamic in response to memory pressure. As

00:01:23.340 --> 00:01:26.160
I mentioned earlier, the memory pressure is not something that

00:01:26.160 --> 00:01:29.740
stays constant, right? So over time, depending on what's going

00:01:29.740 --> 00:01:33.140
on in a particular node, you may have more need

00:01:33.140 --> 00:01:35.880
for holding the working set of all your processes. In

00:01:35.880 --> 00:01:38.950
which case the local part may keep increasing. On the

00:01:38.950 --> 00:01:41.880
other hand, if I go off for lunch, my workstation

00:01:41.880 --> 00:01:47.150
is not in use. And in that case, my local part is going to shrink, and I can

00:01:47.150 --> 00:01:51.380
house more of my peers swapped out pages in

00:01:51.380 --> 00:01:55.430
my global part of the physical memory. So, the

00:01:55.430 --> 00:01:57.140
global part is a spare memory that I'm

00:01:57.140 --> 00:02:00.540
making available for my peers And local part is

00:02:00.540 --> 00:02:03.470
the part that I need for holding the working

00:02:03.470 --> 00:02:06.850
set of the currently active process at my node,

00:02:06.850 --> 00:02:09.538
and this boundary keeps shifting depending on what's going

00:02:09.538 --> 00:02:13.040
on at my node. Pretty simple, normally if all

00:02:13.040 --> 00:02:17.390
the processes executing in the entire local area network

00:02:17.390 --> 00:02:20.520
are independent of one another, all the pages are private.

00:02:20.520 --> 00:02:22.920
You know, I'm running a process, my process, my

00:02:22.920 --> 00:02:26.120
pages, and the contents of that pages are private

00:02:26.120 --> 00:02:28.710
to my process. On the other hand, you could

00:02:28.710 --> 00:02:31.910
also be using the cluster for running an application that

00:02:31.910 --> 00:02:34.150
spans multiple nodes of the cluster, in which

00:02:34.150 --> 00:02:36.440
case it is possible that a particular page is

00:02:36.440 --> 00:02:39.730
shared, and in that case, that page will be

00:02:39.730 --> 00:02:43.730
in the local part of multiple peers, because multiple

00:02:43.730 --> 00:02:46.810
peers are actively using a page. So, we

00:02:46.810 --> 00:02:49.930
have two states for a particular page. It could

00:02:49.930 --> 00:02:53.100
be private, or it could be shared. If a

00:02:53.100 --> 00:02:57.220
page is in the global part of my physical

00:02:57.220 --> 00:03:00.410
memory, then it is guaranteed to be private. Because the

00:03:00.410 --> 00:03:03.710
global part is nothing different from a disk. So when I

00:03:03.710 --> 00:03:06.260
swap out something, I throw it onto the disk. Similarly,

00:03:06.260 --> 00:03:08.390
when I swap out something in GMS, I throw it into

00:03:08.390 --> 00:03:12.760
my. Peer memory is the global cache, and therefore what

00:03:12.760 --> 00:03:14.960
is in the global cache is always going to be private

00:03:14.960 --> 00:03:18.020
copies of pages, whereas what is in the local part can

00:03:18.020 --> 00:03:22.420
be private or can be shared, depending on whether that particular

00:03:22.420 --> 00:03:24.970
page is being actively shared by more than

00:03:24.970 --> 00:03:28.300
one node at a time. Now one important point,

00:03:28.300 --> 00:03:32.170
the whole idea of GSM is to serve as

00:03:32.170 --> 00:03:35.280
a paging facility. In other words, if you think

00:03:35.280 --> 00:03:38.380
about even a uni processor, if it had multiple

00:03:38.380 --> 00:03:42.010
processes, sharing a page, the virtual memory manager has

00:03:42.010 --> 00:03:44.710
no concern about the coherence about the pages that

00:03:44.710 --> 00:03:48.110
are being shared by multiple processes, that's the same

00:03:48.110 --> 00:03:50.950
Semantic that is used in GSM also, and

00:03:50.950 --> 00:03:54.810
that is coherence. For shared pages, it's outside

00:03:54.810 --> 00:03:57.030
GSM, it's an application problem. If there are

00:03:57.030 --> 00:04:00.060
multiple copies of the pages residing in the local

00:04:00.060 --> 00:04:03.710
parts of multiple peers, maintaining the coherence is

00:04:03.710 --> 00:04:07.080
the concern. of the application. That is not, that

00:04:07.080 --> 00:04:09.580
is not GSM's problem. Only thing that the

00:04:09.580 --> 00:04:13.810
GSM is providing is a service for remote at.

00:04:13.810 --> 00:04:16.410
That's important distinction that one has to keep

00:04:16.410 --> 00:04:19.779
in mind. In any workshop memory management system, what

00:04:19.779 --> 00:04:25.740
you do is when you have to throw out a physical page. When you have to throw out

00:04:25.740 --> 00:04:28.740
a page from physical memory. You use an

00:04:28.740 --> 00:04:32.230
algorithm, a page replacement algorithm and the page replacement

00:04:32.230 --> 00:04:36.190
algorithm that is typically employed in computer systems is

00:04:36.190 --> 00:04:39.300
some variant of an LRU or a least recently

00:04:39.300 --> 00:04:42.310
used algorithm. GSM also does exactly the

00:04:42.310 --> 00:04:46.060
same thing, except it integrates cluster memory management

00:04:46.060 --> 00:04:48.510
of the lowest level across the entire

00:04:48.510 --> 00:04:52.620
cluster. So the goal in picking a replacement

00:04:52.620 --> 00:04:55.760
candidate in GSM is to pick the

00:04:55.760 --> 00:04:59.660
globally oldest place for replacement. If, let's say

00:04:59.660 --> 00:05:04.360
that the memory pressure in the, system is such that I have to throw out some

00:05:04.360 --> 00:05:06.780
page from the cluster memory onto the

00:05:06.780 --> 00:05:10.050
disk. The candidate page that I'll choose is

00:05:10.050 --> 00:05:16.850
the one that is oldest in the entire cluster. So managing age information is one

00:05:16.850 --> 00:05:20.640
of the key technical contributions of GSM,

00:05:20.640 --> 00:05:23.680
how to manage the age information so that

00:05:23.680 --> 00:05:27.610
we pick. A globally oldest page for replacement

00:05:27.610 --> 00:05:30.020
in the community service for handling page faults.

