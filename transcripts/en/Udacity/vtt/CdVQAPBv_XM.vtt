WEBVTT
Kind: captions
Language: en

00:00:00.360 --> 00:00:05.153
So we mentioned, a number of complete
technologies that are used in cloud

00:00:05.153 --> 00:00:09.794
computing and also we mentioned
a number of types of functionality that

00:00:09.794 --> 00:00:12.914
cloud computing technology
needs to provide.

00:00:12.914 --> 00:00:16.939
Again, let me offer a birds eye
view of two popular stack for

00:00:16.939 --> 00:00:21.085
big data that are used in
cloud computing platforms.

00:00:21.085 --> 00:00:25.490
The two concrete stacks I want to show
you is the Hadoop Big Data Stack,

00:00:25.490 --> 00:00:30.732
it's an open source stack and then also
the Berkeley Data Analytics Stack, BDAS.

00:00:30.732 --> 00:00:32.900
This is another open source stack.

00:00:32.900 --> 00:00:34.921
These are by the way,
not the only options.

00:00:34.921 --> 00:00:37.926
There are number of both
propriety stacks and

00:00:37.926 --> 00:00:41.480
also a number of other
open source stacks.

00:00:41.480 --> 00:00:47.570
For instance, one example is
the so-called HPCC stack by LexisNexis.

00:00:47.570 --> 00:00:51.040
This actually, even predates Hadoop.

00:00:51.040 --> 00:00:54.368
However, it wasn't
necessarily popular or

00:00:54.368 --> 00:00:58.318
widely used outside of
the LexisNexis environment.

00:00:58.318 --> 00:01:01.580
When it comes to the overall
popularity and adoption rate,

00:01:01.580 --> 00:01:05.168
both in commercial and
academic settings or research settings,

00:01:05.168 --> 00:01:08.510
these two are probably the dominant
stacks out there today.

00:01:10.370 --> 00:01:13.120
The Hadoop architecture looks like this.

00:01:13.120 --> 00:01:16.650
At the bottom layer,
there is the data storage layer,

00:01:16.650 --> 00:01:21.370
the Hadoop file system and this takes
care of taking large amounts of data and

00:01:21.370 --> 00:01:25.680
somehow, splitting them and replicating
and making sure the data doesn't get

00:01:25.680 --> 00:01:29.330
lost and making sure that there
are no hot spots in the system, etc.

00:01:29.330 --> 00:01:33.820
Then there is a processing framework
that can allow computation to

00:01:33.820 --> 00:01:38.630
operate on such data and deals with
the scheduling of what are the specific

00:01:38.630 --> 00:01:43.530
notes that particular data manipulation
operations need to be scheduled.

00:01:43.530 --> 00:01:46.853
Ideally, the scheduling
should be done in such a way,

00:01:46.853 --> 00:01:51.260
so that you don't have to constantly
move data from one note to another,

00:01:51.260 --> 00:01:54.599
depending on what is the task
that needs to process it.

00:01:54.599 --> 00:01:59.180
We're really not going to talk in more
detail about the Map Reduce framework.

00:01:59.180 --> 00:02:02.965
The intent of these is just as
an illustration to provide you with

00:02:02.965 --> 00:02:06.412
an overview of the breadth of
technologies in this space.

00:02:06.412 --> 00:02:11.459
There's a component Hbase and
this provides a table like view

00:02:11.459 --> 00:02:16.895
of the stored data that is more
similar to with what we're familiar

00:02:16.895 --> 00:02:22.621
with in the context of databases, but
it is not the same as the relation

00:02:22.621 --> 00:02:28.861
of database representation of the data
as were used in the SQL environment.

00:02:28.861 --> 00:02:31.586
In order to support data processing and

00:02:31.586 --> 00:02:35.550
data query operations like
what SQL databases support,

00:02:35.550 --> 00:02:40.009
there's a language front end hive
that will take an SQL query and

00:02:40.009 --> 00:02:45.060
then translate it into a number
of these Map Reduce operations.

00:02:45.060 --> 00:02:49.880
That will then operate on top of
the data that's stored in this Hbase

00:02:49.880 --> 00:02:53.080
tables on top of
the distributed file system.

00:02:53.080 --> 00:02:57.666
Order number of higher levels services
that would also provide the same kind of

00:02:57.666 --> 00:02:58.230
things.

00:02:58.230 --> 00:03:03.070
So end users can use the R environment
in order to describe certain

00:03:03.070 --> 00:03:07.206
rules about how data should
be processed and analyzed or

00:03:07.206 --> 00:03:12.574
we can use machine learning algorithms,
one of a collection of many that

00:03:12.574 --> 00:03:18.570
are supported in the Mahout component
that's part of the Hadoop stack.

00:03:18.570 --> 00:03:22.940
And a number of other technologies
that provide more specialized

00:03:22.940 --> 00:03:27.750
type soft functionality or different
kinds of interfaces to the end users.

00:03:27.750 --> 00:03:29.360
At the lowest level, however,

00:03:29.360 --> 00:03:33.850
all of these end up being a number of
these more primitive operations that can

00:03:33.850 --> 00:03:38.110
execute on top of the distributed
file system where the data is stored.

00:03:38.110 --> 00:03:41.750
And there are a number of supporting
services that are needed in order to

00:03:41.750 --> 00:03:47.710
deal with locker or coordination or
to provide the streaming of data into

00:03:47.710 --> 00:03:53.550
this distributed environment and this
is what the Berkeley BDAS looks like.

00:03:53.550 --> 00:03:58.100
There's similarly a component
that's the data storage layer and

00:03:58.100 --> 00:04:03.210
then there is a in memory component
that is the in memory file system,

00:04:03.210 --> 00:04:06.240
so that you can avoid the caches.

00:04:06.240 --> 00:04:11.137
You can run the regular Hadoop Map
Reduce engines on top of this layer or

00:04:11.137 --> 00:04:14.458
you can run another type
of programming model,

00:04:14.458 --> 00:04:17.712
another processing
framework called Spark.

00:04:17.712 --> 00:04:22.510
There are a number of front-ends for
the Spark in terms of the kinds of

00:04:22.510 --> 00:04:27.809
execution models that are supported,
so whether it's in SQLite queries or

00:04:27.809 --> 00:04:32.528
stream processing or graph processing or
machine learning types of

00:04:32.528 --> 00:04:38.150
operations that should be executed
on top of this processing framework.

00:04:38.150 --> 00:04:43.006
Another component that's important
to mention is this Mesos component

00:04:43.006 --> 00:04:47.465
that's the lowest level scheduling
framework, the lowest level

00:04:47.465 --> 00:04:51.844
resource manager that allows
the resources to be partitioned and

00:04:51.844 --> 00:04:54.884
then used by different
types of frameworks.

00:04:54.884 --> 00:04:57.570
You may have a partition
that's a Hadoop partition.

00:04:57.570 --> 00:04:59.673
A partition that's a Spark partition.

00:04:59.673 --> 00:05:02.200
A partition that's an MPI partition.

00:05:02.200 --> 00:05:03.650
And using this stack,

00:05:03.650 --> 00:05:08.280
the two will be able to basically
coordinate and negotiate among them and

00:05:08.280 --> 00:05:12.415
then you'll have elasticity across these
very different types of framework.

