WEBVTT
Kind: captions
Language: en

00:00:00.230 --> 00:00:04.154
And now let's look at the second
possible write-update optimization,

00:00:04.154 --> 00:00:06.755
which is about reusing
the number of bus writes.

00:00:06.755 --> 00:00:09.147
So after we added our dirty bit,

00:00:09.147 --> 00:00:13.765
what we got is that the memory
now gets relatively few writes.

00:00:13.765 --> 00:00:17.272
Only those writes that
are coming from replacements and

00:00:17.272 --> 00:00:21.227
also the memory no longer needs
to respond to all the reads, but

00:00:21.227 --> 00:00:24.899
the bus still gets all of
the traffic for all of the writes.

00:00:24.899 --> 00:00:28.985
Every single write will need to go
on the bus and broadcast the value.

00:00:28.985 --> 00:00:33.709
So now the bus, which sees all of
the writes will become the bottleneck in

00:00:33.709 --> 00:00:38.280
the system, because every single
write from every single core ends up

00:00:38.280 --> 00:00:41.475
going to the bus and
the bus can only take so much.

00:00:41.475 --> 00:00:46.920
The bus broadcasts for writes that
are needed to update other copies of

00:00:46.920 --> 00:00:52.469
the data, need to happen,
because this is a write-update protocol.

00:00:52.469 --> 00:00:57.340
It needs to update other copies of
the data, but the optimization we

00:00:57.340 --> 00:01:02.480
can do is about the writes that
do not need to update anybody.

00:01:02.480 --> 00:01:07.830
So we will add another bit called the
shared bit to each block in each cache

00:01:07.830 --> 00:01:13.410
and that bit will tell us, whether
the block is shared with others or not.

00:01:13.410 --> 00:01:14.542
Let's see how things would work.

00:01:14.542 --> 00:01:17.073
Suppose we read A here.

00:01:17.073 --> 00:01:20.708
We get this valid not dirty,
but for the shared bit,

00:01:20.708 --> 00:01:24.768
we need to know whether others
also have this block or not.

00:01:24.768 --> 00:01:29.226
For this purpose,
we add a line to the bus.

00:01:29.226 --> 00:01:34.606
When our read goes to memory,
other's snoop this read and if they have

00:01:34.606 --> 00:01:39.723
the same block in the cache,
then they pull the shared line to one.

00:01:39.723 --> 00:01:45.070
If nobody pulls the shared line to one,
then it will remain at zero.

00:01:45.070 --> 00:01:49.735
So for this particular block,
because this is the first read,

00:01:49.735 --> 00:01:55.030
nobody pulls the shared line to one,
so the block we know is not shared.

00:01:55.030 --> 00:01:58.583
This is the tag and
let's say, we're at six.

00:01:58.583 --> 00:02:02.387
Now let's see what happens when
this processor writes to A, and

00:02:02.387 --> 00:02:05.050
let's say puts a value of 17 there.

00:02:05.050 --> 00:02:08.133
It's a miss, we wrote us both
the write and the value.

00:02:08.133 --> 00:02:12.598
The first time and
we see now that somebody is writing and

00:02:12.598 --> 00:02:17.164
this cache here, snoops that write and
does two things.

00:02:17.164 --> 00:02:19.505
One, it now knows that
the block is shared,

00:02:19.505 --> 00:02:21.349
because somebody is accessing it now.

00:02:21.349 --> 00:02:23.544
Second, it updates the value.

00:02:23.544 --> 00:02:29.860
Third, it pulls this line to 1, so that
this cache knows the block is shared and

00:02:29.860 --> 00:02:34.503
now it has the block in the dirty
state with a value of 17.

00:02:34.503 --> 00:02:39.907
So far, this has behaved exactly as
it should without the shared line and

00:02:39.907 --> 00:02:41.777
without the shared bit.

00:02:41.777 --> 00:02:43.983
So what's the benefit
of the shared bits?

00:02:43.983 --> 00:02:47.044
Well, the benefit is
that now this cache,

00:02:47.044 --> 00:02:51.464
if it wants to write again,
it sees that the shared bit is one,

00:02:51.464 --> 00:02:56.410
which means that it does need
to broadcast same as before.

00:02:56.410 --> 00:03:01.391
So the broadcast will happen exactly
as before, if there is another sharer,

00:03:01.391 --> 00:03:05.695
because we need to update that sharer
to the new value for the data.

00:03:05.695 --> 00:03:11.311
The benefit of the shared bit
is in that, if this block reads,

00:03:11.311 --> 00:03:18.340
let's say, B and gets a value of two
here and it's valid and it's not dirty.

00:03:18.340 --> 00:03:23.634
And it sees that so far nobody has B,
so sharing is zero here.

00:03:23.634 --> 00:03:29.381
And then once you write five to B,
it checks the shared bit here.

00:03:29.381 --> 00:03:36.514
And because we know that nobody else has
this block, we can write the value here.

00:03:36.514 --> 00:03:41.033
Make the thing dirty, because
the memory's no longer up to date, but

00:03:41.033 --> 00:03:43.491
because the shared bit stays at zero.

00:03:43.491 --> 00:03:46.000
Meaning, we are the only one who has it.

00:03:46.000 --> 00:03:48.391
We don't do a bus right here.

00:03:48.391 --> 00:03:51.553
So as long as some block is
being accessed only by one core,

00:03:51.553 --> 00:03:54.339
it's no longer going to
broadcast all of the writes.

00:03:54.339 --> 00:03:59.415
Meanwhile, this core could be
having in a non-shared state,

00:03:59.415 --> 00:04:04.510
for example, block C and
it can write anything it wants there.

00:04:04.510 --> 00:04:08.667
Can write 17, then 65, etc.

00:04:08.667 --> 00:04:14.374
So B and C, because they belong
to only one core at this time

00:04:14.374 --> 00:04:20.100
will not do bus writes,
while A will do bus writes.

00:04:20.100 --> 00:04:23.780
So we still get the write optic
behavior when there is sharing, but

00:04:23.780 --> 00:04:27.310
now we avoid writes going to
the bus when there is no sharing.

00:04:28.720 --> 00:04:30.580
This can happen a lot, for example,

00:04:30.580 --> 00:04:34.170
B could be something that belongs
to the stack of core zero.

00:04:34.170 --> 00:04:36.476
C could be something that is
on the stack of core one.

00:04:36.476 --> 00:04:40.476
So naturally, we will be just pushing
and popping things to our own stack and

00:04:40.476 --> 00:04:43.867
never really needing to broadcast
the updates somewhere else.

00:04:43.867 --> 00:04:46.080
But for data that is actually shared,

00:04:46.080 --> 00:04:49.758
we still get exactly the same
write update behavior as before.

00:04:49.758 --> 00:04:54.600
So this optimization will save
us a lot of writes on the bus.

00:04:54.600 --> 00:04:59.170
It will save us all the writes that
are not necessary to maintain coherence

00:04:59.170 --> 00:05:03.015
among multiple copies of the same
block in different caches.

