WEBVTT
Kind: captions
Language: en

00:00:00.330 --> 00:00:03.330
As a giant scale service provider, another

00:00:03.330 --> 00:00:06.120
thing that the service provider has to

00:00:06.120 --> 00:00:09.670
worry about is online evolution and growth

00:00:09.670 --> 00:00:14.200
of the service. because services are evolving continuously.

00:00:14.200 --> 00:00:19.110
The Gmail that you're accessing for getting your email today may not be the same

00:00:19.110 --> 00:00:22.050
that you accessed a month back. So,

00:00:22.050 --> 00:00:26.250
since the services are continuously evolving, the servers

00:00:26.250 --> 00:00:29.300
at the data centers have to be upgraded with

00:00:29.300 --> 00:00:33.080
a new version of the software or maybe new nodes

00:00:33.080 --> 00:00:35.510
are being added, or maybe all the old nodes

00:00:35.510 --> 00:00:38.540
are being retired, and brand-new nodes are being brought in

00:00:38.540 --> 00:00:42.270
to serve the user community. Whether it is hardware

00:00:42.270 --> 00:00:45.130
or software upgrade that needs to be done, that has

00:00:45.130 --> 00:00:48.960
to be done with the understanding that while that upgrade

00:00:48.960 --> 00:00:52.130
is happening, there is going to be loss of service.

00:00:52.130 --> 00:00:58.830
Again the DQ principal comes in handy in measuring what exactly is the loss

00:00:58.830 --> 00:01:04.690
that we're observing of the service when we do this kind of online evolution and

00:01:04.690 --> 00:01:11.460
growth. The first choice, is what is called fast reboot. That is, bring down all

00:01:11.460 --> 00:01:17.710
the servers at once, upgrade them, and then turn them back on. So this diagram

00:01:17.710 --> 00:01:23.598
is showing you, time on the x axis, and the loss, DQ loss, on the y axis,

00:01:23.598 --> 00:01:26.160
and what you're seeing here, this is the

00:01:26.160 --> 00:01:30.350
time for the upgrade per node. So the amount

00:01:30.350 --> 00:01:35.070
of time a node is going to be down in order to do that upgrade, whether it is

00:01:35.070 --> 00:01:38.310
a software upgrade or a hardware upgrade. And this

00:01:38.310 --> 00:01:42.940
y axis segment is the DQ loss per node.

00:01:42.940 --> 00:01:44.680
So if I bring down a node and upgrade

00:01:44.680 --> 00:01:47.460
it, it's going to be down for some amount of time.

00:01:47.460 --> 00:01:50.550
And this is the amount of server capacity that is

00:01:50.550 --> 00:01:53.410
lost, the DQ that is lost, as a result of

00:01:53.410 --> 00:01:55.910
one server being down. If all the servers are

00:01:55.910 --> 00:01:59.090
down, which is what is happening with fast reboot, then

00:01:59.090 --> 00:02:03.674
for this entire time, the area bounded by this green-shaded

00:02:03.674 --> 00:02:08.160
rectangle, we're going to have no service. The ideal is here

00:02:08.160 --> 00:02:15.350
in terms of the total amount of DQ we want, and the access is saying how much is

00:02:15.350 --> 00:02:21.320
the DQ that is lost and what we are saying is, if we do this fast reboot, that

00:02:21.320 --> 00:02:24.580
fast reboot is going to bring all the servers down

00:02:24.580 --> 00:02:26.560
for a certain amount of time that it takes

00:02:26.560 --> 00:02:29.520
to upgrade them, and for the entire duration, the

00:02:29.520 --> 00:02:33.230
service is unavailable. This idea of fast reboot is

00:02:33.230 --> 00:02:37.320
particularly useful in situations where we can use

00:02:37.320 --> 00:02:41.010
diurnal server property. For instance, if you think

00:02:41.010 --> 00:02:43.970
about services that are being all across the

00:02:43.970 --> 00:02:47.350
globe. We can use factors such as oh, this

00:02:47.350 --> 00:02:50.800
is nighttime for the user community and the

00:02:50.800 --> 00:02:54.110
users have probably gone night-night and therefore, they are

00:02:54.110 --> 00:02:56.040
not going to access the servers. This is a

00:02:56.040 --> 00:02:58.820
good time to bring down the whole service and

00:02:58.820 --> 00:03:03.990
upgrade the service. So that might be a situation where fast reboot is very

00:03:03.990 --> 00:03:10.400
useful. So we are assuming that the user community is segmented so that they're

00:03:10.400 --> 00:03:14.220
directed to geographically different locations, and we

00:03:14.220 --> 00:03:17.168
can use the diurnal server property to

00:03:17.168 --> 00:03:24.140
do this off-peak fast reboot of chosen replicas of the services. In this figure,

00:03:24.140 --> 00:03:26.813
so in this figure this segment that I'm

00:03:26.813 --> 00:03:29.920
showing you here is the DQ loss per node.

00:03:29.920 --> 00:03:32.600
And the total DQ losses, of course, n times

00:03:32.600 --> 00:03:35.930
DQ, where n is a number of servers that

00:03:35.930 --> 00:03:38.410
are undergoing this fast reboot. So in other

00:03:38.410 --> 00:03:42.200
words, for u units of time, there is complete

00:03:42.200 --> 00:03:46.180
loss of DQ with fast reboot. An alternative to

00:03:46.180 --> 00:03:50.210
fast reboot is what is called a rolling upgrade.

00:03:50.210 --> 00:03:52.710
Now here, what we're doing is, rather than bring

00:03:52.710 --> 00:03:55.340
all the servers down at the same time, we

00:03:55.340 --> 00:03:58.240
are bringing one server down at a time. And

00:03:58.240 --> 00:04:01.530
upgrading one server, bringing down the next server, upgrading

00:04:01.530 --> 00:04:04.024
it, and so on. This is what is called

00:04:04.024 --> 00:04:07.970
rolling upgrade or wave upgrade. And in this case,

00:04:07.970 --> 00:04:12.440
services available all throughout, there is no time that

00:04:12.440 --> 00:04:15.680
we are saying that the service is completely unavailable.

00:04:15.680 --> 00:04:22.010
But, for the entire duration of time, the duration of time here is n times

00:04:22.010 --> 00:04:28.550
u, because u is the upgrade time per node, and the upgrade, because it is a wave

00:04:28.550 --> 00:04:33.620
upgrade, is going to last for n times u time units, where n is a number of

00:04:33.620 --> 00:04:37.480
servers being upgraded in this fashion. But during

00:04:37.480 --> 00:04:41.020
the entire time, service is available, but in

00:04:41.020 --> 00:04:43.590
every u units of time, there's a DQ loss of

00:04:43.590 --> 00:04:48.460
this much bounded by this area during the entire upgrade process.

