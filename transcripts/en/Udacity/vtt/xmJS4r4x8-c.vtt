WEBVTT
Kind: captions
Language: en

00:00:00.210 --> 00:00:02.950
Another heavy-duty topic which is good to know about

00:00:02.950 --> 00:00:05.670
is edge caching. To describe this, let's look at

00:00:05.670 --> 00:00:09.150
the information flow for your App Engine application. First

00:00:09.150 --> 00:00:11.760
of all, users that want to use your application are

00:00:11.760 --> 00:00:15.670
connected to their internet service provider. This provider connects

00:00:15.670 --> 00:00:18.576
to Google data center. After the DNS lookup has

00:00:18.576 --> 00:00:22.036
determined that your application is hosted by Google, Google

00:00:22.036 --> 00:00:25.693
then identifies the data center where your App Engine application

00:00:25.693 --> 00:00:28.304
run, and starts talking to the App Engine front

00:00:28.304 --> 00:00:30.939
end. If the content is dynamic, the App Engine front

00:00:30.939 --> 00:00:34.350
end determines the instance that should manage the request.

00:00:34.350 --> 00:00:37.560
So these are your App Engine instances that run your

00:00:37.560 --> 00:00:40.890
application code. But if the request is for static

00:00:40.890 --> 00:00:44.880
content, for example images or static HTML, the front end

00:00:44.880 --> 00:00:48.370
can retrieve it directly from the static servers. And in

00:00:48.370 --> 00:00:51.960
both cases, the response is returned back to the user.

00:00:51.960 --> 00:00:54.350
So this is a good architecture. But as it looks

00:00:54.350 --> 00:00:57.000
right now, all the requests have to be sent to

00:00:57.000 --> 00:01:00.230
the data center, which hosts your App Engine application. It

00:01:00.230 --> 00:01:02.850
would be much better if more content could be served

00:01:02.850 --> 00:01:06.160
directly by this data center. First of all, it would

00:01:06.160 --> 00:01:09.640
ease the load on this data center, but more importantly,

00:01:09.640 --> 00:01:12.340
since it's closer to the users, the response would be

00:01:12.340 --> 00:01:16.150
delivered faster. This is exactly what edge caching is all about.

00:01:17.210 --> 00:01:19.620
Edge caching is a cache that sits in the

00:01:19.620 --> 00:01:22.840
data center closest to the user. So whenever there is

00:01:22.840 --> 00:01:25.290
a request, the result can be served directly from

00:01:25.290 --> 00:01:27.990
the cache if it's available there, rather than going through

00:01:27.990 --> 00:01:31.220
data center 2. That means less load on data

00:01:31.220 --> 00:01:34.700
center 2 in your application, and faster responses to your

00:01:34.700 --> 00:01:38.650
users. A win-win. So the question is, then, what

00:01:38.650 --> 00:01:41.070
do you need to think about to use edge caching?

00:01:42.230 --> 00:01:45.100
Well, there are two ways. The first one is

00:01:45.100 --> 00:01:49.070
to set the cache-control header, in the HTTP response. This

00:01:49.070 --> 00:01:51.490
should only be done if a subsequent request of this

00:01:51.490 --> 00:01:54.730
kind would return the same result. The second option is

00:01:54.730 --> 00:01:58.010
to define as much content as possible as static.

00:01:58.010 --> 00:02:00.900
Since static content does not change, it's great for edge

00:02:00.900 --> 00:02:04.892
caching. You can define which content is static through configuration

00:02:04.892 --> 00:02:07.356
files. A good opportunity for you to look at the

00:02:07.356 --> 00:02:11.190
online documentation. And remember, as most of the time

00:02:11.190 --> 00:02:14.180
with caching, there are no guarantees that the content will

00:02:14.180 --> 00:02:16.340
be cached, but when it is, it will be

00:02:16.340 --> 00:02:19.300
good for both your application as well as your users.

