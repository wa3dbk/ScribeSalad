WEBVTT
Kind: captions
Language: en

00:00:00.275 --> 00:00:03.350
Let's look at a single cache
that is 16 kilobytes in size.

00:00:04.570 --> 00:00:09.575
Let's look also at a single cache
that is 128 kilobytes in size.

00:00:09.575 --> 00:00:14.403
Let's look at no cache, simply we
will just access the main memory, and

00:00:14.403 --> 00:00:19.232
let's look at the hierarchy that has
this kind of cache as the first level

00:00:19.232 --> 00:00:23.061
cache, and this kind of cache
as the second level cache.

00:00:23.061 --> 00:00:27.338
We will look at the the hit time for
this, the hit rate for

00:00:27.338 --> 00:00:30.932
all of this, and the overall AMAT.

00:00:30.932 --> 00:00:35.160
So a 16 kilobyte cache might
have a hit time of 2 cycles,

00:00:36.190 --> 00:00:42.580
a hit rate of 90%, so
it gives us an overall AMAT

00:00:42.580 --> 00:00:47.880
of 2 plus 10% of the time
we have the memory latency.

00:00:47.880 --> 00:00:51.010
Let's say the memory
latency is 100 cycles.

00:00:51.010 --> 00:00:55.075
In that case,
we end up with an overall AMAT of 12,

00:00:55.075 --> 00:01:01.470
2 from the hit time and
10 on average from the miss penalties.

00:01:01.470 --> 00:01:03.600
Now let's look at the larger cache.

00:01:03.600 --> 00:01:07.890
This cache might have a hit
time of 10 cycles, but

00:01:07.890 --> 00:01:11.647
a hit rate of maybe 97.5%.

00:01:11.647 --> 00:01:15.720
This is a bit high for
such a cache, but let's say it is.

00:01:15.720 --> 00:01:20.450
The AMAT when this is used
alone would be 10 plus

00:01:20.450 --> 00:01:23.910
the miss rate times the miss penalty,
and

00:01:23.910 --> 00:01:29.060
we end up with 12.5, which is a little
bit worse than with a smaller cache.

00:01:29.060 --> 00:01:34.860
So having a larger cache alone increases
the hit time, improves the hit rate.

00:01:34.860 --> 00:01:37.330
So it may or
may not improve the AMAT, but

00:01:37.330 --> 00:01:39.850
either way the AMAT is not
going to improve a lot.

00:01:39.850 --> 00:01:43.950
Of course, having a cache is still
lots better than not having a cache.

00:01:43.950 --> 00:01:48.270
Not having a cache means that our
memory has a hit time of 100 cycles,

00:01:48.270 --> 00:01:50.148
basically the memory latency.

00:01:50.148 --> 00:01:53.750
It hits 100% of the time.

00:01:53.750 --> 00:02:00.050
So AMAT ends up being 100 plus 0 times
the penalty, because it never misses.

00:02:00.050 --> 00:02:04.840
But we still end up with 100 cycles
per axis, which is way too big.

00:02:04.840 --> 00:02:08.490
So obviously, having a cache
is better than not having it.

00:02:08.490 --> 00:02:11.280
So now let's look at
the cache hierarchy.

00:02:11.280 --> 00:02:16.110
The hit time is different depending
on which of the levels we hit in.

00:02:16.110 --> 00:02:20.460
The hit time is still going to
be two cycles for a level 1 hit.

00:02:20.460 --> 00:02:24.260
For a level 2 hit, however,
we first check in level 1.

00:02:24.260 --> 00:02:27.180
So we pay 2 cycles to check.

00:02:27.180 --> 00:02:29.330
Then we access L2 and have a hit.

00:02:29.330 --> 00:02:35.210
So overall now, it's going to
be 12 cycles for a level 2 hit.

00:02:35.210 --> 00:02:40.759
The hit rate is going to be 90% for L1.

00:02:40.759 --> 00:02:44.724
It's still the same cache
as if it was alone, and

00:02:44.724 --> 00:02:49.751
of all the axises that go from
level 1 to level 2, we will have

00:02:49.751 --> 00:02:56.000
some hits because the L2 cache has
this hit rate when working alone.

00:02:56.000 --> 00:03:01.240
Of all the processor axises,
it would have a hit on this many, but

00:03:01.240 --> 00:03:03.730
of all the processor axises,

00:03:03.730 --> 00:03:08.200
those that hit in L1 probably
would also have been hits in L2.

00:03:08.200 --> 00:03:16.360
So this cache really has a 75% hit rate
of all the things that go into it.

00:03:16.360 --> 00:03:21.170
It would have this hit rate if it was
alone, but the L1 cache is filtering

00:03:21.170 --> 00:03:25.780
all of the easy to hit axises,
so the L2 only gets 75%.

00:03:25.780 --> 00:03:30.740
Basically it only gets to see kind
of the worst 10% of the axises, and

00:03:30.740 --> 00:03:35.490
for those it's only having
a three quarters hit rate.

00:03:35.490 --> 00:03:40.460
But the AMAT is now going to be two for
L1 hits

00:03:40.460 --> 00:03:46.190
plus 10% of the time we have an L1 miss.

00:03:46.190 --> 00:03:52.006
When we do,
we have 10 cycles to axis L2,

00:03:52.006 --> 00:03:59.680
plus 25% of those also
end up accessing memory.

00:03:59.680 --> 00:04:03.500
So when we compute what this is,
it's 10 plus 25.

00:04:03.500 --> 00:04:10.790
So the overall miss penalty for
our level 1 miss is just 35 cycles.

00:04:10.790 --> 00:04:15.620
It's much better than what it used
to be when the L1 was working alone.

00:04:15.620 --> 00:04:18.660
And we finally end up with 2 plus 3.5,

00:04:18.660 --> 00:04:23.390
which gives us an overall
AMAT of 5.5 cycles.

00:04:23.390 --> 00:04:28.370
This is much better than either
of the two caches working alone.

00:04:28.370 --> 00:04:33.510
And it's much better because
really we are having most

00:04:33.510 --> 00:04:39.010
of the axises hit using the hit
latency of the fast cache.

00:04:39.010 --> 00:04:44.940
Some axises have a higher hit
latency in the second cache,

00:04:44.940 --> 00:04:48.750
and fewer of them made
this huge memory latency.

00:04:48.750 --> 00:04:53.790
So this is why cache hierarchies
work better than individual caches,

00:04:53.790 --> 00:04:55.070
and why we have them.

00:04:55.070 --> 00:05:00.470
It is not enough to simply have
a large cache, if it's also slow.

00:05:00.470 --> 00:05:03.420
In that case,
you can combine their good properties so

00:05:03.420 --> 00:05:05.820
that most of the time
we get this hit time.

00:05:05.820 --> 00:05:08.920
But overall, as far as
the memory axises is concerned,

00:05:08.920 --> 00:05:12.020
we really have this hit
rate in the combined cache.

