WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.370
So in this real-world example of phone numbers and people, for instance

00:00:05.370 --> 00:00:11.190
if we didn't have the phone book yet we could start with every phone number

00:00:11.190 --> 00:00:16.040
and call every person and ask for their names.

00:00:16.040 --> 00:00:19.670
You'd go through a brute-force phase that may take a couple of months

00:00:19.670 --> 00:00:24.350
but once your're done with this you have this beautiful phone book or code book

00:00:24.350 --> 00:00:28.840
as they call it in Cryptography that allows you to do

00:00:28.840 --> 00:00:35.080
the second and third and forth and infinite number of look-ups in basically zero time.

00:00:35.080 --> 00:00:42.340
So that's the basic idea of an attack that then uses very little time

00:00:42.340 --> 00:00:48.240
in fact zero encryption functions are needed after the pre-computation phase

00:00:48.240 --> 00:00:57.010
but that invests storage, in this case the storage to store every possibility

00:00:57.010 --> 00:01:04.129
to achieve the faster computation.

00:01:04.129 --> 00:01:07.960
And that's the basic scheme that in this case is not practical

00:01:07.960 --> 00:01:12.210
because this amount of storage would equal Petabytes

00:01:12.210 --> 00:01:18.880
in fact hundreds of Petabytes and that storage is available to no hacker in the world.

00:01:18.880 --> 00:01:26.220
Google may have this much, but nobody wants to break GSM phone calls for cheap.

00:01:26.220 --> 00:01:28.610
So we need improvements on this scheme.

00:01:28.610 --> 00:01:33.770
Luckily there are many possible choices between this one extreme, the code book

00:01:33.770 --> 00:01:38.520
that uses a lot of storage and very little time and the other extreme, brute force

00:01:38.520 --> 00:01:45.590
that uses a lot of time but very little storage. And those we want to discuss next.

00:01:45.590 --> 00:01:52.480
Some trade-off points are achieved by a technique called Time Memory Trade-Offs.

00:01:52.480 --> 00:01:59.180
And that works as follows: We again start with a table of many of these keys.

00:01:59.180 --> 00:02:03.260
And for each of them again, apply the encryption function

00:02:03.260 --> 00:02:06.880
but not just once but several times.

00:02:06.880 --> 00:02:12.240
And of the resulting data set there of course will be of the same amount of samples

00:02:12.240 --> 00:02:13.890
again we want to have the same coverage.

00:02:13.890 --> 00:02:17.130
We throw away most everything, these things in the middle

00:02:17.130 --> 00:02:21.570
and only keep the first and the last column.

00:02:21.570 --> 00:02:26.590
Now this should be equivalent in coverage to a data set

00:02:26.590 --> 00:02:31.590
that in the simplest scheme took a lot more storage capacity, and here's how.

00:02:31.590 --> 00:02:37.930
You're looking up a message found in the last column, then clearly it works as before.

00:02:37.930 --> 00:02:46.010
You find the encrypted message in this last column and

00:02:46.010 --> 00:02:53.010
you look up the key through following the chain that led up to this message.

00:02:53.010 --> 00:02:57.990
So, after finding the message in the last column, you go to the matching entry

00:02:57.990 --> 00:03:03.600
of the first column and compute the encryption function, in this case twice.

00:03:03.600 --> 00:03:07.620
and that's the key you wanted.

00:03:07.620 --> 00:03:11.860
However, how do you find now a message that is in the middle

00:03:11.860 --> 00:03:15.710
that you didn't in fact store on the hard disk.

00:03:15.710 --> 00:03:22.020
For this you'll have to apply an encryption function first and then find it.

00:03:22.020 --> 00:03:25.310
This parameter three is configurable, of course.

00:03:25.310 --> 00:03:30.460
And to correct something of the size of the GSM 64-bit key

00:03:30.460 --> 00:03:37.130
we would want to choose a parameter more on the magnitude of a million.

00:03:37.130 --> 00:03:40.180
So this table becomes a million columns wide

00:03:40.180 --> 00:03:43.580
of which you only stored the first and the last.

00:03:43.580 --> 00:03:49.090
Now if this before took Petabytes and now you only have to store a millionth of it

00:03:49.090 --> 00:03:52.670
you're down to manageable Terabytes.

00:03:52.670 --> 00:03:59.870
And that's exactly where we want to be to launch this attack on today's computers.

00:03:59.870 --> 00:04:07.480
There is a large amount of academic work to solve these practicality problems

00:04:07.480 --> 00:04:11.730
two of which we want to look into to solve, exactly these two problems now.

00:04:11.730 --> 00:04:17.209
The first one is called Distinguished Points.

00:04:17.209 --> 00:04:21.339
Distinguished points work off this principle.

00:04:21.339 --> 00:04:27.830
You again start with a large list of keys and for each of these your start computing

00:04:27.830 --> 00:04:31.180
encryption functions, other than before though

00:04:31.180 --> 00:04:35.500
you're not computing a certain number of encryption functions

00:04:35.500 --> 00:04:43.760
but rather you're computing until you hit a certain distinguishing criteria.

00:04:43.760 --> 00:04:52.460
Often times the number of zero bits at the end of your output.

00:04:52.460 --> 00:04:58.660
Each of these computations are terminated very quickly or terminate very late

00:04:58.660 --> 00:05:03.020
so they vary in length, the chains.

00:05:03.020 --> 00:05:06.920
The number of zero bits, however, determines the average length.

00:05:06.920 --> 00:05:13.030
So instead of a square data set, so to say

00:05:13.030 --> 00:05:18.690
where you have a stable height and a stable width

00:05:18.690 --> 00:05:24.730
you get more a zigzag data set where each line is of different lengths

00:05:24.730 --> 00:05:28.530
but on average you will have the same coverage.

00:05:28.530 --> 00:05:33.100
Now this solves the hard disk bottleneck because you don't have to go

00:05:33.100 --> 00:05:40.120
through your computation and chainlink by chainlink look up on the hard disk.

00:05:40.120 --> 00:05:44.030
You know that nothing that doesn't have the right number of zeros at the end

00:05:44.030 --> 00:05:47.540
will ever be stored on the hard disk, so you keep computing

00:05:47.540 --> 00:05:54.470
up to let's say on average a million and only then you have to do one hard disk look-up.

00:05:54.470 --> 00:05:59.890
So this scheme is clearly superior to the first one

00:05:59.890 --> 00:06:04.290
in that it requires the same number of encryption functions

00:06:04.290 --> 00:06:12.100
it requires the same amount of storage but it only requires a single hard disk look-up.

00:06:12.100 --> 00:06:18.350
So really now you are at seconds Terabytes and for the hard disk for milliseconds.

00:06:18.350 --> 00:06:24.020
In solving the second bottleneck, the pre-computation expense

00:06:24.020 --> 00:06:27.070
that's a little bit more tricky and there's a technique needed

00:06:27.070 --> 00:06:36.620
that gives this whole project it's name, so-called Rainbow Tables.

00:06:36.620 --> 00:06:38.720
Rainbow tables look as follows:

00:06:38.720 --> 00:06:45.790
again, start with a long list of keys and you do the encryption function

00:06:45.790 --> 00:06:51.340
for each of these keys as before, and you go through all the colors of the rainbow

00:06:51.340 --> 00:06:55.480
in this case a million different colors with a million different encryption functions

00:06:55.480 --> 00:06:59.970
before terminating your chain.

00:06:59.970 --> 00:07:02.140
Whether or not you will need a high coverage very much depends

00:07:02.140 --> 00:07:04.890
on your attack scenario, of course.

00:07:04.890 --> 00:07:09.640
In GSM, for instance, as we saw before, there's a lot of different packets that are

00:07:09.640 --> 00:07:15.010
attackable so maybe your coverage for each single one of them can be very low

00:07:15.010 --> 00:07:21.990
and, in fact, in the project that we computed, the coverage is much smaller than 1%.

00:07:21.990 --> 00:07:28.890
That's still enough to track each transaction with a probability much above 80%.

00:07:28.890 --> 00:07:33.490
So, the Rainbow Table helped us to some degree

00:07:33.490 --> 00:07:40.700
but we actually mixed it with Distinguished Points to kind of mix the benefits of both.

