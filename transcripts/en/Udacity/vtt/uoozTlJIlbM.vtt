WEBVTT
Kind: captions
Language: en

00:00:00.260 --> 00:00:02.730
So at this philosophical level there's
one last thing I want to talk about.

00:00:02.730 --> 00:00:04.730
We just talked about
evaluating a policy but

00:00:04.730 --> 00:00:06.960
remember in the reinforcement
learning setting,

00:00:06.960 --> 00:00:11.550
the policy is what gets output as
a result of the learning process.

00:00:11.550 --> 00:00:13.970
So what if we want to actually
evaluate the learner?

00:00:13.970 --> 00:00:15.180
How good is this learner?

00:00:15.180 --> 00:00:19.490
Can you think of some ways that we might
be able to decide how good a learner is?

00:00:19.490 --> 00:00:20.160
&gt;&gt; Sure.

00:00:20.160 --> 00:00:21.300
It's as good as its policy.

00:00:21.300 --> 00:00:22.710
&gt;&gt; So that seems like a good idea.

00:00:22.710 --> 00:00:26.460
That a good learner is one that
returns a good policy, sure.

00:00:26.460 --> 00:00:30.815
What if we have two learners that return
the same policy say the optimal policy?

00:00:30.815 --> 00:00:32.870
&gt;&gt; Oh okay, well I can think
of two responses to that.

00:00:32.870 --> 00:00:34.590
One is who cares they're
both the same and

00:00:34.590 --> 00:00:38.438
the only thing that matters is how good
the policy is that you come up with.

00:00:38.438 --> 00:00:40.810
Or I could come up with
another answer which would be,

00:00:40.810 --> 00:00:44.290
I will take the one that
does it more quickly.

00:00:44.290 --> 00:00:45.610
&gt;&gt; Quickly in terms of what?

00:00:45.610 --> 00:00:46.408
&gt;&gt; Let's say time.

00:00:46.408 --> 00:00:50.190
&gt;&gt; [LAUGH] I think that's
what quickly means.

00:00:50.190 --> 00:00:53.561
Yes, but time of what?

00:00:53.561 --> 00:00:55.686
There's lots of different
kinds of time that matter.

00:00:55.686 --> 00:00:58.340
So one in particular
is computation time?

00:00:58.340 --> 00:00:59.800
&gt;&gt; Yeah, wall clock time.

00:00:59.800 --> 00:01:01.690
&gt;&gt; And that seems like an important one,
right?

00:01:01.690 --> 00:01:03.460
We want one that's going to
be more efficient in terms of

00:01:03.460 --> 00:01:06.400
the computations that it does in
the process of learning the policy.

00:01:06.400 --> 00:01:09.450
But there's another kind of time
that actually matters a lot

00:01:09.450 --> 00:01:12.060
in the reinforcement learning settings,
so I think it's worth mentioning.

00:01:12.060 --> 00:01:12.870
&gt;&gt; Okay.

00:01:12.870 --> 00:01:15.570
&gt;&gt; So the other kind of complexity that
turns out to be really important in this

00:01:15.570 --> 00:01:17.680
learning setting is
experience complexity.

00:01:17.680 --> 00:01:19.450
Do you have a sense of
what that might mean?

00:01:20.510 --> 00:01:22.040
&gt;&gt; How complex your experiences are?

00:01:23.440 --> 00:01:24.960
&gt;&gt; I'm going to say no.

00:01:24.960 --> 00:01:25.800
&gt;&gt; Oh, okay, I get it.

00:01:25.800 --> 00:01:29.010
So computational complexity is sort of
how much computational energy you have

00:01:29.010 --> 00:01:29.650
to put into it.

00:01:29.650 --> 00:01:33.460
So this would be how much experience
you have to have in order to learn.

00:01:33.460 --> 00:01:35.317
So it's the amount of
data that you need.

00:01:35.317 --> 00:01:38.924
&gt;&gt; Yeah, so if two different learners
can learn the same optimal policy, but

00:01:38.924 --> 00:01:42.531
one only requires a couple interactions
with the environment to do it, and

00:01:42.531 --> 00:01:44.191
the other one requires a billion,

00:01:44.191 --> 00:01:48.100
the one that has the lower experience
complexity should be preferred.

00:01:48.100 --> 00:01:49.390
Though of course there's trade-offs.

00:01:49.390 --> 00:01:52.087
If to do that it actually
has to compute for

00:01:52.087 --> 00:01:55.870
2 billion years then that seems
maybe not so good either.

00:01:55.870 --> 00:02:01.590
So there can be little trade-offs
between how much time that the learner

00:02:01.590 --> 00:02:05.080
takes in terms of interactions with the
environment and how much time that it

00:02:05.080 --> 00:02:08.590
takes in terms of the computations
that it does between interactions.

00:02:08.590 --> 00:02:09.758
&gt;&gt; Hm.
Do you know what this reminds me of?

00:02:09.758 --> 00:02:11.110
It reminds me of two things.

00:02:11.110 --> 00:02:12.400
It reminds me of MIMIC

00:02:13.660 --> 00:02:16.660
because that was the exact
trade-off that we were making then.

00:02:16.660 --> 00:02:17.220
&gt;&gt; Oh, yeah.

00:02:17.220 --> 00:02:18.410
Okay, sure.

00:02:18.410 --> 00:02:21.440
&gt;&gt; And the other thing is that it
reminds me of the theory lecture that

00:02:21.440 --> 00:02:23.950
we did in the Intro to
Machine Learning class

00:02:23.950 --> 00:02:26.380
where we talked about sample complexity.

00:02:26.380 --> 00:02:28.150
&gt;&gt; Yes, that's good.

00:02:28.150 --> 00:02:31.060
That probably is a better name
than experience complexity.

00:02:31.060 --> 00:02:32.450
Let's call it sample complexity.

00:02:33.700 --> 00:02:36.440
Yeah, because it really is about
the data that's necessary to achieve

00:02:36.440 --> 00:02:38.940
the learning ends.

00:02:38.940 --> 00:02:39.670
&gt;&gt; All right.

00:02:39.670 --> 00:02:43.140
&gt;&gt; All right, so this kind of sets the
stage for what reinforcement learning

00:02:43.140 --> 00:02:45.560
is, and how compare different
learners to each other, and

00:02:45.560 --> 00:02:47.530
how we compare the outputs of
those learners to each other.

00:02:47.530 --> 00:02:51.390
What we're going to dive into
next is actual algorithms for

00:02:51.390 --> 00:02:53.460
doing this kind of learning.

00:02:53.460 --> 00:02:54.880
&gt;&gt; Yeah that sounds good,
can I ask you a question?

00:02:54.880 --> 00:02:55.850
&gt;&gt; Sure.

00:02:55.850 --> 00:02:58.569
&gt;&gt; So,
why aren't we talking about space?

00:02:59.950 --> 00:03:03.310
&gt;&gt; Ooh, so space complexity.

00:03:03.310 --> 00:03:04.860
So that's a good question.

00:03:04.860 --> 00:03:07.830
In computer science,
usually computation time and

00:03:07.830 --> 00:03:13.610
computation space are the two dimensions
along which we evaluate algorithms.

00:03:13.610 --> 00:03:16.390
Here I guess we could do that too.

00:03:16.390 --> 00:03:19.280
You could talk about the space
that an algorithm uses.

00:03:19.280 --> 00:03:22.580
Our learning algorithm uses, but
it's generally not that interesting.

00:03:22.580 --> 00:03:25.850
Generally we don't, we're not
limited by the space complexity.

00:03:25.850 --> 00:03:29.440
We usually run into issues more
quickly on the computational or

00:03:29.440 --> 00:03:30.960
the sample complexity side.

