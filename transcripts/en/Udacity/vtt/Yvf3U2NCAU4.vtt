WEBVTT
Kind: captions
Language: en

00:00:00.290 --> 00:00:00.790
We have so

00:00:00.790 --> 00:00:07.100
far built multivariate non-parametric
models using kernel density estimation.

00:00:07.100 --> 00:00:12.700
We can also ask the question,
are there outliers in the data?

00:00:12.700 --> 00:00:18.190
The Mahalanobis distance for a single
variable x, can be defined this way.

00:00:18.190 --> 00:00:22.510
Where Mu x is the mean value for x.

00:00:22.510 --> 00:00:26.290
And S is the covariance matrix.

00:00:26.290 --> 00:00:31.370
We use the inverse of S here
to get this product matrix.

00:00:31.370 --> 00:00:35.880
Similarly for two identically
distributed variables x and

00:00:35.880 --> 00:00:39.550
y, we take the difference transposed.

00:00:39.550 --> 00:00:44.160
And use the inverse of
the covariance matrix and

00:00:44.160 --> 00:00:47.180
then the difference and
multiply them together.

00:00:47.180 --> 00:00:51.550
In both cases the values
are always positive definite.

00:00:51.550 --> 00:00:54.230
Since it's a true distance function.

00:00:54.230 --> 00:00:57.940
The Mahalanobis distance gives
us a simple way to look for

00:00:57.940 --> 00:00:59.760
outliers in the data.

00:00:59.760 --> 00:01:03.350
The square of the Mahalanobis
distance in two dimensions or

00:01:03.350 --> 00:01:09.910
with two variables is equal to the
chi-square with two degrees of freedom.

00:01:09.910 --> 00:01:14.820
Thus that distance directly give
us how far these values of data

00:01:14.820 --> 00:01:19.410
are from their central tendencies
in the probability distributions.

00:01:19.410 --> 00:01:24.836
In our case,
we have two distributions of F1 and F2.

00:01:24.836 --> 00:01:28.501
F1 was the average Medicare
payment amount and

00:01:28.501 --> 00:01:32.565
F2 was the average
Medicare Allowed amount.

00:01:32.565 --> 00:01:35.260
We had inspected these
two distributions and

00:01:35.260 --> 00:01:38.740
they seemed to be quite
identically distributed.

00:01:38.740 --> 00:01:43.152
Assuming they were identically
distributed, given that F1 and

00:01:43.152 --> 00:01:46.420
F2 were quite identically distributed.

00:01:46.420 --> 00:01:52.200
We had the derived variables x and
x bar identically distributed.

00:01:52.200 --> 00:01:58.120
Can we look for outliers in a joint
distribution of x and x bar?

00:01:58.120 --> 00:02:02.600
Moreover if we do find outliers
using the Mahalanobis distance

00:02:02.600 --> 00:02:06.960
we can still ask the question
what do these outliers mean?

00:02:06.960 --> 00:02:09.389
Well, we will leave it up to you

00:02:09.389 --> 00:02:13.050
to find what the meaning
of these outliers could be.

00:02:13.050 --> 00:02:15.690
Let's go back to the i
Python notebook and

00:02:15.690 --> 00:02:19.080
implement the code for
the Mahalanobis distance and

00:02:19.080 --> 00:02:23.480
see if we can find some outliers
in our variables x and x bar.

