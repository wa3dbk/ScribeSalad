WEBVTT
Kind: captions
Language: en

00:00:00.360 --> 00:00:03.040
Okay Michael, so, let me see if I can convince

00:00:03.040 --> 00:00:04.850
you that we actually have some way of actually estimating

00:00:04.850 --> 00:00:07.810
these distributions. So, all I've written up here is the

00:00:07.810 --> 00:00:11.680
chain rule version of a joint probability distribution, okay? But just

00:00:11.680 --> 00:00:15.640
to be clear, what these subscripts mean here, every x

00:00:15.640 --> 00:00:17.849
that we have is made up of a set of features.

00:00:18.980 --> 00:00:21.120
So, there's, let's just say there is N of these

00:00:21.120 --> 00:00:25.650
features. And so really, X is a vector. There's feature one.

00:00:25.650 --> 00:00:29.210
There's feature two. There's feature three, dot, dot,

00:00:29.210 --> 00:00:32.530
dot. All the way up to feature N. Okay?

00:00:32.530 --> 00:00:33.900
&gt;&gt; Sure.

00:00:33.900 --> 00:00:37.220
&gt;&gt; What I really want to know for my piece of theta and I'm

00:00:37.220 --> 00:00:39.680
going to drop the theta's here for the

00:00:39.680 --> 00:00:42.070
purpose of just describing this generic distribution.

00:00:42.070 --> 00:00:44.520
Is I want to say, well the probability of me seeing all of the

00:00:44.520 --> 00:00:50.670
features yeah, all of the features of some particular example is just the joint

00:00:50.670 --> 00:00:53.570
distribution over all of those features. Now of course,

00:00:53.570 --> 00:00:55.610
we could just estimate this, but that's going to be hard.

00:00:55.610 --> 00:00:57.460
&gt;&gt; Why's it going to be hard? Because.

00:00:57.460 --> 00:01:01.290
&gt;&gt; Well, the first distribution is conditioned on a lot

00:01:01.290 --> 00:01:05.300
of things, so it's an exponential sized conditional probability table.

00:01:05.300 --> 00:01:08.090
&gt;&gt; Exactly, so this is exponential table and if

00:01:08.090 --> 00:01:10.970
it's an exponential table then we need to have

00:01:10.970 --> 00:01:13.030
an enormous amount of data in order to estimate

00:01:13.030 --> 00:01:15.510
it well and this is sort of the fundamental problem.

00:01:15.510 --> 00:01:19.440
But, we have addressed this in earlier lectures, earlier lessons Michael.

00:01:19.440 --> 00:01:21.940
&gt;&gt; In the inference lecture maybe?

00:01:21.940 --> 00:01:23.200
&gt;&gt; Yes, in the inference lecture.

00:01:23.200 --> 00:01:24.000
&gt;&gt; Whew.

00:01:24.000 --> 00:01:27.010
&gt;&gt; Where we can try to estimate this incredibly painful joint

00:01:27.010 --> 00:01:29.550
distribution by making some assumptions about

00:01:29.550 --> 00:01:32.100
conditional independence, and in particular I'm

00:01:32.100 --> 00:01:36.360
going to make, one kind of assumption. And that is, that we

00:01:36.360 --> 00:01:40.480
only care about what's called Dependency Trees. Okay, so what's a dependency

00:01:40.480 --> 00:01:41.450
tree Michael? Do you remember?

00:01:41.450 --> 00:01:42.670
&gt;&gt; No I have absolutely no idea, I

00:01:42.670 --> 00:01:44.330
don't think I've ever heard of such a thing.

00:01:44.330 --> 00:01:45.710
&gt;&gt; So the Dependency Tree is a special

00:01:45.710 --> 00:01:48.150
case of a Bayesian network, where the network

00:01:48.150 --> 00:01:52.520
itself is a tree. That is, every node,

00:01:52.520 --> 00:01:55.500
every variable in the tree, has exactly one parent.

00:01:55.500 --> 00:01:57.780
&gt;&gt; I see. So sometimes in Bayesian networks, they

00:01:57.780 --> 00:02:00.450
talk about polytrees. Polytrees just mean that if you

00:02:00.450 --> 00:02:02.040
ignore the direction of the edges, you have a

00:02:02.040 --> 00:02:05.550
tree. But you're actually talking about the, the edges have

00:02:05.550 --> 00:02:08.440
to go in a particular direction. Everybody's got one parent.

00:02:08.440 --> 00:02:10.570
&gt;&gt; Right, exactly right. And in, and in, so,

00:02:10.570 --> 00:02:14.760
you should see these as a directed graph, although I

00:02:14.760 --> 00:02:17.780
almost never draw them that way. Because, you know, it's

00:02:17.780 --> 00:02:19.290
sort of obvious by looking at it. That this is

00:02:19.290 --> 00:02:21.680
the root of the tree. So all we have here

00:02:21.680 --> 00:02:23.840
now is a tree. Every node has one parent, and

00:02:23.840 --> 00:02:26.460
what does that mean? That means that every node, every

00:02:26.460 --> 00:02:30.120
random variable, depends on exactly one other random variable. Yeah.

00:02:30.120 --> 00:02:30.860
&gt;&gt; So

00:02:30.860 --> 00:02:33.360
we can rewrite this joint distribution here now as a

00:02:33.360 --> 00:02:39.800
product over each of the features depending upon only its parent.

00:02:39.800 --> 00:02:42.360
&gt;&gt; I see. So the first capital pi there means

00:02:42.360 --> 00:02:45.880
product. And the second lower case pi there means parent.

00:02:45.880 --> 00:02:48.190
&gt;&gt; Exactly. So when I compare

00:02:48.190 --> 00:02:50.760
this representation of a distribution, dependency to

00:02:50.760 --> 00:02:56.040
representation versus the full joint. What nice properties do I get from doing

00:02:56.040 --> 00:03:00.690
it this way versus doing it that way? Well the, I guess the main positive is

00:03:00.690 --> 00:03:02.890
that you're only ever conditioned on, well it's

00:03:02.890 --> 00:03:05.020
gotta be at most one, right? Not exactly one?

00:03:05.020 --> 00:03:08.110
&gt;&gt; Right. At most one, so, so in fact you, you picked up on

00:03:08.110 --> 00:03:11.860
a nice rotational thing here. The parent of the tree, the root of the tree

00:03:11.860 --> 00:03:13.346
doesn't actually have a parent. So just

00:03:13.346 --> 00:03:15.810
assume that in this case Pi returns itself

00:03:15.810 --> 00:03:17.130
or something and so it's the unconditional

00:03:17.130 --> 00:03:18.810
distribution. And that could happen at any time.

00:03:18.810 --> 00:03:21.140
&gt;&gt; Got, gotcha, alright, yeah and so, like if

00:03:21.140 --> 00:03:23.900
nobody has any parents, then that's the same as Naive

00:03:23.900 --> 00:03:27.040
Bayes, but here it can happen with those one parents.

00:03:27.040 --> 00:03:27.100
&gt;&gt; No.

00:03:27.100 --> 00:03:27.460
&gt;&gt; No?

00:03:27.460 --> 00:03:29.180
&gt;&gt; Naive Bayes has one, exactly one, everyone

00:03:29.180 --> 00:03:30.800
has one parent and it's exactly the same one.

00:03:30.800 --> 00:03:33.670
&gt;&gt; Oh, right, good point.

00:03:33.670 --> 00:03:36.330
&gt;&gt; So, if everyone has no parents, then you're saying that

00:03:36.330 --> 00:03:39.800
all of the features are in fact, independent of one another.

00:03:39.800 --> 00:03:42.120
&gt;&gt; Gotcha. Okay. Alright. But the, but that's not what you

00:03:42.120 --> 00:03:46.090
asked. You asked comparing that probability distribution to the full joint,

00:03:46.090 --> 00:03:48.960
the main thing is that you're, no ones ever conditioned on more than

00:03:48.960 --> 00:03:51.080
one, other feature and therefore the

00:03:51.080 --> 00:03:53.520
conditional probability tables stay very, very small.

00:03:53.520 --> 00:03:56.540
&gt;&gt; Right. In fact do you, how small do they stay?

00:03:56.540 --> 00:03:58.040
&gt;&gt; Well it depends on how big this, are

00:03:58.040 --> 00:04:00.140
there, are there binary features that we're talking about?

00:04:00.140 --> 00:04:01.690
&gt;&gt; Yeah let's say they're binary. So

00:04:01.690 --> 00:04:04.040
then it's like two numbers. Right. It's like

00:04:04.040 --> 00:04:05.850
you're probability when your parent is true

00:04:05.850 --> 00:04:07.380
and your probability when your parent is false.

00:04:07.380 --> 00:04:09.880
&gt;&gt; Well that's each table. But what about representing the entire thing?

00:04:09.880 --> 00:04:11.130
&gt;&gt; So it's going

00:04:11.130 --> 00:04:13.920
to be linear in the size of the number of variables or.

00:04:13.920 --> 00:04:14.100
&gt;&gt; Right.

00:04:14.100 --> 00:04:14.530
&gt;&gt; Features.

00:04:14.530 --> 00:04:16.269
&gt;&gt; Right and the number, the amount of the data that you

00:04:16.269 --> 00:04:19.702
need is going to be fundamentally. In order to get this tape, in

00:04:19.702 --> 00:04:22.005
order to get this tree, it's going to turn out that you only

00:04:22.005 --> 00:04:25.110
need to keep track of quadratic set of numbers, quadratic in the number.

00:04:25.110 --> 00:04:26.500
&gt;&gt; We're not going to be given that

00:04:26.500 --> 00:04:27.850
tree, we're going to have to figure that out?

00:04:27.850 --> 00:04:29.160
&gt;&gt; Well, remember, one of the steps in

00:04:29.160 --> 00:04:31.040
the algorithm is you have to estimate the distribution.

00:04:32.200 --> 00:04:33.840
&gt;&gt; So we're going to have to figure out, of all

00:04:33.840 --> 00:04:36.178
the trees that I might have, which is the best tree?

00:04:36.178 --> 00:04:38.540
&gt;&gt; Yeah, that' doesn't exactly follow from the algorithm

00:04:38.540 --> 00:04:40.880
sketch because you could also say well, then you need

00:04:40.880 --> 00:04:42.280
to figure out that a tree is the right

00:04:42.280 --> 00:04:44.360
thing at all instead of something else like a box.

00:04:44.360 --> 00:04:45.990
&gt;&gt; Oh, that's fair, but what we're going to

00:04:45.990 --> 00:04:47.460
do is were just going to assume that

00:04:47.460 --> 00:04:48.820
we're going to do the dependency trees, now why

00:04:48.820 --> 00:04:49.840
are we doing this? Were actually doing this for

00:04:49.840 --> 00:04:51.250
a couple of reasons Michael, your, your points

00:04:51.250 --> 00:04:55.140
pretty your points well taken. Dependency trees have

00:04:55.140 --> 00:04:57.490
this nice feature that they actually let you

00:04:57.490 --> 00:05:01.300
represent relationships. The point is that you're actually able

00:05:01.300 --> 00:05:04.290
to represent relationships between variables. Which in this case are sort

00:05:04.290 --> 00:05:06.880
of features in our space. But you don't have to worry about

00:05:06.880 --> 00:05:10.620
too many of them, and the only question here then is how

00:05:10.620 --> 00:05:14.320
many relationships do you want, what kind, which of all the possible

00:05:14.320 --> 00:05:16.970
relationships you could have where you only are related to one

00:05:16.970 --> 00:05:19.730
other thing, do you want to have. Well, in some sense a

00:05:19.730 --> 00:05:22.410
dependency tree since you can depend on at most only one other

00:05:22.410 --> 00:05:26.910
thing, is the simplest set of relationships you can keep track of.

00:05:26.910 --> 00:05:29.360
The next simplest would be, as you point out, not having any

00:05:29.360 --> 00:05:34.230
parents at all. In which case, you would be estimating simply this.

00:05:34.230 --> 00:05:35.712
&gt;&gt; Yeah, I wouldn't say that the

00:05:35.712 --> 00:05:38.340
next simplest. That's even simpler. But it doesn't,

00:05:38.340 --> 00:05:40.490
doesn't allow any of the inter-relationships. Any

00:05:40.490 --> 00:05:44.110
of the co-variants essentially information to be captured.

00:05:44.110 --> 00:05:46.870
&gt;&gt; No, that's fair, that's a fair point. So, we could have started with

00:05:46.870 --> 00:05:49.800
something like this except here you must

00:05:49.800 --> 00:05:52.250
you you're forced to ignore all relationships because

00:05:52.250 --> 00:05:55.260
you're treating everything as independent. And we don't believe that things

00:05:55.260 --> 00:05:57.780
are independent or at least we think there a possibility there's some

00:05:57.780 --> 00:06:00.870
dependence. And so by allowing at most that you're connected to

00:06:00.870 --> 00:06:04.790
one other parent that's sort of the least committed to the idea

00:06:04.790 --> 00:06:07.400
you could still be while still allowing you to capture these

00:06:07.400 --> 00:06:10.630
relationships. So that's the basic idea. Now I want to be, I

00:06:10.630 --> 00:06:13.330
want to be strict here that the mimic algorithm or just this

00:06:13.330 --> 00:06:15.930
whole notion of representing probability distributions

00:06:15.930 --> 00:06:18.170
does not depend upon dependency trees.

00:06:18.170 --> 00:06:20.410
We're going to use dependency trees here because you have

00:06:20.410 --> 00:06:22.600
to make some decision about how to represent the

00:06:22.600 --> 00:06:25.230
probability distributions, and this is kind of the easiest

00:06:25.230 --> 00:06:28.670
thing to do that still allows you to capture relationships.

00:06:28.670 --> 00:06:29.120
&gt;&gt; I buy that.

00:06:29.120 --> 00:06:32.060
&gt;&gt; Okay and one other thing worth noting is I you'll I hope

00:06:32.060 --> 00:06:33.590
you'll see this is a couple of slides if you don't see it

00:06:33.590 --> 00:06:36.990
immediately, is that at the very least this will allow us to capture

00:06:36.990 --> 00:06:38.410
the same kind of relationships that we

00:06:38.410 --> 00:06:41.350
get from cross over in genetic algorithms.

00:06:41.350 --> 00:06:41.620
&gt;&gt; Huh?

00:06:41.620 --> 00:06:44.410
&gt;&gt; And that was a bit of the, the inspiration

00:06:44.410 --> 00:06:47.109
for this. That cross-over is representing

00:06:47.109 --> 00:06:49.190
structure. In this case structure that's

00:06:49.190 --> 00:06:53.010
measured by locality, and this is kind of the general form of that.

00:06:53.010 --> 00:06:57.610
&gt;&gt; So you are saying if there is some locality, then whatever,

00:06:57.610 --> 00:07:01.400
however we're going to learn the dependency tree from the samples is going to

00:07:01.400 --> 00:07:04.170
be able to capture that. And therefore, it will kind of wrap

00:07:04.170 --> 00:07:07.650
its head around the same kind of information that that cross over's exploiting.

00:07:07.650 --> 00:07:09.600
&gt;&gt; That's exactly right,

00:07:09.600 --> 00:07:11.860
and in fact, as we'll see in one of the examples

00:07:11.860 --> 00:07:13.640
that I'll give you in a moment, that it can do

00:07:13.640 --> 00:07:17.360
better than that because it doesn't actually require locality the way

00:07:17.360 --> 00:07:21.010
that crossover does. There's one other thing that's worth mentioning here

00:07:21.010 --> 00:07:24.500
about this distribution and why it's nice. It captures relationships. But

00:07:24.500 --> 00:07:27.880
the second thing is, something that you, you sort of alluded

00:07:27.880 --> 00:07:32.740
to earlier is that, it's very easy to sample from. Right?

00:07:32.740 --> 00:07:35.000
So given a dependency tree where each one of these features,

00:07:35.000 --> 00:07:37.500
each one of these nodes, represents a feature, it

00:07:37.500 --> 00:07:40.750
is very simple, very easy to generate samples consistent with

00:07:40.750 --> 00:07:43.080
it. Right? You just start at the root, generate

00:07:43.080 --> 00:07:46.820
a sample, unconditional sample according to whatever the distribution is

00:07:46.820 --> 00:07:48.360
and then you go through the parents and you

00:07:48.360 --> 00:07:51.690
do the same thing. So it's exactly a topological sort

00:07:51.690 --> 00:07:54.670
and in trees topological sorting is very easy and

00:07:54.670 --> 00:07:56.270
this is in fact, linear in the number of features.

00:07:56.270 --> 00:07:57.730
&gt;&gt; Right. I get that and it is

00:07:57.730 --> 00:08:00.090
exactly an instance of what we talked about when

00:08:00.090 --> 00:08:03.250
we did Bayesian inference The thing that is new is

00:08:03.250 --> 00:08:05.860
how do we figure out dependency tree from the sample.

00:08:05.860 --> 00:08:07.000
&gt;&gt; Exactly, that's what we're going to

00:08:07.000 --> 00:08:09.290
do next and that's going to involves math.

