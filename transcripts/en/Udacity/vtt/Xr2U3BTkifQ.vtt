WEBVTT
Kind: captions
Language: en

00:00:00.245 --> 00:00:01.760
Alright, so what we're going to do to figure

00:00:01.760 --> 00:00:03.300
out how Q learning works, is we're going to think

00:00:03.300 --> 00:00:06.290
about what it means to estimate this Q function

00:00:06.290 --> 00:00:10.930
from transitions. So, let's just remember this is the

00:00:10.930 --> 00:00:12.660
form of the Q equation, that we've been

00:00:12.660 --> 00:00:16.040
talking about. And, we can't do this. We can't

00:00:16.040 --> 00:00:19.730
solve this, because we don't have access to R

00:00:19.730 --> 00:00:25.978
and T. All we have access to are transitions.

00:00:25.978 --> 00:00:27.322
&gt;&gt; So this a really, I guess, I'm going to

00:00:27.322 --> 00:00:29.128
guess you said this before, but when you, when you

00:00:29.128 --> 00:00:30.724
write out this equation it really jumps out at

00:00:30.724 --> 00:00:33.180
me. This is the difference between what I was talking

00:00:33.180 --> 00:00:36.970
about, solving MDPs and reinforcement learning. In solving MDPs

00:00:36.970 --> 00:00:38.970
we had R and we had T and now we

00:00:38.970 --> 00:00:40.210
do not have them, so we have to come up

00:00:40.210 --> 00:00:42.850
with some other way to solve these kinds of equations.

00:00:42.850 --> 00:00:43.210
&gt;&gt; That's right.

00:00:43.210 --> 00:00:46.620
&gt;&gt; Okay. So if we did have R and T, then we could solve this?

00:00:46.620 --> 00:00:48.560
&gt;&gt; Yeah, this is, I mean, the same

00:00:48.560 --> 00:00:51.190
things that you talked about, value iteration, policy iteration?

00:00:51.190 --> 00:00:54.390
It can be formulated in terms of Q. So it's, yeah, there's,

00:00:54.390 --> 00:00:57.540
this is easy to do, well, [LAUGH] it's polynomial to do if

00:00:57.540 --> 00:01:00.600
you have access to T and R. But but again, in the

00:01:00.600 --> 00:01:03.810
learning scenario we don't have the model. What we have are transitions.

00:01:03.810 --> 00:01:04.379
&gt;&gt; Okay, okay.

00:01:04.379 --> 00:01:06.600
&gt;&gt; So, here's how we're going to use transitions. This

00:01:06.600 --> 00:01:09.540
is what a transition is. We, we observe that we

00:01:09.540 --> 00:01:12.220
were in some state S of the MDP. And then

00:01:12.220 --> 00:01:16.400
action A was chosen somehow. And, then a transition happens.

00:01:16.400 --> 00:01:18.580
We land in a state. We get the reward for landing

00:01:18.580 --> 00:01:21.900
in that state. And we find out what state we're in. So

00:01:21.900 --> 00:01:25.050
that's, that's the transition. And what are we going to do with

00:01:25.050 --> 00:01:28.100
it? Well, what we're going to do. Is imagine that we've got an

00:01:28.100 --> 00:01:31.510
estimate of the Q function, Q hat, and we're going to update

00:01:31.510 --> 00:01:34.850
it as follows. Here's how we're going to use all these quantities from

00:01:34.850 --> 00:01:38.200
the transition. We're going to take the, the state and action that

00:01:38.200 --> 00:01:41.450
we just experienced. And we're going to change it; we going to update it;

00:01:41.450 --> 00:01:43.820
we're going to move a little bit. Alpha, this is alpha,

00:01:43.820 --> 00:01:45.930
this is called a learning rate. We're going to move a

00:01:45.930 --> 00:01:50.040
little bit in the direction of the immediate reward plus

00:01:50.040 --> 00:01:54.100
the discounted estimated value of the next state. So, we're going to

00:01:54.100 --> 00:01:58.310
take our estimate Q hat, we going to take the state

00:01:58.310 --> 00:02:00.910
that we end up in as prime. We're going to look at

00:02:00.910 --> 00:02:03.430
all the different actions we could take from there and

00:02:03.430 --> 00:02:06.540
take the maximum. So this together is kind of an estimate

00:02:06.540 --> 00:02:07.380
of the utility, right?

00:02:07.380 --> 00:02:08.491
&gt;&gt; Mm-hm.

00:02:08.491 --> 00:02:10.030
&gt;&gt; And this is the utility of the state that we're

00:02:10.030 --> 00:02:14.430
going to. This altogether is the utility of the state that,

00:02:14.430 --> 00:02:16.570
that we're in. To the state S. So this is kind

00:02:16.570 --> 00:02:18.310
of the utility of the state that we're landing in as

00:02:18.310 --> 00:02:22.080
prime. And this all together is, is related to the utility

00:02:22.080 --> 00:02:24.170
of the state, right? You can see that it's related. In

00:02:24.170 --> 00:02:27.220
that we've got the immediate reward, which kind of matches to

00:02:27.220 --> 00:02:32.750
this. We've got the discounting. We don't have the sum over transitions

00:02:32.750 --> 00:02:34.960
but we do have the max A and the lookup in the

00:02:34.960 --> 00:02:37.880
next, in the Q function. Alright so this, this is the Q

00:02:37.880 --> 00:02:40.530
learning equation. Alright, let me just say a little bit more about

00:02:40.530 --> 00:02:43.790
this, this alpha arrow notation, which I really like but is not

00:02:43.790 --> 00:02:46.760
all that standard. So if you, when I write you know something

00:02:46.760 --> 00:02:50.170
like V gets with an alpha X. What we mean is we're

00:02:50.170 --> 00:02:54.490
moving alpha of the way from the current value V towards X,

00:02:54.490 --> 00:02:57.960
which can be written this way. That V gets 1 minus alpha

00:02:57.960 --> 00:03:01.500
of V plus alpha of x. And so in particular, if

00:03:01.500 --> 00:03:05.120
you think about this as so if alpha is 0. That's

00:03:05.120 --> 00:03:06.860
sort of a learning rate of 0, which shouldn't learn at

00:03:06.860 --> 00:03:09.630
all, and in fact, if you set alpha to 0 here, it's

00:03:09.630 --> 00:03:12.760
going to zero out X, and it's going to only assign V to

00:03:12.760 --> 00:03:15.900
V, so nothing's going to change. So learning rate of 0

00:03:15.900 --> 00:03:20.030
corresponds to no learning. And if we set alpha to 1,

00:03:20.030 --> 00:03:22.980
that's like full learning, so we forget everything that we knew and

00:03:22.980 --> 00:03:24.770
we just jumped to the new value. And that's

00:03:24.770 --> 00:03:26.560
what happens here, that 1 minus alpha is 0,

00:03:26.560 --> 00:03:31.400
so the V goes away, and we just get X assigned to V. So does that make sense?

00:03:31.400 --> 00:03:33.570
&gt;&gt; That does make sense. And and if alpha

00:03:33.570 --> 00:03:35.430
were in between 0 and 1 like one half, you're

00:03:35.430 --> 00:03:38.810
basically making V the average of the old value

00:03:38.810 --> 00:03:41.350
of V, and the new value X that you see.

00:03:41.350 --> 00:03:42.250
&gt;&gt; Good.

