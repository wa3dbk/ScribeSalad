WEBVTT
Kind: captions
Language: en

00:00:00.230 --> 00:00:05.500
Recall our illustration that shows how the operating system swaps between P1 and

00:00:05.500 --> 00:00:09.000
P2 for them to share the CPU.

00:00:09.000 --> 00:00:14.160
In this illustration, the process control blocks for P1 and P2 reside in memory.

00:00:14.160 --> 00:00:18.510
And the values of the CPU will change depending on which process is

00:00:18.510 --> 00:00:20.370
currently executing.

00:00:20.370 --> 00:00:25.570
Now we can more formally state that a context switch is the mechanism used by

00:00:25.570 --> 00:00:30.550
the operating system to switch the execution from the context of

00:00:30.550 --> 00:00:34.320
one process to the context of another process.

00:00:34.320 --> 00:00:39.270
In our diagram, this is happening both when the operating system switches from

00:00:39.270 --> 00:00:42.850
the execution of P1 to the execution of P2.

00:00:42.850 --> 00:00:46.980
And then again a second time when the OS switches from the execution of P2

00:00:46.980 --> 00:00:49.110
back to the execution of P1.

00:00:49.110 --> 00:00:53.260
This operation can be expensive, and that's for two reasons.

00:00:53.260 --> 00:00:56.970
First, there are direct costs, and this is basically the number of

00:00:56.970 --> 00:01:00.880
cycles that have to be executed to simply load and

00:01:00.880 --> 00:01:05.830
store all the values of the process control blocks to and from memory.

00:01:05.830 --> 00:01:08.188
There are also indirect costs.

00:01:08.188 --> 00:01:11.330
When process 1 is running on the CPU,

00:01:11.330 --> 00:01:16.050
a lot of its data is going to be stored into the processor cache.

00:01:16.050 --> 00:01:20.750
As long as P1 is executing, a lot of its data is likely going to

00:01:20.750 --> 00:01:25.240
be present somewhere in the processor cache hierarchy.

00:01:25.240 --> 00:01:30.630
In the picture, we show a single processor cache, but in practice, modern CPUs

00:01:30.630 --> 00:01:37.000
have a hierarchy of caches from L1 to L2, down to the last level cache.

00:01:37.000 --> 00:01:42.330
And each one is larger, but potentially slower than the previous one.

00:01:42.330 --> 00:01:46.930
More importantly, however, accessing this cache is much,

00:01:46.930 --> 00:01:50.050
much faster than accessing the memory.

00:01:50.050 --> 00:01:54.207
For instance, the accesses along the processor cache hierarchy will be on

00:01:54.207 --> 00:01:58.850
the order of cycles, whereas the accesses to memory will be on

00:01:58.850 --> 00:02:01.370
the order of hundreds of cycles, for instance.

00:02:01.370 --> 00:02:05.130
When the data we need is present in the cache, in this case,

00:02:05.130 --> 00:02:09.770
that's P1's data, we call this that the cache is hot.

00:02:09.770 --> 00:02:15.530
But when we context switch to P2, some, or even all, of the data belonging

00:02:15.530 --> 00:02:22.210
to P1 in the cache will be replaced to make room for the data needed by P2.

00:02:22.210 --> 00:02:28.960
So, the next time P1 is scheduled to execute, its data will not be in the cache.

00:02:28.960 --> 00:02:32.550
It will have to spend much more time to read data from memory,

00:02:32.550 --> 00:02:35.380
so it will incur cache misses.

00:02:35.380 --> 00:02:38.260
We call this the cold cache.

00:02:38.260 --> 00:02:42.080
Running with a cold cache is clearly bad because every single

00:02:42.080 --> 00:02:46.280
data access requires much longer latency to memory and

00:02:46.280 --> 00:02:48.900
it slows down the execution of the process.

00:02:48.900 --> 00:02:52.720
As a result, we clearly want to limit the frequency with

00:02:52.720 --> 00:02:54.410
which content switching is done.

