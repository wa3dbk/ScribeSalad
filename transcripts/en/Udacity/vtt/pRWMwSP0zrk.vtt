WEBVTT
Kind: captions
Language: en

00:00:00.570 --> 00:00:02.820
Here's our mapper code. Let's look at it line by

00:00:02.820 --> 00:00:06.930
line. We're going to loop around standard input, which gives

00:00:06.930 --> 00:00:08.750
us a line at a time. Of course, the line

00:00:08.750 --> 00:00:11.570
will have a new line character so let's strip that off,

00:00:11.570 --> 00:00:14.140
plus any other white space around the line. Since our

00:00:14.140 --> 00:00:17.890
line is tab delimited, let's split untab at the same

00:00:17.890 --> 00:00:21.710
time. This gives us an array, called data. So now

00:00:21.710 --> 00:00:25.840
we'll take the array, data, and assign it into individual variables

00:00:25.840 --> 00:00:30.190
for date, time, store, item, cost, and payment. Lastly, we'll

00:00:30.190 --> 00:00:33.360
print the items we care about, which is store and cost.

00:00:34.450 --> 00:00:36.500
As you use Hadoop more and more, you'll discover that the

00:00:36.500 --> 00:00:38.890
more data you have, the more likely you are to encounter

00:00:38.890 --> 00:00:42.440
weirdness in the data. Lines could be malformed. There could

00:00:42.440 --> 00:00:46.020
be strange log messages in the data, and many other cases

00:00:46.020 --> 00:00:48.840
that you might not even imagine. So we should make sure

00:00:48.840 --> 00:00:51.100
that no matter what kind of data we get, the mapper

00:00:51.100 --> 00:00:54.250
can continue working. You don't want to be halfway through a two

00:00:54.250 --> 00:00:57.510
terabyte job when it dies. So let's go back and add

00:00:57.510 --> 00:01:01.050
some defensive programming, to make sure things don't break, even if

00:01:01.050 --> 00:01:02.840
you get a strange line in the middle of your data.

