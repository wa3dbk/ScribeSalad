WEBVTT
Kind: captions
Language: en

00:00:00.410 --> 00:00:02.670
To understand threads more deeply, it's important to have a

00:00:02.670 --> 00:00:06.250
clear picture of a traditional process and its address space.

00:00:06.250 --> 00:00:08.880
Typically, at the lower addresses, a process will have the

00:00:08.880 --> 00:00:13.290
instructions followed by literals, that is values in the code, then

00:00:13.290 --> 00:00:17.910
statically allocated memory, really, global variables, and then the heap.

00:00:17.910 --> 00:00:19.850
Which will grow upwards. And then at the top of

00:00:19.850 --> 00:00:22.510
the address space and working its way down, we have

00:00:22.510 --> 00:00:25.750
the current stack of a process. Remember that the stack includes

00:00:25.750 --> 00:00:29.430
all the information local to a procedure. Parameters, local

00:00:29.430 --> 00:00:32.710
variables, and the address of the instruction to return to

00:00:32.710 --> 00:00:35.140
when the current procedure is over. In a multithreaded

00:00:35.140 --> 00:00:38.405
environment, each thread has it's own stack, but it shares

00:00:38.405 --> 00:00:40.540
everything else with the original main thread of the

00:00:40.540 --> 00:00:44.230
process. So, from a certain perspective, a thread acts like

00:00:44.230 --> 00:00:47.860
an entire process unto itself, and hence threaded programming

00:00:47.860 --> 00:00:51.000
isn't much different from a traditional programming. The difference comes

00:00:51.000 --> 00:00:53.690
from the fact that part of the memory is shared. On the

00:00:53.690 --> 00:00:56.880
one hand, this makes it very easy for threads to communicate. But

00:00:56.880 --> 00:00:59.190
it also means that extra care is needed to make sure that

00:00:59.190 --> 00:01:02.300
the threads coordinate as they use this memory. I should point out

00:01:02.300 --> 00:01:06.100
as well, that one can do parallel programming without having multiple threads.

00:01:06.100 --> 00:01:09.020
Each parallelizable task could have it's own process with it's own address

00:01:09.020 --> 00:01:11.160
space. And it could communicate with

00:01:11.160 --> 00:01:13.690
the other processes through message passing.

00:01:13.690 --> 00:01:16.040
In fact if we wanted to take advantage of a distributed system,

00:01:16.040 --> 00:01:19.020
where each processor has it's own separate physical memory, we would be

00:01:19.020 --> 00:01:21.160
forced to use this approach. As

00:01:21.160 --> 00:01:23.160
we think about multi-threaded programming, however, the

00:01:23.160 --> 00:01:26.400
paradigm explored in this lesson, is more appropriate to think of a shared

00:01:26.400 --> 00:01:29.790
memory system, where we have multiple cores sharing a common piece of memory.

