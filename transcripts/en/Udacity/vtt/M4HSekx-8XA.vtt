WEBVTT
Kind: captions
Language: en

00:00:00.640 --> 00:00:05.480
Okay you now have all the pieces you
need to finish the parallel algorithm.

00:00:05.480 --> 00:00:08.730
The only piece that's left
is this process level.

00:00:08.730 --> 00:00:11.170
Remember that bag splits
are very efficient.

00:00:11.170 --> 00:00:14.900
Therefore we should try to use our
favorite scheme, divide and conquer.

00:00:14.900 --> 00:00:17.850
So here's some pseudo code that
implements exactly a divide and

00:00:17.850 --> 00:00:19.180
conquer scheme.

00:00:19.180 --> 00:00:20.690
It's got two parts,

00:00:20.690 --> 00:00:24.060
first the input bag is big enough
then we do divide and conquer.

00:00:24.060 --> 00:00:25.350
Using splitting.

00:00:25.350 --> 00:00:29.420
If the bag is not big enough,
then we just fall back, essentially,

00:00:29.420 --> 00:00:31.210
to the sequential code.

00:00:31.210 --> 00:00:34.120
Now, the one difference is
this parallel for loop.

00:00:34.120 --> 00:00:35.290
So let's see how that works.

00:00:36.390 --> 00:00:38.240
So again, given a bag at level L,

00:00:38.240 --> 00:00:41.300
the first step is to split
it if the bag is big enough.

00:00:42.340 --> 00:00:45.050
Since we can process the elements
in any order we can use divide and

00:00:45.050 --> 00:00:46.420
conquer on the two halves.

00:00:47.420 --> 00:00:50.410
And I said the base case was the same
as the sequential algorithm, but

00:00:50.410 --> 00:00:52.680
I planned out this one difference.

00:00:52.680 --> 00:00:54.100
The difference is this neighbor loop.

00:00:55.180 --> 00:00:58.240
Notice that i'm iterating over
the neighbors using a parallel

00:00:58.240 --> 00:00:59.820
four instead of a conventional four.

00:00:59.820 --> 00:01:03.910
Now that might give you pause because
there might be tasks trying to update

00:01:03.910 --> 00:01:09.270
the same neighbor W, but since were
using a level synchronize album

00:01:09.270 --> 00:01:12.260
all those updates are going to be
doing this exact same thing which

00:01:12.260 --> 00:01:16.230
is writing the value of L
plus 1 into the D of W.

00:01:16.230 --> 00:01:19.910
So even though there's a data race here,
it's actually perfectly safe.

00:01:19.910 --> 00:01:22.780
Now the bag inserts are trickier.

00:01:22.780 --> 00:01:23.580
And for those,

00:01:23.580 --> 00:01:28.840
we're going to have to exploit the fact
that bags are logically associative, and

00:01:28.840 --> 00:01:33.550
therefore we can use these reducer hyper
objects that we talked about earlier.

00:01:33.550 --> 00:01:34.990
Okay, we're almost done.

00:01:34.990 --> 00:01:38.340
The last thing we need to do,
is analyze the cost.

00:01:38.340 --> 00:01:40.440
Now, the cost analysis is really tricky,
so

00:01:40.440 --> 00:01:44.750
if you want all of the gory details, I
refer you to the paper by Lyzer-shin and

00:01:44.750 --> 00:01:47.950
Shettle, which we posted
on the instructor's notes.

00:01:47.950 --> 00:01:50.990
For now, let's just sketch the analysis.

00:01:50.990 --> 00:01:54.270
First, I'm going to claim that
the algorithm is work-optimal.

00:01:54.270 --> 00:01:57.560
If you want to go into details again,
please see the paper.

00:01:57.560 --> 00:01:58.550
Now what about the span?

00:01:59.860 --> 00:02:02.795
The The span is effected by
a couple different factors.

00:02:02.795 --> 00:02:05.245
The first factor is
the number of levels,

00:02:05.245 --> 00:02:07.335
that's essentially
the outer most while loop.

00:02:07.335 --> 00:02:09.865
Of course the while
loop is not shown here

00:02:09.865 --> 00:02:13.375
that was the pseudo code that was on
the left side of the screen earlier.

00:02:13.375 --> 00:02:16.965
The second factor is
the span of process level.

00:02:16.965 --> 00:02:21.130
Now the first factor we said was
bounded by the diameter of the graph.

00:02:21.130 --> 00:02:22.720
let's call it little d.

00:02:22.720 --> 00:02:26.240
The span of process
level has three parts.

00:02:26.240 --> 00:02:30.660
There's the depth of the recursion,
there's the cost of splitting and

00:02:30.660 --> 00:02:32.350
then there's the cost of the base case.

00:02:33.490 --> 00:02:38.210
Now the recursion will be
logarithmic in the size of Fl.

00:02:38.210 --> 00:02:41.710
And since Fl can only be
the total number of vertices,

00:02:41.710 --> 00:02:45.790
in the worst case the depth of
recursion should be log in.

00:02:45.790 --> 00:02:50.070
The splitting we argue was log in,
now what about the base case?

00:02:50.070 --> 00:02:52.860
Now in the base case,
the size of Fl is a constant,

00:02:52.860 --> 00:02:56.380
because we have a constant cut-off
built in as we usually do,

00:02:56.380 --> 00:02:59.100
therefore we can bound
this by a constant.

00:02:59.100 --> 00:03:00.310
So let's put that all together.

00:03:00.310 --> 00:03:05.410
It will turn out that the cost is
basically bounded by the diameter and

00:03:05.410 --> 00:03:09.750
something that's polylogrithmic
in the size of the graph.

00:03:09.750 --> 00:03:11.740
And we love polylogrithmic,
so we're done.

00:03:13.630 --> 00:03:14.264
&gt;&gt; Yay.
[APPLAUSE]

