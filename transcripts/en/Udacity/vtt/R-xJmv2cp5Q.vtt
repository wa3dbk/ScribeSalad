WEBVTT
Kind: captions
Language: en

00:00:00.340 --> 00:00:02.640
So to avoid the space complexity in the

00:00:02.640 --> 00:00:06.280
Anderson's array based queueing lock, we're going to use a

00:00:06.280 --> 00:00:09.080
linked list representation for the queue. So the size

00:00:09.080 --> 00:00:11.500
of the queue is going to be exactly equal to

00:00:11.500 --> 00:00:15.070
the dynamic sharing of the lock. And this particular

00:00:15.070 --> 00:00:18.460
linked list based queueing lock algorithm is due to

00:00:18.460 --> 00:00:21.700
the authors of the paper that I've prescribed for

00:00:21.700 --> 00:00:25.520
you in the reading list. Namely Mellor-Crummey and Scott.

00:00:25.520 --> 00:00:28.150
And so, sometimes this particular queueing lock is

00:00:28.150 --> 00:00:31.930
also referred to as the MCS lock. So the

00:00:31.930 --> 00:00:35.870
lock data structure. The head of the queue is

00:00:35.870 --> 00:00:38.700
a dummy node. It is associated with every lock

00:00:38.700 --> 00:00:40.600
so every lock is going to have this dummy

00:00:40.600 --> 00:00:43.340
node associated with it and will initialize this dummy

00:00:43.340 --> 00:00:46.740
node to indicate there is no lock requesters presently

00:00:46.740 --> 00:00:50.560
for this particular lock. So, this pointer is pointing

00:00:50.560 --> 00:00:53.620
to nil. Nobody's got the lock. And there are two

00:00:53.620 --> 00:00:57.760
fields for every q node for a requester. So every new

00:00:57.760 --> 00:01:00.550
requester is going to get this q node. And in this q

00:01:00.550 --> 00:01:04.730
node there are two fields. One field is the guarded field.

00:01:04.730 --> 00:01:07.580
And guarded is basically a bullion that, which, and, and it

00:01:07.580 --> 00:01:09.730
says whether I have the lock or not. If it is

00:01:09.730 --> 00:01:11.890
true, I've got it. If I don't have, if, if it

00:01:11.890 --> 00:01:15.750
is false I don't have it yet. And the next field

00:01:15.750 --> 00:01:19.460
in the queue note is pointing to my successor

00:01:19.460 --> 00:01:21.410
in the queue. So if I came in and I

00:01:21.410 --> 00:01:23.790
requested the log, I get into the queue. And if

00:01:23.790 --> 00:01:26.900
a, if a successor comes along and requests a log,

00:01:26.900 --> 00:01:29.210
he gets queued up behind me. So that's this

00:01:29.210 --> 00:01:32.460
basic data structure, every queue note Is associated with a

00:01:32.460 --> 00:01:36.270
requester. The dummy node that we start with is representing

00:01:36.270 --> 00:01:40.550
the lock itself. And since we are implementing a queue,

00:01:40.550 --> 00:01:44.100
fairness is automatically assured. The requesters get

00:01:44.100 --> 00:01:46.520
queued up in the order in which they

00:01:46.520 --> 00:01:49.230
make the request, and so we have fairness

00:01:49.230 --> 00:01:51.868
built into this algorithm, just like the Anderson's

00:01:51.868 --> 00:01:58.090
array-based queue lock. The lock to, to

00:01:58.090 --> 00:02:00.860
nil indicating there are no requests yet. And

00:02:00.860 --> 00:02:05.880
let's say that I come along and request a lock. I don't have to wait because

00:02:05.880 --> 00:02:08.330
currently, there's nobody in the queue and therefore I get

00:02:08.330 --> 00:02:11.500
the lock right away. And, and I can go off

00:02:11.500 --> 00:02:14.810
into the critical section and start executing the critical section

00:02:14.810 --> 00:02:18.350
code, that is associated with this particular lock. So what

00:02:18.350 --> 00:02:21.260
I would have done, when I came in to make

00:02:21.260 --> 00:02:24.100
this lock request. Is to get this q node. And

00:02:24.100 --> 00:02:27.640
make the lock data structure point to me. And I'd

00:02:27.640 --> 00:02:31.510
also set the next pointer to null, to indicate there's nobody

00:02:31.510 --> 00:02:36.380
after me. And once I've done that, I know that I've got the lock. And

00:02:36.380 --> 00:02:40.350
I can go off in the critical section, and do whatever I need to do.

