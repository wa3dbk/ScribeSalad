WEBVTT
Kind: captions
Language: en

00:00:00.310 --> 00:00:02.810
So you remember generative
versus discriminative?

00:00:02.810 --> 00:00:05.490
So generative,
I build a model of each class, and

00:00:05.490 --> 00:00:07.040
then I compare it against all of them.

00:00:07.040 --> 00:00:11.130
Discriminative, I build the model of
the boundary between the classes.

00:00:11.130 --> 00:00:14.470
So we've talked a bunch about
building some discriminative ones,

00:00:14.470 --> 00:00:16.460
let's talk again about
building generative.

00:00:16.460 --> 00:00:19.540
How much you build
a reasonable generative model

00:00:19.540 --> 00:00:21.560
of each class of action?

00:00:21.560 --> 00:00:23.390
Okay.
Remember one of the reasons we might

00:00:23.390 --> 00:00:26.300
want generative models we might
not have a whole lot of examples.

00:00:26.300 --> 00:00:30.850
So a simple thing you might do is,
you've got a Hu-moment features space

00:00:30.850 --> 00:00:36.030
and we've got seven things applied
to two images so we get 14 numbers.

00:00:36.030 --> 00:00:40.990
So you could use some sort of Gaussian
or maybe it's a Gaussian with diagonal

00:00:40.990 --> 00:00:44.370
covariance so that you don't have to
worry about having too many points.

00:00:46.020 --> 00:00:49.080
And you might use a small number of
multiple mixture of Gaussians, but

00:00:49.080 --> 00:00:51.510
the idea is you would build a model,
a Gaussian model,

00:00:51.510 --> 00:00:53.340
for each of those classes.

00:00:53.340 --> 00:00:55.520
And then what you'll do is
you'll compare the likelihoods.

00:00:55.520 --> 00:01:00.830
You remember the likelihood was
probability of the data given the model.

00:01:00.830 --> 00:01:04.120
Right so, I build all the models
then when the new data comes in I

00:01:04.120 --> 00:01:06.950
evaluate the probability of the data.

00:01:06.950 --> 00:01:09.670
Then if I have a prior,

00:01:09.670 --> 00:01:11.730
then what I'm going to do is
I'm going to use Bayes rule.

00:01:11.730 --> 00:01:13.220
That's what it says here.

00:01:13.220 --> 00:01:17.442
That basically says I take my
likelihood, I multiply that by the prior

00:01:17.442 --> 00:01:22.920
of my model and that's proportional
to my, to my total posterior.

00:01:22.920 --> 00:01:23.890
If I don't have a prior,

00:01:23.890 --> 00:01:26.400
I might just select whichever
one has the highest likelihood.

00:01:26.400 --> 00:01:29.920
And by the way, if I don't have
enough data to even build some

00:01:29.920 --> 00:01:32.200
reasonable model of the densities.

00:01:32.200 --> 00:01:34.650
I might just use something
like nearest neighbor.

00:01:34.650 --> 00:01:38.720
So, the nice thing that we have is
that mo, the motion energy images,

00:01:38.720 --> 00:01:43.080
motion history images, they're
sort of little global descriptors.

00:01:44.150 --> 00:01:46.760
And the way you do this is you're
going to collect these statistics on

00:01:46.760 --> 00:01:50.340
these global descriptors in
order to do the recognition.

00:01:50.340 --> 00:01:53.660
One of the things that might
be a little less obvious is

00:01:53.660 --> 00:01:56.930
you can't actually recognize
the action till it's done.

00:01:56.930 --> 00:02:00.588
Right, so, I have this description
that goes back in time so

00:02:00.588 --> 00:02:04.820
if I'm watching a person sit down,
when their done sitting down,

00:02:04.820 --> 00:02:08.335
I now have that chunk of data that
represents them sitting down.

00:02:08.335 --> 00:02:12.200
Most activity recognition these days,
there's not a lot of focus on doing

00:02:12.200 --> 00:02:15.610
online recognition that as as
you're watching something happen.

00:02:15.610 --> 00:02:18.540
The idea of, is that they have
the whole sequence to begin with.

00:02:18.540 --> 00:02:21.420
But if you're actually are worried about
recognizing it as it happens, this idea

00:02:21.420 --> 00:02:26.330
that I can't recognize something till
it's totally done can be somewhat

00:02:26.330 --> 00:02:28.850
concerning and you have to think
about how you might deal with that.

