WEBVTT
Kind: captions
Language: en

00:00:00.140 --> 00:00:03.830
We have looked at several different metrics.

00:00:03.830 --> 00:00:08.730
We've looked at the accuracy, the sensitivity and specificity.

00:00:08.730 --> 00:00:12.500
And in general looked at a confusion matrix.

00:00:12.500 --> 00:00:16.910
Let's swing back to our classification models and calculate their accuracy.

00:00:18.080 --> 00:00:20.540
Let's run the piece of code here.

00:00:20.540 --> 00:00:26.560
Upon running this code, you will see accuracy for logistic regression,

00:00:26.560 --> 00:00:32.020
for random forest classifier, and a sampled vector classifier printed.

00:00:32.020 --> 00:00:34.980
In this case, we have used the score method

00:00:34.980 --> 00:00:40.000
of the model object to calculate these accuracy values.

00:00:40.000 --> 00:00:42.530
Let's look at the next block of code.

00:00:42.530 --> 00:00:47.320
This block of code prints out the confusion matrix for you.

00:00:47.320 --> 00:00:49.860
Let's run this block of code.

00:00:49.860 --> 00:00:55.180
Upon running this block of code, you will see the following confusion matrix.

00:00:55.180 --> 00:01:00.870
This code should give you a good idea of all the metrics we have talked about so

00:01:00.870 --> 00:01:03.840
far, and how to calculate them yourself.

00:01:03.840 --> 00:01:08.135
Take some time to go through this block of code yourself.

00:01:08.135 --> 00:01:14.290
Scikit-learn also comes with a method to print the confusion matrix.

00:01:14.290 --> 00:01:19.330
In this block of code, we'll use the scikit-learn's confusion matrix printer

00:01:19.330 --> 00:01:21.940
to see if we get the same values.

00:01:21.940 --> 00:01:25.620
Upon running, we see the following output.

00:01:25.620 --> 00:01:30.730
We leave it up to you to verify that the numbers are the same as

00:01:30.730 --> 00:01:33.790
what we obtained through our own calculations.

00:01:34.830 --> 00:01:38.460
Refer to the result of the confusion matrix you just obtained.

00:01:39.670 --> 00:01:43.500
Now calculate the following for the logistic regression.

00:01:43.500 --> 00:01:46.900
The sensitivity and the specificity.

00:01:46.900 --> 00:01:51.690
Enter your answers to two decimal places in these boxes.

00:01:51.690 --> 00:01:56.630
Remember, sensitivity is the number of true positives divided by

00:01:56.630 --> 00:01:58.360
all actual positives, and

00:01:58.360 --> 00:02:03.750
specificity is the number of true negatives divided by all actual negatives.

00:02:03.750 --> 00:02:07.280
It is okay if you look back at your notes for the formula for

00:02:07.280 --> 00:02:08.940
sensitivity and specificity.

