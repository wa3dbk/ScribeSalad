WEBVTT
Kind: captions
Language: en

00:00:00.190 --> 00:00:02.570
So, in summary about generative models,

00:00:02.570 --> 00:00:04.939
there are some good things about it,
right?

00:00:04.939 --> 00:00:08.650
It's pure probability, right, very,
very clean probabilistic thing.

00:00:08.650 --> 00:00:12.180
In fact, it's been known for a very
long time, which should give you a hint

00:00:12.180 --> 00:00:15.160
that it's not going to be
the most powerful method used,

00:00:15.160 --> 00:00:20.480
because it comes from a time when
computers were nonexistent or scarce.

00:00:20.480 --> 00:00:24.010
And we had to use a lot of
mathematical reasoning,

00:00:24.010 --> 00:00:25.940
pure mathematics in
order to do the work.

00:00:25.940 --> 00:00:29.610
But it is, it says here,
firm probabilistic grounding.

00:00:29.610 --> 00:00:32.259
It allows you to use your priors, so

00:00:32.259 --> 00:00:35.770
if you have priors,
maybe your context gives you a prior.

00:00:35.770 --> 00:00:37.230
I know I'm in a bedroom, so

00:00:37.230 --> 00:00:41.830
the probability of seeing a lamp is
a lot higher than if I'm in a garage,

00:00:41.830 --> 00:00:45.380
okay, that kind of thing, so
I can have a prior built into it.

00:00:45.380 --> 00:00:48.080
One that's in yellow here, actually,
there's two of them that are yellow

00:00:48.080 --> 00:00:50.050
because I think they
actually are important.

00:00:50.050 --> 00:00:52.940
One is that because you're doing this
parametric modeling of continuous

00:00:52.940 --> 00:00:56.420
functions, you can actually get away
with using a pretty small amount of data

00:00:56.420 --> 00:00:59.740
compared to other methods we're going to
look at later, the discriminate methods.

00:00:59.740 --> 00:01:02.200
So that's one, and
the second good thing about it is

00:01:03.300 --> 00:01:07.780
your models are about each category,
and just about the category.

00:01:07.780 --> 00:01:10.570
So when you tell me
about some new category,

00:01:10.570 --> 00:01:13.180
I just have to learn a model for
that category.

00:01:13.180 --> 00:01:16.150
I don't have to play with this model.

00:01:16.150 --> 00:01:20.010
Whereas if I'm trying to learn how to
distinguish between an a and a b and

00:01:20.010 --> 00:01:22.790
an a and a c, now you tell me about d's?

00:01:22.790 --> 00:01:25.610
I have to worry about
a's versus d's as well.

00:01:25.610 --> 00:01:28.230
So when you add in new categories,
and you're trying to discriminate,

00:01:28.230 --> 00:01:31.090
you often have to worry about
a lot of different categories.

00:01:31.090 --> 00:01:35.320
In the generative model, I just
build a model for that new category.

00:01:35.320 --> 00:01:38.210
There are some other advantages of
generative models that we haven't

00:01:38.210 --> 00:01:38.790
talked about.

00:01:38.790 --> 00:01:41.620
You can use unlabeled
data in interesting ways.

00:01:41.620 --> 00:01:43.880
You can also use it to generate data,
right?

00:01:43.880 --> 00:01:46.768
So if I say something is
distributed over a Gaussian,

00:01:46.768 --> 00:01:50.956
I can actually make more examples, and
there are times when that's useful.

00:01:50.956 --> 00:01:52.740
So that would be all the good news.

00:01:52.740 --> 00:01:55.920
What always follows the good
news is the not so good news.

00:01:55.920 --> 00:01:58.650
So, where did you get those priors?

00:01:58.650 --> 00:02:02.610
Okay, so again, do you go to Greece,
do you go to the Sears Prior Store?

00:02:02.610 --> 00:02:04.930
The sensitivity to priors
really matters, and

00:02:04.930 --> 00:02:07.370
the priors can be affected
by things like context.

00:02:07.370 --> 00:02:09.800
There's this other thing
that's also kind of annoying.

00:02:09.800 --> 00:02:13.370
I'm modeling skin and I've got not-skin.

00:02:13.370 --> 00:02:15.528
Well, skin you might say
is a plausible model.

00:02:15.528 --> 00:02:16.660
Not-skin?

00:02:16.660 --> 00:02:20.790
Modeling not-skin is kind of
a weird thing, all right?

00:02:20.790 --> 00:02:25.470
What I really want to do is model
sort of the, the boundary between all

00:02:25.470 --> 00:02:28.410
the stuff that's skin and
everything else that's out there.

00:02:28.410 --> 00:02:31.240
And by the way, a lot of the stuff
that's out there doesn't look anything

00:02:31.240 --> 00:02:34.240
like skin at all, so that stuff is easy.

00:02:34.240 --> 00:02:37.680
What I really need to worry about are
the things that are kind of like skin,

00:02:37.680 --> 00:02:38.580
but aren't.

00:02:38.580 --> 00:02:40.080
In fact, that's the next example.

00:02:40.080 --> 00:02:45.490
It says, the example hard cases aren't
special, and they should be, right?

00:02:45.490 --> 00:02:50.100
So I'm trying to recognize you know,
rattlesnakes in the brush.

00:02:50.100 --> 00:02:53.180
I don't have to worry about
what Maseratis look like.

00:02:53.180 --> 00:02:57.000
I do have to worry about the difference
between what rattlesnakes look like, and

00:02:57.000 --> 00:03:02.040
maybe different kinds of grass, because
there's a tight similarity between them.

00:03:02.040 --> 00:03:06.000
So this idea that modeling the hard
cases is really what's important.

00:03:06.000 --> 00:03:09.590
And in fact, I think that's what's most
important about discriminative learning.

00:03:09.590 --> 00:03:12.220
And then the last thing is, if you have
lots, and lots, and lots, and lots, and

00:03:12.220 --> 00:03:14.170
lots of data, it doesn't really help.

00:03:14.170 --> 00:03:15.600
If I'm modeling my world as a,

00:03:15.600 --> 00:03:20.030
sort of a single distribution,
once I have enough data, doesn't really,

00:03:20.030 --> 00:03:22.950
you know, I can fit some nice
mixture of Gaussians, I'm done.

00:03:22.950 --> 00:03:25.420
It's not helping me comparing
against other elements.

00:03:25.420 --> 00:03:29.230
So, it's not really
leveraging having large data.

00:03:29.230 --> 00:03:31.380
So those are the downsides
of generative models.

