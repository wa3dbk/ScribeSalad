WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.716
One issue that can come up if we write

00:00:01.736 --> 00:00:03.532
a really good random test-case generator

00:00:03.532 --> 00:00:05.221
is that we can be overwhelmed by

00:00:05.221 --> 00:00:06.980
the success of our own bug-finding effort.

00:00:06.990 --> 00:00:08.766
On some level we should be so 
lucky to have this problem,

00:00:08.766 --> 00:00:10.794
but on the other hand if you take 
a large software project

00:00:10.794 --> 00:00:12.954
that's never been subjected 
to random testing,

00:00:12.954 --> 00:00:15.074
and hit it with a sophisticated
random tester

00:00:15.100 --> 00:00:17.456
it's not at all unexpected that you'll be

00:00:17.456 --> 00:00:19.332
overwhelmed by the number of bugs.

00:00:19.332 --> 00:00:21.000
What'll happen is you'll start 
a random testing run.

00:00:21.000 --> 00:00:22.800
You will leave for the weekend and

00:00:22.800 --> 00:00:25.000
next time you come in 
there might be 250 bugs.

00:00:25.000 --> 00:00:27.000
The way we want to visualize 
the situation is like this.

00:00:27.000 --> 00:00:32.560
We have the input domain of course and 
all I'm going to show here are inputs that found bugs.

00:00:32.560 --> 00:00:33.900
There's a bunch of them.

00:00:33.900 --> 00:00:37.000
What we have is a fundamental quandary, 
which is the question

00:00:37.000 --> 00:00:41.000
do we have 250 test inputs that all, 
for one reason or another,

00:00:41.000 --> 00:00:44.000
happen to map to the same bugging output,

00:00:44.000 --> 00:00:47.000
or on the other hand, do we have a situation 
where we found, perhaps,

00:00:47.000 --> 00:00:49.000
250 different bugs.

00:00:49.000 --> 00:00:52.000
Without looking in more detail at what's going on 
there's no way we can tell.

00:00:52.000 --> 00:00:55.000
Most likely--almost certainly--the truth is in the middle.

00:00:55.000 --> 00:00:58.000
Almost certainly we found 10 bugs or maybe 50 bugs,

00:00:58.000 --> 00:01:01.000
but we probably didn't get so lucky as to find 250 bugs.

00:01:01.000 --> 00:01:04.000
We probably weren't so unlucky as to trigger 
the same bug 250 times,

00:01:04.000 --> 00:01:06.000
although, of course, that kind of thing does happen.

00:01:06.000 --> 00:01:08.000
There are basically two ways out of this problem.

00:01:08.000 --> 00:01:11.000
The first solution--pick a bug and report it. 
It's totally irrelevant which bug it is.

00:01:11.000 --> 00:01:12.600
It could be a random bug.

00:01:12.600 --> 00:01:15.000
Most likely what we'd want to do is 
eyeball them a little bit somehow

00:01:15.000 --> 00:01:17.000
and see which one seems the most serious. 
It doesn't matter.

00:01:17.000 --> 00:01:20.000
Let's say we report this test case here, 
so that goes to our developers.

00:01:20.000 --> 00:01:22.000
What they're going to do is fix it, of course.

00:01:22.000 --> 00:01:26.000
This buggy part of the output space 
goes away in the next version of the system.

00:01:26.000 --> 00:01:28.000
Now we don't have range of the system.

00:01:28.000 --> 00:01:31.000
We have range prime, which is just 
the range of the next version.

00:01:31.000 --> 00:01:33.850
So, we still have exactly the same input space

00:01:33.850 --> 00:01:36.000
but the behavior of the software under test 
has changed a little bit.

00:01:36.000 --> 00:01:37.750
Now something interesting happens.

00:01:37.750 --> 00:01:41.000
Not only did that particular failure go away, 
but perhaps some of the other ones did.

00:01:41.000 --> 00:01:45.000
Perhaps all of these over here stopped being inputs 
that trigger failures anymore.

00:01:45.000 --> 00:01:48.000
Of course that's great, because it's nice 
to see that they fixed a bug

00:01:48.000 --> 00:01:50.000
that covers such a large part of the input space.

00:01:50.000 --> 00:01:53.000
On the other hand, another possibility is all of the 
remaining bug-triggering inputs

00:01:53.000 --> 00:01:55.000
that we found still trigger bugs, and so what do we do?

00:01:55.000 --> 00:01:58.000
Well, of course, we just go ahead and report another bug.

00:01:58.000 --> 00:02:00.000
This strategy will keep working.

00:02:00.000 --> 00:02:02.000
As soon as we get a new version of the system 
that fixes a bug we've reported,

00:02:02.000 --> 00:02:03.510
we can just do another one.

00:02:03.510 --> 00:02:04.940
This isn't a bad mode of operation.

00:02:04.940 --> 00:02:08.000
What this works for is 
basically for smallish systems

00:02:08.000 --> 00:02:10.000
where bugs can be fixed rather quickly, 
there's no problem at all

00:02:10.000 --> 00:02:12.000
reporting one bug at a time.

00:02:12.000 --> 00:02:15.000
On the other hand, if the people 
fixing bugs have a slow fix cycle--

00:02:15.000 --> 00:02:19.000
let's say we're only testing actual released 
versions of Microsoft Word, for example--

00:02:19.000 --> 00:02:21.000
we're only getting a new version 
every couple of years.

00:02:21.000 --> 00:02:23.000
If they fix one bug in Microsoft Word 
every couple of years,

00:02:23.000 --> 00:02:26.000
the question is how long do we think 
that'll take for them to arrive at

00:02:26.000 --> 00:02:27.333
a correct version of Microsoft Word?

00:02:27.333 --> 00:02:30.016
The answer, of course, is they never will, 
because they're putting bugs in

00:02:30.016 --> 00:02:33.000
faster than we would take them out, 
using a one-bug-at-a-time model.

00:02:33.000 --> 00:02:36.000
This can easily be the case for real 
software products.

00:02:36.000 --> 00:02:40.000
If that's the situation, if reporting one
bug at a time doesn't work,

00:02:40.000 --> 00:02:43.327
we're forced to use a different strategy. 
I call that bug triage.

