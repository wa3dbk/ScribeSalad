WEBVTT
Kind: captions
Language: en

00:00:00.580 --> 00:00:04.180
We just saw an example where visual spatial knowledge by itself,

00:00:04.180 --> 00:00:07.630
suffices too in our logical reasoning under certain conditions.

00:00:07.630 --> 00:00:12.050
Now let us look at a different problem. There suddenly are situations where we

00:00:12.050 --> 00:00:16.470
might want AI agents to be able to extract [UNKNOWN] presentations.

00:00:16.470 --> 00:00:20.423
Your projects one, two, and three did exactly that. One task,

00:00:20.423 --> 00:00:24.926
where AI agent might want build proper [INAUDIBLE] representations out of

00:00:24.926 --> 00:00:30.055
regional spatial knowledge is when an AI is given a design drawing. So

00:00:30.055 --> 00:00:34.340
here is a vector graphics drawing of a simple engineering system.

00:00:34.340 --> 00:00:38.490
Perhaps some of you can recognize what is happening here. This is a cylinder and

00:00:38.490 --> 00:00:43.550
this a piston. This is the rod of the piston. The piston moves. Left and

00:00:43.550 --> 00:00:48.740
right. The other end of the rod is connected to a crankshaft.

00:00:48.740 --> 00:00:52.830
As this piston moves left and right, this particular crankshaft starts moving

00:00:52.830 --> 00:00:58.430
anticlockwise. This device translates linear motion into rotational motion.

00:00:58.430 --> 00:01:02.178
I just gave you a causal account. Although because [INAUDIBLE] only implicit in

00:01:02.178 --> 00:01:06.940
this [INAUDIBLE] spatial knowledge. You and I were able to extract a causal

00:01:06.940 --> 00:01:12.220
account out of this. How did we do it? How can we help AI agents do it?

00:01:13.390 --> 00:01:18.650
At present if you were to make a CAD drawing using any CAD tool that you want,

00:01:18.650 --> 00:01:23.410
the machine does not understand the drawing. But can machines of tomorrow

00:01:23.410 --> 00:01:28.690
understand drawings by automatically building these causal models out of them?

00:01:28.690 --> 00:01:32.610
Put it another way. There is a story that has been captured in this particular

00:01:32.610 --> 00:01:39.450
diagram. Can a machine automatically extract the story from this diagram?

00:01:39.450 --> 00:01:44.630
In 2007, Patrick Yaner built an AI program called Archytas. Archytas was

00:01:44.630 --> 00:01:48.520
able to extract causal models out of vector graphics drawings of the kind that I

00:01:48.520 --> 00:01:51.910
just showed you. This figure is coming from paper and Archytas and

00:01:51.910 --> 00:01:56.350
hence the form of the figure. We'll have a pointer to the paper in the notes.

00:01:56.350 --> 00:02:02.570
This is how Archytas works. It began with a library of source drawings.

00:02:02.570 --> 00:02:06.880
These were drawings that we already knew about. For each drawing order it

00:02:06.880 --> 00:02:10.830
knew about it already had done the segmentation. The basic shapes for

00:02:10.830 --> 00:02:15.520
example might be things like circles and the composite shapes which were then

00:02:15.520 --> 00:02:20.360
labeled like piston and cylinder. Then a behavioral model or

00:02:20.360 --> 00:02:24.310
a causal model which said what happens when the piston moves in and

00:02:24.310 --> 00:02:29.201
out, namely the crankshaft turns. And then a functional specification we've said

00:02:29.201 --> 00:02:33.170
this particular system can work in linear motion into rotational motion. So

00:02:33.170 --> 00:02:38.740
there was a lot of knowledge with each previous drawing that Archytas already

00:02:38.740 --> 00:02:43.610
had seen. All of this knowledge was put into a library. When a new drawing was

00:02:43.610 --> 00:02:47.400
input into Archytas then it generated line segments and arcs and

00:02:47.400 --> 00:02:52.480
intersections from it. And then, it started mapping them to the lines and

00:02:52.480 --> 00:02:55.300
segments and arcs of previously known drawings.

00:02:56.320 --> 00:03:01.350
Retrieve the drawing that was the closest match in drawing to the new drawing.

00:03:01.350 --> 00:03:05.120
And then started transferring basic shapes, and then composite shapes, and

00:03:05.120 --> 00:03:09.920
it transferred each element through this abstraction hierarchy all the way up to

00:03:09.920 --> 00:03:15.201
the functional level. As an example, if Archytas library contains piston and

00:03:15.201 --> 00:03:18.570
crankshaft drawings like this along with causal functional models for

00:03:18.570 --> 00:03:22.420
them, then given a new drawing of a piston and

00:03:22.420 --> 00:03:26.400
crankshaft device Archytas will then be able to assemble a causal

00:03:26.400 --> 00:03:31.207
functional model for the new drawing. Thus Archytas extracted causal

00:03:31.207 --> 00:03:34.400
information from which spatial presentations to analogical reasoning.

