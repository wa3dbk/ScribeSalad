WEBVTT
Kind: captions
Language: en

00:00:00.280 --> 00:00:02.605
So let me briefly introduce here the idea of cache

00:00:02.605 --> 00:00:04.180
aware scheduling, when you have

00:00:04.180 --> 00:00:07.290
these multithreaded multi-core processors. And to

00:00:07.290 --> 00:00:10.800
make things concrete, let's assume that you have a pool of

00:00:10.800 --> 00:00:13.620
ready threads, and in this case I'm going to tell you that

00:00:13.620 --> 00:00:15.720
the pool of ready threads I have is 32. So I

00:00:15.720 --> 00:00:19.566
have 32 ready threads and I have a four way multi-core

00:00:19.566 --> 00:00:22.020
per CPU. Meaning that there are four cores in the CPU,

00:00:22.020 --> 00:00:25.360
and each core is four way hardware multithreaded. Or in other

00:00:25.360 --> 00:00:27.850
words, at any point of time the operating system

00:00:27.850 --> 00:00:31.310
can choose from this pool of ready threads, 16

00:00:31.310 --> 00:00:35.560
threads to be run on the processor. Because that's

00:00:35.560 --> 00:00:38.710
the number of hardware multi-threads that are available if

00:00:38.710 --> 00:00:41.250
you pool together all the four cores. So each

00:00:41.250 --> 00:00:45.075
core has four multi, hardware multi-threads, together they have

00:00:45.075 --> 00:00:50.520
1,600 threads that can be run on the CPU at any point of time. And the, the job

00:00:50.520 --> 00:00:52.960
of the operating scheduler is to pick from

00:00:52.960 --> 00:00:56.270
the available pool of ready threads, 16 candidates

00:00:56.270 --> 00:00:59.780
to be scheduled on the CPU. So how

00:00:59.780 --> 00:01:02.560
does the operating system choose the 16 threads

00:01:02.560 --> 00:01:08.210
to be run on the CPU at any point of time? What the operating system should

00:01:08.210 --> 00:01:11.740
try to do, is it should call schedule

00:01:11.740 --> 00:01:15.730
some number of cache frugal threads, and some number

00:01:15.730 --> 00:01:22.070
of cache hungry threads on the different course so that together the sum of all

00:01:22.070 --> 00:01:26.500
the cache hungriness of the 16 threads that

00:01:26.500 --> 00:01:29.080
are executing at any point of time in

00:01:29.080 --> 00:01:36.170
the CPU is less than the total size of the L2 cache. And as I said,

00:01:36.170 --> 00:01:40.980
L2 cache in this simple example, I gave you two levels of caching, a caching

00:01:40.980 --> 00:01:43.630
that is associated with each of these cores, and an

00:01:43.630 --> 00:01:47.220
L2 cache that is sitting outside of these cores, but

00:01:47.220 --> 00:01:49.830
it is, it is common to all the four cores.

00:01:49.830 --> 00:01:52.450
But of course, you can generalize this and say it is

00:01:52.450 --> 00:01:55.000
the last level cache, or in other words, you want to

00:01:55.000 --> 00:01:58.190
make sure that this, the universe of threads that are scheduled

00:01:58.190 --> 00:02:01.740
at any point of time, on the CPU, the sum

00:02:01.740 --> 00:02:06.230
total of the cache requirements of the universe of thread schedule

00:02:06.230 --> 00:02:09.830
on the processor, is less than the total capacity

00:02:09.830 --> 00:02:12.578
of the last level cache in the CPU. Because

00:02:12.578 --> 00:02:14.598
if it's missing the last level cache on the

00:02:14.598 --> 00:02:17.750
CPU, you're going outside the chip, out of memory,

00:02:17.750 --> 00:02:20.578
long latency operation, bad news. That's the thing that

00:02:20.578 --> 00:02:23.870
you're trying to do. So we're going to categorize threads

00:02:23.870 --> 00:02:27.935
as either cache frugal threads, or cache hungry threads.

00:02:27.935 --> 00:02:31.260
So cache frugal threads are one in, ones that require

00:02:31.260 --> 00:02:34.650
only a small portion of the cache to keep them

00:02:34.650 --> 00:02:36.940
happy. On the other hand, a cache hungry thread is

00:02:36.940 --> 00:02:39.640
one that requires a huge amount of cache space in

00:02:39.640 --> 00:02:43.100
order to keep it happy, meaning that the working set of

00:02:43.100 --> 00:02:45.980
cache hungry threads is much bigger than the working set

00:02:45.980 --> 00:02:49.080
of cache frugal threads. Now how do we know which

00:02:49.080 --> 00:02:52.500
threads are cache frugal and which threads are cache hungry?

00:02:52.500 --> 00:02:56.570
Well that's something that we can know only by profiling the

00:02:56.570 --> 00:02:59.310
execution of the threads overtime. So the assumption is

00:02:59.310 --> 00:03:02.420
that many of these threads get to run on

00:03:02.420 --> 00:03:05.400
the CPU over and over again, so overtime you

00:03:05.400 --> 00:03:09.070
can profile these threads and figure out whether a

00:03:09.070 --> 00:03:12.230
particular thread belongs to this category of cache frugal

00:03:12.230 --> 00:03:15.390
thread or this category of cache hungry thread. And

00:03:15.390 --> 00:03:18.520
the criterion that you want to use in picking the

00:03:18.520 --> 00:03:21.610
set of threads to be populated in the CPU

00:03:21.610 --> 00:03:25.920
at any point of time from the pool of available threads, is to make sure that

00:03:25.920 --> 00:03:28.970
the sum of the cache requirement of all

00:03:28.970 --> 00:03:30.710
the cache frugal threads is that there are

00:03:30.710 --> 00:03:35.470
N cache frugal threads and there are M cache hungry

00:03:35.470 --> 00:03:41.320
threads, then the cumulative cache requirement of all the threads

00:03:41.320 --> 00:03:46.700
put together is less than the total size of the L2 cache.

00:03:46.700 --> 00:03:49.380
And then I told you, we can generalize this L2 cache

00:03:49.380 --> 00:03:51.750
to the last level cache, that is the cache that is

00:03:51.750 --> 00:03:55.446
sitting at the last level inside the CPU beyond which you

00:03:55.446 --> 00:03:58.030
had to go out of the chip, go out to memory,

00:03:58.030 --> 00:04:01.950
and so that last level cache becomes the determinant in saying

00:04:01.950 --> 00:04:06.180
whether the size of that last level cache is within bounds

00:04:06.180 --> 00:04:09.500
of the cache requirements of all the threads that I want to

00:04:09.500 --> 00:04:12.100
schedule. So this is the set of threads that I want to pick,

00:04:12.100 --> 00:04:15.090
where, in this particular case, since the total

00:04:15.090 --> 00:04:17.700
number of hardware threads that I have available to

00:04:17.700 --> 00:04:19.910
me is 16, I want to make sure that

00:04:19.910 --> 00:04:23.330
M, the cache hungry threads, N, the cache frugal

00:04:23.330 --> 00:04:27.890
threads, is 16 and this inequality is satisfied

00:04:27.890 --> 00:04:30.630
as well. So that's what we want to shoot

00:04:30.630 --> 00:04:37.330
for in picking the set of threads to run on the processor at any point of time.

00:04:37.330 --> 00:04:40.070
I mentioned that we have to profile these

00:04:40.070 --> 00:04:43.090
threads, or monitor these threads as they're executing

00:04:43.090 --> 00:04:46.230
in order to figure out their cache occupancy

00:04:46.230 --> 00:04:49.060
over time so that we can categorize these

00:04:49.060 --> 00:04:52.590
threads as cache frugal or cache hungry, and

00:04:52.590 --> 00:04:56.450
the more information the scheduler has, the better

00:04:56.450 --> 00:05:00.570
decision it can take in terms of scheduling.

00:05:00.570 --> 00:05:02.400
Be we have to be careful about that.

00:05:02.400 --> 00:05:05.340
In order for the system to do this monitoring

00:05:05.340 --> 00:05:09.430
and profiling, clearly, the operating system has to lose some

00:05:09.430 --> 00:05:12.670
work in the middle of these threads doing useful

00:05:12.670 --> 00:05:17.200
work. And I always maintain that a good operating system

00:05:17.200 --> 00:05:19.670
gives you the resources that you need and gets

00:05:19.670 --> 00:05:22.270
out of the way very quickly. And so, you have

00:05:22.270 --> 00:05:24.770
to be very careful about the amount of time

00:05:24.770 --> 00:05:27.480
that the operating system takes in terms of doing this

00:05:27.480 --> 00:05:30.650
kind of monitoring and profiling, and this information is

00:05:30.650 --> 00:05:33.550
useful in scheduling decisions, but it should not be

00:05:33.550 --> 00:05:37.390
disrupting useful work that these guys have to do

00:05:37.390 --> 00:05:39.903
in the first place. Or in other words, the

00:05:39.903 --> 00:05:43.676
overhead for information gathering has to be kept minimal

00:05:43.676 --> 00:05:46.140
so that the OS does not consume too many

00:05:46.140 --> 00:05:49.605
cycles in doing this kind of overhead work accounting

00:05:49.605 --> 00:05:53.480
for making better decisions in, in terms of scheduling.

