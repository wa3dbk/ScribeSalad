WEBVTT
Kind: captions
Language: en

00:00:00.640 --> 00:00:03.020
As we've seen, in order for a cache to be effective

00:00:03.020 --> 00:00:05.480
the hit rate must be high. That is, we need to

00:00:05.480 --> 00:00:08.800
be able to anticipate what data the process will need next.

00:00:08.800 --> 00:00:11.080
Ideally, we would be able to look ahead in the code and

00:00:11.080 --> 00:00:14.550
plan ahead, but so far this has proved impractical. Instead ,we

00:00:14.550 --> 00:00:17.560
used the heuristic of locality. That is ,we assume that if an

00:00:17.560 --> 00:00:21.930
application accesses one memory address, then it will need nearby addresses

00:00:21.930 --> 00:00:25.660
soon. Sort of like, how a psychologist says that the best predictor

00:00:25.660 --> 00:00:28.910
of future behavior is past behavior. Experts like

00:00:28.910 --> 00:00:33.080
to distinguish ,two types of locality. Temporal and spacial.

00:00:33.080 --> 00:00:35.470
Temporal refers to the tendency to refer to the

00:00:35.470 --> 00:00:39.050
same memory close and time. The spacial, refers to

00:00:39.050 --> 00:00:41.440
the tendency to access memory that is close

00:00:41.440 --> 00:00:44.890
together in terms of address. Typical cache policies exploit

00:00:44.890 --> 00:00:48.340
both kinds. It exploits temporal locality by putting the

00:00:48.340 --> 00:00:50.800
data in the cache right after you use it,

00:00:50.800 --> 00:00:52.740
thinking that you're likely to use it again soon.

00:00:52.740 --> 00:00:56.160
It exploits spatial by putting not just the memory

00:00:56.160 --> 00:00:58.810
address that you access, but putting the whole block

00:00:58.810 --> 00:01:01.940
into the cache. Blocks, I should explain, are a division

00:01:01.940 --> 00:01:06.490
of memory by relatively small amounts, often 64 bytes.

00:01:06.490 --> 00:01:09.950
This one block is from zero to 64. Another

00:01:09.950 --> 00:01:13.050
from 64 to 128, etcetera. If we access the

00:01:13.050 --> 00:01:15.930
memory location, 87. Then we reason that we are likely

00:01:15.930 --> 00:01:18.460
to use addresses close to this one. And so ,we put

00:01:18.460 --> 00:01:22.360
the whole block, from 64 to 128, in the cache. Now, you

00:01:22.360 --> 00:01:24.780
may ask yourself, why do we put the block of memory into

00:01:24.780 --> 00:01:29.380
the cache instead of something more consistent? Say, maybe, the previous 32

00:01:29.380 --> 00:01:32.430
bytes, and the next 31 bytes, or something like that. After

00:01:32.430 --> 00:01:35.060
all with blocks, sometimes most of the data we pull in will

00:01:35.060 --> 00:01:38.210
be higher in the address space, and sometimes most of it will

00:01:38.210 --> 00:01:41.110
be lower. Well the answer is that, it makes it much easier

00:01:41.110 --> 00:01:44.550
to figure out what is in the cache and where. The size of the cache

00:01:44.550 --> 00:01:49.300
block is always a power of two, so we can read which cache block we

00:01:49.300 --> 00:01:50.946
belong to just by looking at the

00:01:50.946 --> 00:01:54.220
higher-order bits. The lower-order bits are called the

00:01:54.220 --> 00:01:58.370
offset And tell us where within a given cache block the data we want is.

