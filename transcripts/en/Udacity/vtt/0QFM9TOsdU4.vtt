WEBVTT
Kind: captions
Language: en

00:00:00.054 --> 00:00:04.431
Okay, so here we've run NVVP on the function again.

00:00:04.431 --> 00:00:10.334
I'll zoom in on these second functions. Here's our transpose per element tile.

00:00:10.334 --> 00:00:12.741
This is the kernel we just wrote.

00:00:12.741 --> 00:00:19.369
And as you can see, it's running with 32 by 32 thread blocks, each of which has 32 by 32 threads.

00:00:19.369 --> 00:00:25.482
And sure enough we're achieving a 100% global load efficiency and 100% global store efficiency.

00:00:25.482 --> 00:00:29.699
And yet, our DRAM utilization has actually gone down slightly.

00:00:29.699 --> 00:00:34.589
So whats going on? Why is our achieved bandwidth still so low?

00:00:34.589 --> 00:00:40.509
The answer is going to come down to this statistic here--Shared Memory Replay Overhead.

00:00:40.509 --> 00:00:43.979
But before we get into the details of Shared Memory Replay Overhead,

00:00:43.979 --> 00:00:47.110
what that means and what to do about it, I want to back up for a little bit

00:00:47.110 --> 00:00:52.192
and talk about a general principle of how do we make the GPU fast.

