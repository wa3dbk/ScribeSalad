WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.139
In the next homework, we're going to implement some pretty cool image blurring techniques.

00:00:03.139 --> 00:00:05.920
You now know enough that you can go and implement that program

00:00:05.920 --> 00:00:11.254
on a massively parallel GPU, and you'd get a correct answer, and it would be pretty fast.

00:00:11.254 --> 00:00:12.337
But we can do better.

00:00:12.337 --> 00:00:17.354
Now we have all the ingredients to start talking about writing efficient parallel programs in CUDA.

00:00:17.354 --> 00:00:19.417
For now I'm only going to talk about high level strategies.

00:00:19.417 --> 00:00:23.169
We're going to have a whole unit later on about detailed optimization approaches

00:00:23.169 --> 00:00:25.793
to help you really squeeze the maximum performance out of the GPU.

00:00:25.793 --> 00:00:30.317
So think of this as a preview that covers some of the really important things high level things that you have

00:00:30.317 --> 00:00:32.619
to keep in mind when you are writing a GPU program.

00:00:32.619 --> 00:00:36.513
So the first thing to keep in mind is that GPUs have really incredible computational horsepower.

00:00:36.513 --> 00:00:42.100
A high-end GPU can do over 3 trillion math operations per second.

00:00:42.100 --> 00:00:45.680
You'll sometimes see this written down as T FLOPS, okay?

00:00:45.680 --> 00:00:48.494
A FLOPS stands for a Floating Point Operation Per Second.

00:00:48.494 --> 00:00:54.961
T FLOPS is Tera-FLOPS, and minor GPU's can do over 3 trillion of these every second at the high end.

00:00:54.961 --> 00:00:58.191
But all that power is wasted if the arithmetic units that are doing the math

00:00:58.191 --> 00:01:02.631
need to spend their time waiting while the system fetches the operands from memory.

00:01:02.631 --> 00:01:07.210
So the first strategy we need to keep in mind is to maximize arithmetic intensity.

00:01:07.210 --> 00:01:13.404
Arithmetic intensity is basically the amount of math we do per amount of memory that we access.

00:01:13.404 --> 00:01:17.513
So we can increase arithmetic intensity by making the numerator bigger

00:01:17.513 --> 00:01:19.657
or by making the denominator smaller.

00:01:19.657 --> 00:01:25.188
So this corresponds to maximizing the work we do per thread or minimizing the memory we do per thread.

00:01:25.188 --> 00:01:27.489
And let's be more exact about what we mean here.

00:01:27.489 --> 00:01:30.968
Really what we're talking about is maximizing the number

00:01:30.968 --> 00:01:34.497
of useful compute operations per thread.

00:01:34.497 --> 00:01:40.243
Really what we care about here is minimizing the time spent on memory per thread.

00:01:40.243 --> 00:01:44.772
And I phrased this carefully because it is not the total number of memory operations that we care about

00:01:44.772 --> 00:01:46.962
and it's not the total amount of memory that comes

00:01:46.962 --> 00:01:49.310
and goes in the course of the thread executing its program.

00:01:49.310 --> 00:01:51.215
It's how long it takes us to do that,

00:01:51.215 --> 00:01:54.189
so there are a lot of ways to spend less time on memory accesses.

00:01:54.189 --> 00:01:55.801
And that's what we're going to talk about now.

