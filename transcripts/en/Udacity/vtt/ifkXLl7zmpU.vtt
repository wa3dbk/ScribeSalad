WEBVTT
Kind: captions
Language: en

00:00:00.130 --> 00:00:01.550
So now that we have bars and

00:00:01.550 --> 00:00:04.740
edges in V1,
we can go upstairs a little bit to V2.

00:00:04.740 --> 00:00:07.530
And people do all sorts
of work of looking at

00:00:07.530 --> 00:00:10.850
different types of patterns
that cause different effects.

00:00:10.850 --> 00:00:14.510
And so some of the patterns were
based upon, like, little gratings and

00:00:14.510 --> 00:00:16.940
shapes and swirls and things like that.

00:00:16.940 --> 00:00:19.417
And sometimes, they were just on
these types of edges and things.

00:00:19.417 --> 00:00:22.781
And, in Dave Van Essen's lab,
and, David,

00:00:22.781 --> 00:00:26.430
a very well known neurophysiologist.

00:00:26.430 --> 00:00:27.970
But when you look at things like this,
it's,

00:00:27.970 --> 00:00:30.270
it's a little difficult to understand,
you know,

00:00:30.270 --> 00:00:35.100
exactly how this is moving upstream
in the computational world.

00:00:35.100 --> 00:00:36.940
We understand the need for edges.

00:00:36.940 --> 00:00:40.084
And then you could maybe make some
argument about circles and, or,

00:00:40.084 --> 00:00:41.410
curved parts.

00:00:41.410 --> 00:00:43.980
One might say that, oh, you know,
what I'm seeing is stuff that

00:00:43.980 --> 00:00:47.380
may be dealing with some types of
intersections or those kinds of things.

00:00:47.380 --> 00:00:51.460
But the neurophysiologists, they keep
looking to understand what sorts of

00:00:51.460 --> 00:00:56.790
images or low level features
will cause re cells to respond.

00:00:56.790 --> 00:00:58.240
Going upstairs even
a little bit further,

00:00:58.240 --> 00:01:00.700
there's an area called
the inferotemporal cortex.

00:01:00.700 --> 00:01:05.446
And Tanaka did a lot of work on
looking at different kinds of features

00:01:05.446 --> 00:01:09.942
that seemed to have cells that have
a strong response to these and

00:01:09.942 --> 00:01:11.875
not other kinds of things.

00:01:11.875 --> 00:01:16.714
And the idea was that maybe these
are where cells are starting to put

00:01:16.714 --> 00:01:18.625
things together, okay.

00:01:18.625 --> 00:01:22.882
And I, I guess one of the most
well known examples actually came

00:01:22.882 --> 00:01:26.790
it was earlier and, you know,
the dates go different.

00:01:26.790 --> 00:01:30.250
There was this so-called hand neuron,
okay.

00:01:30.250 --> 00:01:34.290
And what this was is, this is a neuron
that when you showed it a picture of

00:01:34.290 --> 00:01:38.350
a hand, it would fire a lot, and
the front of a hand, the back of a hand.

00:01:38.350 --> 00:01:41.180
A, remember, these are kind of
like line drawings of hands, and

00:01:41.180 --> 00:01:44.662
even this one and, and that one,
so different size scale.

00:01:44.662 --> 00:01:46.036
But what was interesting is,

00:01:46.036 --> 00:01:49.140
if you had an image that just
had this little spokes there,

00:01:49.140 --> 00:01:53.080
it doesn't look like a hand to me,
it doesn't look like a hand to you.

00:01:53.080 --> 00:01:56.460
Well, obviously, it didn't look
like a hand to this cell either.

00:01:56.460 --> 00:01:57.890
And the idea that this was a cell.

00:01:57.890 --> 00:02:01.260
Now, you might wonder what this picture
of this person looking like is.

00:02:01.260 --> 00:02:03.760
Well, there was this whole
conversation of what was called,

00:02:03.760 --> 00:02:05.250
did we find the grandmother cell.

00:02:05.250 --> 00:02:08.280
That is, can you find a cell that just
fires when it sees my grandmother?

00:02:08.280 --> 00:02:10.508
And I think this was
just a play on that.

00:02:10.508 --> 00:02:15.090
But on the one hand, it was kind of
cool that you would find a single cell

00:02:15.090 --> 00:02:17.700
that was responding to, say, just hands.

00:02:17.700 --> 00:02:21.348
On the other hand, we know for a lot of
reasons that it can't be as simple as,

00:02:21.348 --> 00:02:24.314
you know, there's a one for
one mapping between concepts and

00:02:24.314 --> 00:02:28.042
cells, because there's all sorts of
reasons why that would be a bad design.

00:02:28.042 --> 00:02:32.479
But we're getting at this idea that
what's being processed is no longer just

00:02:32.479 --> 00:02:36.097
very simple features, but
something like, you know, this,

00:02:36.097 --> 00:02:40.350
which is obviously a collection
of features in a useful way.

00:02:40.350 --> 00:02:44.310
To further point that out,
here's two pictures of what you and

00:02:44.310 --> 00:02:50.660
I would say are approximately same size
silhouette of a rhinoceros and a lion.

00:02:50.660 --> 00:02:55.330
And these look sort of similar in
terms of where the stuff is, okay, but

00:02:55.330 --> 00:02:57.040
of course they're different animals.

00:02:57.040 --> 00:03:03.125
And what's nice is that in V1
these trigger similar cells.

00:03:03.125 --> 00:03:07.523
So it's like cells that are responsive
to the, the edges in this location,

00:03:07.523 --> 00:03:10.700
because the edges are sort
of in the same spot.

00:03:10.700 --> 00:03:13.542
But of course,
they respond differently in IT.

00:03:13.542 --> 00:03:15.670
IT is inferotemporal cortex.

00:03:15.670 --> 00:03:19.420
You know, the idea is that maybe in
the cortex is a cell that understands

00:03:19.420 --> 00:03:23.630
something about rhinoceros, so
it won't respond when it sees a lion.

00:03:23.630 --> 00:03:28.000
And in fact, you can further confirm
that by showing it, if you find a cell

00:03:28.000 --> 00:03:33.040
that sees lions but not rhinoceros,
now you show it two different pictures.

00:03:33.040 --> 00:03:34.880
One that's a line drawing of a lion,

00:03:34.880 --> 00:03:39.220
and the other one a much smaller
filled-in silhouette of a lion.

00:03:39.220 --> 00:03:42.720
These objects in some sense look
different at the picture level, but

00:03:42.720 --> 00:03:44.550
they are the same thing.

00:03:44.550 --> 00:03:47.510
And unlike the previous pictures
where they are different things but

00:03:47.510 --> 00:03:51.980
similar at the picture level,
these respond very differently in V1,

00:03:51.980 --> 00:03:56.440
the early processing, and then there are
the same in the inferotemporal cortex.

00:03:56.440 --> 00:04:00.720
So the idea being that higher up
are cells in the vision system that

00:04:00.720 --> 00:04:04.340
understand something about
the appearance of object types.

00:04:04.340 --> 00:04:06.490
At least, that's the, that,
that sort of the, the story.

