WEBVTT
Kind: captions
Language: en

00:00:00.510 --> 00:00:03.660
So, like we said earlier in this lesson, we've actually been talking about kinds

00:00:03.660 --> 00:00:06.300
of meta-cognition throughout this course, even if we didn't call it that at

00:00:06.300 --> 00:00:09.570
the time. We were talking about agents reflecting on their own knowledge, and

00:00:09.570 --> 00:00:13.370
correcting it when they were introduced to a mistake. Earlier in this lesson,

00:00:13.370 --> 00:00:16.340
we also talked about the possibility that an agent would reflect on the learning

00:00:16.340 --> 00:00:18.860
process that led it to the incorrect knowledge, and

00:00:18.860 --> 00:00:22.560
correct that learning process, as well. Back during partial order planning,

00:00:22.560 --> 00:00:25.150
we talked about agents that could balance multiple plans and

00:00:25.150 --> 00:00:28.646
resolve conflicts between those plans. This could be seen as a form of

00:00:28.646 --> 00:00:32.366
meta-cognition as well. The agent plans out a plan for achieving one goal,

00:00:32.366 --> 00:00:36.187
a plan for achieving the other goal, and then thinks about its own plans for

00:00:36.187 --> 00:00:39.477
those two goals. Then it detects the conflict between those two plans and

00:00:39.477 --> 00:00:43.022
it resolves that conflict accordingly. Then it detects the conflict between

00:00:43.022 --> 00:00:46.540
those two plans and creates a new plan to avoid that conflict.

00:00:46.540 --> 00:00:50.520
Here the agent is reasoning over its own planning process. We saw this in

00:00:50.520 --> 00:00:54.270
production systems as well. We had an agent that reached an impasse, it had two

00:00:54.270 --> 00:00:57.100
different pitches which is suggested and it couldn't decide between the two.

00:00:57.100 --> 00:01:01.180
Let's find a new learning goal to find a rule to choose between those pitches.

00:01:01.180 --> 00:01:05.300
It then selected a learning strategy, chunking, went into its memory, found

00:01:05.300 --> 00:01:10.310
a case, and chunked a rule that would it resolve that impasse. In this case,

00:01:10.310 --> 00:01:14.000
the agent used that impasse to set up a new learning goal. It didn't select

00:01:14.000 --> 00:01:18.690
the strategy, strategy selection, to achieve that learning goal. We can also see

00:01:18.690 --> 00:01:22.860
medicognition in version spaces. Our agent has the notion of specific and

00:01:22.860 --> 00:01:26.470
general models, and it also has the notion of convergence. The agent is

00:01:26.470 --> 00:01:30.040
consistently thinking about it's own specific and general model, and looking for

00:01:30.040 --> 00:01:34.020
opportunities to converge them down into one model of the concept. And finally,

00:01:34.020 --> 00:01:37.720
we can very clearly see metacognition in our lesson on diagnosis.

00:01:37.720 --> 00:01:40.710
We talked about how all the results for our treatment become new data for our

00:01:40.710 --> 00:01:45.170
iterative process of diagnosis. If our treatment didn't spond desirable results,

00:01:45.170 --> 00:01:48.860
it also sponds data for the metal layer. Not only do we still want to diagnose

00:01:48.860 --> 00:01:52.820
the current malfunction,. But we also want to diagnose, why we weren't able to

00:01:52.820 --> 00:01:56.360
diagnose it correctly in the first place. So, now we're diagnosing the problem

00:01:56.360 --> 00:02:00.140
with our diagnosing process. So as we can see, meta cognition's actually been

00:02:00.140 --> 00:02:02.830
implicit in several of the topics we've talked about in this course.

