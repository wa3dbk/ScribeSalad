WEBVTT
Kind: captions
Language: en

00:00:00.370 --> 00:00:03.680
Let us look at the details of constraint propagation. To do so,

00:00:03.680 --> 00:00:08.650
we'll take a specific example from computer vision. Here's an example of a 2D

00:00:08.650 --> 00:00:14.720
image composed of a large number of pixels. The greyness at any one pixel

00:00:14.720 --> 00:00:19.800
is a depiction of the intensity of light at that pixel. Now of course, you and

00:00:19.800 --> 00:00:23.030
can immediately recognize that this is a cube. But how do we do it, and

00:00:23.030 --> 00:00:27.775
how can we make a machine do it? [UNKNOWN] decompose a task of 3D object

00:00:27.775 --> 00:00:33.750
recognition into several several sub-tasks. Miles said in the first sub-task,

00:00:33.750 --> 00:00:38.770
a visual system detects edges, or lines as shown here. At this particular point,

00:00:38.770 --> 00:00:43.810
no surfaces have been detected. In this particular point, no 3D object has been

00:00:43.810 --> 00:00:49.770
fignized. Just these pixels have been put into lines based on the intensities

00:00:49.770 --> 00:00:54.741
of light in different pixels. According to Miles the second sub task of object

00:00:54.741 --> 00:01:00.409
recognition consists of grouping these lines and the surfaces with orientations,

00:01:00.409 --> 00:01:05.690
as indicated here. So now these four lines have been grouped into the surface,

00:01:05.690 --> 00:01:08.970
and then orientation defined by the perpendicular the surface, and

00:01:08.970 --> 00:01:12.300
similarly these four lines, and these four lines. In the third and

00:01:12.300 --> 00:01:17.730
final phase of the object recognition task, according to Miles surfaces

00:01:17.730 --> 00:01:22.840
are grouped into a complete 3D object. At this particular point,

00:01:22.840 --> 00:01:26.940
your visual system recognizes that this is a cube. Miles theory has been

00:01:26.940 --> 00:01:31.790
very influential in computer vision. It has actually also been influential in AI

00:01:31.790 --> 00:01:36.500
as a whole. One of the lessons we can take away from Miles' theory of computer

00:01:36.500 --> 00:01:41.810
vision of object's recognition is that before we get into our guarded tones for

00:01:41.810 --> 00:01:46.720
addressing the task, we want to understand how a task gets decomposed into sub

00:01:46.720 --> 00:01:53.620
tasks. Throughout this course, we have emphasized task decomposition repeatedly.

00:01:53.620 --> 00:01:56.630
As an example, when we were talking about understanding,

00:01:56.630 --> 00:02:01.070
a big task of understanding got decomposed into a series of small tasks.

00:02:01.070 --> 00:02:06.520
Where surface level cues acted as probes into memory and

00:02:06.520 --> 00:02:12.410
a frame was retrieved. The slice of the frames dented expectations.

00:02:12.410 --> 00:02:17.500
Lexicon and grammatical analysts led to the identification of objects and

00:02:17.500 --> 00:02:22.530
predicates that would satisfy those expectations. And the fillers were put in.

00:02:22.530 --> 00:02:26.400
Problem reduction certainly is a general purpose method for decomposing complex

00:02:26.400 --> 00:02:31.970
tasks into smaller tasks. This notion of class decomposition is a powerful

00:02:31.970 --> 00:02:37.660
idea irrespective of what algorithm we use for any of these specific sub tasks

