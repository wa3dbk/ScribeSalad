WEBVTT
Kind: captions
Language: en

00:00:00.490 --> 00:00:02.160
Here's a simple way
of thinking about it.

00:00:02.160 --> 00:00:07.460
So our goal, let's suppose we're
just worrying about the intensity

00:00:07.460 --> 00:00:10.340
of a pixel where its intensity
is just single value.

00:00:10.340 --> 00:00:11.670
Right?
So it's a grayscale image,

00:00:11.670 --> 00:00:16.880
it goes from 0 to 1, 0 to 255,
minus 27 to plus 18.

00:00:16.880 --> 00:00:21.860
Whatever your range happens to be,
the idea is that you've got this linear

00:00:21.860 --> 00:00:24.130
that, dimension along which
the values are distributed.

00:00:24.130 --> 00:00:26.290
In this case we, we're going.

00:00:26.290 --> 00:00:28.650
So there's our distribution
of our pixels, right?

00:00:28.650 --> 00:00:31.420
So there's a little circle
down here let's say for

00:00:31.420 --> 00:00:34.290
every pixel that's in the image.

00:00:34.290 --> 00:00:34.990
All right?

00:00:34.990 --> 00:00:38.560
And the question is,
how do we find these centers,

00:00:38.560 --> 00:00:43.090
these clusters that we say okay,
those are our three cluster centers.

00:00:43.090 --> 00:00:44.920
And once we found them,
we could say all right,

00:00:44.920 --> 00:00:49.410
I've got these three different areas of
the image, one, two, and three again.

00:00:49.410 --> 00:00:51.570
What do we mean by good cluster?

00:00:51.570 --> 00:00:56.030
Well, generically here we're going to
talk about that our best clusters

00:00:56.030 --> 00:00:59.540
are clusters whose
centers minimize the SSD,

00:00:59.540 --> 00:01:04.364
the sum of squared differences, between,
the, all their points and their centers.

00:01:04.364 --> 00:01:07.260
Okay, so the idea here,
here is our SSD and

00:01:07.260 --> 00:01:12.720
it says summing over all the clusters,
given a point within the cluster these.

00:01:12.720 --> 00:01:14.210
Actually we'll make that square just so

00:01:14.210 --> 00:01:17.950
it's clear, the distance between
the point and the cluster center.

00:01:17.950 --> 00:01:19.120
All right?

00:01:19.120 --> 00:01:22.950
And the challenge in finding these
clusters is that it's a little bit

00:01:22.950 --> 00:01:24.870
of a chicken and the egg problem.

00:01:24.870 --> 00:01:25.720
All right?

00:01:25.720 --> 00:01:27.090
So here's, right?

00:01:27.090 --> 00:01:28.708
Suppose, that's what Q.

00:01:28.708 --> 00:01:32.130
Suppose we knew where
the cluster centers were, right?

00:01:32.130 --> 00:01:35.120
So they're here, here, and here.

00:01:35.120 --> 00:01:37.770
Well if we knew those where
the cluster centers were,

00:01:37.770 --> 00:01:40.770
which points would we
assign to each cluster?

00:01:40.770 --> 00:01:41.950
Well that would be pretty easy.

00:01:41.950 --> 00:01:43.770
Just as it says in the answer.

00:01:43.770 --> 00:01:46.690
We would assign the points
to the cluster depending

00:01:46.690 --> 00:01:49.120
upon which cluster center
they were closest to.

00:01:49.120 --> 00:01:52.990
So given the center,
it's obvious to assign the points.

00:01:52.990 --> 00:01:55.100
On the other hand, what if we,

00:01:55.100 --> 00:01:59.100
instead of knowing the cluster centers,
all we knew was the cluster memberships?

00:01:59.100 --> 00:02:02.450
That's what these ovals are signif,
showing, right.

00:02:02.450 --> 00:02:05.130
We know which points
belong to which clusters.

00:02:05.130 --> 00:02:07.830
Right, this is the chicken problem or
the egg prob, I dont know,

00:02:07.830 --> 00:02:09.139
it's the other problem.

00:02:09.139 --> 00:02:12.860
The question is, if i knew which
clusters the points belonged to,

00:02:12.860 --> 00:02:14.500
where would i put the centers?

00:02:14.500 --> 00:02:17.730
Well, i would put
the centers to be the mean,

00:02:17.730 --> 00:02:21.400
the average of each of
the points of their cluster.

00:02:21.400 --> 00:02:23.040
So everybody know why?

00:02:23.040 --> 00:02:28.030
Do you know why if I gave you a bunch of
scores that represented how people were

00:02:28.030 --> 00:02:31.170
doing on a test and I asked you sort of,
you know, what's, what, you know,

00:02:31.170 --> 00:02:34.270
how, how well do you think people do on
this test you would take the average?

00:02:34.270 --> 00:02:36.070
You know why you take the average?

00:02:36.070 --> 00:02:40.150
Turns out the average is
the value that minimizes

00:02:40.150 --> 00:02:42.070
the sum of squared differences.

00:02:42.070 --> 00:02:44.210
It's trivial to show.

00:02:44.210 --> 00:02:47.400
And the reason you do that is you
believe somewhere in your head that

00:02:47.400 --> 00:02:50.100
the actual thing you're
looking at is a distribution

00:02:50.100 --> 00:02:54.460
that's centered about a point with
a Gaussian fall off around it, right?

00:02:54.460 --> 00:02:58.900
Some, some value whose probability falls
off as the square of the distance.

00:02:58.900 --> 00:03:03.450
So the value that would generate
the maximum likelihood of the data

00:03:03.450 --> 00:03:07.360
is the mean value, cause it minimized
the sum of squared differences.

00:03:07.360 --> 00:03:11.060
I thought every masters student in
computer science would have known that.

00:03:11.060 --> 00:03:14.850
And I just gave this lecture, just
a little while ago, in class here, and

00:03:14.850 --> 00:03:17.410
it turned out, well there were
undergraduates in there, too, so

00:03:17.410 --> 00:03:20.450
maybe they were the ones who didn't
know that, but not everybody knew that.

00:03:20.450 --> 00:03:24.270
So, The reason we take the averages
of things, the mean values,

00:03:24.270 --> 00:03:26.570
is it minimizes the sum
of squared distance.

00:03:26.570 --> 00:03:29.950
And if you have a Gaussian model or
any other distribution,

00:03:29.950 --> 00:03:33.050
where the likelihood of
probability falls off as a square,

00:03:33.050 --> 00:03:37.900
then if you minimize the sum of the
squares you generate the, the value for

00:03:37.900 --> 00:03:41.480
which the data you saw would
have the maximum likelihood.

00:03:41.480 --> 00:03:43.450
Just tuck that away so
you'll remember it somewhere.

