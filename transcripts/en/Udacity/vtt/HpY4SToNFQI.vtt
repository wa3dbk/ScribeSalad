WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.000
And so in practice what we ended up with is not this idea of coming up with a good partitioning

00:00:05.000 --> 00:00:08.000
for the input domain rather than a notion of test coverage.

00:00:08.000 --> 00:00:11.000
What the test coverage is doing is to try to accomplish exact the same thing

00:00:11.000 --> 00:00:14.000
that partitioning was accomplishing, but it goes about in a different way.

00:00:14.000 --> 00:00:18.000
Test coverage is an automatic way of partitioning the input domain 

00:00:18.000 --> 00:00:21.000
with some observed features of the source code so let me say what I mean.

00:00:21.000 --> 00:00:23.000
So one particular kind of test coverage that we might aim for

00:00:23.000 --> 00:00:26.000
that is sort of an easy kind of test coverage is called function coverage,

00:00:26.000 --> 00:00:30.000
and function coverage is achieved if we managed to test our system in such a way

00:00:30.000 --> 00:00:34.000
 that every function in our source code is executed during testing.

00:00:34.000 --> 00:00:37.000
We will be dividing our input domain in chunks where any test case in this part

00:00:37.000 --> 00:00:42.000
of the input space is going to result, for example, in a call to foo.

00:00:42.000 --> 00:00:46.000
So now, there's going to be some different subset of our input domain

00:00:46.000 --> 00:00:50.000
and any point in this subset of the input domain when used as a test input

00:00:50.000 --> 00:00:55.000
is going to result in a different function in the system under test--let's say bar being called.

00:00:55.000 --> 00:00:58.000
We can keep subdividing the input domain for the software under test

00:00:58.000 --> 00:01:02.000
until we have split it into parts that results in every function being called.

00:01:02.000 --> 00:01:05.000
So now, of course, doing this in theory is easy.

00:01:05.000 --> 00:01:07.000
In practice, we start with a set of test of cases,

00:01:07.000 --> 00:01:10.000
and we run them all through the software under test.

00:01:10.000 --> 00:01:12.000
We see which functions are called,

00:01:12.000 --> 00:01:14.000
and then we're going to end up with some sort of  a score.

00:01:14.000 --> 00:01:18.000
So, for example, some sort of a tool that is watching our software execute can say--

00:01:18.000 --> 00:01:22.000
we called 181/250 functions.

00:01:22.000 --> 00:01:25.000
And so what this kind of score is called a test coverage metric.

00:01:25.000 --> 00:01:29.000
It means that our test cases so far have covered 181 of the functions

00:01:29.000 --> 00:01:31.000
out of the 250 that we implemented.

00:01:31.000 --> 00:01:33.000
And so now that we have achieved this goal that we had,

00:01:33.000 --> 00:01:35.000
which is assigning a score to a collection of test cases.

00:01:35.000 --> 00:01:38.000
The next thing we have to ask is this score any good?

00:01:38.000 --> 00:01:42.000
Is that a good test coverage to have executed 181/250 functions?

00:01:42.000 --> 00:01:44.000
With this example, it's probably not.

00:01:44.000 --> 00:01:47.000
So, we can do is for each of the functions that wasn't covered, we can go and look at it.

00:01:47.000 --> 00:01:52.000
And we can try to come up with the test input that causes that function to execute.

00:01:52.000 --> 00:01:55.000
There is some function baz here, and we can't seem to devise an input

00:01:55.000 --> 00:01:58.000
that causes it to execute, then there are a couple of possibilities.

00:01:58.000 --> 00:02:02.000
One possibility is that it can't be called at all. It's dead code.

00:02:02.000 --> 00:02:04.000
Another possibility is that we simply don't understand our system

00:02:04.000 --> 00:02:06.000
well enough to be able to trigger it.

00:02:06.000 --> 00:02:08.000
Either way, there is something possibly suspicious or wrong.

