WEBVTT
Kind: captions
Language: en

00:00:00.400 --> 00:00:02.310
Recall the reduction example.

00:00:02.310 --> 00:00:05.920
The work is linear, and the number
of transfers, is at least n over L.

00:00:05.920 --> 00:00:08.740
Now let's analyze a concrete
algorithm to see, whether or not,

00:00:08.740 --> 00:00:11.020
we can achieve this lower bound.

00:00:11.020 --> 00:00:14.840
Now here's the natural thing you would
write in the conventional RAM model.

00:00:14.840 --> 00:00:17.100
That is the one without the fast memory.

00:00:17.100 --> 00:00:20.950
It maintains an accumulator s, and
makes a sweep over all the elements,

00:00:20.950 --> 00:00:22.490
accumulating them.

00:00:22.490 --> 00:00:26.089
Now you need to modify this procedure,
to think about when to move data,

00:00:26.089 --> 00:00:27.630
between slow and fast memory.

00:00:27.630 --> 00:00:30.000
Now, the variable s is easy.

00:00:30.000 --> 00:00:33.870
You can just assume that it starts
locally, in the fast memory.

00:00:33.870 --> 00:00:36.840
It's the same way you might
treat any temporary scalar or

00:00:36.840 --> 00:00:40.220
local variable in your favorite
imperative programming language.

00:00:40.220 --> 00:00:43.660
For my pseudo code,
I've just declared s to be local.

00:00:43.660 --> 00:00:45.110
I'm doing that just to be clear.

00:00:45.110 --> 00:00:48.770
Most of the time you can ignore
these kinds of local variables.

00:00:48.770 --> 00:00:50.720
Now what about the array X?

00:00:50.720 --> 00:00:54.390
For simplicity, let's assume that
little n is, much bigger than,

00:00:54.390 --> 00:00:56.260
the size of fast memory.

00:00:56.260 --> 00:01:00.480
Let's further assume that X is
aligned,on an L word boundary.

00:01:00.480 --> 00:01:04.699
With these assumptions, let's transform
the program, to make slow and

00:01:04.699 --> 00:01:06.681
fast memory transfers explicit.

00:01:06.681 --> 00:01:07.563
Yikes.

00:01:07.563 --> 00:01:09.450
Let's start with the outer loop.

00:01:09.450 --> 00:01:12.810
As with the original algorithm, it steps
through the elements of the array but

00:01:12.810 --> 00:01:16.270
it does so,
one block of size L at a time.

00:01:16.270 --> 00:01:18.960
Next, there's the computation L hat.

00:01:18.960 --> 00:01:22.620
This mumbo jumbo just determines whether
the block that starts a position

00:01:22.620 --> 00:01:25.380
i is of length L, or
a little bit smaller.

00:01:25.380 --> 00:01:26.160
It's a detail.

00:01:26.160 --> 00:01:27.060
I just wanted to be clear.

00:01:27.060 --> 00:01:29.770
But most of the time,
we'll ignore this sort of detail.

00:01:29.770 --> 00:01:32.560
Next, there's
the assignment to little y.

00:01:32.560 --> 00:01:37.600
This is an explicit load or read,
from slow memory, to fast memory.

00:01:37.600 --> 00:01:42.290
Notice that it requests at most L words,
which is one block transfer.

00:01:42.290 --> 00:01:45.610
Now, since little y and
S are both local to fast memory,

00:01:45.610 --> 00:01:47.900
the processor can execute
this innermost loop.

00:01:48.900 --> 00:01:52.000
So what's the work in the number
of transfers for this algorithm?

00:01:53.000 --> 00:01:56.930
The work is just the same as this
conventional algorithm in the RAM model,

00:01:56.930 --> 00:01:59.240
that is, it's just theta of n.

00:01:59.240 --> 00:02:04.070
Here's the number of transfers, it's
just the ceiling of n over L, hopefully,

00:02:04.070 --> 00:02:06.450
you can see how this falls out,
very naturally,

00:02:06.450 --> 00:02:08.650
from the structure of the code.

00:02:08.650 --> 00:02:12.110
So how do these compare
to the lower bounds?

00:02:12.110 --> 00:02:14.350
Why they compare very well, indeed.

00:02:14.350 --> 00:02:18.000
Before moving on, I want to make two
remarks about what you've just done.

00:02:18.000 --> 00:02:22.100
First, I realize that was a lot of
painful detail to do what must seem like

00:02:22.100 --> 00:02:24.130
a really simple analysis.

00:02:24.130 --> 00:02:27.380
We will make simplifications, as we go,
but I wanted to start by just

00:02:27.380 --> 00:02:31.760
being clear about exactly what has to
happen under the hood in this model.

00:02:31.760 --> 00:02:33.140
Now, my second remark.

00:02:33.140 --> 00:02:35.080
Yes, I know about caches.

00:02:35.080 --> 00:02:39.200
They're those fast memory thingys that
the hardware manages automatically.

00:02:39.200 --> 00:02:42.660
In fact, there's an awesome OMSCS
class that covers their design in

00:02:42.660 --> 00:02:44.090
a lot of detail.

00:02:44.090 --> 00:02:46.920
While caches are very useful,
what you'll eventually see

00:02:46.920 --> 00:02:50.710
is that they aren't sufficient
to guarantee high performance.

00:02:50.710 --> 00:02:54.650
That is why we're discussing an explicit
model of locality, like this one.

