WEBVTT
Kind: captions
Language: en

00:00:00.280 --> 00:00:02.550
Even if you know that your application will only run on

00:00:02.550 --> 00:00:06.090
a single core single CPU, it can still be useful to express

00:00:06.090 --> 00:00:09.510
parallelism in your programs. In fact, almost every time you load

00:00:09.510 --> 00:00:13.260
a web page, your browser is making something called an asynchronous request

00:00:13.260 --> 00:00:16.309
back to the server for more information that exploits a certain

00:00:16.309 --> 00:00:19.190
kind of parallelism. You see, the web server rarely sends all the

00:00:19.190 --> 00:00:22.380
information for a web page in response to your initial request.

00:00:22.380 --> 00:00:25.570
Instead, it sends a kind of outline for the page. That includes

00:00:25.570 --> 00:00:28.640
other URL's where your browser can find the details. To get

00:00:28.640 --> 00:00:32.509
these details your browser then sends other HTTP requests back to

00:00:32.509 --> 00:00:35.680
the server, for example, we might need a style sheet and

00:00:35.680 --> 00:00:38.830
also an image to help fill out the website. Now if we

00:00:38.830 --> 00:00:41.650
were to implement this in a naive synchronous way our program

00:00:41.650 --> 00:00:44.040
might run for a while, but when it discovers that it

00:00:44.040 --> 00:00:46.460
needs a CSS file from the server it would make the

00:00:46.460 --> 00:00:51.040
HTTP request And then pause part way to get the response back.

00:00:51.040 --> 00:00:54.670
After receiving the response it could then, process the CSS

00:00:54.670 --> 00:00:58.180
file, and then continue with work, until it discovers that it

00:00:58.180 --> 00:01:02.140
needs image file. Make that request, wait til it receives

00:01:02.140 --> 00:01:05.820
it, and then process that image file. Clearly this is inefficient.

00:01:05.820 --> 00:01:07.790
There is no sense in making the browser, and hence

00:01:07.790 --> 00:01:10.600
the user, wait for a response from the server While there

00:01:10.600 --> 00:01:12.990
was more work to be done in reading and rendering

00:01:12.990 --> 00:01:16.540
the original request. This is why requests back to the server

00:01:16.540 --> 00:01:19.410
are made asynchronously. And this is really just a fancy

00:01:19.410 --> 00:01:22.260
word meaning that we get to continue our program without having

00:01:22.260 --> 00:01:24.580
to wait for a web request or sometimes a system

00:01:24.580 --> 00:01:28.370
call to complete. So an asynchronous approach, we would begin by

00:01:28.370 --> 00:01:30.870
processing the HTML profile just as we did in the

00:01:30.870 --> 00:01:34.310
naive approach. But when we find that we need to request

00:01:34.310 --> 00:01:37.570
a CSS page, we do so in a new thread. This

00:01:37.570 --> 00:01:41.880
allows our original thread to continue processing a HTML file and

00:01:41.880 --> 00:01:45.630
discover that he also needs to request a PNG file,

00:01:45.630 --> 00:01:47.960
again he will do this in a new thread. When he

00:01:47.960 --> 00:01:51.140
gets this CSS file back from the server the requesting thread

00:01:51.140 --> 00:01:53.970
can process it. And when he gets back the p and

00:01:53.970 --> 00:01:56.940
g file, the requesting thread can also process that. And

00:01:56.940 --> 00:02:00.210
the end result is that we finished loading the page much

00:02:00.210 --> 00:02:03.320
faster. Now remember, we're still assuming that we only have one

00:02:03.320 --> 00:02:07.300
CPU. This means that the computation that the naive approach did,

00:02:07.300 --> 00:02:10.538
say this red portion here, can't run in parallel with

00:02:10.538 --> 00:02:13.620
the other parts of the processing. They still have to

00:02:13.620 --> 00:02:17.160
take turns. Nevertheless, because we weren't idle while we waited

00:02:17.160 --> 00:02:20.000
for the web server, as we were in the naive approach,

00:02:20.000 --> 00:02:22.400
we've made our page load faster by always giving the

00:02:22.400 --> 00:02:25.380
CPU something to do. And it's the programming abstraction of

00:02:25.380 --> 00:02:28.260
threads that makes it possible to achieve, both, this behavior,

00:02:28.260 --> 00:02:31.360
as well as the true parallel processing that we discussed earlier.

