WEBVTT
Kind: captions
Language: en

00:00:00.350 --> 00:00:03.980
This notion of maximum
variance should strike

00:00:03.980 --> 00:00:06.960
a little bit of recognition in your mind
about then notion of fitting a line.

00:00:06.960 --> 00:00:09.210
You remember we did line fitting?

00:00:09.210 --> 00:00:09.800
Okay.

00:00:09.800 --> 00:00:12.850
In fact we came up with
this equation of saying

00:00:12.850 --> 00:00:17.960
we're going to measure the error that's
essentially just the perpendicular error

00:00:17.960 --> 00:00:19.450
of the points to this line.

00:00:19.450 --> 00:00:22.040
And the, and the equation of
the line that we had there was

00:00:22.040 --> 00:00:24.750
a x plus b y minus d equals 0.

00:00:24.750 --> 00:00:27.130
Or it could be plus d, doesn't matter.

00:00:27.130 --> 00:00:32.770
The idea is that a and b was
the normal with respect to the line and

00:00:32.770 --> 00:00:34.710
in fact that's what
that says right there.

00:00:34.710 --> 00:00:37.060
And if I take the dot product of x and
y on that,

00:00:37.060 --> 00:00:41.270
it's supposed to be a distance d away
and that's what this equation says.

00:00:41.270 --> 00:00:46.090
Alright, so that was when we were
trying to do a least squares fit.

00:00:46.090 --> 00:00:47.880
So then we, we did this quick operation.

00:00:47.880 --> 00:00:53.080
We took the derivative with respect to
the d, came up with this formula for

00:00:53.080 --> 00:00:57.000
d in terms of the average x,
the average y.

00:00:57.000 --> 00:01:01.590
We plug that in,
substitute d equals a x bar b y bar.

00:01:01.590 --> 00:01:04.400
We get this new error function E.

00:01:04.400 --> 00:01:05.360
Just having substituted.

00:01:05.360 --> 00:01:07.840
And we wrote it, this way.

00:01:07.840 --> 00:01:09.000
Okay?

00:01:09.000 --> 00:01:12.680
And this is where b is this matrix here.

00:01:12.680 --> 00:01:18.680
And you can see it's just the x's and
y's in a row with the means subtracted.

00:01:18.680 --> 00:01:19.390
Okay?

00:01:19.390 --> 00:01:21.890
So what we want to do is we
want to minimize that quantity,

00:01:21.890 --> 00:01:23.780
the magnitude of B times n,

00:01:23.780 --> 00:01:27.260
where n's going to be the normal AB
that we're going to solve for, and

00:01:27.260 --> 00:01:32.460
we said last time that what we want to
do is we want to minimize Bn squared,

00:01:32.460 --> 00:01:38.300
but remember, since the normal has to be
unit normal we say subject to n equal 1.

00:01:38.300 --> 00:01:42.530
Now, what might be not so obvious
because we didn't mention exactly last

00:01:42.530 --> 00:01:48.140
time is that this distance,
these square distances, this

00:01:48.140 --> 00:01:51.752
is going to be the axis of least, let's
call this the axis of least inertia.

00:01:51.752 --> 00:01:54.000
Right?
[INAUDIBLE] From your physics.

00:01:54.000 --> 00:01:57.960
If I've got an axis, then the inertia of
the whole thing is proportional of all

00:01:57.960 --> 00:02:01.990
the points, the square distance from
those, of those points to the axis.

00:02:01.990 --> 00:02:05.360
So the line fitting here in 2D
is an axis of least inertia.

00:02:05.360 --> 00:02:08.570
And like I said,
this should sound familiar to you.

00:02:08.570 --> 00:02:09.880
And we, remember we did this.

00:02:09.880 --> 00:02:11.740
We, we looked at several
ways of doing this.

00:02:11.740 --> 00:02:15.860
We had those in fact back when we
did calibration, we said well.

00:02:15.860 --> 00:02:21.370
We have this A, M, because we're
doing M matrix for the calibration.

00:02:21.370 --> 00:02:23.490
We said make,
let the norm of that, well,

00:02:23.490 --> 00:02:26.610
we want to make it as small as
possible subject to M equal to one.

00:02:26.610 --> 00:02:29.970
And remember we were doing this thing
with eigenvalues and eigenvectors, so

00:02:29.970 --> 00:02:33.381
it shouldn't surprise you that we're
going to be revisiting eigenvalues and

00:02:33.381 --> 00:02:34.120
eigenvectors.

