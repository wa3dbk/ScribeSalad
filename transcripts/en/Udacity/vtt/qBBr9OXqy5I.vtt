WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.000
Now, let's look at a very similar case, where I'm going to visualize the execution of the queue

00:00:04.000 --> 00:00:07.000
as a finite state machine, but now we're going to have a much larger queue.

00:00:07.000 --> 00:00:09.000
We're going to have a queue that stores a thousand elements instead of two.

00:00:09.000 --> 00:00:11.000
We're going to have exactly the same kind of state machine, but its shape is changed.

00:00:11.000 --> 00:00:15.000
Instead of containing 3 nodes, it contains 1001 and so, I left out a vast area of state in the middle,

00:00:15.000 --> 00:00:19.000
and so when we randomly test this queue, we still are going to start at the empty state.

00:00:19.000 --> 00:00:21.000
It looks like with the dynamic side at this time.

00:00:21.000 --> 00:00:24.000
Here I have a queue with N = 1000 and nothing else has change

00:00:24.000 --> 00:00:29.000
When we run the random testing, this time we've done around 50,000 adds to a non-full queue,

00:00:29.000 --> 00:00:31.000
and we haven't done any adds to a full queue.

00:00:31.000 --> 00:00:35.000
We've done almost 50,000 removes from a non-empty queue and 10 removes from an empty queue.

00:00:35.000 --> 00:00:37.000
So, let's try to understand what happened here.

00:00:37.000 --> 00:00:41.000
So, what happened is and I'm going to come up with another view of that state machine.

00:00:41.000 --> 00:00:45.000
So, here we have the empty queue and here we have the full queue.

00:00:45.000 --> 00:00:49.000
and here we have the number of times we visit a particular state.

00:00:49.000 --> 00:00:53.000
and what's happening is with 50% probability we're randomly walking back or forward

00:00:53.000 --> 00:00:57.000
and we're going to be getting a situation where the probability of visiting queue

00:00:57.000 --> 00:01:02.000
states farther away from where we started drops off exponentially and actually they're good close

00:01:02.000 --> 00:01:05.000
form equations for being the probability of getting to any particular point,

00:01:05.000 --> 00:01:10.000
but as we saw using 100,000 tests, I believe, we never actually manage to make to 1000.

00:01:10.000 --> 00:01:13.000
Although, we did perfectly easily make it to a queue size of two.

00:01:13.000 --> 00:01:16.000
So, 1000 is particularly a large size for a data structure,

00:01:16.000 --> 00:01:19.000
we could easily have some sort of a queue to have 10,000 or 100,000 elements

00:01:19.000 --> 00:01:24.000
and the chances of randomly walking all the way out to the end become even more negligible

00:01:24.000 --> 00:01:26.000
and so the question we're going to have ourselves is,

00:01:26.000 --> 00:01:30.000
What do we have to do differently to a random tester to make sure to test this situation

00:01:30.000 --> 00:01:34.000
as thoroughly as tested to this situation and so there is no common answer to this kind of question.

00:01:34.000 --> 00:01:37.000
These kind of questions definitely are hard in practice and when something changes

00:01:37.000 --> 00:01:40.000
about the software under test, we might have to adjust the probabilities to compensate.

00:01:40.000 --> 00:01:42.000
Let's just look at one possible solution.

00:01:42.000 --> 00:01:46.000
One possible solution would be to bias the probabilities towards enqueueing.

00:01:46.000 --> 00:01:50.000
If the random number generator returns a number less than 0.6 instead of 0.5,

00:01:50.000 --> 00:01:54.000
we're going to enqueue and the other 40% of the time, we're going to dequeue.

00:01:54.000 --> 00:01:56.000
So, let's see what effect that has.

00:01:56.000 --> 00:01:58.000
So this time, we attempted to add a list to full queue a large number of times,

00:01:58.000 --> 00:02:02.000
but this time, we seem to have not particularly well tested the case of removing from an empty queue

00:02:02.000 --> 00:02:04.000
and let's run it one more time and see what happens.

00:02:04.000 --> 00:02:08.000
Yeah--so this time we didn't remove it from an empty queue anytime so we biased the probabilities

00:02:08.000 --> 00:02:12.000
too far towards adding, and what's going to happen is in any kind of random walk is

00:02:12.000 --> 00:02:16.000
as long as the probabilities are respectably balance it's going to take a long time to get somewhere

00:02:16.000 --> 00:02:20.000
unless we unbalance the probabilities significantly like we did with the 60-40 distribution.

00:02:20.000 --> 00:02:25.000
What they're probably doing in this case is make a configurable biased probability

00:02:25.000 --> 00:02:27.000
and now add a completely new random testing loop.

00:02:27.000 --> 00:02:32.000
We're now going to set that bias variable to be something sort of large unless x is odd.

00:02:32.000 --> 00:02:36.000
If x is odd, we're going to set the bias variable to be something less.

00:02:36.000 --> 00:02:38.000
Okay, so let's look at what we did.

00:02:38.000 --> 00:02:41.000
We took a random testing loop and we enclose it in a larger random testing loop

00:02:41.000 --> 00:02:45.000
and in that larger to random testing loop, we sort of made qualitative change to one of the probabilities

00:02:45.000 --> 00:02:49.000
that is to say we bias execution towards one of our API call in favor of the other

00:02:49.000 --> 00:02:52.000
and on even-numbered calls, we biased it the other way.

00:02:52.000 --> 00:02:55.000
So, what we're hoping to do now is create a situation where start of in the empty state,

00:02:55.000 --> 00:02:59.000
we migrate with pretty high probability towards full and bounce around there,

00:02:59.000 --> 00:03:02.000
and at the end of that particular configuration of the testing run,we're going to walk back

00:03:02.000 --> 00:03:04.000
We're going to do that, I believe, 20 times.

00:03:04.000 --> 00:03:07.000
And so what we hope is that this will test even for the fairly large queue

00:03:07.000 --> 00:03:10.000
a lot of its possibilities so let's see if that actually happens.

00:03:10.000 --> 00:03:12.000
So of course, this is going to take longer to run this time.

