WEBVTT
Kind: captions
Language: en

00:00:00.450 --> 00:00:03.190
But first,
I want to introduce you to another idea,

00:00:03.190 --> 00:00:06.010
it's the idea of one
by one convolutions.

00:00:06.010 --> 00:00:10.550
You might wonder, why might one ever
want to use one by one convolutions?

00:00:10.550 --> 00:00:13.880
They're not really looking at a patch
of the image, just that one pixel.

00:00:15.070 --> 00:00:17.380
Look at the classic convolution setting.

00:00:17.380 --> 00:00:22.140
It's basically a small classifier for
a patch of the image, but

00:00:22.140 --> 00:00:24.617
it's only a linear classifier.

00:00:24.617 --> 00:00:28.606
But if you add a one by one convolution
in the middle, suddenly you have

00:00:28.606 --> 00:00:33.910
a mini neural network running over the
patch instead of a linear classifier.

00:00:33.910 --> 00:00:37.560
Interspersing your convolutions
with one by one convolutions

00:00:37.560 --> 00:00:40.920
is a very inexpensive way to
make your models deeper and

00:00:40.920 --> 00:00:45.250
have more parameters without
completely changing their structure.

00:00:45.250 --> 00:00:48.350
They're also very cheap,
because if you go through the math,

00:00:48.350 --> 00:00:50.110
they're not really convolutions at all.

00:00:50.110 --> 00:00:54.670
They're really just matrix multiplies,
and they have relatively few parameters.

00:00:54.670 --> 00:00:59.034
I mention all of this, average pooling
and one by one convolutions because I

00:00:59.034 --> 00:01:02.923
want to talk about a general strategy
that has been very successful at

00:01:02.923 --> 00:01:05.379
creating covnets that
are both smaller and

00:01:05.379 --> 00:01:09.088
better than covnets that simply
use a pyramid of convolutions.

