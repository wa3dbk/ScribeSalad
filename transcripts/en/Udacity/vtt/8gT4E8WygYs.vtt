WEBVTT
Kind: captions
Language: en

00:00:00.910 --> 00:00:01.422
Okay, so

00:00:01.422 --> 00:00:05.142
how often can we expect to guess
correctly in a way prediction cache?

00:00:05.142 --> 00:00:10.220
We can get an idea for this by looking
at the smaller direct mapped cache.

00:00:10.220 --> 00:00:13.720
Basically, let's say we have
a two way set associative cache.

00:00:13.720 --> 00:00:17.181
Each set of this cache has two ways,
two lines in it.

00:00:17.181 --> 00:00:21.790
And by doing way prediction, we are
effectively using one of these at first.

00:00:21.790 --> 00:00:25.430
And only if we don't find it there,
we look at the other one.

00:00:25.430 --> 00:00:29.310
So effectively, a way prediction cache

00:00:29.310 --> 00:00:33.460
first tries to access what looks
like a smaller direct mapped cache.

00:00:33.460 --> 00:00:36.820
Then it will try the entire
set associative cache.

00:00:36.820 --> 00:00:41.310
So we can get a pretty good estimate for
the hit rate and hit latency and so

00:00:41.310 --> 00:00:45.849
on of a way prediction cache, if we
look at the direct mapped cache and

00:00:45.849 --> 00:00:47.730
the set associative cache.

00:00:47.730 --> 00:00:52.220
So let's look at the basic 32 kilobyte,
8-way set associative cache.

00:00:52.220 --> 00:00:57.660
Let's look at its hit rate, hit latency,
miss penalty, and the over AMAT.

00:00:57.660 --> 00:01:00.532
And we will also look at a 32 kilobyte,

00:01:00.532 --> 00:01:04.200
8-way set-associative
cache with way prediction.

00:01:04.200 --> 00:01:08.530
The hit rate of this cache,
let's say its around 90%.

00:01:08.530 --> 00:01:14.070
The hit latency might be 2 cycle
because it's highly associative.

00:01:14.070 --> 00:01:16.990
The miss penalty will be 20 cycles,
for example.

00:01:18.040 --> 00:01:22.800
And the overall AMAT would then be 2 for
the hit latency,

00:01:22.800 --> 00:01:27.640
plus 10% of the time we
have the miss penalty.

00:01:27.640 --> 00:01:29.340
And we get 4 here.

00:01:29.340 --> 00:01:31.800
Now we already said that way prediction

00:01:31.800 --> 00:01:35.670
behaves like accessing only
one of the ways in the cache.

00:01:35.670 --> 00:01:38.370
With way prediction in
a 8-way associative cache,

00:01:38.370 --> 00:01:42.490
we are really guessing which of the 8
places is going to have the block.

00:01:42.490 --> 00:01:46.330
So you effectively, with way prediction,
our first attempt will

00:01:46.330 --> 00:01:51.770
be to a 4 kilobyte direct
mapped subset of this cache.

00:01:51.770 --> 00:01:55.040
If we look at the normal 4
kilobyte direct mapped cache,

00:01:55.040 --> 00:01:59.860
that's going to have, for
example, a 70% hit rate,

00:01:59.860 --> 00:02:03.050
but the 1 cycle hit latency,
because it's faster.

00:02:03.050 --> 00:02:05.460
And the miss penalty will be the same.

00:02:05.460 --> 00:02:09.820
If we now try to get the AMAT for
this basic direct mapped cache,

00:02:09.820 --> 00:02:15.715
we will have 1 + 0.3, the miss rate,

00:02:15.715 --> 00:02:21.670
times 20, and this is going to
be 1 plus 6 so it gives us 7.

00:02:21.670 --> 00:02:26.540
So obviously we are better off with
a 8 way set associative cache.

00:02:26.540 --> 00:02:30.220
However, we are paying an extra
cycle each time we access it for

00:02:30.220 --> 00:02:36.440
the hit latency in order to get
the low missed penalties here.

00:02:36.440 --> 00:02:40.840
With the way prediction cache,
what we're getting is 70% of the time

00:02:41.930 --> 00:02:46.100
we're going to find what we're looking
for in the 4 kilobyte subset that we

00:02:46.100 --> 00:02:49.620
are checking first and
we will have a 1 cycle latency for that.

00:02:49.620 --> 00:02:55.040
In the remaining 20%, we're going to
check the rest of the cache so

00:02:55.040 --> 00:02:57.250
our overall hit rate will be 90%.

00:02:57.250 --> 00:02:59.520
What we don't find here,

00:02:59.520 --> 00:03:03.530
we will still find here if
it's in the 32 kilobyte cache.

00:03:04.600 --> 00:03:08.170
So we get a 90% hit rate overall.

00:03:08.170 --> 00:03:11.020
Our hit latency is now 1 or 2.

00:03:12.330 --> 00:03:15.990
And our miss penalty is 20, so
how do we compute the AMAT?

00:03:15.990 --> 00:03:21.480
Well, what we now have
is that 70% of the time,

00:03:21.480 --> 00:03:23.704
we find what we are looking for
in one cycle.

00:03:23.704 --> 00:03:27.552
The other 30% of the time,
whether we have a hit or

00:03:27.552 --> 00:03:31.148
a miss in the 8-way cache,
we have to check it.

00:03:31.148 --> 00:03:35.558
So the other 30% of the time we're
checking all of the ways for

00:03:35.558 --> 00:03:40.865
which we pay a 2 cycle latency, and
then 10% of the time we don't find what

00:03:40.865 --> 00:03:45.786
we are looking for in all of the ways,
so we have to pay the miss penalty.

00:03:45.786 --> 00:03:49.455
So now we have what
looks like our hit time.

00:03:49.455 --> 00:03:51.288
70% of the time, it's 1.

00:03:51.288 --> 00:03:55.154
30% of the time, we have to use a 2, so

00:03:55.154 --> 00:04:00.570
we end up having a 1.3
cycle on average hit time.

00:04:00.570 --> 00:04:04.980
And a miss penalty of the 8-way
set associative cache

00:04:04.980 --> 00:04:06.830
which is still going to be 2.

00:04:06.830 --> 00:04:10.980
And this is how we improve things,
we now get an AMAT of 3.3.

00:04:10.980 --> 00:04:16.390
Because what we effectively
got was the misses of an 8-way

00:04:16.390 --> 00:04:21.050
set associative cache, but
the hit time that is much closer to

00:04:21.050 --> 00:04:24.150
a direct mapped cache then it is
to an 8-way set associative cache.

