WEBVTT
Kind: captions
Language: en

00:00:00.320 --> 00:00:02.230
All right,
welcome back to Computer Vision.

00:00:02.230 --> 00:00:05.770
Last time, we introduced
the notion of image motion.

00:00:05.770 --> 00:00:08.690
We said how motion is actually a,
a construct of your head,

00:00:08.690 --> 00:00:10.840
because there's just a bunch
of static frames, and

00:00:10.840 --> 00:00:15.600
your mind your brain induces this notion
of believing that there's actual motion.

00:00:15.600 --> 00:00:18.660
So the question then becomes,
how do we compute that motion?

00:00:18.660 --> 00:00:22.250
And we talked about motion
estimation techniques are,

00:00:22.250 --> 00:00:23.870
are going to be
the methods of doing this.

00:00:23.870 --> 00:00:27.210
The first one that we mentioned
was featured-based methods,

00:00:27.210 --> 00:00:31.950
where you detect, describe and locate
features in your subsequent frames.

00:00:31.950 --> 00:00:36.300
And we've done a bunch of that in
looking at how we do the sift stuff and

00:00:36.300 --> 00:00:37.670
panoramas and those kinds of things.

00:00:38.720 --> 00:00:41.360
But the other methods were
called direct or dense methods,

00:00:41.360 --> 00:00:44.510
and that's what we're going
to be focusing on today.

00:00:44.510 --> 00:00:48.050
Direct and dense methods,
what they do is they recover motion at

00:00:48.050 --> 00:00:52.105
every pixel in the image and
that gives you a dense flow feel.

00:00:52.105 --> 00:00:56.330
And it is based upon what we call the
spatial temporal brightness variations,

00:00:56.330 --> 00:00:59.380
how the appearances is moving and
it's changing.

00:00:59.380 --> 00:01:04.450
It can be sensitive to appearance
changes but as long as you're getting

00:01:04.450 --> 00:01:09.370
sort of, video like sequences where
you have frames sampled regularly and

00:01:09.370 --> 00:01:10.980
frequently, it works pretty well

