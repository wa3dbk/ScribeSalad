WEBVTT
Kind: captions
Language: en

00:00:00.012 --> 00:00:01.905
Now we're going to talk about the memory model.

00:00:01.905 --> 00:00:05.010
Let's go back to our diagram and draw the threads and blocks and kernels.

00:00:05.010 --> 00:00:09.608
So every thread has access to something called local memory,

00:00:09.608 --> 00:00:13.360
and this is memory that's private to that thread, things like its local variables.

00:00:13.360 --> 00:00:15.852
So the thread can read and write from local memory,

00:00:15.852 --> 00:00:19.311
and the threads in the thread block also have access to something called shared memory.

00:00:19.311 --> 00:00:23.325
So all the threads in this thread block can read and write to the per block shared memory.

00:00:23.325 --> 00:00:26.906
It's important to understand that shared memory is shared among the threads in a block.

00:00:26.906 --> 00:00:30.432
This is a small amount of memory that sits on the SM directly.

00:00:30.432 --> 00:00:34.084
And finally, there's global memory; every thread in the entire system at any time

00:00:34.084 --> 00:00:36.370
can read and write to global memory.

00:00:36.370 --> 00:00:39.272
So threads in 1 kernel can read and write from it.

00:00:39.272 --> 00:00:42.008
Threads in a later kernel can also read and write from it.

00:00:42.008 --> 00:00:46.015
So every thread, to recap, has access to its own local memory,

00:00:46.015 --> 00:00:49.351
has access to shared memory

00:00:49.351 --> 00:00:54.089
that's also accessible to threads specifically in its thread block,

00:00:54.089 --> 00:00:58.027
and to global memory, which is accessible to all of the threads everywhere.

00:00:58.027 --> 00:01:02.837
Of course, everything we've been talking about is on the GPU, but there's also a CPU.

00:01:02.837 --> 00:01:06.274
The CPU thread launches the work on the GPU,

00:01:06.274 --> 00:01:11.579
and of course the CPU has access to its own memory which in CUDA we call host memory.

00:01:11.579 --> 00:01:16.479
Usually data is copied to and from this host memory into the GPU's fast global memory

00:01:16.479 --> 00:01:19.018
before launching a kernel to work on that data.

00:01:19.018 --> 00:01:23.489
We'll talk later about how CUDA threads can access host memory directly.

