WEBVTT
Kind: captions
Language: en

00:00:00.025 --> 00:00:03.512
So let's recap some of the important lessons from this unit.

00:00:03.512 --> 00:00:05.873
If you've made it this far, good for you.

00:00:05.873 --> 00:00:07.637
There's a lot of material in this unit,

00:00:07.637 --> 00:00:10.080
advanced material that's pushing the frontiers of field,

00:00:10.080 --> 00:00:12.625
but that's why you took this class, right?

00:00:12.625 --> 00:00:15.238
So here's some of the lessons we learned along the way.

00:00:15.238 --> 00:00:16.985
Dense N-body.

00:00:16.985 --> 00:00:18.860
We learn 2 main lessons here.

00:00:18.860 --> 00:00:22.132
One is the importance of minimizing global memory bandwidth,

00:00:22.132 --> 00:00:26.463
and the second, reducing parallelism by increasing the amount of work per thread

00:00:26.463 --> 00:00:31.101
might reduce your overall communication costs and hence, your overall run time.

00:00:31.101 --> 00:00:33.940
Sparse Matrix Vector Multiply.

00:00:33.940 --> 00:00:36.973
The right data structure can make a big difference,

00:00:36.973 --> 00:00:39.376
and the keys to high performance with our implementation

00:00:39.376 --> 00:00:42.512
was reducing load imbalance between threads,

00:00:42.512 --> 00:00:44.180
keeping all of our threads busy

00:00:44.180 --> 00:00:47.948
and optimizing to use the most efficient communication possible.

00:00:47.948 --> 00:00:50.186
Breadth-first Reversal Traversal.

00:00:50.186 --> 00:00:54.891
Choosing the most efficient parallel algorithm is perhaps the most important thing you can do.

00:00:54.891 --> 00:00:58.995
For large problems, a superior problem in terms of asymptotic word complexity

00:00:58.995 --> 00:01:02.675
will nearly always be even an optimized, more expensive algorithm.

00:01:02.675 --> 00:01:05.194
And the real challenge in our optimized algorithm

00:01:05.194 --> 00:01:08.836
was handling the irregular expansion and compaction at each step.

00:01:08.836 --> 00:01:12.936
Scan is the natural primitive to handle these operations.

00:01:12.936 --> 00:01:14.872
List ranking.

00:01:14.872 --> 00:01:18.509
This is a good example of a problem that is not inherently parallel.

00:01:18.509 --> 00:01:23.923
To solve it well on a GPU, we use the important technique of trading more work for fewer steps.

00:01:23.923 --> 00:01:27.449
And once again, we see the power of scan to address a problem

00:01:27.449 --> 00:01:31.333
that at first glance seems difficult to parallelize.

00:01:31.333 --> 00:01:33.223
And the hash table.

00:01:33.223 --> 00:01:36.001
The key insight in the hash table implementation

00:01:36.001 --> 00:01:38.395
was recognizing that a serial data structure

00:01:38.395 --> 00:01:40.530
was the wrong fit for this problem.

00:01:40.530 --> 00:01:42.766
Instead, we used cuckoo hashing,

00:01:42.766 --> 00:01:47.577
which was much more parallel friendly.

