WEBVTT
Kind: captions
Language: en

00:00:00.100 --> 00:00:02.310
So, as I mentioned in
sort of a conventional or

00:00:02.310 --> 00:00:04.180
traditional tracking approach,

00:00:04.180 --> 00:00:08.210
what you do is you build a model
before something starts moving, right?

00:00:08.210 --> 00:00:09.690
So you might cut out a patch,

00:00:09.690 --> 00:00:13.938
find a contour,
some method of describing the object.

00:00:13.938 --> 00:00:15.570
And then you do one of,

00:00:15.570 --> 00:00:18.950
remember we talked about optic flow
where you essentially connect the dots.

00:00:18.950 --> 00:00:22.410
You do patch tracking with particles,
which if you're in the OMS class,

00:00:22.410 --> 00:00:23.870
you did as a problem set.

00:00:23.870 --> 00:00:25.980
Or you might even solve some
interesting, complicated,

00:00:25.980 --> 00:00:27.670
optimization problem.

00:00:27.670 --> 00:00:31.760
And then you somehow try to
incorporate some invariance.

00:00:31.760 --> 00:00:36.190
So you might use edges, because you
know that those don't change a lot

00:00:36.190 --> 00:00:40.090
depending upon how the illumination
changes, let's say, all right?

00:00:40.090 --> 00:00:44.010
But the problem is, if I'm going to
track an object over an extended period

00:00:44.010 --> 00:00:46.920
of time, the object and
the environment tend to change.

00:00:46.920 --> 00:00:50.610
And what I would like to do is I would
like to not just track the object but

00:00:50.610 --> 00:00:52.560
in some sense track the changes,

00:00:52.560 --> 00:00:56.630
incorporate the changes
slowly as the object moves.

00:00:56.630 --> 00:00:59.740
So some work that we're
going to talk about and

00:00:59.740 --> 00:01:02.410
these are some slides taken from,
from Yang.

00:01:02.410 --> 00:01:05.550
Who showed a piece,
who did a piece of work that I'll talk

00:01:05.550 --> 00:01:09.690
about along with Ross and Edal they
took some inspiration from two places.

00:01:09.690 --> 00:01:14.060
First of all Michael Black and
Allen Jepson way back in 1996 did

00:01:14.060 --> 00:01:18.230
something called Eigen tracking, so
you guys know all about Eigen faces.

00:01:18.230 --> 00:01:22.150
Well, Eigen tracking was the same
idea but the idea is so, here we have

00:01:22.150 --> 00:01:28.350
Coca Cola cans and here we have these
Eigen images, up this one's a 7 Up can.

00:01:28.350 --> 00:01:29.570
How did that get in there?

00:01:29.570 --> 00:01:33.410
Okay, we have Eigen images of
these different objects and

00:01:33.410 --> 00:01:38.410
the idea was we're going to track
this thing by finding the places

00:01:38.410 --> 00:01:42.750
we can represent well by
using those Eigen images.

00:01:42.750 --> 00:01:46.530
But one of the cool things they did was,
they said, you know ,remember what

00:01:46.530 --> 00:01:51.130
didn't work so well in eigen analysis,
the eigen face, was the alignment?

00:01:51.130 --> 00:01:53.160
Things had to be aligned perfectly?

00:01:53.160 --> 00:01:58.100
Well, suppose we decompose
the problem into the geometric part.

00:01:58.100 --> 00:02:01.140
That is, how is my object moving,
maybe rotating,

00:02:01.140 --> 00:02:04.590
scaling, to what does it look like.

00:02:04.590 --> 00:02:06.230
Now we've already seen this, right?

00:02:06.230 --> 00:02:08.820
When we were doing the good
features to track, we talked a bit.

00:02:08.820 --> 00:02:12.150
In fact, there was an image of of
a speed limit sign getting bigger and

00:02:12.150 --> 00:02:13.310
bigger and it was being tracked and

00:02:13.310 --> 00:02:17.460
the idea was it's the same image patch,
it just deforms.

00:02:17.460 --> 00:02:20.010
Well, there they were using
a single image patch.

00:02:20.010 --> 00:02:25.360
In the eigen tracking, the idea was that
we're going to look for a deformation.

00:02:25.360 --> 00:02:27.970
So could be affine,
could be otherwise, where we got,

00:02:27.970 --> 00:02:32.120
where we have remote translation,
rotation, scaling maybe even shearing.

00:02:32.120 --> 00:02:34.770
But now instead of just
taking a single patch,

00:02:34.770 --> 00:02:39.400
we actually have a set of eigen
vectors that describe the coke can.

00:02:39.400 --> 00:02:43.830
So for example, maybe if I rotate
the coke can a little bit or maybe some,

00:02:43.830 --> 00:02:47.850
some other change, I could represent
all those different appearances.

00:02:47.850 --> 00:02:52.190
When they did it, it was done in sort of
a non linear optimization way and they,

00:02:52.190 --> 00:02:54.370
but more importantly they
took a fixed basis set.

00:02:54.370 --> 00:02:57.530
So it took a whole bunch of images
of coke cans, created a basis set,

00:02:57.530 --> 00:03:00.550
said that's our Coca Cola basis set.

00:03:00.550 --> 00:03:02.500
So we're going to need to do
some improvement on that.

00:03:02.500 --> 00:03:05.440
The other inspiration here is also
something that we've covered,

00:03:05.440 --> 00:03:07.490
which was particle filtering.

00:03:07.490 --> 00:03:11.820
Remember Isard and Blake,
they instead of having a single

00:03:11.820 --> 00:03:14.050
proposal the idea is that you'd
have a bunch of particles and

00:03:14.050 --> 00:03:17.580
each particle would represent
a possible location.

00:03:17.580 --> 00:03:21.510
And that allowed us to handle sort
of non parametric densities, right?

00:03:21.510 --> 00:03:23.320
Use the sampling based approach and

00:03:23.320 --> 00:03:25.330
there what they were using
were like contours, right?

00:03:25.330 --> 00:03:27.430
And they would propagate this over time,

00:03:27.430 --> 00:03:29.170
they would,
they would move the particles forward.

