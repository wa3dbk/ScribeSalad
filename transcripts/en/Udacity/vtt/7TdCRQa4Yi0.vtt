WEBVTT
Kind: captions
Language: en

00:00:00.290 --> 00:00:02.460
Thanks, Ian. Okay, now that we've seen how data

00:00:02.460 --> 00:00:05.640
is stored in HDFS, let's discuss how that data

00:00:05.640 --> 00:00:08.430
is processed with MapReduce. Say I had a large

00:00:08.430 --> 00:00:11.073
file. Processing that serially from the top to the

00:00:11.073 --> 00:00:14.030
bottom could take a long time. Instead, MapReduce is

00:00:14.030 --> 00:00:17.200
designed to process data in parallel, so your file

00:00:17.200 --> 00:00:21.140
is broken into chunks, and then processed in parallel.

00:00:21.140 --> 00:00:23.310
To explain, let's look at a real world scenario.

