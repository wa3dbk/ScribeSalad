WEBVTT
Kind: captions
Language: en

00:00:00.203 --> 00:00:03.468
One of the questions I ask the students in the classes that I teach is,

00:00:03.468 --> 00:00:05.955
"What are you going to do with 100 times more compute?"

00:00:05.955 --> 00:00:07.895
And sometimes that's a really hard question for them.

00:00:07.895 --> 00:00:13.866
There's a lot of head scratching both in terms of what can we do with a super computer that's 100 times more powerful

00:00:13.866 --> 00:00:16.973
and what can you do with something on your desk or in your pocket?

00:00:16.973 --> 00:00:22.816
-Where do you see us going in this direction? 
-Yeah, well I I have an insatiable appetite for FLOPs.

00:00:22.816 --> 00:00:27.847
I would have no trouble using 100 or even 1,000 or even 10,000 times more compute.

00:00:27.847 --> 00:00:31.031
A lot of what I do is designing computers,

00:00:31.031 --> 00:00:35.200
and a lot of that involves prototyping and simulation new computer designs.

00:00:35.200 --> 00:00:37.914
I'm always frustrated about how those simulations run.

00:00:37.914 --> 00:00:43.042
So of I could run RTL simulations of a new computer 100 times faster,

00:00:43.042 --> 00:00:47.745
it would enable me to be much more productive in trying out new ideas for computer design.

00:00:47.745 --> 00:00:48.945
Same for circuit simulations.

00:00:48.945 --> 00:00:51.885
I spend a lot of time waiting for circuit simulation to converge.

00:00:51.885 --> 00:00:57.519
If I could run it 100 times faster, I could not just run one simulation but run whole parameter sweeps at once

00:00:57.519 --> 00:01:02.241
and do optimizations the same time I'm simulating.

00:01:02.241 --> 00:01:04.962
Another thing is also you look at the computers in your car.

00:01:04.962 --> 00:01:08.520
I mean our Tegra processors are actually designed into lots of different automobiles,

00:01:08.520 --> 00:01:13.015
including the Tesla Model S, the Motor Trend Car of the Year,

00:01:13.015 --> 00:01:21.247
but also Audis and BMWs and all sorts of Fords have Tegras in them.

00:01:21.247 --> 00:01:25.818
And the applications people are starting to use for these mobile processors in cars

00:01:25.818 --> 00:01:30.221
involve having lots of computer vision to look at what people inside the car are doing,

00:01:30.221 --> 00:01:31.888
look at what people outside of the car are doing.

00:01:31.888 --> 00:01:37.013
And in many ways it makes your cars much safer by having the car aware of what's going on around it.

00:01:37.013 --> 00:01:41.264
It can in many ways compensate for the driver not being completely alert

00:01:41.264 --> 00:01:43.968
or perhaps texting or doing something they shouldn't be doing.

00:01:43.968 --> 00:01:47.871
And in mobile devices I think there are a lot of compelling applications

00:01:47.871 --> 00:01:51.731
in both computational photography and augmented reality.

00:01:51.731 --> 00:01:56.216
If your mobile device is constantly aware of what's around you, it can be informing you.

00:01:56.216 --> 00:01:57.738
Oh, I think you're hungry.

00:01:57.738 --> 00:02:01.186
Here's a place that has gyros that I know you like

00:02:01.186 --> 00:02:07.746
because I have your profile of your likes and dislikes. Maybe you should stop for lunch.

00:02:07.746 --> 00:02:10.461
Or a block away is this guy who you really don't like.

00:02:10.461 --> 00:02:13.998
Maybe you should turn right at this corner and avoid running into him.

00:02:13.998 --> 00:02:19.504
In many ways, I think it sort of evolved to having your computing devices becoming your personal assistant.

00:02:19.504 --> 00:02:22.674
I always liked Jeeves in the Iron Man movies.

00:02:22.674 --> 00:02:25.945
I would like to have a device I can kind of talk to that is aware

00:02:25.945 --> 00:02:30.384
of the environment around me and can be basically a brain amplifier for me.

00:02:30.384 --> 00:02:33.659
It can sort of remember things that I forget

00:02:33.659 --> 00:02:39.691
and tell me about things in my environment and basically assist me in going through my day,

00:02:39.691 --> 00:02:42.340
both on professional and personal bases.

00:02:42.340 --> 00:02:46.648
So one of the goals of the supercomputer industry is to get up to—the term they use is exascale

00:02:46.648 --> 00:02:50.315
that they'd like to do 10 ^ 18 FLOPs per second.

00:02:50.315 --> 00:02:55.178
Certainly, Nvidia is going to be interested in being in those computers. What are we going to use that for?

00:02:55.178 --> 00:02:58.588
Well, I think first of all, there's nothing magical about an exascale.

00:02:58.588 --> 00:03:00.354
It's like, you know, when we first made

00:03:00.354 --> 00:03:02.888
petascale machines, which is just a few years ago,

00:03:02.888 --> 00:03:07.285
it wasn't like breaking the sound barrier or anything really qualitatively changed,

00:03:07.285 --> 00:03:10.991
but enabled better science and there's always—

00:03:10.991 --> 00:03:14.724
You look at sort of the fidelity of simulations we're able to do today

00:03:14.724 --> 00:03:18.675
to, say, simulate a more efficient engine for automobiles to improve gas mileage,

00:03:18.675 --> 00:03:23.472
and we're making lots of approximations to fit them on the supercomputers we have today.

00:03:23.472 --> 00:03:26.939
As we can get to higher fidelity by resolving grids finer

00:03:26.939 --> 00:03:29.877
and modeling a bunch of effects like turbulence more directly

00:03:29.877 --> 00:03:33.855
rather than using macro models to model them, we'll get more accurate simulations.

00:03:33.855 --> 00:03:39.860
And that will enable a better understanding of combustion in some of the you biotech applications

00:03:39.860 --> 00:03:45.051
of how proteins fold, various other climate—

00:03:45.051 --> 00:03:46.786
-Climate modeling.
-Sure.

00:03:46.786 --> 00:03:48.260
Climate evolves.

00:03:48.260 --> 00:03:52.829
Basically as we get better computing capacity—

00:03:52.829 --> 00:03:56.275
and it's not you're reaching magic exascale and wonderful things happen,

00:03:56.275 --> 00:03:59.034
but at every step along the way, we get better science,

00:03:59.034 --> 00:04:01.572
we are able to design better products.

00:04:01.572 --> 00:04:05.059
And computing is a big driver of both scientific understanding

00:04:05.059 --> 00:04:08.241
and economic progress across across the board.

00:04:08.241 --> 00:04:11.377
And I think it's very important that we maintain that steady march forward,

00:04:11.377 --> 00:04:14.347
and exascale is just one milestone along that march.

00:04:14.347 --> 00:04:21.091
And my understanding is that power is really an enormously crucial thing for them to get right

00:04:21.091 --> 00:04:24.058
to be able to enable the exascale that we don't want machines

00:04:24.058 --> 00:04:27.204
that are going to cost $2 million a month just to plug in.
-Right.

00:04:27.204 --> 00:04:28.368
It's really an economic argument.

00:04:28.368 --> 00:04:31.334
I mean if you really wanted an exascale machine today, you could build one.

00:04:31.334 --> 00:04:35.345
You just have to write a really big check and locate it right next to the nuclear power plant,

00:04:35.345 --> 00:04:38.008
the entire output of which it will consume.

00:04:38.008 --> 00:04:40.783
But I think if there was some application that was so compelling

00:04:40.783 --> 00:04:46.383
they were willing to really write the multi-billion dollar check required to do that, you would do it.

00:04:46.383 --> 00:04:50.016
I think that the real question of exascale is an economical exascale,

00:04:50.016 --> 00:04:56.959
and because on total cost of ownership the power bill is a tremendous fraction.

00:04:56.959 --> 00:04:59.762
So it's not actually an economical exascale machine

00:04:59.762 --> 00:05:02.604
unless you can do it for reasonable power level,

00:05:02.604 --> 00:05:06.908
and the number that's been thrown out is 20 megawatts.

00:05:06.908 --> 00:05:07.943
So that's $20 million a year.

00:05:07.943 --> 00:05:12.871
Yeah, $20 million a year power bill if you're paying roughly $10 a kilowatt hour.

00:05:12.871 --> 00:05:16.529
In fact, the bill actually winds up usually being a little bit higher than that

00:05:16.529 --> 00:05:22.916
because the cost of provisioning energy amortized over, say, a 30-year lifetime of the facility,

00:05:22.916 --> 00:05:27.565
usually is about equal to the annual bill for the energy.

00:05:27.565 --> 00:05:29.401
There is also something called the PUE,

00:05:29.401 --> 00:05:31.650
which is basically the efficiency of providing the energy.

00:05:31.650 --> 00:05:37.429
Even for a very good installation today maybe on the order of 1.1 to 1.2.

00:05:37.429 --> 00:05:43.238
So you pay another, say, 20% to run the air conditioners and fans and things like that in the facility,

00:05:43.238 --> 00:05:47.508
and basically energy you're consuming isn't being consumed by the computer.

00:05:47.508 --> 00:05:52.210
But it's a big challenge for us to get from, say, Sandy Bridge today—

00:05:52.210 --> 00:05:58.572
that's 1.5 nanojoules per instruction—to if you wanted to do exa instructions per second,

00:05:58.572 --> 00:06:02.157
to do an exa FLOP you might have to do more than an exa instruction per second.

00:06:02.157 --> 00:06:05.292
But even if you take that as a thing at 20 megawatts,

00:06:05.292 --> 00:06:07.527
that's 20 picojoules per instruction.

00:06:07.527 --> 00:06:09.852
And that's not just the processor; that's everything.

00:06:09.852 --> 00:06:14.558
That's the memory system, that's the network, that's the io storage system.

00:06:14.558 --> 00:06:16.935
It's the whole ball of wax that to do it.

00:06:16.935 --> 00:06:20.964
So you mainly get 10 picojoules per instruction to actually use in the processor.

00:06:20.964 --> 00:06:24.373
And so even in Nvidia it's not quite close enough to that.

00:06:24.373 --> 00:06:27.100
Yeah, well compared to Sandy Bridge, that's a factor of 150 down,

00:06:27.100 --> 00:06:29.804
and process isn't going to help you much.

00:06:29.804 --> 00:06:32.740
So that's why conventional CPUs are not going to get there.

00:06:32.740 --> 00:06:35.328
It's going to require a hybrid multi-core approach

00:06:35.328 --> 00:06:40.961
with most of the work being done in a GPU like throughput processor to get there.

00:06:40.961 --> 00:06:43.724
But even we have a ways to go.

00:06:43.724 --> 00:06:48.812
We're probably close to over-magnitude, and we might get a factor of three from process.

00:06:48.812 --> 00:06:52.434
We need to be very clever to come up with the other factor of 3 or 4 that we need.

00:06:52.434 --> 00:06:55.682
-Titan does have CPUs in it, yes?
-That's correct.

00:06:55.682 --> 00:06:58.667
So is there a vision where that won't even be the case?

00:06:58.667 --> 00:07:01.424
No I think there are always pieces of the code

00:07:01.424 --> 00:07:06.460
where you have a critical path, you have a piece of single thread code that you need to run very quickly.

00:07:06.460 --> 00:07:10.340
And so you always need a latency optimized processor around to do that,

00:07:10.340 --> 00:07:16.845
but most of the work it's one of these things, it's kind of like a cache memory, where most of your acesses

00:07:16.845 --> 00:07:20.843
are to this little memory that runs really fast but you still need the capacity

00:07:20.843 --> 00:07:22.885
of the big memory sitting behind it, right?

00:07:22.885 --> 00:07:25.912
And so it's, it's the same thing on throughput versus latency.

00:07:25.912 --> 00:07:28.420
Most of your work is done in the throughput processors,

00:07:28.420 --> 00:07:32.254
but when you do have a latency critical thing, you run it in on the latency optimized processors.

00:07:32.254 --> 00:07:36.258
And so you wind up getting the critical path performance of the CPU

00:07:36.258 --> 00:07:39.234
with the bulk of the energy consumption of the GPU.

00:07:39.234 --> 00:07:42.164
-And the bulk of the FLOPs and Titan is certainly going to the GPU's. 
-Right.

00:07:42.164 --> 00:07:45.000
The bulk of the FLOPs will be in the GPU's.

