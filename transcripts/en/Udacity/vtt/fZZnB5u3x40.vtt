WEBVTT
Kind: captions
Language: en

00:00:00.140 --> 00:00:04.560
Another technique that uses a similar
idea to what we did when we increased

00:00:04.560 --> 00:00:08.293
the block size to reduce the number
of misses, is called pre-fetching.

00:00:08.293 --> 00:00:14.070
The way prefetching works is that we
guess which blocks will be accessed soon

00:00:14.070 --> 00:00:18.080
in the future, before they're actually
accessed, and then we bring those

00:00:18.080 --> 00:00:22.300
blocks into the cache ahead of time,
before they actually will be accessed.

00:00:22.300 --> 00:00:23.250
So with no prefetching,

00:00:23.250 --> 00:00:27.380
if time goes to time goes to the right,
we might have an access here.

00:00:27.380 --> 00:00:32.430
Let's say load word A, and then we check
quickly whether it's in our cache,

00:00:32.430 --> 00:00:36.480
and if it is not, we will go to memory
and spend a lot of time waiting for

00:00:36.480 --> 00:00:41.510
it until it comes back, so here we
can supply the data to the processor.

00:00:41.510 --> 00:00:43.690
So this is what happens
with no prefetching.

00:00:43.690 --> 00:00:49.280
With prefetching, assuming that the load
would happen here, sometime before

00:00:49.280 --> 00:00:54.890
the load, we have to guess that A will
be accessed and request it from memory.

00:00:54.890 --> 00:01:00.160
Now, what was memory latency here,
will be here, and at this point,

00:01:00.160 --> 00:01:05.300
the block is in the cache, so
when we try to load it, we have a hit.

00:01:05.300 --> 00:01:09.570
As you can see, with prefetching, we
are guessing what will be accessed and

00:01:09.570 --> 00:01:12.400
start fetching it from
memory into the cache.

00:01:12.400 --> 00:01:16.620
If we guess correctly,
instead of a miss, we get a hit.

00:01:16.620 --> 00:01:20.960
If we guessed incorrectly,
we brought something into the cache

00:01:20.960 --> 00:01:23.700
that replaced something that
might have been useful.

00:01:23.700 --> 00:01:28.360
So with prefetching we have, the good
guesses will eliminate misses, but

00:01:28.360 --> 00:01:31.800
bad guesses lead to what is called

00:01:31.800 --> 00:01:36.930
cache pollution because we are bringing
stuff that is useless into the cache.

00:01:36.930 --> 00:01:40.060
If it doesn't get access, that means
that maybe it would never have been

00:01:40.060 --> 00:01:42.380
brought to the cache in the first place.

00:01:42.380 --> 00:01:43.750
And because of cache pollution,

00:01:43.750 --> 00:01:47.235
because we kick out something that might
have been useful with useless data,

00:01:47.235 --> 00:01:52.380
not only that we didn't
eliminate the miss here,

00:01:52.380 --> 00:01:55.455
because we guessed wrongly,
we also might have created another

00:01:55.455 --> 00:01:58.990
miss because we kicked out something
that later might be accessed.

00:01:58.990 --> 00:02:00.940
And that we don't like.

00:02:00.940 --> 00:02:06.210
So overall prefetching is about
trying to make good guesses so

00:02:06.210 --> 00:02:11.380
that we eliminate misses while
trying to eliminate bad guesses

00:02:11.380 --> 00:02:13.560
because we don't want to
create additional misses.

