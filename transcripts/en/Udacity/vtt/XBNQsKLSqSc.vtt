WEBVTT
Kind: captions
Language: en

00:00:00.150 --> 00:00:05.580
We will now look at two other metrics, known as sensitivity and specificity.

00:00:05.580 --> 00:00:07.520
Let's consider this diagram.

00:00:07.520 --> 00:00:12.610
In this case, the circle represents actual positives,

00:00:12.610 --> 00:00:18.730
which is in fact a sum of the true positives and the false negatives.

00:00:18.730 --> 00:00:24.530
The sensitivity is defined as the true positives, divided by

00:00:24.530 --> 00:00:30.230
true positives plus the false negatives, which are all the actual positives.

00:00:30.230 --> 00:00:33.750
Similarly, let's look at all the actual negatives.

00:00:33.750 --> 00:00:39.720
In this case, it is a sum of true negatives and the false positives.

00:00:39.720 --> 00:00:43.020
The metric specificity is defined as the true

00:00:43.020 --> 00:00:49.140
negatives divided by the sum of the true negatives and the false positives.

00:00:49.140 --> 00:00:54.390
In our example, we were classifying person f and person b.

00:00:54.390 --> 00:00:59.950
In this case we would denote f as a positive case and

00:00:59.950 --> 00:01:01.930
b as a negative case for f.

00:01:03.030 --> 00:01:07.450
Let us denote the true positives, which is the number of

00:01:07.450 --> 00:01:13.870
actual positives that were classified or predictive to be positives, with TP.

00:01:13.870 --> 00:01:16.120
Let's denote the false negatives,

00:01:16.120 --> 00:01:20.550
which are actual positives classified as negative, with FN.

00:01:20.550 --> 00:01:23.590
Let's denote true negatives, which are the number of

00:01:23.590 --> 00:01:28.610
actual negatives that are classified to be negative, with TN.

00:01:28.610 --> 00:01:30.440
And false positives,

00:01:30.440 --> 00:01:36.200
which are actually negatives classified as positive, with FP.

00:01:36.200 --> 00:01:42.205
Also remember, in the language of hypothesis testing where events are classified

00:01:42.205 --> 00:01:47.949
as belonging to a null hypothesis or an alternate hypothesis, false positives

00:01:47.949 --> 00:01:54.070
are called type I errors, and false negatives are called type II errors.

00:01:54.070 --> 00:01:58.510
The accuracy is given as the sum of the true positive, and

00:01:58.510 --> 00:02:02.470
the true negative divided by all the cases.

00:02:02.470 --> 00:02:06.750
All the cases are sum of everything listed here.

00:02:06.750 --> 00:02:12.430
With this notation, we can write the sensitivity and specificity like this.

00:02:12.430 --> 00:02:16.860
Sometimes, you will see the specificity written as 1 minus the false

00:02:16.860 --> 00:02:21.970
positive over the sum of true negative, and the false positive.

00:02:21.970 --> 00:02:25.540
This essentially gives you the expression above.

00:02:25.540 --> 00:02:29.790
So now you're familiar with the accuracy metric,

00:02:29.790 --> 00:02:33.580
the sensitivity metric, and the specificity metric.

00:02:33.580 --> 00:02:40.610
For our poisoned wine classifier, we would want our sensitivity to be very high.

00:02:40.610 --> 00:02:44.720
That is, we want to catch almost all instances of poisoning.

00:02:44.720 --> 00:02:49.740
For the example that you showed in the quiz, this metric is less important.

00:02:49.740 --> 00:02:56.590
For our poisoned wine classifier, the specificity metric is less important,

00:02:56.590 --> 00:03:02.930
since if we falsely label a harmless wine as poisoned, it's not as dangerous.

00:03:02.930 --> 00:03:09.180
For the example that you gave, we want the specificity to be very high.

00:03:09.180 --> 00:03:13.700
We will return to the concept of sensitivity and specificity and

00:03:13.700 --> 00:03:18.760
show you how to choose between classifiers based on these metrics.

