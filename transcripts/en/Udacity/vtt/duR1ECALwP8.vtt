WEBVTT
Kind: captions
Language: en

00:00:00.210 --> 00:00:02.570
This copying overhead that we're talking about

00:00:02.570 --> 00:00:04.800
in this client server interaction in RPC

00:00:04.800 --> 00:00:09.110
call is serious concern in RPC design.

00:00:09.110 --> 00:00:13.890
Why? Because this copying happens every time you

00:00:13.890 --> 00:00:19.530
have a call return between the client and the server. And so if there is

00:00:19.530 --> 00:00:25.600
a place where we want to focus on shaving overheads, it'll be on avoiding

00:00:25.600 --> 00:00:30.010
copying multiple times between the client and the server

00:00:30.010 --> 00:00:33.010
in order to make the RPC calls efficient. And

00:00:33.010 --> 00:00:34.870
if you go back to this analogy of a

00:00:34.870 --> 00:00:37.408
procedure call, the nice thing about this is that this,

00:00:37.408 --> 00:00:41.390
the arguments are set up in the stack. And

00:00:41.390 --> 00:00:44.590
and that might involve some data movement, but there is

00:00:44.590 --> 00:00:48.150
not kernel involvement in the data movement. And that's

00:00:48.150 --> 00:00:50.700
what we would like to be able to accomplish in

00:00:50.700 --> 00:00:57.338
the RPC world as well. And, in fact let's analyze how many times copying

00:00:57.338 --> 00:01:04.370
happens in the RPC system. Recall that in a RPC system the kernel has

00:01:04.370 --> 00:01:10.880
no idea of the syntax and semantics of the arguments that are passed between

00:01:10.880 --> 00:01:15.830
the client and the server. But yet, the kernel has to be the intermediary in

00:01:15.830 --> 00:01:19.130
arranging the rendezvous between the client and the server.

00:01:19.130 --> 00:01:22.441
And therefore what happens in the RPC system is that

00:01:22.441 --> 00:01:25.598
when a client makes a call, there's an entity,

00:01:25.598 --> 00:01:29.070
that is called the client stub. And what the client

00:01:29.070 --> 00:01:31.930
stub is going to do is, the client's thinking

00:01:31.930 --> 00:01:34.340
that it's making a normal procedure call, but it is

00:01:34.340 --> 00:01:37.470
a remote procedure call. And the client stub knows

00:01:37.470 --> 00:01:41.870
that. And what it does is it takes the arguments

00:01:41.870 --> 00:01:44.160
that is in the client call, which is living

00:01:44.160 --> 00:01:47.590
on the stack of the client, and makes an RPC

00:01:47.590 --> 00:01:50.350
packet out of it. This RPC packet is essentially

00:01:50.350 --> 00:01:54.160
serializing the data structures that are being passed as arguments

00:01:54.160 --> 00:01:57.360
by the client into a sequence of bytes. It's

00:01:57.360 --> 00:02:00.420
sort of like herding cats into an enclosed space. So

00:02:00.420 --> 00:02:04.100
that's what is happening by the client stack taking the

00:02:04.100 --> 00:02:07.610
arguments that are on the stack of the client and

00:02:07.610 --> 00:02:11.008
creating a packet of contiguous bytes, which is

00:02:11.008 --> 00:02:13.780
the RPC message. Because that is the only

00:02:13.780 --> 00:02:16.890
way the client can actually communicate this information

00:02:16.890 --> 00:02:19.170
to the kernel. So this is the first copy

00:02:19.170 --> 00:02:22.560
that's happening from the client stack into creating

00:02:22.560 --> 00:02:24.870
the RPC message is the first copy that's

00:02:24.870 --> 00:02:28.830
happening. Even before, the kernel is involved in

00:02:28.830 --> 00:02:32.580
this client server interchange. The next thing that happens,

00:02:32.580 --> 00:02:35.200
the client traps into the kernel and the kernel says

00:02:35.200 --> 00:02:38.170
well, you know there is a message, which is the

00:02:38.170 --> 00:02:41.480
RPC message that has to be communicated to the server.

00:02:41.480 --> 00:02:44.450
And that's sitting in the user address space. I better

00:02:44.450 --> 00:02:47.210
copy it into my kernel buffer so that's a second

00:02:47.210 --> 00:02:50.650
copy that's happening. From the address piece of the client

00:02:50.650 --> 00:02:53.650
is the RPC message is copied into the kernel buffer.

00:02:53.650 --> 00:02:58.020
So that's the second copy. Next the kernel schedules the

00:02:58.020 --> 00:03:01.450
server in the server domain because the server

00:03:01.450 --> 00:03:04.530
has to execute this procedure. So once that server

00:03:04.530 --> 00:03:09.450
has been scheduled the kernel copies the buffer. It,

00:03:09.450 --> 00:03:12.770
it, it has all the arguments packaged in, into

00:03:12.770 --> 00:03:14.880
the server domain. So that it the third copy

00:03:14.880 --> 00:03:17.720
that's happening. So this, so we went from the

00:03:17.720 --> 00:03:21.000
client stack to the RPC message first copy. From

00:03:21.000 --> 00:03:23.790
the RPC message to the kernel buffer, second copy.

00:03:23.790 --> 00:03:26.120
And now the kernel buffer is passed out to

00:03:26.120 --> 00:03:29.710
the service domain, that's a third copy. But unfortunately

00:03:29.710 --> 00:03:32.180
even though we've reached the address space of the

00:03:32.180 --> 00:03:35.900
server, the server procedure cannot access this because from

00:03:35.900 --> 00:03:38.770
the point of view of the procedure call semantics,

00:03:38.770 --> 00:03:41.920
the client of the server think that they are

00:03:41.920 --> 00:03:44.830
just doing procedure call. So the server procedure is

00:03:44.830 --> 00:03:49.420
expecting all of the arguments in the original form on

00:03:49.420 --> 00:03:54.810
the stack of the server, and that's where the server stub comes in. So what the

00:03:54.810 --> 00:04:01.010
server stub is, just like the client stub, the server stub is a piece of code

00:04:01.010 --> 00:04:04.150
that is part of the RPC infrastructure that

00:04:04.150 --> 00:04:06.866
understands the syntax and semantics of the client

00:04:06.866 --> 00:04:10.560
server communication for this particular RPC call. And

00:04:10.560 --> 00:04:14.580
therefore it can take this information that has

00:04:14.580 --> 00:04:20.740
now been passed into the server's address space by the kernel and structure it

00:04:20.740 --> 00:04:24.420
into the set of actual parameters that

00:04:24.420 --> 00:04:27.690
the procedure, the server procedure is expecting.

00:04:27.690 --> 00:04:33.590
So this, from the server domain, wherever the kernel put it, into the stack

00:04:33.590 --> 00:04:36.260
of the server for the server procedure

00:04:36.260 --> 00:04:39.810
to execute that procedure, that's the fourth copy.

00:04:39.810 --> 00:04:42.390
So you can see that just going from

00:04:42.390 --> 00:04:44.955
the client to the server there are four copies

00:04:44.955 --> 00:04:47.760
involved. These two copies are at the user level.

00:04:47.760 --> 00:04:49.990
And these two copies are what the kernel is

00:04:49.990 --> 00:04:53.230
doing in order to protect itself and the

00:04:53.230 --> 00:04:57.230
address spaces from one another by buffering the address

00:04:57.230 --> 00:05:01.240
space contents into a kernel buffer, and passing that

00:05:01.240 --> 00:05:04.900
to the server domain before the server domain can

00:05:04.900 --> 00:05:07.890
start using it in the form of actual parameters

00:05:07.890 --> 00:05:11.630
on the stack. So at this point, the server can

00:05:11.630 --> 00:05:15.550
start executing, the server procedure can start executing, do its

00:05:15.550 --> 00:05:19.150
job. And when it is done, it has to do

00:05:19.150 --> 00:05:22.200
exactly the same thing in order to pass the

00:05:22.200 --> 00:05:24.590
results back to the client. So it is going to

00:05:24.590 --> 00:05:27.340
go through four copies except that we're going to reverse

00:05:27.340 --> 00:05:30.020
it. We're going to start from the server stack and

00:05:30.020 --> 00:05:33.120
go all the way down to getting the information to

00:05:33.120 --> 00:05:36.110
the client stack in order for that exchange to happen.

00:05:36.110 --> 00:05:40.420
So, in other words, with the client server RPC call

00:05:40.420 --> 00:05:44.798
on the same machine with the kernel involvement in this process,

00:05:44.798 --> 00:05:47.580
there's going to be four copies each way. Going from

00:05:47.580 --> 00:05:50.130
the client to the server, there's four copies. Going from

00:05:50.130 --> 00:05:51.700
the server back to the client, there's going to be

00:05:51.700 --> 00:05:55.740
four copies. Two copies are happening in the user space and

00:05:55.740 --> 00:06:00.065
two copies are happening in the kernel space. Are orchestrated by

00:06:00.065 --> 00:06:04.040
the kernel, and two copies orchestrated on the user level. Now

00:06:04.040 --> 00:06:07.550
as you can see this is a huge, huge overhead compared

00:06:07.550 --> 00:06:11.610
to a simple procedure call that I showed you early on.

