WEBVTT
Kind: captions
Language: en

00:00:00.360 --> 00:00:04.610
Android 5.0 introduced a new way of
writing media playback applications.

00:00:04.610 --> 00:00:07.460
Based on media session,
media controller, and

00:00:07.460 --> 00:00:09.900
media browser service classes.

00:00:09.900 --> 00:00:13.320
One of the nice features of this API
is that apps can be abstracted into two

00:00:13.320 --> 00:00:14.470
components.

00:00:14.470 --> 00:00:15.340
One part stores and

00:00:15.340 --> 00:00:18.990
plays back the media and
the other part provides a user interface

00:00:18.990 --> 00:00:22.570
to allow the user to select the item
to play, and a pause, next track, etc.

00:00:22.570 --> 00:00:25.390
An interesting side
effect of this design

00:00:25.390 --> 00:00:29.360
is that your app can export the media
to other apps running on the device.

00:00:29.360 --> 00:00:33.210
So the Android Auto app can query
the available music from your app and

00:00:33.210 --> 00:00:36.782
show it using a user interface
appropriate for the car.

00:00:36.782 --> 00:00:41.080
Android Wear is also able to do the same
and show user interface appropriate for

00:00:41.080 --> 00:00:42.450
the wearable device.

00:00:42.450 --> 00:00:44.902
This all works without you having
to right user interfaces for

00:00:44.902 --> 00:00:46.130
these other platforms.

00:00:46.130 --> 00:00:48.950
If you implement the API correctly,
it all comes for free.

00:00:50.035 --> 00:00:54.105
As a final bonus, Android Wear also
includes media browser support.

00:00:54.105 --> 00:00:56.595
If you allow Android Wear to
call your own GitRoot method,

00:00:56.595 --> 00:00:59.395
it will allow you to browse and
play back music from a wearable device.

00:01:00.455 --> 00:01:04.075
You don't need to write any code for
Android Wear, it just works for free.

00:01:04.075 --> 00:01:06.865
You can try the Sound player
yourself to see this in action.

00:01:08.240 --> 00:01:12.320
So let's talk about how we implement
a media playback app for Android Auto.

00:01:12.320 --> 00:01:14.510
This diagram shows three components.

00:01:14.510 --> 00:01:19.070
Your app on the right, which is all in
an APK file, the Android Auto Companion

00:01:19.070 --> 00:01:22.860
app, this app is responsible for
drawing the user interface and sending

00:01:22.860 --> 00:01:26.720
the pixels to the vehicle display, and
this here is the vehicle display itself.

00:01:26.720 --> 00:01:30.470
It doesn't do much except draw the
pixels from the Android Auto Companion,

00:01:30.470 --> 00:01:33.130
play sound, and caption's voice input.

00:01:33.130 --> 00:01:36.340
Inside your app,
you implement a media browser service.

00:01:36.340 --> 00:01:39.200
This service maintains a true
structure of all of your media,

00:01:39.200 --> 00:01:40.890
such as a collection of music.

00:01:40.890 --> 00:01:43.560
This could be either streamed or
stored locally.

00:01:43.560 --> 00:01:45.680
Your app also implements
a media session,

00:01:45.680 --> 00:01:48.470
which tracks the current state
of what your app is playing.

00:01:48.470 --> 00:01:52.540
You implement a MediaSession.Callback,
to get notified of when the user selects

00:01:52.540 --> 00:01:55.560
a new song or
when the playback controls are pressed.

00:01:55.560 --> 00:01:59.010
The Android Auto App connects to
your media browser service and

00:01:59.010 --> 00:02:02.460
queries it to get the tree structure
of your app's music library.

00:02:02.460 --> 00:02:05.110
The driver of the car then
gets to select a song

00:02:05.110 --> 00:02:09.940
using either the touch screen like
this or using voice search in the car.

00:02:09.940 --> 00:02:13.570
Then Android Auto we use the media
session to run your call backs.

00:02:13.570 --> 00:02:16.726
So you never have to worry about all the
details of making a user interface that

00:02:16.726 --> 00:02:20.370
is safe for driving, because Android
Auto takes care of all that for you.

