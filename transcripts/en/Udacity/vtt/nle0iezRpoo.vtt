WEBVTT
Kind: captions
Language: en

00:00:00.170 --> 00:00:01.260
Okay Michael what's the answer.

00:00:01.260 --> 00:00:03.120
&gt;&gt; Alright, so you kind of were walking us through

00:00:03.120 --> 00:00:08.690
it, but basically if Yi and Ht agree, that means

00:00:08.690 --> 00:00:10.590
they're both negative or they're both positive. They're equal

00:00:10.590 --> 00:00:12.450
to each other. So when we multiply them together we

00:00:12.450 --> 00:00:16.160
get one. One times whatever our alpha thing is,

00:00:16.160 --> 00:00:18.780
some positive number is going to be positive. We're negating

00:00:18.780 --> 00:00:21.500
that, so it's negative E to the negative something is

00:00:21.500 --> 00:00:25.780
something between zero and one. Less than, less than one.

00:00:25.780 --> 00:00:28.870
So, that's going to scale it down. So, it looks

00:00:28.870 --> 00:00:31.400
like. And you know assuming that everything else goes ok

00:00:31.400 --> 00:00:34.960
with, with the way that ,uh, the normalization happens right?

00:00:34.960 --> 00:00:37.580
It seems like it could be depends on the normalization.

00:00:37.580 --> 00:00:42.800
&gt;&gt; So by the way. That's a good point. The the x sub t. Is in fact, what ever

00:00:42.800 --> 00:00:46.230
normalization constant you need at time T, in order

00:00:46.230 --> 00:00:47.550
to make it all work out to be a distribution.

00:00:47.550 --> 00:00:51.270
&gt;&gt; Correct. Then not going to, not going to change.

00:00:51.270 --> 00:00:51.870
&gt;&gt; True.

00:00:51.870 --> 00:00:54.250
&gt;&gt; But is some of them are correct and some of them incorrect, the ones

00:00:54.250 --> 00:00:56.530
that are correct are going to decrease. And the

00:00:56.530 --> 00:00:57.950
ones that are incorrect are going to increase.

00:00:58.970 --> 00:01:01.100
&gt;&gt; That's right, so what's the answer to the quiz.

00:01:01.100 --> 00:01:01.880
&gt;&gt; Depends.

00:01:01.880 --> 00:01:04.780
&gt;&gt; That's true, it does. That's exactly the right answer.

00:01:04.780 --> 00:01:08.480
It depends ,on what else is going on, you're correct. Now.

00:01:08.480 --> 00:01:09.550
&gt;&gt; But I feel like it should

00:01:09.550 --> 00:01:12.470
be decreases, like that's really, mainly what happens.

00:01:12.470 --> 00:01:16.810
&gt;&gt; That's also fair. The answer is, if this one is correct,

00:01:16.810 --> 00:01:20.220
that is they agree, and you disagree on at least some of

00:01:20.220 --> 00:01:24.900
them, at least one, one other example, it will in fact decrease.

00:01:24.900 --> 00:01:28.310
So I could ask a similar question, which is, well what happens

00:01:28.310 --> 00:01:33.210
when they disagree? And at least one other example agrees. Then what happens?

00:01:33.210 --> 00:01:36.020
&gt;&gt; Yeah, then they, then that should increase. Oh.

00:01:36.020 --> 00:01:36.600
&gt;&gt; Right.

00:01:36.600 --> 00:01:39.630
&gt;&gt; Oh. It's going to put more weight on the ones that it's getting wrong.

00:01:39.630 --> 00:01:41.840
&gt;&gt; Exactly. And the ones that it's getting

00:01:41.840 --> 00:01:45.690
wrong must be the ones that are harder. Or at least that's the underlying

00:01:45.690 --> 00:01:47.650
idea. All right, Michael, so you got

00:01:47.650 --> 00:01:49.990
it? So you understand what the equation's for?

00:01:49.990 --> 00:01:53.100
&gt;&gt; Yeah, it look. It seemed really scary at first but it seems you know

00:01:53.100 --> 00:01:55.700
marginally less scary now because all that it's

00:01:55.700 --> 00:01:58.800
doing, it's doing it in a particular way.

00:01:58.800 --> 00:02:01.310
I don't know why it's doing it in this particular way. But all it seems to

00:02:01.310 --> 00:02:07.010
be doing is. The answers that it, it had, it was getting wrong... It puts more

00:02:07.010 --> 00:02:08.180
weight on those and the ones that its

00:02:08.180 --> 00:02:09.800
getting right, it puts less weight on those

00:02:09.800 --> 00:02:11.880
and then you know, the loop goes around

00:02:11.880 --> 00:02:13.450
again and it tries to make a new classifier.

00:02:13.450 --> 00:02:17.600
&gt;&gt; Right, and since the ones that its getting wrong are getting more and

00:02:17.600 --> 00:02:21.820
more weight but we are guaranteed or atleast we've assumed that we have a weak

00:02:21.820 --> 00:02:23.900
learner that will always do better than

00:02:23.900 --> 00:02:28.200
chance. On ,ah, any distribution, it means that

00:02:28.200 --> 00:02:32.490
you'll always be able to output some learner that can get some of the ones

00:02:32.490 --> 00:02:34.080
that you were getting wrong, right.

