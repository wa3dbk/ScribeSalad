WEBVTT
Kind: captions
Language: en

00:00:00.260 --> 00:00:03.100
Fundamentally, the use of dynamics,

00:00:03.100 --> 00:00:08.960
is what's different between just doing
detection, and actually doing tracking.

00:00:08.960 --> 00:00:10.920
And that's shown as an example here.

00:00:10.920 --> 00:00:12.740
Here we have 20 frames taken.

00:00:12.740 --> 00:00:14.250
And here's some dude right there.

00:00:14.250 --> 00:00:16.650
You can see that he's
walking across all these.

00:00:16.650 --> 00:00:18.600
And we just like to keep track of him.

00:00:18.600 --> 00:00:20.770
And of course, he's changing
his appearance every frame.

00:00:20.770 --> 00:00:23.060
He's not going to look identical
from one frame to the next.

00:00:24.220 --> 00:00:29.540
So, detection, we independently
detect the person each time.

00:00:29.540 --> 00:00:31.390
Right?
So, we maybe have a little model of what

00:00:31.390 --> 00:00:34.440
this person looks like, and
we run it maybe all over the image, and

00:00:34.440 --> 00:00:37.376
we say uh-huh, you know, he's here.

00:00:37.376 --> 00:00:39.138
Uh-huh, he's here.

00:00:39.138 --> 00:00:40.740
Uh-huh, he's there.

00:00:40.740 --> 00:00:42.420
And, just these there.

00:00:42.420 --> 00:00:44.990
No more uh-huh's,
cause it's like not exciting anymore.

00:00:44.990 --> 00:00:47.500
Okay, so that's detection.

00:00:47.500 --> 00:00:49.390
Tracking, we do a little different.

00:00:49.390 --> 00:00:52.990
What we do is we predict
the new location

00:00:52.990 --> 00:00:56.250
of the object based upon
the estimated dynamics.

00:00:56.250 --> 00:01:00.570
And I say estimated dynamic, because for
example, this guy, he's walking, so

00:01:00.570 --> 00:01:03.010
maybe we est,
maybe he's got a constant velocity, but

00:01:03.010 --> 00:01:05.170
we don't know what that
velocity is a priority, right?

00:01:05.170 --> 00:01:06.610
We have to estimate it, right?

00:01:06.610 --> 00:01:11.390
So here we have an example
where we detect him here.

00:01:11.390 --> 00:01:14.490
And it says, you know, we'll
estimate the velocity, but maybe we

00:01:14.490 --> 00:01:18.520
estimated zero velocity, or we have some
prior reason to believe he's moving to

00:01:18.520 --> 00:01:22.140
the left, because this is a sidewalk
where people move to the left often.

00:01:22.140 --> 00:01:23.170
Fine.

00:01:23.170 --> 00:01:26.520
That allows us to make
a prediction in the next image

00:01:26.520 --> 00:01:30.250
of where that person will be and
then we detect them.

00:01:30.250 --> 00:01:31.610
So now we can do two things.

00:01:31.610 --> 00:01:35.350
First of all, we can improve our
estimate of where he is based upon both

00:01:35.350 --> 00:01:37.340
our detection and our prediction.

00:01:37.340 --> 00:01:41.340
And second, now we do have
a reasonable estimate of the velocity.

00:01:41.340 --> 00:01:46.280
So we can use that velocity to predict
in the third fame, detect etc., etc.,

00:01:46.280 --> 00:01:47.440
and we iterate.

00:01:47.440 --> 00:01:50.430
So this is what the,
the basic tracking loop is.

