WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.000
So the other thing you mentioned to me that you're improving is this notion of, like, memcache ejection.

00:00:05.000 --> 00:00:12.000
Right. So the memcache plant library has the ability to notice that a memcache node has gone down

00:00:12.000 --> 00:00:15.000
and decide that it's not going to try to talk to it anymore.

00:00:15.000 --> 00:00:18.000
It's kind of a heuristic.

00:00:18.000 --> 00:00:22.000
It notices, like, a number of failures happen so it just decides to back off,

00:00:22.000 --> 00:00:29.000
and it will basically, at that point, just treat the ring as if there's one fewer node.

00:00:29.000 --> 00:00:36.000
And we can not use that until the locking is gone, but once we've done that, memcache will automatically heal itself.

00:00:36.000 --> 00:00:42.000
So we can have self-healing memcache, not the one memcache dies, and the whole site gets a little wonky.

00:00:42.000 --> 00:00:44.000
Right. And we probably could do with more memcache right now,

00:00:44.000 --> 00:00:48.000
but we don't want to add more because it increases our risk of failure.

00:00:48.000 --> 00:00:53.000
Yes. That was something I remember, too. We're always--

00:00:53.000 --> 00:00:57.000
Sometimes we wouldn't add a memcache because we didn't want to redistribute the keys.

00:00:57.000 --> 00:01:03.000
Right. Just the simple act of redistributing the keys was kind of a scary thought.

00:01:03.000 --> 00:01:11.000
Yeah. And right now, even with consistent hashing, if we add one memcache, like in the middle of the night,

00:01:11.000 --> 00:01:16.000
the database slaves will actually be kind of unhappy for maybe an hour or two.

00:01:16.000 --> 00:01:18.000
And that's just one server.

00:01:18.000 --> 00:01:21.000
One thing I used to do, this is kind of a hacky thing.

00:01:21.000 --> 00:01:24.000
I can feel people losing respect for me as I describe this up.

00:01:24.000 --> 00:01:29.000
Whenever we'd bring up a new database slave, I would actually go into the database,

00:01:29.000 --> 00:01:33.000
and I would have an app server that would connect only to that machine,

00:01:33.000 --> 00:01:35.000
and then I would hit all the most popular pages.

00:01:35.000 --> 00:01:37.000
I knew they were the most popular.

00:01:37.000 --> 00:01:40.000
I'd do it by hand. I'd got to reddit hot, funny hot, pics hot.

00:01:40.000 --> 00:01:44.000
And I would just load all those queries to make sure that the cache,

00:01:44.000 --> 00:01:48.000
everything, was all up to date and warm and the database was good,

00:01:48.000 --> 00:01:51.000
because when you bring up a new database slave,

00:01:51.000 --> 00:01:54.000
it hasn't run any queries yet so nothing's been cached.

00:01:54.000 --> 00:02:00.000
One of the things that Postgres does really, really nice is it manages the kind of disk memory dichotomy.

00:02:00.000 --> 00:02:05.000
You know, some of the data's on disk. No, all the data's on disk but only some of it fits in the memory.

00:02:05.000 --> 00:02:11.000
And you need to kind of basically tell Postgres this is the data I want in memory now.

00:02:11.000 --> 00:02:14.000
And so we have to run these queries to get these data machines up,

00:02:14.000 --> 00:02:18.000
because the first few times we bring up a new read slave, we turn it on

00:02:18.000 --> 00:02:21.000
and all of a sudden, it was performing at, like one-tenth the speed of the master,

00:02:21.000 --> 00:02:25.000
and you get monster, like, lag issues. It's a bad situation.

00:02:25.000 --> 00:02:32.000
Yeah, and I mean, heating it up is great because then you don't have to worry about, like, the piling on effect.

00:02:32.000 --> 00:02:36.000
Yes. Yeah. We talked about in unit 6 that cache stampede.

00:02:36.000 --> 00:02:38.000
That shows up in a lot of different flavors.

00:02:38.000 --> 00:02:42.000
You know, if your cache isn't warm, a bunch of people are probably trying to do that query at the same time,

00:02:42.000 --> 00:02:48.000
and it may take 1 second for one person, but if ten people ask at the same time, it's not going to take 10 seconds.

00:02:48.000 --> 00:02:52.000
It might never finish because they might all be slowing each other down trying to,

00:02:52.000 --> 00:02:56.000
like, bring this data in and out of the cache, and things start thrashing. It's nasty.

