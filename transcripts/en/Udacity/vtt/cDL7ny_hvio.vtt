WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:06.000
The way we got around replication lag was
by having memcached. I think at the time--

00:00:06.000 --> 00:00:11.000
Did we run memcached on the app servers
or that there is separate memcached boxes?

00:00:11.000 --> 00:00:17.000
I don't know back then until very recently
there was no memcached on the servers.

00:00:17.000 --> 00:00:19.000
Okay. There is memcached on servers now?

00:00:19.000 --> 00:00:23.000
Yes.There is render cache on the servers
actually. &gt;&gt;Okay. Okay.

00:00:23.000 --> 00:00:25.000
Now, there is a stable cache. &gt;&gt;Okay.

00:00:25.000 --> 00:00:28.000
So, we transitioned, I think, over time.

00:00:28.000 --> 00:00:31.000
I think when we started of memcached
was on each app server,

00:00:31.000 --> 00:00:34.000
and then we started adding more and more app
servers, and the configuration got a little weird

00:00:34.000 --> 00:00:37.000
because we'd bring up a new app server and do
you want to bring up new memcached server also

00:00:37.000 --> 00:00:43.000
re-distribute the keys, so I think when
I left we had a bunch of memcaches

00:00:43.000 --> 00:00:49.000
that were a separate cluster and
these are the memcaches.

00:00:49.000 --> 00:00:54.000
We use memcaches at Reddit for everything.

00:00:54.000 --> 00:00:58.000
It is like the Swiss Army knife of systems.

00:00:58.000 --> 00:01:01.000
I think we used it definitely to avoid replication lag.

00:01:01.000 --> 00:01:05.000
We'd write to the database and
memcached at the same time

00:01:05.000 --> 00:01:08.000
so that when you do an immediate redirect to
a permalink page or something like that

00:01:08.000 --> 00:01:12.000
the data is good to go, if your read
would've otherwise hit the slave.

00:01:12.000 --> 00:01:15.000
The other big system we had and I think
this is kind of the final big system.

00:01:15.000 --> 00:01:20.000
is we had what was called
as the precompute system.

00:01:20.000 --> 00:01:23.000
Doing real time queries against database
was too slow to generate our listing pages.

00:01:23.000 --> 00:01:27.000
So, we had a whole separate database
cluster called the precompute cluster,

00:01:27.000 --> 00:01:31.000
which if I recall was just mirrored version
of all these machines,

00:01:31.000 --> 00:01:37.000
and whenever you would submit a link to Reddit or
vote, we would submit a job to this Q.

00:01:37.000 --> 00:01:41.000
The job would be something like update the
front page or update this person's liked page,

00:01:41.000 --> 00:01:45.000
or all these different things like a vote
can--affects the front page,

00:01:45.000 --> 00:01:50.000
it affects the new page, it affects your
liked listing, all that sort of stuff.

00:01:50.000 --> 00:01:53.000
We put this job in the Q and then
what the Q would do is

00:01:53.000 --> 00:01:59.000
it would say recompute that listing's front
page or recompute that listing's rising page

00:01:59.000 --> 00:02:02.000
or recompute that users' liked page.

00:02:02.000 --> 00:02:04.000
Some of them can be done in place
without actually hitting the database.

00:02:04.000 --> 00:02:08.000
If you submit a link, we just put it
at the top of your submitted page.

00:02:08.000 --> 00:02:13.000
You don't have to do anything fancy but it
also affects the htoness of that link, etc, etc.,

00:02:13.000 --> 00:02:20.000
and we had a separate set of memcaches that were
actually running a technology called memcache DB,

00:02:20.000 --> 00:02:25.000
and memcache DB is just like memcache
but instead of being totally in memory

00:02:25.000 --> 00:02:30.000
it had a little disk datastore so it was
like kind of fast like memcache

00:02:30.000 --> 00:02:32.000
because its mostly memory
but also would persist.

00:02:32.000 --> 00:02:41.000
Data that got recomputed would be put in memcache
DB as kind of this middle-layer cache,

00:02:41.000 --> 00:02:44.000
so we can avoid running queries on these databases.

00:02:44.000 --> 00:02:47.000
That was basically the state of the system when I left.

00:02:47.000 --> 00:02:50.000
Lots of replicated databases--this really
complicated precompute cluster.

00:02:50.000 --> 00:02:53.000
We had this whole separate set of databases
that we could just run queries on

00:02:53.000 --> 00:02:56.000
as hard as we could just one after another.

00:02:56.000 --> 00:02:59.000
These machines were really sad all the time.

00:02:59.000 --> 00:03:08.000
Actually, more specifically, they were literally on
fire all the time like these machines are hot. Right.

00:03:08.000 --> 00:03:15.000
Because no query that the user would see
would actually hit these machines

00:03:15.000 --> 00:03:20.000
so we could just beat the hell out of them, and
when the result is done, it hit this memcache DB

00:03:20.000 --> 00:03:23.000
that's where we'd store the data,
and the users will only hit this,

00:03:23.000 --> 00:03:27.000
so we would lose nodes here all the time
because we're abusing them.

00:03:27.000 --> 00:03:31.000
We could add more. They can be slow. It didn't matter.
It was out of the actual request loop.

00:03:31.000 --> 00:03:35.000
That took a lot of load off the whole system.

