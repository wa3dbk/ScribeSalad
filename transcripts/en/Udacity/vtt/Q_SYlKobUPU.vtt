WEBVTT
Kind: captions
Language: en

00:00:00.570 --> 00:00:05.190
Finally, the last topic we'll cover in this class is AI ethics. Often,

00:00:05.190 --> 00:00:09.310
scientists go about doing science without asking questions about the ethics of

00:00:09.310 --> 00:00:13.350
the science they do. We are also engrossed in questions of funding and proposals

00:00:13.350 --> 00:00:18.630
and papers. However, part of our job as scientists is to ask the question about

00:00:18.630 --> 00:00:22.640
are we doing the right kind of things? There are a large number of

00:00:22.640 --> 00:00:27.080
questions connected with the ethics of AI. We'll post a small number here today.

00:00:27.080 --> 00:00:30.400
There are no easy answers to these questions. So I invite you to discuss these

00:00:30.400 --> 00:00:35.810
questions on the forum? First, AI Ethics put into our economy and our society.

00:00:35.810 --> 00:00:39.910
We have talked a lot in this course about designing AI agent that can act and

00:00:39.910 --> 00:00:43.470
think and behave like humans. However, in the process,

00:00:43.470 --> 00:00:47.520
we quite likely would replace some human jobs with robots. We have talked, for

00:00:47.520 --> 00:00:51.720
example, of robots that can assemble a camera. Does this mean that humans who

00:00:51.720 --> 00:00:55.500
assemble the cameras today will lose their jobs? Of course,

00:00:55.500 --> 00:00:59.790
a counter argument is that new jobs might be created, for example, jobs for

00:00:59.790 --> 00:01:04.760
designing robots. Nevertheless, there are hard issues, but ethical implications

00:01:04.760 --> 00:01:10.090
of AI in terms of human economy and society. Second, much of the modern

00:01:10.090 --> 00:01:13.550
development of AI is driven by defense applications all across the world.

00:01:13.550 --> 00:01:18.680
We already have drones, for example. It is not far-fetched to imagine a future

00:01:18.680 --> 00:01:23.380
where there are robot soldiers on the battlefield. What are the implications of

00:01:23.380 --> 00:01:28.310
introducing robot soldiers? Should we build morality into these soldiers?

00:01:28.310 --> 00:01:31.660
How do we do so? And if you are to build morality into robot,

00:01:31.660 --> 00:01:36.950
what does it teach us about our own morality? A third and related question is,

00:01:36.950 --> 00:01:40.140
that if it's hard building human characteristics like creativity and

00:01:40.140 --> 00:01:45.770
morality into AI agents, at what point do these agents become like humans?

00:01:45.770 --> 00:01:49.060
At what point do we start talking about civil rights for these machines

00:01:49.060 --> 00:01:53.440
because they're indistinguishable from humans. The idea has been touched upon in

00:01:53.440 --> 00:01:57.720
the popular culture a lot, but it is coming closer and closer to reality.

00:01:57.720 --> 00:02:02.020
What are the criteria under which we'd consider machines to be equal to humans?

