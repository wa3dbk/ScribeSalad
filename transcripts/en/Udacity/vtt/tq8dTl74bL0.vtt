WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.000
This gets back to the fundamental question we have of how hard is factoring.

00:00:04.000 --> 00:00:10.000
We saw that it was possible to factor 129 decimal digits in 1994.

00:00:10.000 --> 00:00:15.000
The computing resources to do this were about 1600 machines

00:00:15.000 --> 00:00:17.000
collaborating on the internet.

00:00:17.000 --> 00:00:20.000
Certainly that's much less than many people have access to today.

00:00:20.000 --> 00:00:23.000
There are larger numbers that have been broken since.

00:00:23.000 --> 00:00:29.000
The largest challenge that's been broken so far was RSA-768, which was a challenge.

00:00:29.000 --> 00:00:32.000
Those are bits instead of decimal digits.

00:00:32.000 --> 00:00:37.000
That's equivalent to 232 decimal digits.

00:00:37.000 --> 00:00:42.000
That was done in 2009 using about 2000 years of computational power.

00:00:42.000 --> 00:00:45.000
If we want to know that RSA is secure, we need to understand

00:00:45.000 --> 00:00:50.000
how the cost of factoring depends on the size of the numbers that we need to factor.

00:00:50.000 --> 00:00:53.000
We'd like to know that if we pick a large enough key,

00:00:53.000 --> 00:00:56.000
even an adversary with a large amount of computational power--

00:00:56.000 --> 00:00:59.000
and as the years go on adversaries will have more and more power--

00:00:59.000 --> 00:01:03.000
still won't be able to factor the number and break the RSA.

00:01:03.000 --> 00:01:06.000
We don't know any way to actually prove a problem like this is fundamentally hard.

00:01:06.000 --> 00:01:09.000
The best we can do is look at the best-known algorithms

00:01:09.000 --> 00:01:14.000
and have some confidence because people worked very hard to find better algorithms--

00:01:14.000 --> 00:01:19.000
and progress has been slow--that, barring some very unexpected breakthrough,

00:01:19.000 --> 00:01:21.000
it won't bet much faster.

00:01:21.000 --> 00:01:26.000
This is quite unsatisfying, but it's the best we can do.

00:01:26.000 --> 00:01:30.000
To talk about this, I want to measure the size of the input.

00:01:30.000 --> 00:01:34.000
That's the number of bits--we'll use "b" for that--in the modulus.

00:01:34.000 --> 00:01:37.000
We could try a brute force approach, which would go through all the numbers

00:01:37.000 --> 00:01:40.000
from 2 up to the square root of n, checking whether each one is a factor.

00:01:40.000 --> 00:01:43.000
If it finds a factor, then it returns that.

00:01:43.000 --> 00:01:48.000
Let's be optimistic and assume, unrealistically, that we could do this factoring test

00:01:48.000 --> 00:01:52.000
which could be done by finding the greatest common divisor of the two numbers in constant time.

00:01:52.000 --> 00:01:56.000
Then we're going to need to go through this loop square root of n times,

00:01:56.000 --> 00:02:01.000
which means our running time will be linear in the square root of n,

00:02:01.000 --> 00:02:06.000
but b is the log of n. Our running time will be exponential in b/2.

00:02:06.000 --> 00:02:09.000
This clearly is not going to work for large b.

00:02:09.000 --> 00:02:12.000
But this is not the best-known factoring algorithm.

00:02:12.000 --> 00:02:17.000
The fastest known factoring algorithm as of 2012 when I'm recording this

00:02:17.000 --> 00:02:20.000
is what's known as the General Number Field Sieve.

00:02:20.000 --> 00:02:26.000
This is a bit faster than the brute force, but it's still essentially requires trying all possibilities.

00:02:26.000 --> 00:02:30.000
Its running time is exponential in b^1/3 log b^2/3,

00:02:30.000 --> 00:02:32.000
which is still much worse than being polynomial.

00:02:32.000 --> 00:02:38.000
One important caveat--this is the best known factoring algorithm assuming a classical computer.

00:02:38.000 --> 00:02:42.000
If you have a large quantum computer, which no one does yet,

00:02:42.000 --> 00:02:45.000
there's a faster algorithm, which is known as Shor's algorithm,

00:02:45.000 --> 00:02:49.000
which was created by Peter Shor in 1994.

00:02:49.000 --> 00:02:53.000
That actually has a running time that's polynomial in the number of bits.

00:02:53.000 --> 00:02:57.000
This development, which we won't go into more depth in this class,

00:02:57.000 --> 00:03:00.000
is both why there's a tremendous amount of practical interest

00:03:00.000 --> 00:03:03.000
as well as theoretical interest in quantum computing.

00:03:03.000 --> 00:03:10.000
It seems to allow for some problems that seem to be hard a way to compute them more efficiently.

00:03:10.000 --> 00:03:13.000
This means that factoring is in a complexity class called

00:03:13.000 --> 00:03:17.000
"bounded error quantum polynomial time"--known as BQP.

00:03:17.000 --> 00:03:20.000
What's unknown is whether factoring is in the class NP-Hard,

00:03:20.000 --> 00:03:24.000
which are the hardest problems that can be solved by a nondeterministic turing machine

00:03:24.000 --> 99:59:59.000
in polynomial time.

