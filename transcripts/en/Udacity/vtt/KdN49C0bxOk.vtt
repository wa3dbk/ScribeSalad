WEBVTT
Kind: captions
Language: en

00:00:00.278 --> 00:00:04.778
Given these technical trends, let's characterize the decisions that GPU designers have made.

00:00:04.778 --> 00:00:10.815
One, GPUs have lots of simple compute units that together can perform a large amount of computation.

00:00:10.815 --> 00:00:13.951
In general, the GPU is willing to trade off control for compute

00:00:13.951 --> 00:00:17.154
and choose simpler control complexity and more compute power.

00:00:17.154 --> 00:00:20.226
The consequence of this decision is that the GPU programming model,

00:00:20.226 --> 00:00:24.830
the programmer's view of the machine, is perhaps more restrictive than the CPU's.

00:00:24.830 --> 00:00:28.666
Two, GPUs have an explicitly parallel programming model.

00:00:28.666 --> 00:00:32.168
When we write programs for this machine, we know that we have lots of processors,

00:00:32.168 --> 00:00:34.174
and we have to program it in that way.

00:00:34.174 --> 00:00:36.278
We don't pretend that it has one processor

00:00:36.278 --> 00:00:40.847
and rely on a magic compiler chain to figure out how to map work onto many processors.

00:00:40.847 --> 00:00:43.382
This programming model is a main focus of the class.

00:00:43.382 --> 00:00:45.150
We'll talk a lot more about this.

00:00:45.150 --> 00:00:48.754
And three, GPUs optimize for throughput, not latency.

00:00:48.754 --> 00:00:52.790
They are willing to accept increased latency of any single individual computation

00:00:52.790 --> 00:00:55.559
in exchange for more computation being performed per second.

00:00:55.559 --> 00:01:00.364
Consequently, they're well suited for application domains where throughput is the most important metric.

