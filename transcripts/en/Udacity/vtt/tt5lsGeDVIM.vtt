WEBVTT
Kind: captions
Language: en

00:00:00.690 --> 00:00:04.220
In real life, fast memories are managed
automatically in hardware or

00:00:04.220 --> 00:00:05.990
by the operating system.

00:00:05.990 --> 00:00:07.290
Caches are one example.

00:00:08.320 --> 00:00:11.350
Now, these automatically managed
fast memories are great.

00:00:11.350 --> 00:00:13.670
You can go about your merry way,
writing code and

00:00:13.670 --> 00:00:16.510
algorithms that are oblivious to
what's happening under the hood.

00:00:17.520 --> 00:00:20.475
The only problem is that, when you
do that, performance can suffer.

00:00:20.475 --> 00:00:24.450
Think of the resource
oblivious binary search

00:00:24.450 --> 00:00:26.610
compared to a resource
aware bee tree search.

00:00:27.810 --> 00:00:29.130
But bee trees have a problem too.

00:00:29.130 --> 00:00:32.780
You need to tune that bee perameter
in a machine specific way,

00:00:32.780 --> 00:00:34.005
which effects portability.

00:00:35.095 --> 00:00:37.245
So, this leads us to a really
interesting question.

00:00:38.305 --> 00:00:42.305
Is there a different algorithm or
data structure that would be efficient,

00:00:42.305 --> 00:00:47.525
no matter what the memory hierarchy
looks like or how it's managed?

00:00:47.525 --> 00:00:49.995
In 1999, Matteo Frigo,
Charles Leiserson, and

00:00:49.995 --> 00:00:54.095
a bunch of other MIT yahoos,
discovered a way to be cache oblivious,

00:00:54.095 --> 00:00:57.200
at least for basic problems like
matrix multiply and sorting.

00:00:57.200 --> 00:01:02.231
And that friends, is the topic of this
lesson, cache oblivious algorithms.

