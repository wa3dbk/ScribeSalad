WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.014
We are using CUDA to run a blurring kernel on a gray scale image

00:00:04.037 --> 00:00:10.180
where each pixel is a 32-bit single precision floating point number.

00:00:10.203 --> 00:00:16.642
Let's consider that the kernel is a 5 by 5 kernel, and we're not going to worry about where it's stored.

00:00:16.665 --> 00:00:24.582
Then our operation will be 25 multiplies and 24 adds to compute each pixel output.

00:00:24.620 --> 00:00:29.716
Naturally, we want to use shared memory to store the image so that

00:00:29.716 --> 00:00:33.763
we save memory bandwidth by reading each pixel as few times as possible.

00:00:33.763 --> 00:00:35.844
Our code will look something like this.

00:00:35.844 --> 00:00:40.784
You can choose how to launch this kernel in terms of threads per block configuration.

00:00:40.784 --> 00:00:50.301
You have 2 choices, 1024 by 1 or 32 by 32. Both choices will feature 1,024 threads per block.

00:00:50.301 --> 00:00:55.782
So the first question is, which 1 of these 2 configurations

00:00:55.782 --> 00:00:58.794
will require less global memory bandwidth?

00:00:58.794 --> 00:01:01.115
Please choose here.

00:01:01.126 --> 00:01:05.197
And the second question is, how much less was the ratio

00:01:05.197 --> 00:01:11.183
of global memory bandwidth between the kernel that uses more memory bandwidth and the kernel with less?

00:01:11.183 --> 00:01:15.953
In your calculation, please ignore the bandwidth required for the blurKernel

00:01:15.953 --> 00:01:19.953
and the bandwidth required for right back of v new, and please enter your answer here.

