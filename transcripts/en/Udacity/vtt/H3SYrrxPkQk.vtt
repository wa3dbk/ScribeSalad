WEBVTT
Kind: captions
Language: en

00:00:34.370 --> 00:00:38.020
&gt;&gt; So to give this answer, David again uses background knowledge.

00:00:38.020 --> 00:00:42.230
Someone else in the class might say that, well, he does not think that

00:00:42.230 --> 00:00:47.490
this particular wedge here is the same kind of block as the brick. And

00:00:47.490 --> 00:00:51.780
therefore this is not an example of foo. So I want to draw a number of

00:00:51.780 --> 00:00:57.730
lessons from this particular exercise. First, learning is often incremental.

00:00:57.730 --> 00:01:04.140
We learn from one example at a time. Cognitive agents, human beings,

00:01:04.140 --> 00:01:09.280
intelligent agents in general, are not always given hundreds or thousands or

00:01:09.280 --> 00:01:14.600
millions of examples right from the beginning. We get one example at a time.

00:01:14.600 --> 00:01:17.880
Second, often the examples that we get, are labeled.

00:01:17.880 --> 00:01:22.830
There is a teacher which tells us this a positive example, or this is a negative

00:01:22.830 --> 00:01:26.790
example. This is called supervised learning in machine learning literature.

00:01:26.790 --> 00:01:30.600
Because here there is a teacher which has labeled all the examples for

00:01:30.600 --> 00:01:34.990
you. Third, the examples can come in a particular order.

00:01:34.990 --> 00:01:39.030
There are always some positive examples, always some negative examples.

00:01:39.030 --> 00:01:43.340
The first example, typically is a positive example. Fourth,

00:01:43.340 --> 00:01:46.890
this is quite different from case based reasoning. In case based reasoning,

00:01:46.890 --> 00:01:51.880
which we had discussed last time, we had all of these examples, which we

00:01:51.880 --> 00:01:57.620
stored in their raw form in memory. We'll reuse them. I this particular case,

00:01:57.620 --> 00:02:03.010
however, we're abstracting concepts from there. Fifth, the number

00:02:03.010 --> 00:02:07.100
of examples from which we're extracting concepts is very small. We're not

00:02:07.100 --> 00:02:10.810
talking here about millions of examples from which we're doing the abstraction.

00:02:10.810 --> 00:02:15.530
Sixth, when we are trying to abstract concepts from examples, then,

00:02:15.530 --> 00:02:19.720
what exactly to abstract? What exactly, to learn? What exactly to generalize,

00:02:19.720 --> 00:02:25.251
becomes a very hard problem. There is a tendency to often overgeneralize, or

00:02:25.251 --> 00:02:29.930
often, to overspecialize. How does the intelligent agent find out,

00:02:29.930 --> 00:02:33.950
exactly what is [UNKNOWN] generalization? These are hard questions, and

00:02:33.950 --> 00:02:35.675
we'll look at some of these questions in just a minute.

