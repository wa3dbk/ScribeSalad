WEBVTT
Kind: captions
Language: en

00:00:00.310 --> 00:00:02.380
Which ones did you think,
David, and why?

00:00:02.380 --> 00:00:05.550
&gt;&gt; So for learning a script, I said that
five of the things we've talked about so

00:00:05.550 --> 00:00:08.250
far would really help
an agent learn a script.

00:00:08.250 --> 00:00:10.430
So we've seen in the past
that semantic networks and

00:00:10.430 --> 00:00:12.530
frames are representationally
equivalent.

00:00:12.530 --> 00:00:16.149
We saw that when we put the raven's
progressive matrices problems

00:00:16.149 --> 00:00:20.010
in terms of first semantic networks and
then converted them to frames.

00:00:20.010 --> 00:00:23.140
Frames, as we've seen, are very useful
for storing the type of information

00:00:23.140 --> 00:00:26.050
necessary to construct
a thorough script.

00:00:26.050 --> 00:00:28.490
And if semantic networks
are representationally equivalent,

00:00:28.490 --> 00:00:32.479
then we can also imagine a script
composed of semantic networks instead.

00:00:32.479 --> 00:00:35.280
To skip the middle couple for a second,
I can imagine incremental concept

00:00:35.280 --> 00:00:37.790
learning to be very important
to learning scripts.

00:00:37.790 --> 00:00:40.140
We can an imagine an AI agent
acting in the world and

00:00:40.140 --> 00:00:43.830
encountering multiple events everyday,
and even to start to kind of develop

00:00:43.830 --> 00:00:48.090
a categorization scheme for
those different experiences.

00:00:48.090 --> 00:00:51.745
So for example, that agent might learn
that if I'm developing a script for

00:00:51.745 --> 00:00:55.695
fast food, whether or not I see a
McDonald's logo or a Wendy's logo when I

00:00:55.695 --> 00:00:59.185
walk in, is not necessarily
important to which script I run.

00:00:59.185 --> 00:01:01.915
But whether or not I see a counter
with cashiers behind it or

00:01:01.915 --> 00:01:04.275
a hostess waiting to see me,
is important.

00:01:04.275 --> 00:01:08.225
So that way, an agent can use
incremental concept learning to learn

00:01:08.225 --> 00:01:12.762
the difference, for example, a fast
food script and a fine dining script.

00:01:12.762 --> 00:01:16.300
So Ashok discussed before, planning
happens when an agent has an initial

00:01:16.300 --> 00:01:20.200
state and a goal state and figures
out how to navigate between the two.

00:01:20.200 --> 00:01:21.510
Once they figured out that plan for

00:01:21.510 --> 00:01:23.830
navigating between that initial
state and that goal state,

00:01:23.830 --> 00:01:27.590
that then becomes a script that could be
transferred to a new similar situation

00:01:27.590 --> 00:01:29.886
without having to completely
re-plan the route from scratch.

00:01:29.886 --> 00:01:34.220
And finally common sense reasoning helps
the agent out because it gives the agent

00:01:34.220 --> 00:01:37.380
a kind of a language within which to
learn the script in the first place.

00:01:37.380 --> 00:01:40.660
It can learn a script within this
language of primitive actions that

00:01:40.660 --> 00:01:44.860
it understands and then can use those to
make sense of new and novel situations.

00:01:44.860 --> 00:01:47.690
Production systems and learning by
recording cases don't really apply as

00:01:47.690 --> 00:01:50.720
much to scripts because they both
involve representations at a very

00:01:50.720 --> 00:01:54.850
different level of abstraction,
at a very low level of abstraction.

00:01:54.850 --> 00:01:57.250
With learning by recording cases,
we tend to stick with the cases,

00:01:57.250 --> 00:01:59.240
whereas scripts we have
an abstraction over them.

00:01:59.240 --> 00:02:02.560
And production systems are more like
atoms of knowledge representation

00:02:02.560 --> 00:02:05.750
instead of molecules or compounds
like we deal with with scripts.

00:02:05.750 --> 00:02:06.660
&gt;&gt; That's good, David.

00:02:06.660 --> 00:02:10.070
I may add, one of the things
regarding the semantic networks.

00:02:10.070 --> 00:02:12.640
Recall that when we
discussed semantic networks,

00:02:12.640 --> 00:02:16.470
we had considered how we could use
semantic networks to interpret stories.

00:02:16.470 --> 00:02:17.700
We'll use this same example.

00:02:17.700 --> 00:02:19.270
Ashok wanted to become rich.

00:02:19.270 --> 00:02:20.370
He got a gun.

00:02:20.370 --> 00:02:24.270
And we said that inside a semantic
network the notes that correspond to

00:02:24.270 --> 00:02:28.550
Ashok wanted rich and gun get activated.

00:02:28.550 --> 00:02:32.357
And the activation spread from there and
there's a path that formed a spare

00:02:32.357 --> 00:02:36.920
semantic network that path is the
interpretation of this particular story.

00:02:36.920 --> 00:02:39.640
In a sense a script is that part.

00:02:39.640 --> 00:02:42.270
&gt;&gt; Of course if you think you see a
connection between production systems or

00:02:42.270 --> 00:02:45.190
learning by recording cases and
scripts that I haven't seen.

00:02:45.190 --> 00:02:47.560
Or if you think the connection
between the other topics and

00:02:47.560 --> 00:02:49.830
scripts isn't quite as
close as I've described,

00:02:49.830 --> 00:02:51.980
feel free to head over to our forums and
we'll discuss it there.

