WEBVTT
Kind: captions
Language: en

00:00:00.320 --> 00:00:04.350
So, to do this even risk assessment,
we said we needed to know two things.

00:00:04.350 --> 00:00:06.440
One is, we need these loss functions.

00:00:06.440 --> 00:00:08.070
We need these costs, right?

00:00:08.070 --> 00:00:09.260
Somebody has to tell me,

00:00:09.260 --> 00:00:13.610
because I can't know that, it's not
defined intrinsically in the data.

00:00:13.610 --> 00:00:16.720
It's the cost of, you know,
either societal cost,

00:00:16.720 --> 00:00:18.330
economic cost, you know, whatever.

00:00:18.330 --> 00:00:21.570
As I said before, the cost of
somebody calling somebody stupid,

00:00:21.570 --> 00:00:26.410
who's really smart and
large might be much

00:00:26.410 --> 00:00:31.540
worse than the cost of calling somebody
smart whose actually stupid and large.

00:00:31.540 --> 00:00:32.940
Think about that one, okay?

00:00:32.940 --> 00:00:36.480
The, but the basic idea is that
the cost come from outside the data.

00:00:36.480 --> 00:00:41.860
But the other thing that I need is that
I actually need to know the probability

00:00:41.860 --> 00:00:44.690
that something really is
a four given some measurement.

00:00:44.690 --> 00:00:47.590
The probability that really is
a nine given some measurement.

00:00:47.590 --> 00:00:48.140
All right?

00:00:48.140 --> 00:00:49.540
And we need to be able
to evaluate those.

00:00:49.540 --> 00:00:50.320
The way we did that,

00:00:50.320 --> 00:00:54.830
if you recall, is that we, we talked
about estimating the likelihood.

00:00:54.830 --> 00:00:58.250
That's the probability of
the measurement given that it's,

00:00:58.250 --> 00:00:59.800
here we were doing skin colors.

00:00:59.800 --> 00:01:02.420
Given that it's a four or nine, or
given that it's skin or not skin.

00:01:02.420 --> 00:01:08.220
And then, how did we go from likelihoods
to actual probabilities posteriors?

00:01:08.220 --> 00:01:10.310
Well, remember we used Bayes rule.

00:01:10.310 --> 00:01:14.770
Okay, and Bayes rule would allow us
to take these likelihood, right?

00:01:14.770 --> 00:01:17.960
The probability of getting the
measurement given the class, skin, etc.

00:01:17.960 --> 00:01:19.774
Multiply that by this prior,

00:01:19.774 --> 00:01:23.197
just what's the probability
of getting a four or nine?

00:01:23.197 --> 00:01:25.024
Or, in this case,
of getting a pixel being skin.

00:01:25.024 --> 00:01:27.800
Or getting a pixel not being skin.

00:01:27.800 --> 00:01:29.760
And you multiply them, and
you have to normalize them.

00:01:29.760 --> 00:01:32.870
And you get this posterior,
which was the thing you wanted, okay?

00:01:32.870 --> 00:01:34.517
And that's what this
equation down here says.

00:01:34.517 --> 00:01:37.967
The probability of skin, given x,
proportional to P of x, given skin,

00:01:37.967 --> 00:01:39.564
the likelihood times the prior.

00:01:39.564 --> 00:01:43.127
And of course, then, the question came
up of, where does that prior come from?

00:01:43.127 --> 00:01:47.220
And again, we had to learn it
somehow from training data.

00:01:47.220 --> 00:01:48.340
So we showed an example.

00:01:48.340 --> 00:01:50.950
This is from Garrett Bradsky
of classifying skin color.

00:01:50.950 --> 00:01:54.850
At the end of the day,
you would basically take this value and

00:01:54.850 --> 00:01:56.900
you would compare it to some threshold.

00:01:56.900 --> 00:01:58.930
And you'd say okay,
if it's higher than the threshold,

00:01:58.930 --> 00:02:01.320
I'm going to call it skin,
otherwise it's not.

