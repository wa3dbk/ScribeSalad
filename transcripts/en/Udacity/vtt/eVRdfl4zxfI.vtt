WEBVTT
Kind: captions
Language: en

00:00:00.130 --> 00:00:02.719
So now let's try to apply the idea of pipelining

00:00:02.719 --> 00:00:06.610
to a processor. In a traditional processor, that is, nowaday

00:00:06.610 --> 00:00:08.656
is too simple so we only use it to teach

00:00:08.656 --> 00:00:12.180
students, but it still shows how things work. We have

00:00:12.180 --> 00:00:15.510
a program counter, we use the program counter, to act

00:00:15.510 --> 00:00:19.840
as the instruction memory. We get the instruction from there.

00:00:19.840 --> 00:00:22.280
We look at the instruction to decode it, to figure

00:00:22.280 --> 00:00:25.220
out which type of instruction it is. Meanwhile we could be

00:00:25.220 --> 00:00:29.200
reading our registers. Once we have read our registers, we can

00:00:29.200 --> 00:00:31.760
feed them to the ALU, where we are going to do the

00:00:31.760 --> 00:00:35.370
add or subtract or an XO or whatever the instruction wants

00:00:35.370 --> 00:00:38.010
us to do. The decoding logic is going to tell the ALU

00:00:38.010 --> 00:00:40.822
what to do. Once we get the result of the ALU,

00:00:40.822 --> 00:00:43.318
we could be done and just write the result to the

00:00:43.318 --> 00:00:46.800
register, or we could have a load or a store instruction.

00:00:46.800 --> 00:00:51.150
In which case, what the ALU computed is really the address

00:00:51.150 --> 00:00:53.830
that we use to access our data memory, and what

00:00:53.830 --> 00:00:56.360
comes out of data memory is what we end up

00:00:56.360 --> 00:01:00.072
writing to our registers. And then of course there is

00:01:00.072 --> 00:01:02.844
stuff to do with branches and so on, but basically

00:01:02.844 --> 00:01:05.550
we can do one instruction per cycle by starting at

00:01:05.550 --> 00:01:09.642
the BC, fetching the instruction, accessing the registers, doing the

00:01:09.642 --> 00:01:13.338
operation, accessing the data memory and then writing the result

00:01:13.338 --> 00:01:16.752
back to registers. So you can see that the instruction

00:01:16.752 --> 00:01:19.594
kind of goes through these five phases. We fetch

00:01:19.594 --> 00:01:22.762
the instruction, we read registers and decode, we

00:01:22.762 --> 00:01:24.994
use the ALU, we access the memory and

00:01:24.994 --> 00:01:28.400
finally, we write the register. The time to

00:01:28.400 --> 00:01:31.990
do this might be something like 20 nanoseconds.

00:01:31.990 --> 00:01:34.440
So now we can do one instruction every

00:01:34.440 --> 00:01:38.390
20 nanoseconds. So how do we apply pipelining

00:01:38.390 --> 00:01:42.180
to this? Well, the idea is that if here

00:01:42.180 --> 00:01:47.424
we have our fetch, the code, ALU memory and width part

00:01:47.424 --> 00:01:52.590
of this processor. And here we show what happens in cycle one.

00:01:52.590 --> 00:01:57.493
We will fetch some instruction I1. In cycle two instruction

00:01:57.493 --> 00:02:02.320
I1 moves to decode. In cycle C3 instruction I1

00:02:02.320 --> 00:02:07.326
will be doing the aerial operation. In cycle C4 I1 will

00:02:07.326 --> 00:02:13.970
move to do memory, and then in cycle C5 I1 will write the result. And the next

00:02:13.970 --> 00:02:16.480
cycle we can begin the instruction two. If

00:02:16.480 --> 00:02:18.920
we do that, then we really will finish one

00:02:18.920 --> 00:02:22.444
instruction every 20 nanoseconds. If we apply the

00:02:22.444 --> 00:02:25.057
idea of pipelining here, in cycle one, we are

00:02:25.057 --> 00:02:28.620
still fetching instruction I1. In cycle two, we will

00:02:28.620 --> 00:02:32.850
be decoding instruction I1, but we can begin fetching

00:02:32.850 --> 00:02:38.946
the instruction I2. When instruction I1 move to do the ALU operation, I2 can

00:02:38.946 --> 00:02:45.398
move to be decoded and I3 can be fetched. In the fourth cycle, I1 is the memory

00:02:45.398 --> 00:02:51.539
stage, I2 will be doing the ALU operation, I3 will be here being decoded and I4

00:02:51.539 --> 00:02:57.990
will be fetched. And then when I1 is in the last part of the pipeline,

00:02:57.990 --> 00:03:00.450
I2 will be right after it in the

00:03:00.450 --> 00:03:04.190
memory state. I3 will be doing the ALU operation.

00:03:04.190 --> 00:03:06.740
I4 will be decoded, and we will be

00:03:06.740 --> 00:03:10.010
fetching an instruction I5. So now the idea is

00:03:10.010 --> 00:03:13.070
that once the I1 leaves the pipeline, very

00:03:13.070 --> 00:03:15.966
soon after that I2 will leave the pipeline. If

00:03:15.966 --> 00:03:19.251
we divide this 20 nanosecond into five equal pieces

00:03:19.251 --> 00:03:22.960
for these stages, each stage will be four nanoseconds.

00:03:22.960 --> 00:03:26.210
And now, the latency to do I1 is till

00:03:26.210 --> 00:03:29.740
20 nanoseconds. So it takes 20 nanoseconds to do

00:03:29.740 --> 00:03:33.438
an instruction. But the throughput will be one instruction,

00:03:33.438 --> 00:03:36.870
will finish every four nanoseconds because once I1 leaves,

00:03:36.870 --> 00:03:39.246
that's how long it takes for I2 to leave,

00:03:39.246 --> 00:03:42.580
and then we just keep pouring instructions out. So,

00:03:42.580 --> 00:03:45.122
it's similar to the oil pipeline. It takes a

00:03:45.122 --> 00:03:47.675
while to fill the pipeline, but once we do,

00:03:47.675 --> 00:03:50.670
instructions keep pouring out at a very high rate.

