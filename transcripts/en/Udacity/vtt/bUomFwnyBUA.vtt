WEBVTT
Kind: captions
Language: en

00:00:00.970 --> 00:00:05.550
So, let's go ahead and fit our collected data to an exponential distribution,

00:00:05.550 --> 00:00:08.230
we'll adjust our analysis graph as such.

00:00:08.230 --> 00:00:11.940
Now, as you recall from your introduction to statistics class,

00:00:11.940 --> 00:00:16.590
the form of an exponential distribution is 1 over beta times e to

00:00:16.590 --> 00:00:19.210
the power minus x over beta.

00:00:19.210 --> 00:00:23.440
Thus, fitting an exponential curve to the earlier histogram,

00:00:23.440 --> 00:00:27.510
means finding the parameter beta forming the PDF from which

00:00:27.510 --> 00:00:30.190
the observed data is most likely to have been produced.

00:00:31.530 --> 00:00:35.700
Now this gets into something called a maximum likelihood estimation.

00:00:35.700 --> 00:00:40.000
This is something that another Udacity class goes into a lot of detail about,

00:00:40.000 --> 00:00:43.300
we've put a link to that lecture in the instructor's notes.

00:00:43.300 --> 00:00:44.880
But very briefly,

00:00:44.880 --> 00:00:48.960
the maximum likelihood estimation strategy takes the following approach.

00:00:48.960 --> 00:00:53.350
Let's suppose that I've got a collection of data points, data point d1,

00:00:53.350 --> 00:00:54.160
d2, through dN.

00:00:55.370 --> 00:00:58.270
The maximum likelihood estimation approach,

00:00:58.270 --> 00:01:01.860
asks the question, what's the probability that I saw each of

00:01:01.860 --> 00:01:04.650
these observed data points all at the same time.

00:01:04.650 --> 00:01:08.960
I don't know the specific values of these probabilities, but I do know the form

00:01:08.960 --> 00:01:12.740
of them, because I know that they conform to the exponential distribution.

00:01:12.740 --> 00:01:15.180
The only thing I don't know is beta.

00:01:15.180 --> 00:01:18.480
And, so I can write this expression as a function of beta.

00:01:18.480 --> 00:01:20.420
When I maximize this,

00:01:20.420 --> 00:01:24.160
I can then find the value of beta that gives me that maximum.

00:01:24.160 --> 00:01:27.200
That's maximum likelihood estimation in a nutshell.

00:01:27.200 --> 00:01:29.160
Now, what does this get us?

00:01:29.160 --> 00:01:32.850
If it is the case that an exponential process is a good model for

00:01:32.850 --> 00:01:37.520
describing tweeting behavior, then we can use it to predict the next tweet time.

00:01:37.520 --> 00:01:41.010
So this comes actually from a simple expectation calculation.

00:01:41.010 --> 00:01:43.980
Let's suppose that we already know the parameter beta.

00:01:43.980 --> 00:01:48.008
Let's define that x is the random variable time until next tweet,

00:01:48.008 --> 00:01:50.170
a.k.a inter-tweet time.

00:01:50.170 --> 00:01:55.730
Now the PDF for x at time t is just the exponential evaluated at t.

00:01:55.730 --> 00:02:00.090
The expected value of the distribution, it's just this integral here,

00:02:00.090 --> 00:02:04.110
which should look very familiar, which is equal to the parameter data.

00:02:04.110 --> 00:02:06.060
So let's think about what this means fora second.

00:02:06.060 --> 00:02:08.830
If we have a fitted exponential distribution meaning we

00:02:08.830 --> 00:02:13.680
know what the parameter data is, then it turns out we can use the parameter data

00:02:13.680 --> 00:02:18.000
as a prediction of the number of seconds to wait until the next tweet.

00:02:18.000 --> 00:02:22.660
Now, Let's go ahead and find the beta parameter using Python Notebook.

00:02:22.660 --> 00:02:26.900
Let's go ahead and find the beta parameter using IPython Notebook.

00:02:26.900 --> 00:02:30.180
So here we have again the same histogram describing intertweet times that

00:02:30.180 --> 00:02:31.480
we saw earlier.

00:02:31.480 --> 00:02:34.270
So let's first think about what we're trying to fix.

00:02:34.270 --> 00:02:37.630
We want to find the beta parameter which produces a curve which

00:02:37.630 --> 00:02:39.640
most looks like this.

00:02:39.640 --> 00:02:41.780
In order to perform the exponential fit,

00:02:41.780 --> 00:02:46.050
we're going to use a function from the scipy package called curve_fit.

00:02:46.050 --> 00:02:47.890
Let's just go ahead and import that.

00:02:47.890 --> 00:02:50.260
So curve_fit does the following.

00:02:50.260 --> 00:02:53.630
Let's suppose that we got some values which we're trying to reproduce.

00:02:53.630 --> 00:02:57.260
And we got a callable function here called fitFunc,

00:02:57.260 --> 00:03:01.255
which you can pass an independent variable t and a parameter,

00:03:01.255 --> 00:03:05.430
any number of parameters, but in this case we've just got 1, the beta parameter.

00:03:06.540 --> 00:03:07.100
And as you can see,

00:03:07.100 --> 00:03:11.760
all that does is just evaluate an exponential at the appropriate value.

00:03:11.760 --> 00:03:15.970
You can see here that the number b is defined as the inverse of what it

00:03:15.970 --> 00:03:19.860
would typically be defined at in an exponential distribution.

00:03:19.860 --> 00:03:23.100
So instead of 1 over beta, it just appears as b.

00:03:23.100 --> 00:03:28.630
So you can, anywhere you see b, you can think of that as 1 divided by beta.

00:03:28.630 --> 00:03:31.560
So again, fitFunc is just a callable function which takes

00:03:31.560 --> 00:03:35.530
the input independent variable time t and

00:03:35.530 --> 00:03:41.110
the beta parameter represented here as its inverse just as the letter b.

00:03:41.110 --> 00:03:45.610
And then evaluates the exponential function at the appropriate time.

00:03:45.610 --> 00:03:50.960
So if you hand curve fit that callable function and

00:03:50.960 --> 00:03:56.000
the values which are trying to reproduce here captured in the variable count.

00:03:56.000 --> 00:04:00.520
Then the curved fit finds the value of beta to put into fit func that

00:04:00.520 --> 00:04:05.390
best matches the count values, it does this using mean squared error loss.

00:04:05.390 --> 00:04:06.430
Let's go ahead and evaluate that.

00:04:06.430 --> 00:04:11.218
You can see here that curve_fit actually returns two parameters,

00:04:11.218 --> 00:04:12.900
fitParams and fitCov.

00:04:12.900 --> 00:04:17.491
The first one, fitParams is just the beta parameter that we're interested in,

00:04:17.491 --> 00:04:20.189
and you can see that the actual beta parameter is

00:04:20.189 --> 00:04:22.640
one over the parameter that we specified.

00:04:22.640 --> 00:04:30.140
So, 1,451.5 seconds, but curve_fit also returns a covariance matrix.

00:04:30.140 --> 00:04:34.130
The second thing that cur fit returns is a covariance matrix.

00:04:34.130 --> 00:04:36.520
There's one entry in the covariance matrix for

00:04:36.520 --> 00:04:39.610
each pair of parameters that we're trying to fit for.

00:04:39.610 --> 00:04:43.500
So in our case, we have only single parameter, b, that we're trying to fit for,

00:04:43.500 --> 00:04:46.310
and so the covariance matrix with only a single entry.

00:04:46.310 --> 00:04:48.170
Although in general there is more.

00:04:48.170 --> 00:04:50.205
So what does the matrix mean here in this case.

00:04:50.205 --> 00:04:53.028
Well, what curve_fit actually did,

00:04:53.028 --> 00:04:58.160
is it tried to the best value of b over many bootstrapped samples.

00:04:58.160 --> 00:05:00.930
This number here which amounts to the variance of that

00:05:00.930 --> 00:05:06.090
number describes how much b changed over those bootstrapped samples.

00:05:06.090 --> 00:05:09.520
So, the higher this covariance value here means,

00:05:09.520 --> 00:05:12.720
the more that be changed over the bootstrap samples.

00:05:12.720 --> 00:05:16.460
That means that we should be less certain of what the parameter's value is.

00:05:16.460 --> 00:05:17.330
As you can see here,

00:05:17.330 --> 00:05:21.630
the covariance value is quite low, 1.04 times 10 to the negative ninth.

00:05:21.630 --> 00:05:23.850
That translates to high confidence.

00:05:23.850 --> 00:05:28.590
So, we got our beta value, 1451 and a half seconds.

00:05:28.590 --> 00:05:31.040
Let's take a look at how well this fit does.

00:05:31.040 --> 00:05:34.530
You can see, here, in blue, is the original intertweet times.

00:05:34.530 --> 00:05:38.150
The exponential fit that we just did, is displayed in yellow.

00:05:38.150 --> 00:05:41.420
So we got our beta value, 1451 and a half seconds.

00:05:42.700 --> 00:05:46.800
Recall from earlier that if we are going to use an exponential fit as our model,

00:05:46.800 --> 00:05:49.930
then we use the beta parameter as the number of seconds to

00:05:49.930 --> 00:05:53.010
guess until the next time that the person tweets.

00:05:53.010 --> 00:05:57.620
And so, the model that we would use in this case is that we're going to

00:05:57.620 --> 00:06:01.450
guess 1451.5 seconds, until this person tweets next.

00:06:01.450 --> 00:06:04.670
Let's take a look at a histogram of the signed error of

00:06:04.670 --> 00:06:06.350
always making that guess.

00:06:06.350 --> 00:06:09.660
So, here, we're looping through each value in timeUntilNext.

00:06:09.660 --> 00:06:13.990
And evaluating the difference between that and our guess.

00:06:13.990 --> 00:06:17.330
Now, let's look at a histogram, that's very interesting.

00:06:17.330 --> 00:06:19.250
In the next few videos,

00:06:19.250 --> 00:06:22.230
we'll take a deeper look into how well this guest turned out.

00:06:22.230 --> 00:06:25.100
But, before we do that, let's just summarize where we are.

