WEBVTT
Kind: captions
Language: en

00:00:00.390 --> 00:00:02.830
Okay, Michael. Which of these two decision trees is smaller?

00:00:02.830 --> 00:00:05.910
&gt;&gt; [LAUGH] The one on the right is smaller.

00:00:05.910 --> 00:00:08.360
&gt;&gt; That's exactly right because it's easier, it's,

00:00:08.360 --> 00:00:10.810
it's easier to represent it in sort of almost

00:00:10.810 --> 00:00:12.190
any obvious way that you could think of. It

00:00:12.190 --> 00:00:15.890
has fewer nodes, so smaller decision trees, trees with

00:00:15.890 --> 00:00:18.320
fewer nodes, less depth, whatever you need to

00:00:18.320 --> 00:00:21.420
make it smaller, have smaller lengths than bigger decision

00:00:21.420 --> 00:00:23.420
trees. So that means that if all we cared

00:00:23.420 --> 00:00:25.980
about was the second term here. We would prefer

00:00:25.980 --> 00:00:28.380
smaller decision trees, over bigger decisions trees.

00:00:28.380 --> 00:00:29.300
&gt;&gt; Which we do.

00:00:29.300 --> 00:00:32.880
&gt;&gt; Which we do. Now what about this over here? The, what

00:00:32.880 --> 00:00:35.310
does it mean? So this is pretty straight forward. You got this right?

00:00:35.310 --> 00:00:37.350
&gt;&gt; That the length of. Well, I mean guess

00:00:37.350 --> 00:00:39.270
what's weird that you, you're kind of moving back and

00:00:39.270 --> 00:00:41.430
forth between a notion of a prior, which is

00:00:41.430 --> 00:00:43.510
where the p of h came from and a notion

00:00:43.510 --> 00:00:45.670
of Well, you know, if we're going to actually have

00:00:45.670 --> 00:00:47.630
to describe the hypothesis you're going to have to write

00:00:47.630 --> 00:00:49.570
it down in some way, and this gives you

00:00:49.570 --> 00:00:51.020
a way of measuring how long it takes to write

00:00:51.020 --> 00:00:53.400
it down. But I guess what this whole derivation

00:00:53.400 --> 00:00:55.120
is doing is linking those two concepts, so that

00:00:55.120 --> 00:00:57.740
you can think about our bias for shorter decision

00:00:57.740 --> 00:01:00.980
trees as actually being the prior, right? Actually being the

00:01:00.980 --> 00:01:03.820
thing that says the smaller ones are more likely

00:01:03.820 --> 00:01:05.900
And vica versa, that when we think about things that

00:01:05.900 --> 00:01:08.510
are priors, that are assigning higher probability to certain

00:01:08.510 --> 00:01:10.520
things, it's kind of like giving them a shorter description.

00:01:10.520 --> 00:01:13.310
&gt;&gt; Right, so infact if you were to take

00:01:13.310 --> 00:01:16.090
this example literally here, that we prefer smaller trees

00:01:16.090 --> 00:01:19.420
to bigger trees, this kind of a bayesian argument for occam's razor.

00:01:19.420 --> 00:01:20.340
&gt;&gt; And pruning.

00:01:20.340 --> 00:01:23.660
&gt;&gt; And pruning. Well, you, often use

00:01:23.660 --> 00:01:25.950
razors to prune, so it makes perfect sense.

00:01:25.950 --> 00:01:29.130
&gt;&gt; Ok, so this is kind of straight foreward, that basically smaller

00:01:29.130 --> 00:01:33.940
trees are smaller than bigger trees. It sort of makes sense.

00:01:33.940 --> 00:01:36.190
Now, what about this over here? What does it mean to

00:01:36.190 --> 00:01:41.200
talk about the length of the data given a particular hypothesis.

00:01:41.200 --> 00:01:44.130
&gt;&gt; Uh...I could think of one interpretation there. So

00:01:44.130 --> 00:01:47.550
like, if the hypothesis generates the data really well, then

00:01:47.550 --> 00:01:49.950
you don't really need the data at all, right?

00:01:49.950 --> 00:01:52.800
You just have...you already have the hypothesis. The data is

00:01:52.800 --> 00:01:55.410
free. Right? But if it deviates a lot from

00:01:55.410 --> 00:01:58.140
the hypothesis, then you're going to have to have a long

00:01:58.140 --> 00:02:01.650
description of where the deviations are. So maybe it's kind of

00:02:01.650 --> 00:02:04.120
capturing this sort of notion of how well it fits.

00:02:04.120 --> 00:02:06.210
&gt;&gt; Right, that's exactly right. So I like that

00:02:06.210 --> 00:02:08.449
explanation so let me write it down. So here

00:02:08.449 --> 00:02:13.550
we literally just mean something like size of h.

00:02:13.550 --> 00:02:17.360
But over here we are talking about, well sort

00:02:17.360 --> 00:02:19.480
of error right? if the hypo, if just exactly what

00:02:19.480 --> 00:02:23.290
you said if the hypothesis perfectly describes the data,

00:02:23.290 --> 00:02:24.980
then you don't need any of the data. But let's

00:02:24.980 --> 00:02:27.310
imagine that the hypothesis gets all of the data

00:02:27.310 --> 00:02:31.600
labels wrong. Then when you send the hypothesis over To

00:02:31.600 --> 00:02:33.800
this person. This, this sort of person we're making up

00:02:33.800 --> 00:02:36.570
who, trying to understand the Daden hypothesis. And you're also

00:02:36.570 --> 00:02:38.810
going to have to send over what all the correct answers

00:02:38.810 --> 00:02:43.340
were. So, what this really is, is a notion of miss-classification

00:02:43.340 --> 00:02:46.200
error, or just error in general. If we're thinking about

00:02:46.200 --> 00:02:50.450
regression. So, basically, what we're saying is, if we're trying

00:02:50.450 --> 00:02:54.060
to find the maximum a posteriori Hypothesis. We want to maximize this

00:02:54.060 --> 00:02:58.020
expression. We want to find the h that maximizes this expression.

00:02:58.020 --> 00:02:59.560
That's the same as finding the h that

00:02:59.560 --> 00:03:02.350
maximizes the log of that expression, which gives you

00:03:02.350 --> 00:03:05.650
this. Which is the same as minimizing this expression,

00:03:05.650 --> 00:03:08.300
which is just maximizing this expression but throwing a

00:03:08.300 --> 00:03:13.010
minus one in front But these terms actually have meanings in information theory,

00:03:13.010 --> 00:03:18.110
the best hypothesis, the hypothesis with the maximum a posteriori probability is

00:03:18.110 --> 00:03:24.240
the one that minimizes error and the size of your hypothesis.

00:03:24.240 --> 00:03:27.990
You want the most simple hypothesis that minimizes

00:03:27.990 --> 00:03:32.990
your error. That is pretty much literally occam's razor.

00:03:32.990 --> 00:03:36.290
What is important here In reality is that

00:03:36.290 --> 00:03:38.890
these are often traded off of one another.

00:03:38.890 --> 00:03:41.730
If I give a more complicated or bigger

00:03:41.730 --> 00:03:44.810
hypothesis, I can typically drive down my error.

00:03:44.810 --> 00:03:49.340
Or I can have a little bit of error for a smaller hypothesis. But this is the

00:03:49.340 --> 00:03:53.010
sort of fundamental tradeoff here. You want to find The simplest

00:03:53.010 --> 00:03:56.480
hypothesis that still explains your data, that is, minimizes your error.

00:03:56.480 --> 00:03:56.970
&gt;&gt; Hm.

00:03:56.970 --> 00:03:59.150
&gt;&gt; So this actually has a name, and

00:03:59.150 --> 00:04:02.340
that is the minimum description, and there have

00:04:02.340 --> 00:04:03.890
been many algorithms over the years that have

00:04:03.890 --> 00:04:06.460
tried to do this directly by simply trading

00:04:06.460 --> 00:04:09.080
off some notion of error, and some notion

00:04:09.080 --> 00:04:11.780
of size. And finding the tradeoff between them

00:04:11.780 --> 00:04:13.160
that actually works. Now, if you think about

00:04:13.160 --> 00:04:14.910
it for a little whiel Michael you'll realize that

00:04:14.910 --> 00:04:17.529
yea this sort of makes sense at the hand wavy level

00:04:17.529 --> 00:04:20.399
at which I just talked about it. But, you do have some

00:04:20.399 --> 00:04:24.560
real issues here about for example units. So, I don't know if

00:04:24.560 --> 00:04:28.290
the units of the size of the hypothesis are directly comparable to

00:04:28.290 --> 00:04:31.600
the counts of errors or you know sum of squared errors

00:04:31.600 --> 00:04:33.990
or something like that and so you have to come up with

00:04:33.990 --> 00:04:36.530
some way of translating between them... And some way of making the

00:04:36.530 --> 00:04:40.430
decision whether you would rather minimize this or you'd rather minimize that

00:04:40.430 --> 00:04:42.580
if you were forced to make a decision. But the

00:04:42.580 --> 00:04:45.320
basic idea is still the same here. That the best

00:04:45.320 --> 00:04:49.180
hypothesis is the one that minimizes error without paying too

00:04:49.180 --> 00:04:51.970
much of a price for the complexity of the hypothesis.

00:04:51.970 --> 00:04:55.860
&gt;&gt; Wow. So I've been sitting here thinking about, so with decision trees,

00:04:55.860 --> 00:04:59.530
this notion of length feels... Like you could translate it directly into bits

00:04:59.530 --> 00:05:02.820
right like you actually had to write it down and transmit it, it

00:05:02.820 --> 00:05:05.430
makes a lot of sense. But then I was thinking about neural networks.

00:05:05.430 --> 00:05:08.870
And, and, and given that a fixed neural network architecture it's always

00:05:08.870 --> 00:05:12.750
the same number of weights and they're just numbers. So you just

00:05:12.750 --> 00:05:15.750
transmit those numbers. So I thought, hmmm, this isn't really helping us

00:05:15.750 --> 00:05:17.552
understand? ? ? ? ? ? and then it occurred to me

00:05:17.552 --> 00:05:21.237
that those weights, if they get really you're going to need more

00:05:21.237 --> 00:05:25.380
bits to express those big weights. And in fact that's exactly when

00:05:25.380 --> 00:05:27.540
we get over fitting with neural nets if we let the weights

00:05:27.540 --> 00:05:30.970
get too big. So like this gives a really nice story for understanding

00:05:30.970 --> 00:05:32.520
neural nets as well.

00:05:32.520 --> 00:05:35.310
&gt;&gt; Right. That the complexity is not in the number of parameters

00:05:35.310 --> 00:05:37.860
directly but in what you need to represent the value of the parameters.

00:05:37.860 --> 00:05:38.550
&gt;&gt; Wow.

00:05:38.550 --> 00:05:40.690
&gt;&gt; So I could have ten parameters that are all

00:05:40.690 --> 00:05:43.810
binary, in which case I need ten bits. Or they

00:05:43.810 --> 00:05:46.800
could be arbitrary real numbers, in which case I might

00:05:46.800 --> 00:05:49.730
need, well, an arbitrary number of bits. That's really weird.

00:05:49.730 --> 00:05:52.660
&gt;&gt; Yeah, but the point here, Michael, I want to wrap this

00:05:52.660 --> 00:05:55.980
up. The point here is we've now used Bayesian learning to derive

00:05:55.980 --> 00:05:58.330
a bunch of different things that we've actually been using

00:05:58.330 --> 00:06:01.240
all along, and so again the beauty of Bayesian learning is

00:06:01.240 --> 00:06:03.930
that it gives you a sort of handle on why

00:06:03.930 --> 00:06:05.810
you might be making some of the decisions that you're making.

00:06:05.810 --> 00:06:07.850
&gt;&gt; It seems like this raises the theory question

00:06:07.850 --> 00:06:11.360
that you threw at me in a previous unit. Right.

00:06:11.360 --> 00:06:13.330
Which is like well so if it doesn't really tell

00:06:13.330 --> 00:06:16.260
us anything we didn't already know, how important is it?

00:06:16.260 --> 00:06:17.940
&gt;&gt; Well in this case, I think it is important

00:06:17.940 --> 00:06:21.080
because it told us something that we were thinking and tells

00:06:21.080 --> 00:06:23.220
us in fact we were right. So now we can

00:06:23.220 --> 00:06:25.300
comfortably go out in the world minimizing some of squared

00:06:25.300 --> 00:06:27.940
error when we're in a world where there is some

00:06:27.940 --> 00:06:31.520
kind of Gaussian transmission noise. We can go about trying to

00:06:31.520 --> 00:06:35.270
Believe Occam's Razor because Bayes told us so. [LAUGH] Thanks

00:06:35.270 --> 00:06:37.190
to Shannon. And so on and so forth. We can

00:06:37.190 --> 00:06:39.990
do these things and know that in some sense, they're

00:06:39.990 --> 00:06:41.930
the right things to do, at least in a Bayesian sense.

00:06:41.930 --> 00:06:42.780
&gt;&gt; Neat.

00:06:42.780 --> 00:06:45.980
&gt;&gt; Okay, good. Now one more thing, Michael, I'm going to show you.

00:06:45.980 --> 00:06:49.810
Which is that everything I've told you so far is a lie. [SOUND]

