WEBVTT
Kind: captions
Language: en

00:00:00.340 --> 00:00:06.320
We saw the system's issues at a macro level from the point of view of

00:00:06.320 --> 00:00:13.120
administering the engine that powers internet scale computing. How do

00:00:13.120 --> 00:00:18.664
we program services such as websearch and airline reservation on top of the

00:00:18.664 --> 00:00:22.430
data center cluster resources? How do

00:00:22.430 --> 00:00:25.830
they exploit the hardware parallelism that's available

00:00:25.830 --> 00:00:29.310
in these clusters? We will learn about

00:00:29.310 --> 00:00:32.700
the map produced programming paradigm that answers

00:00:32.700 --> 00:00:35.920
these questions. The term Big Data, has

00:00:35.920 --> 00:00:39.320
become a buzz word. Computations in giant

00:00:39.320 --> 00:00:46.310
scale services are usually simple, but they work over large data sets and hence,

00:00:46.310 --> 00:00:48.800
the name Big Data. And naturally, because

00:00:48.800 --> 00:00:51.260
they are working with a large data set,

00:00:51.260 --> 00:00:54.180
these computations take a long time to compute.

00:00:54.180 --> 00:00:56.540
For example let's say that I want to

00:00:56.540 --> 00:01:00.770
search for John F Kennedy's photographs in all

00:01:00.770 --> 00:01:03.580
the documents that are available on the web.

00:01:03.580 --> 00:01:05.360
It's going to take a long time. And that

00:01:05.360 --> 00:01:08.110
is an example of a Big Data computation.

00:01:08.110 --> 00:01:12.540
Similar examples include online reservations, shopping, et cetera.

00:01:12.540 --> 00:01:16.430
And applications that work on Big Data would

00:01:16.430 --> 00:01:18.710
like to exploit the pluralism that's available

00:01:18.710 --> 00:01:21.150
in the cluster at the data centers. I

00:01:21.150 --> 00:01:24.860
mentioned in the last lesson that data

00:01:24.860 --> 00:01:28.740
centers these days comprise of computation elements on

00:01:28.740 --> 00:01:31.100
the order of thousands and even 10,000

00:01:31.100 --> 00:01:35.040
nodes that are ready to do computations. And

00:01:35.040 --> 00:01:38.230
we would like to exploit the computational resources

00:01:38.230 --> 00:01:42.370
available in such Big Data centers to do

00:01:42.370 --> 00:01:48.020
computation on Big Data. For example, if it is John F Kennedy's photographs, I'm

00:01:48.020 --> 00:01:50.490
looking in all the different documents. We

00:01:50.490 --> 00:01:55.200
can parallelize that's search for Kennedy's photo

00:01:55.200 --> 00:02:00.410
in all the documents in parallel on all the available nodes in the data

00:02:00.410 --> 00:02:03.350
center. And since computations are also called

00:02:03.350 --> 00:02:07.240
embarrassingly parallel computations. What does this mean?

00:02:07.240 --> 00:02:09.970
Well, there is not much synchronization or

00:02:09.970 --> 00:02:14.000
coordination that is needed among the parallel threads

00:02:14.000 --> 00:02:17.600
that comprise the applications and that run

00:02:17.600 --> 00:02:21.240
on different nodes of the computational cluster. Looking

00:02:21.240 --> 00:02:25.820
for John F Kennedy's photographs in all the documents on the web, is a good

00:02:25.820 --> 00:02:29.660
example of such an embarrassingly parallel application. What

00:02:29.660 --> 00:02:32.390
are all the issues in programming in the

00:02:32.390 --> 00:02:39.050
large, on large data sets, so the data sets are also large and the computational

00:02:39.050 --> 00:02:44.650
resources on which we want to run this big data application is also vast.

00:02:44.650 --> 00:02:47.080
So some of the interesting issues in

00:02:47.080 --> 00:02:50.250
programming in the large include, how to parallelize

00:02:50.250 --> 00:02:54.490
an application across let's say, 10,000 machines.

00:02:54.490 --> 00:02:57.830
How to handle the data distribution and plumbing

00:02:57.830 --> 00:03:01.320
between the producers of data and consumers of

00:03:01.320 --> 00:03:05.470
data. Remember these are embarrassingly parallel applications, but different

00:03:05.470 --> 00:03:08.970
phases of the application will require data from one

00:03:08.970 --> 00:03:10.980
phase of the application to be passed on to

00:03:10.980 --> 00:03:13.130
the next phase of the application. That's what

00:03:13.130 --> 00:03:16.750
we mean by plumbing between the producers of data,

00:03:16.750 --> 00:03:20.360
intermediate data to be more specific, and consumers of

00:03:20.360 --> 00:03:22.880
that intermediate data. And of course, one of the

00:03:22.880 --> 00:03:26.820
biggest challenges in Big Data applications on

00:03:26.820 --> 00:03:30.750
large computational clusters is failure handling. Recall what

00:03:30.750 --> 00:03:32.990
we said about the nature of these

00:03:32.990 --> 00:03:36.344
data centers. They employ thousands and thousands of

00:03:36.344 --> 00:03:42.600
processes. When you have so many parts, in any setting, failure is not a

00:03:42.600 --> 00:03:47.880
question of if it will happen. It is a question of, when it is going to happen?

00:03:47.880 --> 00:03:52.850
So that's a fact of life, and therefore, programming models for Big Data, have

00:03:52.850 --> 00:03:58.980
to worry about the fact that failures are to be expected in this environment.

