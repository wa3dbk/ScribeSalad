WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.000
Now that we have an idea about the effect of round-off error,

00:00:03.000 --> 00:00:05.000
we can actually compute some estimates.

00:00:05.000 --> 00:00:10.000
For the forward Euler method, the total error is composed of two parts--

00:00:10.000 --> 00:00:15.000
the part due to the Euler method, the global truncation error, if you remember that term.

00:00:15.000 --> 00:00:19.000
A constant times the step size plus the error due to round off,

00:00:19.000 --> 00:00:21.000
which seems to be proportionate to the number of steps

00:00:21.000 --> 00:00:24.000
and, hence, inversely proportional to the step size

00:00:24.000 --> 00:00:27.000
Epsilon denotes the relative size of the error.

00:00:27.000 --> 00:00:32.000
It's something like 10⁻⁷ or 10⁻¹⁶.

00:00:32.000 --> 00:00:36.000
By which fraction does our number tend to change due to round off?

00:00:36.000 --> 00:00:38.000
Again, we should see proportionality here.

00:00:38.000 --> 00:00:41.000
If we have twice the amount of error in each step.

00:00:41.000 --> 00:00:44.000
We should be seeing twice the amount of total error,

00:00:44.000 --> 00:00:50.000
even though, again, the error induced in the earlier steps is growing over time.

00:00:50.000 --> 00:00:54.000
D is some proportionality constant that we don't know yet

00:00:54.000 --> 00:00:57.000
and that depends on the problem as does C.

00:00:57.000 --> 00:01:03.000
So, there is one component to the error that grows from zero to infinity on principle.

00:01:03.000 --> 00:01:08.000
There is another component to the error that starts at infinity and decays to zero.

00:01:08.000 --> 00:01:10.000
We have to have a minimum in between.

00:01:10.000 --> 00:01:12.000
This is what we saw in the experiment.

00:01:12.000 --> 00:01:16.000
It's called the step size at that minimum hmin.

00:01:16.000 --> 00:01:21.000
It does not make sense to use more steps, that is, to use a smaller step size,

00:01:21.000 --> 00:01:24.000
because the error will be growing again due to round-off.

00:01:24.000 --> 00:01:26.000
Now, here is a quiz.

00:01:26.000 --> 00:01:27.000
For the two types of floating point numbers that we're typically dealing with,

00:01:27.000 --> 00:01:31.000
we can specify the value of epsilon.

00:01:31.000 --> 00:01:35.000
It's about 10⁻⁷ for single precision.

00:01:35.000 --> 00:01:39.000
In C and related languages, that's called float.

00:01:39.000 --> 00:01:43.000
It's about 10⁻¹⁶ for double position.

00:01:43.000 --> 00:01:48.000
Python works at double position, and the arrays of numpy can be configured

00:01:48.000 --> 00:01:50.000
as to which position they should be using.

00:01:50.000 --> 00:01:52.000
Now here comes the quiz.

00:01:52.000 --> 00:01:54.000
Say we do an experiment at single position

00:01:54.000 --> 00:01:59.000
and find that the value of hmin amounts to 10⁻⁴.

00:01:59.000 --> 00:02:03.000
If we try to solve the same problem at double position,

00:02:03.000 --> 00:02:06.000
what do you expect to be the value of hmin?

00:02:06.000 --> 00:02:13.000
Pick one of these: 3 * 10⁻⁹, 4 * 10⁻¹⁰, 5 * 10⁻¹¹?

00:02:13.000 --> 00:02:21.000
Here is a hint: at the minimum, it turns out that the contribution of both parts is the same.

00:02:21.000 --> 09:59:59.000
Ch will equal Dε/h.

