WEBVTT
Kind: captions
Language: en

00:00:00.470 --> 00:00:05.780
So now let's ask the question, how can we use the filtering mechanisms that

00:00:05.780 --> 00:00:09.420
we have looked at so far to find interesting features in an image?

00:00:09.420 --> 00:00:11.830
So here, for an example, are the two images.

00:00:11.830 --> 00:00:16.239
You may recall them from the instance of the panorama building experiment or

00:00:16.239 --> 00:00:18.110
exercise we did earlier.

00:00:18.110 --> 00:00:20.480
And we want to be able to take these two images.

00:00:20.480 --> 00:00:23.090
You know, one this image here and that image.

00:00:23.090 --> 00:00:26.800
And actually for this case, for just sake of, let's say building a panorama,

00:00:26.800 --> 00:00:31.530
we want to be able to find features that are similar in between those things.

00:00:31.530 --> 00:00:33.130
Then we can do things like alignment.

00:00:34.220 --> 00:00:37.510
So in this case what I'm interested in is finding information that's

00:00:37.510 --> 00:00:39.230
similar in both of them.

00:00:39.230 --> 00:00:42.760
Here I've basically created about one, two, three, four,

00:00:42.760 --> 00:00:47.810
five circles that kind of point to specific features or information in

00:00:47.810 --> 00:00:52.080
this image, and again the same five features are available in this image.

00:00:52.080 --> 00:00:56.520
Again, if you remember, this was a pan camera motion from this to that.

00:00:56.520 --> 00:00:58.538
So there were two different images of course.

00:00:58.538 --> 00:01:00.380
And you can notice that there are different images,

00:01:00.380 --> 00:01:03.090
except that they have a little bit of overlap.

00:01:03.090 --> 00:01:06.740
And of course what we want to do is find the same feature in both of them.

00:01:06.740 --> 00:01:10.760
Here I've just drawn the lines between them pointing out the correspondence that

00:01:10.760 --> 00:01:16.030
this same point here is also visible here, that one is visible here, and so on.

00:01:16.030 --> 00:01:21.070
So to achieve this process of being able to then align these two images, or

00:01:21.070 --> 00:01:25.500
find different things that are similar in them so then we can actually register

00:01:25.500 --> 00:01:29.240
them together, we need to extract some sort of higher level features.

00:01:29.240 --> 00:01:31.540
So one of the biggest advantages of mapping or

00:01:31.540 --> 00:01:35.040
extracting these features from an image is it allows us to

00:01:35.040 --> 00:01:39.190
map these raw pixels into an intermediate representation.

00:01:39.190 --> 00:01:42.920
Which basically means, is that now we can basically take an image,

00:01:42.920 --> 00:01:47.200
extract those features, and not actually be looking at the image any more, but

00:01:47.200 --> 00:01:48.980
just those features.

00:01:48.980 --> 00:01:51.520
Such an intermediate representation allows us to have,

00:01:51.520 --> 00:01:56.050
to have a lot of information but also kind of reduce the amount of data.

00:01:56.050 --> 00:01:59.520
Because what I would just do is, after a while, process this image,

00:01:59.520 --> 00:02:04.000
find all those 5 or maybe sometimes 20 different features.

00:02:04.000 --> 00:02:05.625
And 20 different features in here,

00:02:05.625 --> 00:02:08.270
and basically just attach that information and

00:02:08.270 --> 00:02:12.530
not anymore require me to carry around the image or the information in there.

00:02:12.530 --> 00:02:18.300
So this is of course a kind of a data preservation in of information,

00:02:18.300 --> 00:02:19.900
which we can use for a variety of things.

