WEBVTT
Kind: captions
Language: en

00:00:00.200 --> 00:00:02.984
So far, we've seen three different memory consistency

00:00:02.984 --> 00:00:06.395
models. One is the sequential consistent memory model, the

00:00:06.395 --> 00:00:09.790
release consistent memory model. And, strictly speaking, I would

00:00:09.790 --> 00:00:12.840
say, the eager version and the lazy version are

00:00:12.840 --> 00:00:15.522
just variants of the same memory model, namely

00:00:15.522 --> 00:00:18.810
the release consistent memory model. And now we're going to

00:00:18.810 --> 00:00:22.060
transition and talk about software distributed shared memory, and

00:00:22.060 --> 00:00:25.340
how these memory models come into play in building

00:00:25.340 --> 00:00:27.837
software distributed shared memory. So we're dealing

00:00:27.837 --> 00:00:30.760
with a computational cluster, that is, in

00:00:30.760 --> 00:00:36.053
the cluster, each node of the cluster has its own private physical memory, but

00:00:36.053 --> 00:00:38.989
there is no physically shared memory. And

00:00:38.989 --> 00:00:43.165
therefore, the system, meaning the system software,

00:00:43.165 --> 00:00:46.210
has to implement the consistency model to

00:00:46.210 --> 00:00:50.543
the programmer. In a tightly coupled multiprocessor,

00:00:50.543 --> 00:00:55.438
coherence is maintained at individual memory access level by the

00:00:55.438 --> 00:01:00.880
hardware. Unfortunately, that fine grain of

00:01:00.880 --> 00:01:06.100
maintaining coherence at individual memory access level will lead to too

00:01:06.100 --> 00:01:11.230
much overhead in a cluster. Why? Because on every load or store instruction that

00:01:11.230 --> 00:01:15.710
is happening on any one of these processors, the system software has to butt

00:01:15.710 --> 00:01:18.140
in, and implement the coherence action

00:01:18.140 --> 00:01:21.450
in software through the entire cluster. And

00:01:21.450 --> 00:01:23.940
this is simply infeasible. So what do

00:01:23.940 --> 00:01:27.290
we do to implement software distributed shared

00:01:27.290 --> 00:01:34.600
memory? So, first part is to implement this sharing and coherence maintenance at

00:01:34.600 --> 00:01:40.880
the level of pages. So the granularity of coherence maintenance is at the level

00:01:40.880 --> 00:01:47.665
of a page. Now, even in a simple processor or in a true multiprocessor, the

00:01:47.665 --> 00:01:54.001
unit of coherence maintenance is not simply a single word that a processor is

00:01:54.001 --> 00:02:00.179
doing a load or a store on. Because in order to exploit spatial locality, the

00:02:00.179 --> 00:02:06.094
block size used in caches in processors tend to be bigger than the granularity

00:02:06.094 --> 00:02:12.613
of memory access that is possible from individual instructions in the processor.

00:02:12.613 --> 00:02:17.893
So we're taking this up a level and saying, if you're going to do it all in

00:02:17.893 --> 00:02:21.853
software, let's keep the granularity of coherence

00:02:21.853 --> 00:02:24.589
maintenance to be an entire page. And

00:02:24.589 --> 00:02:26.940
you're going to maintain the coherence of the

00:02:26.940 --> 00:02:31.510
distributed shared memory in software by cooperating

00:02:31.510 --> 00:02:33.590
with the operating system that is running

00:02:33.590 --> 00:02:35.940
on every node of the processor. So what

00:02:35.940 --> 00:02:38.290
we're going to do is, we're providing a

00:02:38.290 --> 00:02:43.340
global virtual memory abstraction to the application program

00:02:43.340 --> 00:02:45.800
running on the cluster. So the application

00:02:45.800 --> 00:02:49.780
programmer views the entire cluster as a globally

00:02:49.780 --> 00:02:52.850
shared virtual memory. Under the cover, what the

00:02:52.850 --> 00:02:57.265
DSM software is doing is, it is partitioning

00:02:57.265 --> 00:03:00.720
this global address space into chunks that are

00:03:00.720 --> 00:03:04.015
managed individually on the nodes of the different

00:03:04.015 --> 00:03:07.165
processors of the cluster. From the application point

00:03:07.165 --> 00:03:10.155
of view, what this global virtual memory abstraction

00:03:10.155 --> 00:03:13.077
is giving is address equivalence. And that is,

00:03:13.077 --> 00:03:15.399
if I access a memory location x in

00:03:15.399 --> 00:03:18.925
my program, that means exactly the same thing,

00:03:18.925 --> 00:03:22.795
whether I access the memory location x from processor

00:03:22.795 --> 00:03:27.803
1, processor 2, and so on and so forth. That's the idea in providing

00:03:27.803 --> 00:03:30.660
a global virtual memory abstraction. And the

00:03:30.660 --> 00:03:34.450
way the DSM software is going to handle maintenance

00:03:34.450 --> 00:03:38.180
of coherence is by having distributed ownership

00:03:38.180 --> 00:03:42.790
for the different virtual pages that constitute this

00:03:42.790 --> 00:03:45.020
global virtual address space. So you can

00:03:45.020 --> 00:03:48.160
think of this global virtual address space as

00:03:48.160 --> 00:03:50.750
constituted by several pages, and we're going to

00:03:50.750 --> 00:03:53.750
say some number of these pages are owned

00:03:53.750 --> 00:03:58.310
by processor 1. Some number of these pages are owned by processor 2. Some number

00:03:58.310 --> 00:04:03.930
by processor 3, and so on. So we split the ownership responsibility into

00:04:03.930 --> 00:04:09.040
individual processors. Now what that means, is that the owner

00:04:09.040 --> 00:04:13.450
particular page is also responsible for keeping complete

00:04:13.450 --> 00:04:15.970
coherence information for that particular page

00:04:15.970 --> 00:04:19.248
and taking the coherence actions commensurate with

00:04:19.248 --> 00:04:24.120
that page. And the local physical memories are available in each one of this

00:04:24.120 --> 00:04:32.540
processors is being used for hosting portions of the global virtual memory space

00:04:32.540 --> 00:04:35.430
in the individual processors commensurate with the

00:04:35.430 --> 00:04:38.700
access pattern that is being displayed by

00:04:38.700 --> 00:04:41.420
the application on the different processors. So for

00:04:41.420 --> 00:04:45.590
instance, if processor 1 accesses this portion of the

00:04:45.590 --> 00:04:49.470
global virtual memory space, then this portion of the

00:04:49.470 --> 00:04:53.100
address space is mapped into the local physical memory

00:04:53.100 --> 00:04:55.000
of this processor. So that a thread that

00:04:55.000 --> 00:04:57.640
is running on this processor can access this portion

00:04:57.640 --> 00:05:00.273
of the global address space. And it might be

00:05:00.273 --> 00:05:03.845
that same page is being shared with some other

00:05:03.845 --> 00:05:09.409
processor n over here. In that case, a copy of this page is existing in both

00:05:09.409 --> 00:05:14.995
this processor, as well as this processor. Now it is up to the processor that is

00:05:14.995 --> 00:05:18.675
responsible for the ownership of this particular page

00:05:18.675 --> 00:05:21.715
to worry about the consistency of this page,

00:05:21.715 --> 00:05:25.270
that is now resident in multiple locations. For

00:05:25.270 --> 00:05:29.240
instance, if this node, let's say, is the owner

00:05:29.240 --> 00:05:35.338
for this page. Then this node will have metadata that indicates that this

00:05:35.338 --> 00:05:42.220
particular page is currently shared by both p 1 and p n. So that

00:05:42.220 --> 00:05:48.470
is the directory that is associated with the portion of the global virtual

00:05:48.470 --> 00:05:50.850
memory space that is being owned and

00:05:50.850 --> 00:05:54.180
managed by this particular processor. So statically,

00:05:54.180 --> 00:05:56.900
we are making an association between a portion of

00:05:56.900 --> 00:06:00.900
the address space and the owner for that portion

00:06:00.900 --> 00:06:04.160
of the address space in terms of coherence maintenance

00:06:04.160 --> 00:06:07.530
for that portion of the global virtual memory space.

