WEBVTT
Kind: captions
Language: en

00:00:00.220 --> 00:00:03.580
So having discussed several different scheduling policies, we have

00:00:03.580 --> 00:00:06.140
to talk about performance. Now the figures of merit that

00:00:06.140 --> 00:00:09.700
is associated with the scheduling policy are threefold. The

00:00:09.700 --> 00:00:12.840
first scheduling policy figures of merit is what is called

00:00:12.840 --> 00:00:16.050
throughput. And as the name suggests, what this is

00:00:16.050 --> 00:00:20.290
saying is how many threads get executed or completed in

00:00:20.290 --> 00:00:22.320
per unit time. So that is. You know, how

00:00:22.320 --> 00:00:25.320
many threads are being pushed through the system per unit

00:00:25.320 --> 00:00:28.710
type, so that's what you're asking the super, and

00:00:28.710 --> 00:00:32.250
as the name suggests, it's a system centric metric.

00:00:32.250 --> 00:00:34.980
It doesn't say anything about the performance of individual

00:00:34.980 --> 00:00:37.790
threads, how soon they are performing their work and

00:00:37.790 --> 00:00:39.740
getting out of the system, but it is asking

00:00:39.740 --> 00:00:43.460
the question. What is the throughput of the system

00:00:43.460 --> 00:00:46.210
with respect to the threads that need to run

00:00:46.210 --> 00:00:50.660
on it? And the next two metrics are user-centric metrics.

00:00:50.660 --> 00:00:54.080
The response time is saying, if I start up

00:00:54.080 --> 00:00:56.350
a thread, how long does it take for that thread

00:00:56.350 --> 00:00:58.930
to complete execution? And that's what response time is

00:00:58.930 --> 00:01:03.320
saying and variance of responsing's time is saying. Well, does

00:01:03.320 --> 00:01:06.020
the time that it takes for me to run

00:01:06.020 --> 00:01:09.660
my particular thread vary depending on when I run it

00:01:09.660 --> 00:01:13.010
on the system. Why will it vary, well for instance,

00:01:13.010 --> 00:01:16.150
if you think about a first come first serve policy

00:01:16.150 --> 00:01:19.330
if I have a very small job to run,

00:01:19.330 --> 00:01:21.870
and if it gets the processor immediately it's going to

00:01:21.870 --> 00:01:25.340
quickly complete its execution. But suppose when I start

00:01:25.340 --> 00:01:28.500
up my particular thread, there are other threads in the

00:01:28.500 --> 00:01:30.740
system ahead of me that are going to take

00:01:30.740 --> 00:01:33.850
a long time to execute, then I'm going to see

00:01:33.850 --> 00:01:37.440
a very poor response time. So depending on from

00:01:37.440 --> 00:01:41.220
run to run, the same program may experience different response

00:01:41.220 --> 00:01:43.610
times depending on the load that is currently on that

00:01:43.610 --> 00:01:47.100
system. And that's where the variance of response time comes in

00:01:47.100 --> 00:01:50.240
and so clearly from a user's perspective I want response

00:01:50.240 --> 00:01:53.700
time to be very good and variance to be very small

00:01:53.700 --> 00:01:55.930
as well. Now when you think about first come, first

00:01:55.930 --> 00:01:59.440
serve scheduling the figure of measure that is really good about

00:01:59.440 --> 00:02:02.490
it, is the fact it is fair. But, it doesn't

00:02:02.490 --> 00:02:06.780
pay attention to infinity at all. And it doesn't give importance

00:02:06.780 --> 00:02:10.889
to small jobs vs big jobs. It's just doing it

00:02:10.889 --> 00:02:14.270
first come first serve, and therefore, there's going to be a high

00:02:14.270 --> 00:02:18.430
variance, especially if it is small jobs that need attention of

00:02:18.430 --> 00:02:22.680
the processor, and there are long-running jobs on the processor connecting...

