WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.000
Now I'd like to talk a little bit about how random testing

00:00:02.000 --> 00:00:04.000
fits into the larger software development process.

00:00:04.000 --> 00:00:09.000
So first of all, I just want to start by asking a question, why is it that random testing works at all?

00:00:09.000 --> 00:00:12.000
And I don't think the answer to this question is actually known in any kind of a detailed sense.

00:00:12.000 --> 00:00:14.000
But we do know parts of the answer.

00:00:14.000 --> 00:00:18.000
The big part is that random testing is based on very weak hypotheses, about where bugs live.

00:00:18.000 --> 00:00:22.000
And what I mean by this is every test case that we run is a little experiment.

00:00:22.000 --> 00:00:25.000
The input to the experiment is a test case and the outcome of the experiment is a bit of information

00:00:25.000 --> 00:00:27.000
about whether the system worked or it didn't work.

00:00:27.000 --> 00:00:30.000
What random testing does is it makes the conditions,

00:00:30.000 --> 00:00:32.000
under which we are running the experiment weaker.

00:00:32.000 --> 00:00:35.000
We don't have to guess about some particular thing that might fail.

00:00:35.000 --> 00:00:39.000
What we're rather doing is guessing about a whole class of things that might possibly fail.

00:00:39.000 --> 00:00:43.000
This turns out to be powerful because, given the very complex behavior of modern software,

00:00:43.000 --> 00:00:47.000
people don't seem to be very good about forming good hypotheses about where bugs lie.

00:00:47.000 --> 00:00:49.000
Second reason is people tend to make the same mistakes

00:00:49.000 --> 00:00:51.000
while they're coding and while they're testing.

00:00:51.000 --> 00:00:53.000
For example, if Iforget to take into account some sort of a special case

00:00:53.000 --> 00:00:56.000
while I'm implementing my system then I'd probably also forget to test it.

00:00:56.000 --> 00:01:00.000
What I mean by this is that if I forgot to implement some feature or if I miss-implemented on feature,

00:01:00.000 --> 00:01:04.000
I'm not going to test the stuff that I did wrong because if I was able to think of the test case,

00:01:04.000 --> 00:01:06.000
I probably would have got the feature right in the first place.

00:01:06.000 --> 00:01:12.000
Random testing to some extent get us out of this problem because it can construct test cases

00:01:12.000 --> 00:01:15.000
to test things that we don't actually understand or know very well.

00:01:15.000 --> 00:01:17.000
The third reason is there's a gigantic asymmetry between

00:01:17.000 --> 00:01:20.000
how fast computers are and how fast people are.

00:01:20.000 --> 00:01:23.000
Evidenceen if the random tester is mostly generating stupid test cases,

00:01:23.000 --> 00:01:28.000
if it can generate a clever test case, maybe one in a million times just by getting lucky,

00:01:28.000 --> 00:01:32.000
then that still might be a more effective use of our testing resources than writing test cases by hand.

00:01:32.000 --> 00:01:34.000
And there has been a similar finding in other areas.

00:01:34.000 --> 00:01:38.000
For example, the game Go has an extremely large state space and it was traditionally thought

00:01:38.000 --> 00:01:40.000
that computer Go players were just never going to be very good.

00:01:40.000 --> 00:01:42.000
The game was just too hard.

00:01:42.000 --> 00:01:44.000
What turned out to be the case is, is that today's computer go players

00:01:44.000 --> 00:01:46.000
are quite a bit stronger than previous ones, and they're based on

00:01:46.000 --> 00:01:51.000
what are called Monte Carlo methods, which are simply randomized methods for exploring

00:01:51.000 --> 00:01:55.000
small parts of the Go state space and it turns out that this is often good enough

00:01:55.000 --> 00:01:57.000
to create respectively strong players.

00:01:57.000 --> 00:01:59.000
They're still not nearly as good as the best human players, but they do pretty well.

00:01:59.000 --> 00:02:03.000
And I feel this is exploiting sort of a very similar insight to random testing

00:02:03.000 --> 00:02:07.000
where we probabilistically explore these spaces that are very large

00:02:07.000 --> 00:02:09.000
and even if we can't achieve any kind of meaningful coverage,

00:02:09.000 --> 00:02:12.000
we can still often find interesting things, especially if we have this

00:02:12.000 --> 00:02:15.000
extremely fast 4- and 8-core machines that are really quite cheap today.

00:02:15.000 --> 00:02:17.000
Now, I'd like to ask a slightly different question, which is

00:02:17.000 --> 00:02:21.000
why random testing is so incredibly effective on commercial software, at least sometimes?

00:02:21.000 --> 00:02:23.000
What I don't want to do here is start some sort of a debate

00:02:23.000 --> 00:02:25.000
about whether random testing is or isn't effective.

00:02:25.000 --> 00:02:28.000
I think there's pretty ample evidence, so for example the fuzzer papers

00:02:28.000 --> 00:02:33.000
that we discussed yesterday or the talk that you can watch online, babysitting an army of monkeys.

00:02:33.000 --> 00:02:37.000
People shown that random testing really is effective on commercial software. Why is that?

00:02:37.000 --> 00:02:40.000
I'm going to give some opinions, and of course, you should feel free to disagree with these.

