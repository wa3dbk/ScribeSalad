WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.000
All right, so let's say we want to try Alice's vertex cover a little bit smarter.

00:00:05.000 --> 00:00:08.320
So let's look at Alice's vertex cover.

00:00:08.320 --> 00:00:13.150
The main thing that happens, the key idea is that we're just going to try

00:00:13.150 --> 00:00:18.250
every single possible assignment of a cover to the underlying graph.

00:00:18.250 --> 00:00:26.390
So, let's say that graph, we might try this, this, and this

00:00:26.390 --> 00:00:38.570
or we might try this, this, and this, or just this, or maybe all of the vertices.

00:00:38.570 --> 00:00:43.370
The point is that we're not specifying an order to check the vertices in.

00:00:43.370 --> 00:00:46.500
We're just saying check every single one.

00:00:46.500 --> 00:00:53.080
What if we did though, what if we decided to check the vertices in order of size?

00:00:53.080 --> 00:00:57.110
That is we're checking the covers with increase in size.

00:00:57.110 --> 00:01:01.500
So first, we check a cover with zero vertices in it,

00:01:01.500 --> 00:01:07.830
that is no cover at all then we check every cover with one vertex in it.

00:01:07.830 --> 00:01:15.510
So let's say this one, then we check this one, then this one, and so on.

00:01:15.510 --> 00:01:21.300
And after we're done with that, then we do every vertex cover with two vertices in it.

00:01:21.300 --> 00:01:29.510
So this and this and this and so on, and we keep going checking all of the covers in increasing order.

00:01:29.510 --> 00:01:33.030
That way, once we found a possible cover,

00:01:33.030 --> 00:01:38.690
we know that that is the minimum possible cover and we can simply stop it.

00:01:38.690 --> 00:01:45.470
Now, my question then is does this change how the underlying algorithm performs?

00:01:45.470 --> 00:01:47.050
So let's go down the questions.

00:01:47.050 --> 00:01:51.800
First, does the new algorithm on average checks fewer assignments than the original?

00:01:51.800 --> 00:01:56.070
Second, does the original algorithm sometimes look through fewer assignments?

00:01:56.070 --> 00:02:00.330
And by that, I mean, does it look through fewer assignments

00:02:00.330 --> 00:02:03.750
than the original algorithm at least once?

00:02:03.750 --> 00:02:10.050
Next, is the worst case behavior of the new algorithm in O-notation better than the original?

00:02:10.050 --> 00:02:13.930
And similarly for the best case and the average case of the new algorithm

00:02:13.930 --> 00:02:17.180
in O-notation, are they better than the original?

00:02:17.180 --> 00:02:19.600
Please check all either true or false.

