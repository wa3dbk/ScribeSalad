WEBVTT
Kind: captions
Language: en

00:00:00.290 --> 00:00:04.464
Okay, Michael, so I wanted to,
before diving into a couple of examples,

00:00:04.464 --> 00:00:08.020
I wanted to remind you of
a conversation that we had earlier.

00:00:08.020 --> 00:00:10.700
Does this little picture
look familiar to you?

00:00:10.700 --> 00:00:13.240
&gt;&gt; It looks like the Monte Carlo
tree search stuff we talked about in

00:00:13.240 --> 00:00:14.520
the options lesson.

00:00:14.520 --> 00:00:15.160
&gt;&gt; It actually is.

00:00:15.160 --> 00:00:17.400
So, here's the point that I wanted,
I made the point at the time, but

00:00:17.400 --> 00:00:19.630
I wanted to really kind
of drive it home here.

00:00:20.940 --> 00:00:25.440
If you recall, I asked you to come up
with some options for solving Pac-Man.

00:00:25.440 --> 00:00:27.740
And you came up with four of them.

00:00:27.740 --> 00:00:29.190
Do you remember what they were?

00:00:29.190 --> 00:00:31.120
&gt;&gt; Yeah, I think they're on a slide,
fortunately.

00:00:31.120 --> 00:00:32.430
I just have to remember what they mean.

00:00:32.430 --> 00:00:33.780
It's like eat with three
different bullets,

00:00:33.780 --> 00:00:35.030
and they're getting successively larger.

00:00:35.030 --> 00:00:39.260
But I think it's actually food pellet,
power pellet, monster or

00:00:39.260 --> 00:00:42.030
ghost, and then avoid ghost.

00:00:42.030 --> 00:00:42.720
&gt;&gt; And avoid ghost.

00:00:42.720 --> 00:00:45.290
Right.
And if you recall, at the time

00:00:45.290 --> 00:00:48.780
we briefly discussed that these
things really do look like options.

00:00:48.780 --> 00:00:51.430
And this last one doesn't really look
like an option in the sense that it

00:00:51.430 --> 00:00:53.755
doesn't have a goal and
there's something you can succeed.

00:00:53.755 --> 00:00:55.230
In some sense you can only fail.

00:00:55.230 --> 00:00:57.690
And this turned out to be
interesting for a couple of reasons.

00:00:57.690 --> 00:01:01.370
One, just because you came up with them,
and in fact we've done this study

00:01:01.370 --> 00:01:04.780
multiple, multiple humans at
various levels of expertise.

00:01:04.780 --> 00:01:07.390
And, basically,
they all come up with the same four.

00:01:07.390 --> 00:01:10.650
Sometimes they'll come up with a fifth
that kind of distinguishes between

00:01:10.650 --> 00:01:14.220
eating a real ghost that's edible and
a ghost that isn't edible,

00:01:14.220 --> 00:01:14.860
and that kind of thing.

00:01:14.860 --> 00:01:16.170
But basically,
they come with the same four.

00:01:16.170 --> 00:01:19.280
And the point here, and why I want to
bring it up is that if you just ask

00:01:19.280 --> 00:01:23.500
people to give you what they know,
you ask them to communicate,

00:01:23.500 --> 00:01:25.740
you ask them to coach an agent.

00:01:25.740 --> 00:01:28.400
They will often come up with
things that are different from

00:01:28.400 --> 00:01:30.225
what your machine expects.

00:01:30.225 --> 00:01:33.970
And the sort of claim I want to make is
that often in research what we do is we

00:01:33.970 --> 00:01:37.200
come up with wonderful machine learning
algorithms, decide what information they

00:01:37.200 --> 00:01:39.730
need, and then try to force humans
to give us that information.

00:01:39.730 --> 00:01:42.290
But actually, human beings will
naturally sometimes give us that

00:01:42.290 --> 00:01:45.480
information, but often give us
different kinds of information.

00:01:45.480 --> 00:01:47.960
And if you look at it the wrong way,
you would say, well, look,

00:01:47.960 --> 00:01:49.220
these three are useful.

00:01:49.220 --> 00:01:51.750
This last one can't be implemented,
so I'm going to ignore it.

00:01:51.750 --> 00:01:54.360
But in fact, even in the Monte Carlo
tree search example,

00:01:54.360 --> 00:01:58.170
this last one, this constraint,
actually helped us

00:01:58.170 --> 00:02:01.830
develop a better algorithm because it
gave us a better rollout strategy.

00:02:01.830 --> 00:02:05.470
And, in fact,
as the students listening will know,

00:02:05.470 --> 00:02:08.830
because they've read the paper
on this that we made available,

00:02:08.830 --> 00:02:11.940
that it actually improves
performance an amazing amount.

00:02:11.940 --> 00:02:16.250
So, the point of this is that when
we ask humans to communicate,

00:02:16.250 --> 00:02:19.040
to be a part of the sort
of team of how we teach and

00:02:19.040 --> 00:02:22.870
demonstrate to our agents, we need to
meet them where they are as opposed to

00:02:22.870 --> 00:02:25.470
try to force them to meet us
where our algorithms are.

00:02:25.470 --> 00:02:27.548
&gt;&gt; And I want to give you just
a couple examples of that.

00:02:27.548 --> 00:02:28.090
That sound fair?

00:02:28.090 --> 00:02:28.916
&gt;&gt; Yeah, that's really cool.

00:02:28.916 --> 00:02:29.600
&gt;&gt; Cool.
All right.

00:02:29.600 --> 00:02:32.850
So, the first one's going to be
something called policy shaping.

00:02:32.850 --> 00:02:36.440
And as a preview, just want you
to know the whole point of this

00:02:36.440 --> 00:02:40.960
is to say that all the stuff you talked
about with the word shaping was wrong.

00:02:40.960 --> 00:02:42.230
&gt;&gt; Yeah.
Let's take a look.

