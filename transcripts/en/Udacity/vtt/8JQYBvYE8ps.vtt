WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.540
And the correct answers here in my opinion are the first two.

00:00:02.540 --> 00:00:10.050
The first one is even if the algorithm makes an error with 90% probability, running it only a few times,

00:00:10.050 --> 00:00:12.890
it does guarantee a correct solution and that of course as you've seen before

00:00:12.890 --> 00:00:19.510
these probabilities here have to be multiplied with each other if we run the algorithm a couple of times.

00:00:19.510 --> 00:00:23.010
So, if you run it the first time, of course we have a 90% error chance,

00:00:23.010 --> 00:00:28.230
but if you run it the second time, we only have (90%)² error chance.

00:00:28.230 --> 00:00:31.900
If we run it three times, we have (90%)³.

00:00:31.900 --> 00:00:34.520
And once we have run this algorithm 50 times,

00:00:34.520 --> 00:00:41.270
we have an error probability of 90%^⁵⁰, which is about 0.5%,

00:00:41.270 --> 00:00:45.310
and running it a couple of times more of course, we can even get this figure out much much lower.

00:00:45.310 --> 00:00:50.700
So, since we only have to run it a constant number of times to get the error very very low,

00:00:50.700 --> 00:00:53.860
it would mean that we're staying still in polynomial time,

00:00:53.860 --> 00:00:56.340
but we're almost guaranteed a perfect solution.

00:00:56.340 --> 00:00:59.090
Now, I'm not saying that this is impossible because

00:00:59.090 --> 00:01:02.480
the laws of NP completeness indeed do not account for randomness

00:01:02.480 --> 00:01:04.690
but of course it's very very unlikely

00:01:04.690 --> 00:01:07.320
It's almost the same as with the approximation algorithm

00:01:07.320 --> 00:01:10.130
where you wouldn't expect an approximation algorithm with

00:01:10.130 --> 00:01:14.260
an approximation factor of 1.01 even though for some problems

00:01:14.260 --> 00:01:19.250
it has not been proven that that is impossible but you still wouldn't expect it.

00:01:19.250 --> 00:01:21.500
Now, the second choice here I think is also correct.

00:01:21.500 --> 00:01:26.030
And that is basically my reasoning why I say you shouldn't expect this.

00:01:26.030 --> 00:01:30.560
The number of potential solutions for an NP-complete problem is exponential.

00:01:30.560 --> 00:01:33.170
Since the algorithm only runs in polynomial time,

00:01:33.170 --> 00:01:36.600
it can only afford to check a small part of that solution.

00:01:36.600 --> 00:01:38.960
That is basically the image that we just had

00:01:38.960 --> 00:01:43.180
where you only able to explore small areas of the whole solution space.

00:01:43.180 --> 00:01:45.630
And of course you have to employ the strategy.

00:01:45.630 --> 00:01:47.810
I just think that with this strategy

00:01:47.810 --> 00:01:50.970
it is highly unlikely to get an algorithm with this performance up here.

00:01:50.970 --> 00:01:54.250
It just doesn't make sense because you're still poking around a lot.

00:01:54.250 --> 00:01:58.210
So why would you get a fixed error probability in an exponentially large space

00:01:58.210 --> 00:02:01.570
if you can only afford to check a polynomial size part of it.

00:02:01.570 --> 00:02:05.840
And finally as I said the laws of NP completeness indeed

00:02:05.840 --> 00:02:08.310
do not account for randomness, but the thing is this

00:02:08.310 --> 00:02:12.230
just because that is so it doesn't mean we should expect anything to happen.

00:02:12.230 --> 00:02:16.010
Again, I think this is the same thing as with the approximation algorithm.

00:02:16.010 --> 00:02:19.260
Of course for some problems it would theoretically be possible

00:02:19.260 --> 99:59:59.000
to have a 1.01 approximation algorithm, but it just seems too unlikely to be true.

