WEBVTT
Kind: captions
Language: en

00:00:00.150 --> 00:00:01.950
Okay, the way I like to go about auditing my

00:00:01.950 --> 00:00:04.820
data is to write code that performs that kinds of checks

00:00:04.820 --> 00:00:08.440
that I'm interested in doing. now, you could use something like

00:00:08.440 --> 00:00:12.770
a piece of ETL software, there are a number. Clover, there

00:00:12.770 --> 00:00:16.980
are some Python-based ones, PETL is one of those. For

00:00:16.980 --> 00:00:19.580
me, I find those get in the way a lot and

00:00:19.580 --> 00:00:23.090
this might just be personal preference. In terms of this class,

00:00:23.090 --> 00:00:25.850
I think it's better for us to talk about the basics.

00:00:26.850 --> 00:00:31.500
So what I'd like to do is just give you an idea for the type of process

00:00:31.500 --> 00:00:34.320
in terms of the codes you'll be writing in

00:00:34.320 --> 00:00:37.600
order to do auditing and cleaning tasks and we'll

00:00:37.600 --> 00:00:41.050
just write Python scripts to do this. So in

00:00:41.050 --> 00:00:44.910
my case, I'm interested in auditing the accuracy of

00:00:44.910 --> 00:00:49.100
the country field here. So I've written a little

00:00:49.100 --> 00:00:52.100
script here that is going to follow the process

00:00:52.100 --> 00:00:55.670
I just described of comparing country field values in

00:00:55.670 --> 00:00:59.820
our data with this reliable list of country names.

00:00:59.820 --> 00:01:01.810
Now, this is the type of thing that we

00:01:01.810 --> 00:01:05.000
would probably want to use a database for. So,

00:01:05.000 --> 00:01:06.230
we're going to have a little bit of a

00:01:06.230 --> 00:01:09.920
preview here for the next lesson in that,I'm actually

00:01:09.920 --> 00:01:14.150
taking advantage of some data stored in mongoDB, in

00:01:14.150 --> 00:01:18.220
fact, that country codes data, that I've stored in mongoDB.

00:01:18.220 --> 00:01:20.280
And I'm going to just do a very

00:01:20.280 --> 00:01:23.630
simple query in this code. That happens right here

00:01:23.630 --> 00:01:27.670
using the PyMongo module. Which is the Python driver

00:01:27.670 --> 00:01:31.420
or client library for Mongo DB. Again, what I'm

00:01:31.420 --> 00:01:33.220
doing is moving through every value in my

00:01:33.220 --> 00:01:37.010
cities data and executing a query against the database.

00:01:37.010 --> 00:01:39.810
Asking weather the value I'm finding in the country

00:01:39.810 --> 00:01:43.560
field is in that list of country names from

00:01:43.560 --> 00:01:49.850
the ISO. Which I have stored in a collection in mongoDB. Okay

00:01:49.850 --> 00:01:54.320
so, let's run this and see what we find. Okay,

00:01:54.320 --> 00:01:58.780
so this just ran through all 20,000 odd cities and here's what we get as

00:01:58.780 --> 00:02:01.830
country names. That were not found in our list.

00:02:01.830 --> 00:02:03.780
You can see that in some cases what we've got

00:02:03.780 --> 00:02:05.710
here is the need to do some further parsing

00:02:05.710 --> 00:02:09.620
on the country field. Because we've got multiple names listed.

00:02:09.620 --> 00:02:12.430
And you could imagine why for some cities,

00:02:12.430 --> 00:02:15.090
there would be two names listed. So, let's just

00:02:15.090 --> 00:02:17.820
note this. This is just problems with the country

00:02:17.820 --> 00:02:19.940
field. So, the first thing that we found is

00:02:19.940 --> 00:02:25.310
that some values are actually arrays. Take a look at this one. Or

00:02:25.310 --> 00:02:29.850
this one. This is naming a county in Wisconsin, a county in

00:02:29.850 --> 00:02:35.160
Texas and a county in Florida. So these are examples

00:02:35.160 --> 00:02:40.570
of the wrong type of value being in the field. A lot of times that is due to

00:02:40.570 --> 00:02:43.610
something called column shift which is a particular value

00:02:43.610 --> 00:02:46.970
that got moved one column over. Now, that's probably

00:02:46.970 --> 00:02:49.660
not in fact what happened here. But the idea

00:02:49.660 --> 00:02:52.960
is the same. Someone entered a value that would

00:02:52.960 --> 00:02:56.630
be valid in another field, other than our country

00:02:56.630 --> 00:03:00.290
field. Then, we have some instances of data that

00:03:00.290 --> 00:03:02.920
simply needs to be cleaned up a bit. So, the

00:03:02.920 --> 00:03:07.570
parenthesis here is to distinguish the country of Georgia. From

00:03:07.570 --> 00:03:10.390
the state by the same name in the United States.

00:03:10.390 --> 00:03:12.840
And here you can see we've got an underscore separating

00:03:12.840 --> 00:03:17.050
the individual words for this particular country. I would call

00:03:17.050 --> 00:03:20.050
those examples of where we need regular expressions to come

00:03:20.050 --> 00:03:22.600
to the rescue. We simply need to account for these

00:03:22.600 --> 00:03:25.350
types of things in our field and clean them up by

00:03:25.350 --> 00:03:28.210
writing a little regular expression That will pull out the

00:03:28.210 --> 00:03:32.270
country name that's sitting there. And then finally, we've got

00:03:32.270 --> 00:03:35.240
some countries that appear here that aren't recognized in our

00:03:35.240 --> 00:03:38.270
list for one reason or another. There might be a political

00:03:38.270 --> 00:03:41.190
reason. It might be a language issue. So for these,

00:03:41.190 --> 00:03:43.990
we need to make a decision, and the decision is

00:03:43.990 --> 00:03:47.030
whether or not we want to include these, maybe add

00:03:47.030 --> 00:03:50.350
them to our gold standard list. That's something you really have

00:03:50.350 --> 00:03:54.230
to make on a situation by situation basis. So, there, we

00:03:54.230 --> 00:03:57.850
simply have possibly valid countries that we'll need to make a decision

00:03:57.850 --> 00:04:02.580
about. Okay. So, this provides us with a nice concrete example

00:04:02.580 --> 00:04:05.670
of how we might go about auditing accuracy for a particular field.

