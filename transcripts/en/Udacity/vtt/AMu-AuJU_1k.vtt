WEBVTT
Kind: captions
Language: en

00:00:00.347 --> 00:00:02.942
One of the cool recent announcements we've seen is the announcement

00:00:02.942 --> 00:00:06.477
of the Titan Supercomputer, which is now the fastest supercomputer in the world,

00:00:06.477 --> 00:00:09.448
and this has NVIDIA processors in its core.

00:00:09.448 --> 00:00:13.181
Can you talk a little bit about that process and how NVIDIA got to be involved

00:00:13.181 --> 00:00:15.986
and why that's such an exciting thing for GPU computing?

00:00:15.986 --> 00:00:17.617
Well, first of all, Titan is an awesome machine.

00:00:17.617 --> 00:00:31.089
It's 18,688 Kepler K20 GPUs and is the fastest computer in the world at running high performance winPAC.

00:00:31.089 --> 00:00:32.701
There's an interesting story there.

00:00:32.701 --> 00:00:36.994
The story of Titan actually starts with a meeting that I had with Steve Scott,

00:00:36.994 --> 00:00:43.700
who at the time was CTO of Cray at the Salishan Conference up on the Oregon Coast in 2009.

00:00:43.700 --> 00:00:48.413
I was talking to Steve and trying to see how can we work together.

00:00:48.413 --> 00:00:51.253
We really should get NVIDIA GPUs into Cray supercomputers

00:00:51.253 --> 00:00:55.587
because we have the best compute per dollar, compute per watt,

00:00:55.587 --> 00:00:57.957
which are the two things that matter in high performance computing,

00:00:57.957 --> 00:01:02.329
of anybody in the world, and they were actually going through a problem

00:01:02.329 --> 00:01:06.399
because they had bet on a different vendor who cancelled a project on them,

00:01:06.399 --> 00:01:12.872
and it left a hole in what they wanted to bid for this solicitation

00:01:12.872 --> 00:01:17.177
that was out from Oakridge to build what they call their leadership class computing facility--

00:01:17.177 --> 00:01:19.578
ultimately what turned in into Titan.

00:01:19.578 --> 00:01:23.983
It was just a nice sort of juxtaposition in time that I was having this conversation

00:01:23.983 --> 00:01:27.486
with him right at the point in time where there was a hole to be filled.

00:01:27.486 --> 00:01:30.090
It turns out Kepler filled that hole wonderfully.

00:01:30.090 --> 00:01:34.994
There was a lot of challenges along the way that, I think, really had to do with getting the people

00:01:34.994 --> 00:01:41.068
in the National Labs to embrace the model of parallelism that Cuda presents.

00:01:41.068 --> 00:01:43.602
I think that once they embraced it, they found it was actually easier

00:01:43.602 --> 00:01:47.072
to write their programs that way, and they actually ran better across the board

00:01:47.072 --> 00:01:55.114
once they were reorganized into that style of parallelism of watching CTAs and organizing things in that style.

00:01:55.114 --> 00:01:59.453
But they had a very large chunk of legacy code mostly in Fortran.

00:01:59.453 --> 00:02:03.985
It was coded sort of Fortran running on a single node with MPI used to communicate between the nodes,

00:02:03.985 --> 00:02:08.193
and it was a nontrivial exercise to really bring that software over

00:02:08.193 --> 00:02:11.698
and get it to run well on a GPU accelerated system.

00:02:11.698 --> 00:02:16.377
And I think beyond the LINPAC number, which is extra relatively easy number to get because it's one program,

00:02:16.377 --> 00:02:20.005
what really is a success of Titan is the very large number

00:02:20.005 --> 00:02:27.677
of basic energy science and defense codes that have been ported over very successfully

00:02:27.677 --> 00:02:31.598
and get just tremendous performance on the K20s.

