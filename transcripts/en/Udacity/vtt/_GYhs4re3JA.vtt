WEBVTT
Kind: captions
Language: en

00:00:00.490 --> 00:00:02.469
Okay, Michael so we talked a little bit about the curse of dimensionality,

00:00:02.469 --> 00:00:05.500
but I think it's worthwhile to talk about some other stuff that comes

00:00:05.500 --> 00:00:07.600
up. We've been sort of skirting around this and you know bring it

00:00:07.600 --> 00:00:12.360
up in various ways throughout our discussion so far. But I think it's worthwhile

00:00:12.360 --> 00:00:15.060
kind of writing them all down on a slide and trying to think

00:00:15.060 --> 00:00:18.100
through them for a little bit. So ,uh, the other stuff that comes

00:00:18.100 --> 00:00:21.232
up in [UNKNOWN] mainly comes up in these sort of assumptions we make

00:00:21.232 --> 00:00:25.671
about parameters to the algorithm. So the one we talked about ,uh, probably the

00:00:25.671 --> 00:00:28.155
most is our distance measure, you know our

00:00:28.155 --> 00:00:30.777
distance between some X and some query point Q

00:00:30.777 --> 00:00:33.480
and we've explored a couple. We looked at

00:00:33.480 --> 00:00:37.780
Eucudean and we looked at Manhattan. And we even

00:00:37.780 --> 00:00:40.680
looked at weighted versions of those. And this

00:00:40.680 --> 00:00:42.860
really matters, I've said this before but I really

00:00:42.860 --> 00:00:45.340
think it bears repeating that your choice of

00:00:45.340 --> 00:00:50.910
distance function Really matters. If you pick the wrong

00:00:50.910 --> 00:00:53.700
kind of distance function, you're just going to get very poor behavior.

00:00:53.700 --> 00:00:57.760
&gt;&gt; So I, so I have a question about these these distance functions.

00:00:57.760 --> 00:00:59.670
So you mentioned Euclidean and Manhattan,

00:00:59.670 --> 00:01:01.040
are there other distance functions that the

00:01:01.040 --> 00:01:04.510
students should know? Like, things that they, that might come up, or things

00:01:04.510 --> 00:01:06.920
that they should think of first if they have a particular kind of data?

00:01:08.060 --> 00:01:11.150
&gt;&gt; yeah, there's a, there's a ton of them. I think Well, first off,

00:01:11.150 --> 00:01:13.260
it, it's probably worth pointing out that

00:01:13.260 --> 00:01:15.980
this, this notion of weighted distance is one

00:01:15.980 --> 00:01:18.580
way to deal with the curse of dimensionality. You can weight

00:01:18.580 --> 00:01:21.610
different dimensions differently. And that would be one, and you might

00:01:21.610 --> 00:01:24.100
come up with sort of automatic ways of doing that. That,

00:01:24.100 --> 00:01:27.260
that's sort of worth mentioning. But you will notice that both Euclidean

00:01:27.260 --> 00:01:30.560
and Manhattan distance at least as we have talked about them,

00:01:30.560 --> 00:01:34.640
are really useful for things like regression. Their kind of assuming

00:01:34.640 --> 00:01:38.110
that you have numbers in that subtraction kind of makes sense.

00:01:38.110 --> 00:01:41.340
But there are other functions, distance functions that you might do if

00:01:41.340 --> 00:01:46.504
you are dealing with cases like, I don't know Discrete

00:01:46.504 --> 00:01:50.760
data, right? Where instead of it all being numbers, it's colors,

00:01:50.760 --> 00:01:54.730
or something like that. Alright so, your distance might be mismatches.

00:01:54.730 --> 00:01:56.870
For example, or it might be a mixture of those. In

00:01:56.870 --> 00:01:58.800
fact, one of the nice things about KNN, is that

00:01:58.800 --> 00:02:00.670
we've been talking about it with points, because it's sort of

00:02:00.670 --> 00:02:02.950
easy to think about it that way. But this distance function

00:02:02.950 --> 00:02:07.160
is just a black box. You can take Arbitrary things and

00:02:07.160 --> 00:02:09.539
try to decide how similar they are based on whatever you

00:02:09.539 --> 00:02:12.125
know about the domain and that could be very useful. So

00:02:12.125 --> 00:02:14.960
,you could talk about images right, where you take pictures of

00:02:14.960 --> 00:02:18.160
people and you know rather than doing something like a pixel

00:02:18.160 --> 00:02:21.960
by pixel comparison, you try to line up their eyes. And

00:02:21.960 --> 00:02:24.750
look at their mouths, and try to see if they're the

00:02:24.750 --> 00:02:27.740
same shape you know things like that, that might be more

00:02:27.740 --> 00:02:29.690
complicated and and perhaps even arbitrarily

00:02:29.690 --> 00:02:32.570
computational to determine notions of similarity

00:02:32.570 --> 00:02:35.620
so really this idea of distance in similarity tells

00:02:35.620 --> 00:02:36.830
you a lot about your domain and what you

00:02:36.830 --> 00:02:39.190
believe about it. ,another thing that's worth what what's

00:02:39.190 --> 00:02:41.730
pushing on a little bit is how you pick k.

00:02:41.730 --> 00:02:43.440
Well there's no good was to pick k you

00:02:43.440 --> 00:02:46.580
just You just have to know something about it, but

00:02:46.580 --> 00:02:48.590
I want to think about a particular case. Well,

00:02:48.590 --> 00:02:51.915
what if we end up in a world where K=N.

00:02:51.915 --> 00:02:52.760
&gt;&gt; Well, that would be silly.

00:02:52.760 --> 00:02:53.800
&gt;&gt; Why would it be silly?

00:02:53.800 --> 00:02:57.740
&gt;&gt; Well, so if K=N, then what you're doing is you're taking, so in the case

00:02:57.740 --> 00:02:59.540
of regression for example, you're taking all

00:02:59.540 --> 00:03:02.930
of the data points and averaging the.

00:03:02.930 --> 00:03:06.080
Y values together. Basically ignoring the query.

00:03:06.080 --> 00:03:08.530
So, you end up with a constant function.

00:03:08.530 --> 00:03:10.310
&gt;&gt; But that's only if you do a

00:03:10.310 --> 00:03:12.480
simple average. What if you do a weighted average?

00:03:16.100 --> 00:03:19.040
&gt;&gt; A weighted average. So the near, the points that are

00:03:19.040 --> 00:03:21.520
the query are going to get more weight in the average, so

00:03:21.520 --> 00:03:25.200
that acually will be diffrent. Even though k equals n, it

00:03:25.200 --> 00:03:28.170
will be different depending on where you actually put your query down.

00:03:28.170 --> 00:03:32.180
&gt;&gt; Exactly. That's exactly right so, for example, if I have

00:03:32.180 --> 00:03:35.820
a little bunch of points like this say. Where you notice it

00:03:35.820 --> 00:03:38.480
kind of looks like I have two different lines here and

00:03:38.480 --> 00:03:41.300
I can pick a query point way over here, all of these

00:03:41.300 --> 00:03:44.670
points are going to influence me as oppose to these points and

00:03:44.670 --> 00:03:48.240
so I'm going to end up. Estimating with something that looks more

00:03:48.240 --> 00:03:51.990
like this because these points over here won't have much to

00:03:51.990 --> 00:03:54.540
say. But if I have a query point that's way over here

00:03:54.540 --> 00:03:57.010
somewhere these points are going to matter and I'm going to end up

00:03:57.010 --> 00:03:59.760
looking something looks a little bit more like this than like

00:03:59.760 --> 00:04:02.880
that. Now I'm drawing these as lines. They won't exactly look

00:04:02.880 --> 00:04:06.300
like lines because these points will have some influence. They'll be more

00:04:06.300 --> 00:04:09.170
curvy than that. But the point is that near, near

00:04:09.170 --> 00:04:10.870
the place we want to do the query it will

00:04:10.870 --> 00:04:13.880
look To be more strongly influenced by these points over

00:04:13.880 --> 00:04:16.880
here or these points over here depending on where you are.

00:04:16.880 --> 00:04:18.450
&gt;&gt; Well that gives me an idea.

00:04:18.450 --> 00:04:19.890
&gt;&gt; Oh, what kind of idea does it give you?

00:04:19.890 --> 00:04:21.920
&gt;&gt; Well, what about instead of just taking

00:04:21.920 --> 00:04:24.900
a weighted average, what about using the distance matrix

00:04:24.900 --> 00:04:26.930
to pick up some of the points? And

00:04:26.930 --> 00:04:30.220
then do a different regression on that substantive point.

00:04:30.220 --> 00:04:31.380
&gt;&gt; Right, I like that.

00:04:31.380 --> 00:04:32.920
So we can replace this whole notion of

00:04:32.920 --> 00:04:36.270
average with a more kind of, regression-y thing.

00:04:36.270 --> 00:04:39.080
&gt;&gt; So it actually, instead of using the same value for

00:04:39.080 --> 00:04:42.250
the whole patch. Actually, it still continues to use the input values.

00:04:42.250 --> 00:04:45.160
&gt;&gt; Yeah. So, in fact, average is just

00:04:45.160 --> 00:04:46.890
a special case of a kind of regression, right?

00:04:46.890 --> 00:04:47.520
&gt;&gt; Mm hm, mm hm.

00:04:47.520 --> 00:04:49.430
&gt;&gt; Right? So this actually has a name,

00:04:49.430 --> 00:04:52.130
believe it or not. It's actually called locally

00:04:52.130 --> 00:04:54.850
weighted regression. Yeah, so this actually works pretty

00:04:54.850 --> 00:04:56.770
well and in place of sort of averaging

00:04:56.770 --> 00:04:59.750
function, you can do just about anything you want to.

00:04:59.750 --> 00:05:02.460
You could throw in a decision tree, you could throw in

00:05:02.460 --> 00:05:06.810
a neural network, you could throw in lines do linear

00:05:06.810 --> 00:05:11.270
regression. You can do, almost anything that you can imagine doing.

00:05:11.270 --> 00:05:11.440
&gt;&gt; Neat,

00:05:11.440 --> 00:05:14.314
&gt;&gt; Yeah. Add that works out very well. And again, it

00:05:14.314 --> 00:05:16.680
gives you a little bit of power. So here's something I don't

00:05:16.680 --> 00:05:18.980
think is very obvious until it's pointed out to you. Which is

00:05:18.980 --> 00:05:21.980
this notion of replacing the average with a more general regression or

00:05:21.980 --> 00:05:24.930
even classification function. It actually allows

00:05:24.930 --> 00:05:26.570
you to do something more powerful

00:05:26.570 --> 00:05:29.470
than it seems. So let's imagine that we were going to do locally

00:05:29.470 --> 00:05:33.250
weighted regression and we were going to do, in fact, linear regression. So,

00:05:33.250 --> 00:05:36.650
what would locally- weighted linear regression look like? Well, if we go

00:05:36.650 --> 00:05:39.360
back to this example over here on the left basically, you take

00:05:39.360 --> 00:05:41.250
all the points that are nearby and you try to fit a

00:05:41.250 --> 00:05:43.680
line to it. And, so you would end up with stuff that

00:05:43.680 --> 00:05:47.200
looked, pretty much, like this. While you're over here, you would get

00:05:47.200 --> 00:05:49.030
the line like this, but while you were over here you'd

00:05:49.030 --> 00:05:51.590
get a line like this. Then, somewhere in the middle you

00:05:51.590 --> 00:05:54.630
would get lines that started to look like this and And

00:05:54.630 --> 00:05:57.400
you would end up with something that kind of ended up looking

00:05:57.400 --> 00:06:00.720
a lot like a curve. So that's kind of cool because

00:06:00.720 --> 00:06:04.640
you notice that we start with a hypothesis state of lines

00:06:04.640 --> 00:06:07.990
and this locally weighted linear regression. But then we end up

00:06:07.990 --> 00:06:14.050
actually being able to represent a hypothesis space that is strictly bigger.

00:06:14.050 --> 00:06:16.570
than the set of lines. Hm. So we can

00:06:16.570 --> 00:06:19.310
use a very simple kind of hypothesis space but by

00:06:19.310 --> 00:06:21.800
using this locally weighted regression we end up with

00:06:21.800 --> 00:06:26.010
a more complicated space that is complicated, that's made more

00:06:26.010 --> 00:06:29.310
complicated depending upon the complications that are represented by

00:06:29.310 --> 00:06:33.110
your data points. So this results, this sort of reveals

00:06:33.110 --> 00:06:36.460
another bit of power with kNN. Which is, it

00:06:36.460 --> 00:06:39.650
allows you to take local information and build functions or

00:06:39.650 --> 00:06:42.860
build concepts around the local things that are similar to

00:06:42.860 --> 00:06:45.920
you. And that allows you to make arbitrarily complicated functions.

00:06:45.920 --> 00:06:46.770
&gt;&gt; Neat.

00:06:46.770 --> 00:06:49.800
&gt;&gt; At least in principle. Okay, cool. Alright so you got all that?

00:06:49.800 --> 00:06:51.090
&gt;&gt; I, think so yeah.

00:06:51.090 --> 00:06:53.220
&gt;&gt; Okay, cool. So then, I think we should wrap up.

00:06:53.220 --> 00:06:54.000
&gt;&gt; Nice.

00:06:54.000 --> 00:06:54.810
&gt;&gt; Nice.

