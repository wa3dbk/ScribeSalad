WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.924
We're just about ready to wrap up the course.

00:00:01.924 --> 00:00:05.186
We've covered Stratton's taxonomy of parallel optimization patterns,

00:00:05.186 --> 00:00:09.020
and we've tied those back to the lessons and assignments that you've had throughout the course.

00:00:09.020 --> 00:00:10.922
We've discussed the wide array of libraries

00:00:10.922 --> 00:00:14.256
that let you easily exploit the computational horsepower of the GPU.

00:00:14.256 --> 00:00:16.418
We've reviewed a few programming power tools

00:00:16.418 --> 00:00:19.791
to help you write high-performance applications with less work.

00:00:19.791 --> 00:00:23.847
And finally, we've talked about other platforms, including CUDA support for other languages

00:00:23.847 --> 00:00:26.597
like Python and MATLAB and Fortran

00:00:26.597 --> 00:00:31.251
as well as cross-platform solutions for CUDA-style massively parallel programming.

00:00:31.251 --> 00:00:33.378
So to close the lecture and the course,

00:00:33.378 --> 00:00:37.121
we're going to hear about one of the more exciting new features in the latest CUDA GPUs,

00:00:37.121 --> 00:00:39.035
dynamic parallelism.

00:00:39.035 --> 00:00:42.862
We've invited the real expert on this topic, Dr. Stephen Jones from NVIDIA,

00:00:42.862 --> 00:00:45.390
to give us a guest lecture on dynamic parallelism.

00:00:45.390 --> 00:00:48.090
We've also recorded an interview with Stephen for those of you interested

00:00:48.090 --> 00:00:49.967
in diving a bit deeper afterwards.

00:00:49.967 --> 00:00:52.462
So let's turn it over to Stephen, then we'll wrap up the course.

