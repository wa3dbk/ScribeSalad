WEBVTT
Kind: captions
Language: en

00:00:00.203 --> 00:00:01.839
This example's a little more complicated.

00:00:01.839 --> 00:00:05.177
For clarity, remember that I'm just hard coding the idea

00:00:05.177 --> 00:00:11.787
that there's 128 threads and therefore we're going to operate on 128 elements of the array, all right?

00:00:11.787 --> 00:00:14.669
And I'm going to skip all this sort of out-of-bounds check and assertions

00:00:14.669 --> 00:00:20.141
that you would normally use to make sure that you're not trying to access a piece of memory that's not there.

00:00:20.141 --> 00:00:25.880
So once again, we have a function, use shared memory GPU.

00:00:25.880 --> 00:00:29.985
This function is a kernel, and we're going to pass in a local variable,

00:00:29.985 --> 00:00:32.055
which is a pointer to a bunch of floats.

00:00:32.055 --> 00:00:36.692
And, this local variable is a pointer to global memory that's been allocated in advance.

00:00:36.692 --> 00:00:39.962
I wanted to come up with some code that actually did something using shared memory,

00:00:39.962 --> 00:00:43.064
and that's why function is a little more complicated than the examples you've seen.

00:00:43.064 --> 00:00:46.638
So, we're going to declare a few local variables that are private to each thread,

00:00:46.638 --> 00:00:52.576
a couple of indices we'll declare this variable index, just to be shorthand for thread index dot x.

00:00:52.576 --> 00:00:54.242
That's just to save some typing.

00:00:54.242 --> 00:00:59.283
And we're going to declare a floating point variable called average, and another one called sum.

00:00:59.283 --> 00:01:01.784
And we'll initialize sum to 0.0.

00:01:01.784 --> 00:01:03.558
Here's the big example.

00:01:03.558 --> 00:01:06.487
Now we're going to declare a variable that lives in shared memory.

00:01:06.487 --> 00:01:08.055
In this case, it's an array.

00:01:08.055 --> 00:01:11.093
Again, I've hard coded that array to contain 128 elements.

00:01:11.093 --> 00:01:12.568
It's an array of floats.

00:01:12.568 --> 00:01:19.401
And I tag it as being a shared memory with this shared_declspec.

00:01:19.401 --> 00:01:21.345
And remember the whole point of shared memory is that

00:01:21.345 --> 00:01:25.078
this variable is visible to all the threads in the thread block.

00:01:25.078 --> 00:01:28.182
And it only has the lifetime of the thread block.

00:01:28.182 --> 00:01:30.419
So it doesn't exist outside of this thread block.

00:01:30.419 --> 00:01:32.787
Every thread block is going to have its own copy,

00:01:32.787 --> 00:01:37.227
it's own single copy of this array that all of the threads in that thread block can see.

00:01:37.227 --> 00:01:39.260
I call it sh_array.

00:01:39.260 --> 00:01:43.161
The first thing we're going to do is put some data in this array.

00:01:43.161 --> 00:01:47.661
Remember I passed in this array that's in global memory called array,

00:01:47.661 --> 00:01:51.973
and I'm basically going to initialize the shared memory array

00:01:51.973 --> 00:01:55.078
to contain exactly what's in the global memory array. Notice how I do it.

00:01:55.078 --> 00:01:59.077
I'm copying data from this array in global memory to this array in shared memory.

00:01:59.077 --> 00:02:01.744
And I'm doing it with a single operation.

00:02:01.744 --> 00:02:02.386
How does this work?

00:02:02.386 --> 00:02:08.791
If you look at this code, every thread is figuring out what its own index is, okay?

00:02:08.791 --> 00:02:18.496
Which thread it is, and it's copying the element at array sub index into the element at shared array sub index.

00:02:18.496 --> 00:02:22.337
Okay, so since all of the threads in the thread block will be doing

00:02:22.337 --> 00:02:25.645
exactly this operation and since they will all have different values for index,

00:02:25.645 --> 00:02:29.276
when this single line has completed in all the threads then

00:02:29.276 --> 00:02:34.851
we'll have copied all of the information in this global memory array into our shared memory array.

00:02:34.851 --> 00:02:39.728
Okay, and the trick is that operation is going to take some time.

00:02:39.728 --> 00:02:41.122
Multiple threads are running.

00:02:41.122 --> 00:02:44.625
They're not running all at the same time, so it won't happen instantaneously.

00:02:44.625 --> 00:02:49.295
We have to make sure all of these writes to shared memory have completed before we go on

00:02:49.295 --> 00:02:51.752
and do anything with that array in shared memory.

00:02:51.752 --> 00:02:54.301
And that's what the syncthreads operation is about.

00:02:54.301 --> 00:02:55.502
You've seen this before.

00:02:55.502 --> 00:02:59.335
We call our barrier to make sure that all the writes to shared memory have completed.

00:02:59.335 --> 00:03:03.008
Now after that barrier we're guaranteed that this shared memory array is fully populated.

00:03:03.008 --> 00:03:05.761
Every element has been initialized now.

00:03:05.761 --> 00:03:08.117
Just to be doing something, I said let's just find

00:03:08.117 --> 00:03:13.486
the average of all the elements previous to this thread's index.

00:03:13.486 --> 00:03:16.713
What we're going to do is we're going to do is with this for loop

00:03:16.713 --> 00:03:24.930
we're going to set i = 0 and go up and up to index, which is the number of this thread.

00:03:24.930 --> 00:03:32.846
And we're going to accumulate all the variables in the shared memory array up to this thread's index.

00:03:32.846 --> 00:03:35.634
And after we're done we'll compute the average,

00:03:35.634 --> 00:03:41.673
which is simply equal to the sum divided by the number of elements that we added up.

00:03:41.673 --> 00:03:45.609
And then, once again, now we need to do something with that average.

00:03:45.609 --> 00:03:50.615
What I decided to do is to have every thread

00:03:50.615 --> 00:03:55.886
look at the average that it just computed of all the elements

00:03:55.886 --> 00:04:00.324
in the array to its left if you will.

00:04:00.324 --> 00:04:04.762
If the value in the array at this thread's index is greater than the average

00:04:04.762 --> 00:04:09.063
that it just computed of all of the elements in the array to the left of this thread's index,

00:04:09.063 --> 00:04:13.472
then we're going to set array for this thread's index equal to that average.

00:04:13.472 --> 00:04:16.613
In other words, we're going to replace any threads that are greater than

00:04:16.613 --> 00:04:19.250
the average of all the threads to the left with that average.

00:04:19.250 --> 00:04:22.485
Notice that I'm operating on array and not shared array.

00:04:22.485 --> 00:04:25.789
I used this shared memory array to do my averaging.

00:04:25.789 --> 00:04:29.860
And that's a good idea, because remember that shared memory is fast.

00:04:29.860 --> 00:04:31.961
It's much faster to access than global memory.

00:04:31.961 --> 00:04:37.351
Here every thread is accessing a bunch of elements in the array.

00:04:37.351 --> 00:04:42.206
It make sense to move this array to first shared memory so that it moves faster.

00:04:42.206 --> 00:04:43.379
We'll talk about this later.

00:04:43.379 --> 00:04:47.266
But now I'm making this change back in the global memory array.

00:04:47.266 --> 00:04:53.196
And that means that when this kernel completes this change is going to be seen by the host

00:04:53.196 --> 00:04:58.134
and would also potentially be seen by other threads in other thread blocks if there were any.

00:04:58.134 --> 00:04:59.868
And then just to sort of make a point,

00:04:59.868 --> 00:05:02.503
here's a piece of code afterwards that has no effect at all,

00:05:02.503 --> 00:05:09.076
because I'm going to set an element of the shared memory array to 3.14, but then the kernel completes.

00:05:09.076 --> 00:05:11.312
Nothing ever gets done with that value that's sitting in shared memory.

00:05:11.312 --> 00:05:13.383
And since the shared memory has the lifetime of the thread block,

00:05:13.383 --> 00:05:16.937
this memory evaporates as soon as this thread block completes.

00:05:16.937 --> 00:05:20.272
This code has no effect and in fact can probably be removed by the compiler.

00:05:20.272 --> 00:05:23.061
Calling a kernel that uses a shared memory is no different

00:05:23.061 --> 00:05:24.938
than calling a kernel that uses global memory right.

00:05:24.938 --> 00:05:27.040
Since all you can do is pass in a local variable

00:05:27.040 --> 00:05:31.133
that points to global memory if you've so allocated it.

00:05:31.133 --> 00:05:35.506
Then you know what that kernel does with its shared memory is completely up to it

00:05:35.506 --> 00:05:37.405
and not visible to the host code at all.

00:05:37.405 --> 00:05:42.778
This code showing how to use shared memory is identical to the code we saw up here.

