WEBVTT
Kind: captions
Language: en

00:00:00.120 --> 00:00:05.230
There're several ways of how we can deal with visuospatial knowledge.

00:00:05.230 --> 00:00:08.460
In fact in your projects you've already come across some of them. So imagine

00:00:08.460 --> 00:00:13.190
there is a figure here. Here is a triangle with the apex facing to the right.

00:00:13.190 --> 00:00:17.400
Here is another triangle with the apex facing to the left. So in one view,

00:00:17.400 --> 00:00:22.550
the AI agent can extract propositional representations out of figures like this.

00:00:22.550 --> 00:00:25.680
And similarly propositional representations out of figures like this. So

00:00:25.680 --> 00:00:29.180
this is a propositional representation, this is a propositional representation.

00:00:29.180 --> 00:00:33.150
And then, the AI agent can work on these propositional representations to

00:00:33.150 --> 00:00:37.070
produce new propositional representations. So some AI agent can

00:00:37.070 --> 00:00:41.840
use a logic engine or a production rule to say that this particular triangle,

00:00:41.840 --> 00:00:46.740
which was rotated 90 degrees, has not been rotated to 270 degrees. So

00:00:46.740 --> 00:00:51.140
although the input wasn't in formula's figures, the action here was at the level

00:00:51.140 --> 00:00:55.850
of propositional representations of these figures. The agent may extract

00:00:55.850 --> 00:00:59.410
propositional representations like this through image processing, through image

00:00:59.410 --> 00:01:04.038
segmentation, perhaps using some techniques like constraint propagation as well.

00:01:04.038 --> 00:01:08.610
Alternatively, the agent may have analogical representations.

00:01:08.610 --> 00:01:10.440
In these analogical representations,

00:01:10.440 --> 00:01:13.930
it is a structural correspondence between the representation and

00:01:13.930 --> 00:01:17.900
the external figure. So the external world headed triangle like this, and

00:01:17.900 --> 00:01:22.650
the analogical representation will also have a triangle like this. Notice that

00:01:22.650 --> 00:01:25.640
I'm using the term Analogical Representation, we use a separate thing from

00:01:25.640 --> 00:01:29.465
analogical reasoning. We are not talking about analogical reasoning right now.

00:01:29.465 --> 00:01:33.370
We're talking about analogical representation and analogical representation is

00:01:33.370 --> 00:01:37.630
one, which is some structural correspondence with the external world that is

00:01:37.630 --> 00:01:42.490
being represented. Give a certain analogical representation, then I might want

00:01:42.490 --> 00:01:46.910
affine transformations or set transformations to get this. So I may say that I

00:01:46.910 --> 00:01:50.510
got this triangle out of that one, simply by the operation of reflection or

00:01:50.510 --> 00:01:55.130
rotation. So these proposed representations in the previous view are A model.

00:01:55.130 --> 00:02:00.120
They are separated from, divorced from the perceptual modality.

00:02:00.120 --> 00:02:02.220
These analogical representations on the other hand,

00:02:02.220 --> 00:02:06.910
are modal representations. They're very close to the perceptual modality.

00:02:06.910 --> 00:02:13.370
And human cognition, mental imagery, appears to use analogical representations.

00:02:13.370 --> 00:02:16.640
What would be an equally intuitive of computational imagery?

00:02:16.640 --> 00:02:20.850
Human cognition is very good at using both propositional representations and

00:02:20.850 --> 00:02:25.110
analogical representations. Computers however, are not yet

00:02:25.110 --> 00:02:29.020
good at using analogical representations. Most computers, most of the time,

00:02:29.020 --> 00:02:33.730
use only prepositional presentations. The same kind of analysis may apply to

00:02:33.730 --> 00:02:38.240
other perceptual modalities, not just to our visual images. So here are two

00:02:38.240 --> 00:02:42.350
measures and we can either extract proposed representations out of them and

00:02:42.350 --> 00:02:46.590
then analyze those propositional representations. Or, we could think directly

00:02:46.590 --> 00:02:50.080
with the relationship in these two particular measures. There is a question for

00:02:50.080 --> 00:02:53.870
building queries of human cognition. When you're driving a car, and

00:02:53.870 --> 00:02:57.930
you listen to a melody on your radio and you're reminded of something.

00:02:57.930 --> 00:03:00.840
Reminded of a similar melody that you had heard earlier.

00:03:00.840 --> 00:03:04.093
What exactly is happening? Are you extracting a purpose for

00:03:04.093 --> 00:03:08.050
your presentation out of the melody that you just heard? And then

00:03:08.050 --> 00:03:12.710
the proposition representation reminds you of the proposition representation for

00:03:12.710 --> 00:03:18.300
a previously heard melody. Or, does a new melody somehow directly remind

00:03:18.300 --> 00:03:22.490
you of a previously heard melody without any intermediate propositional

00:03:22.490 --> 00:03:26.980
representation? These are our open issues in cognitive science,

00:03:26.980 --> 00:03:31.660
as well as in knowledge based AI. In cognitive science, it is by now,

00:03:31.660 --> 00:03:37.230
significant agreement that human cognition does use mental imagery at least

00:03:37.230 --> 00:03:41.750
with visual images. But we don't know how to do mental imagery in computers.

