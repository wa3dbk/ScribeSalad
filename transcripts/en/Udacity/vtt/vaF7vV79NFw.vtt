WEBVTT
Kind: captions
Language: en

00:00:00.360 --> 00:00:04.530
To do incremental visual tracking
using principal component analysis,

00:00:04.530 --> 00:00:07.460
what we want to do is you want to build
a tracker that is not just based upon

00:00:07.460 --> 00:00:12.140
a single patch but sort of constantly
update some form of a model.

00:00:12.140 --> 00:00:15.460
between me and you, that model is
going to be a basis set, so were

00:00:15.460 --> 00:00:19.820
going to keep changing the basis set
a little bit as the, as the model moves.

00:00:19.820 --> 00:00:22.190
We want something that runs quickly and

00:00:22.190 --> 00:00:24.740
can operate even if
the camera is moving.

00:00:24.740 --> 00:00:27.260
And, of course, the,
the general challenge here is,

00:00:27.260 --> 00:00:32.060
we would like this thing to be able
to handle if the pose is changing, so

00:00:32.060 --> 00:00:35.700
how the thing is moving,
you know, rotating, translating.

00:00:35.700 --> 00:00:38.150
Maybe parts of it get occluded, okay?

00:00:38.150 --> 00:00:40.490
And we'll talk about how to
handle occlusion in just a bit.

00:00:40.490 --> 00:00:41.900
You have illumination change.

00:00:41.900 --> 00:00:44.870
And you want to avoid drift, that is,
you don't want to start, you know,

00:00:44.870 --> 00:00:47.630
tracking someone's face and all of a
sudden you realize you're just tracking

00:00:47.630 --> 00:00:50.620
the bottom half of the face and then
it just gets stuck on a file cabinet.

00:00:50.620 --> 00:00:52.240
Right, you want to stick to their face.

00:00:52.240 --> 00:00:56.460
So the paper that some of this is pulled
from is this incremental learning for

00:00:56.460 --> 00:00:58.070
robust visual tracking.

00:00:58.070 --> 00:00:59.260
And I'm just using this.

00:00:59.260 --> 00:01:01.390
I mean it's, it's,
at this point known well.

00:01:01.390 --> 00:01:04.640
And also, it gives you a sense of how
to use principle component analysis,

00:01:04.640 --> 00:01:06.730
which we just learned,
particle filtering,

00:01:06.730 --> 00:01:09.760
which you know,
in order to do incremental tracking.

00:01:09.760 --> 00:01:12.540
This doesn't really belong
in the recognition unit, but

00:01:12.540 --> 00:01:17.680
since we couldn't do it until
you knew about PCA, here it is.

00:01:17.680 --> 00:01:20.350
So here are the main ideas, all right?

00:01:20.350 --> 00:01:23.230
First, we are going to use some
form of a particle filter, but

00:01:23.230 --> 00:01:26.710
the particle,
are going to represent the deformation.

00:01:26.710 --> 00:01:31.230
And the deformation may mean just an a
fine that is six degrees of freedom.

00:01:31.230 --> 00:01:33.510
It could be similarity,
it could even be just translation.

00:01:33.510 --> 00:01:36.010
But the idea is that the particles
are going to capture

00:01:36.010 --> 00:01:38.780
how the geometry changes
from frame to frame.

00:01:38.780 --> 00:01:42.810
The second main idea is that, we're
going to use the subspace method that I

00:01:42.810 --> 00:01:44.860
talked before about, detection, right?

00:01:44.860 --> 00:01:49.390
So, the idea is that we have some small
set of eigen vectors, they can reproduce

00:01:49.390 --> 00:01:53.610
only images that kind of look like
some thing that comes from this class.

00:01:53.610 --> 00:01:56.630
And we're going to use that
subspace in order to say, ha!

00:01:56.630 --> 00:01:58.730
That's a good example of
the thing I'm tracking,

00:01:58.730 --> 00:02:01.400
because I can reconstruct
that image really well.

00:02:01.400 --> 00:02:03.710
The third thing,
which is kind of the new, new and

00:02:03.710 --> 00:02:08.340
cool part is,
that we don't fix the subspace.

00:02:08.340 --> 00:02:13.320
We let it change incrementally as we
get new it, so we, we track this image,

00:02:13.320 --> 00:02:17.030
we track this object, we bring in
the new image and we might say, oh.

00:02:17.030 --> 00:02:18.240
Maybe it's changed a little bit.

00:02:18.240 --> 00:02:21.370
Let me change my subspace
just a little bit.

00:02:21.370 --> 00:02:26.100
So by changing my subspace a little bit,
I can track changes in appearance but

00:02:26.100 --> 00:02:27.930
it's because it's an entire subspace.

00:02:27.930 --> 00:02:32.150
I don't get fooled by a sort of small
variation that's just local in time.

00:02:32.150 --> 00:02:34.100
And I can sort of hang on to the object.

00:02:34.100 --> 00:02:35.920
You'll see an example of
that as we go forward.

