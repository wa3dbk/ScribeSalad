WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.801
Now, some libraries are less about solving a particular domain of problems

00:00:03.801 --> 00:00:07.384
and more about enabling the programmers to design their own solutions.

00:00:07.384 --> 00:00:09.204
And I call these programming power tools,

00:00:09.204 --> 00:00:12.268
and the first example I'm going to highlight is called Thrust.

00:00:12.268 --> 00:00:17.879
Now, C++ programmers will know about the Standard Template Library, or STL.

00:00:17.879 --> 00:00:21.116
STL provides a set of incredibly useful abstractions

00:00:21.116 --> 00:00:25.067
that are organized into containers and iterators.

00:00:25.067 --> 00:00:29.303
Thrust provides a data parallel analog to the STL for CUDA

00:00:29.303 --> 00:00:32.869
and also borrows niceties from the popular Boost library.

00:00:32.869 --> 00:00:35.935
Thrust allows host code that runs on the CPU

00:00:35.935 --> 00:00:39.087
to very easily create and manipulate data on the GPU.

00:00:39.087 --> 00:00:43.571
The principal container abstraction in Thrust is device vector,

00:00:43.571 --> 00:00:46.759
and this is analogous to the vector container in STL,

00:00:46.759 --> 00:00:50.335
but as the name implies, it lives on the device, on the GPU.

00:00:50.335 --> 00:00:54.798
Like the STL vector container, Thrust device vectors are generic containers,

00:00:54.798 --> 00:00:58.773
which means they're able to hold any data type and they can be resized dynamically.

00:00:58.773 --> 00:01:02.645
So once your data is in a device vector, you can do a bunch of things trivially.

00:01:02.645 --> 00:01:07.341
You can do things like sort the device vector or perform a scan operation on it,

00:01:07.341 --> 00:01:10.009
you can do a reduction operation or a reduce-by-key operation

00:01:10.009 --> 00:01:15.513
where you actually take a vector and reduce it according to a key that's in another vector.

00:01:15.513 --> 00:01:19.511
So, for example, if you have a device_vector X--

00:01:19.511 --> 00:01:22.867
in this case it's got 3 elements and it's of type float--

00:01:22.867 --> 00:01:25.695
then I can do a reduction on those 3 elements

00:01:25.695 --> 00:01:30.173
by just saying thrust::reduce, pass in x.begin and x.end

00:01:30.173 --> 00:01:32.869
to indicate that I'm going to reduce over the entire range of the vector,

00:01:32.869 --> 00:01:34.471
and it will give me the result.

00:01:34.471 --> 00:01:37.312
Or you can do a reduction of a different sort.

00:01:37.312 --> 00:01:42.709
So rather than simply doing a sum reduce, we can pass in an operator to use or a functor.

00:01:42.709 --> 00:01:44.788
In this case we'll do thrust::maximum.

00:01:44.788 --> 00:01:48.158
So in this case, this reduction will give us the maximum number in this vector.

00:01:48.158 --> 00:01:51.538
You can also do more general transformations.

00:01:51.538 --> 00:01:54.859
You can transform 1 or more input vectors into an output vector.

00:01:54.859 --> 00:01:58.562
For instance, you could do a vector addition operation, taking 2 vectors

00:01:58.562 --> 00:02:02.273
and adding them into a third vector using the built-in Thrust plus operator.

00:02:02.273 --> 00:02:07.076
Or you can apply a user-defined transformation, using a functor,

00:02:07.076 --> 00:02:11.733
and this is a chunk of code that you give Thrust and tell it, run this on every element

00:02:11.733 --> 00:02:16.014
or on the collection of input and output elements that I'm interested in.

00:02:16.014 --> 00:02:21.041
And you can interoperate with CUDA codes, so you can mix up Thrust code

00:02:21.041 --> 00:02:23.660
which is running on the host and doing things on the device,

00:02:23.660 --> 00:02:27.558
but if you then need to do something that is not built in to Thrust or that's difficult to do with Thrust

00:02:27.558 --> 00:02:30.185
and you've got some raw CUDA kernels that you want to run,

00:02:30.185 --> 00:02:34.680
then you can simply get the pointer to the data in a device vector

00:02:34.680 --> 00:02:39.242
or hand a pointer to Thrust to wrap up as a device vector.

00:02:39.242 --> 00:02:43.913
In the end, using Thrust is a good idea because it helps you avoid

00:02:43.913 --> 00:02:47.313
writing a lot of error-prone sort of cut and paste boilerplate code,

00:02:47.313 --> 00:02:52.454
and you can exploit high-performance implementations of these data parallel primitives

00:02:52.454 --> 00:02:55.057
like sort and scan and reduce and reduce-by-key.

00:02:55.057 --> 00:03:00.031
These have all been implemented by CUDA Ninjas for you so that you can just reuse that code.

00:03:01.200 --> 00:03:02.440
So Thrust can be very handy.

00:03:02.440 --> 00:03:05.806
We're going to give you Thrust code that sorts 10^6 floats,

00:03:05.806 --> 00:03:08.064
and we're going to ask you to time it,

00:03:08.064 --> 00:03:12.887
and then we're going to ask you to also time sorting 10^5 and 10^7 floats

00:03:12.887 --> 00:03:18.543
and then enter here how long it took to sort 10^5 floats, 10^6 floats, 10^7 floats,

00:03:18.543 --> 00:03:22.346
and 10^5, 10^6, and 10^7 bytes.

00:03:22.346 --> 00:03:24.381
And enter your answer in milliseconds,

00:03:24.381 --> 00:03:27.757
and we'll just check to within a significant digit or so.

