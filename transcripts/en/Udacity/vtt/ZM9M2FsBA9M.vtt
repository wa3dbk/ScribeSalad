WEBVTT
Kind: captions
Language: en

00:00:00.080 --> 00:00:03.360
Okay Michael so before we get started diving into

00:00:03.360 --> 00:00:06.150
a particular formalism or framework that I want to

00:00:06.150 --> 00:00:07.630
talk about, that we are going to use for

00:00:07.630 --> 00:00:09.880
this mini course or at least the first half or

00:00:09.880 --> 00:00:12.220
so of it. I want to remind everybody what

00:00:12.220 --> 00:00:14.170
the differences are between the three types of learning

00:00:14.170 --> 00:00:15.660
that we said we are going to look at

00:00:15.660 --> 00:00:18.390
over this entire course. Th, you recall what they are?

00:00:18.390 --> 00:00:22.250
&gt;&gt; Well reading off the slides supervised, unsupervised and reinforcement.

00:00:22.250 --> 00:00:25.180
&gt;&gt; That's right. And you know, again these things are all strongly

00:00:25.180 --> 00:00:28.610
related to one other but it's very useful to think about them as being very

00:00:28.610 --> 00:00:31.760
separate. So just as a reminder, supervised learning

00:00:31.760 --> 00:00:35.130
sort of takes the form of function approximation

00:00:35.130 --> 00:00:40.500
where you're given a bunch of x, y pairs And your goal is to find

00:00:40.500 --> 00:00:45.470
a function f that will map some new x to a proper y, you recall that?

00:00:45.470 --> 00:00:46.290
&gt;&gt; Yep.

00:00:46.290 --> 00:00:50.680
&gt;&gt; Unsupervised learning is very similar to supervised learning except that

00:00:50.680 --> 00:00:53.810
it turns out that you're given a bunch of x's

00:00:53.810 --> 00:00:56.870
and your goal is to find some f. That gives

00:00:56.870 --> 00:01:00.110
you a compact description of the set of x's that

00:01:00.110 --> 00:01:04.310
you've seen. So we call this clustering, or description as

00:01:04.310 --> 00:01:08.000
opposed to function approximation, and finally we're getting to reinforcement

00:01:08.000 --> 00:01:11.400
learning. Now reinforcement learning is actually a, a name that

00:01:11.400 --> 00:01:14.020
means many things in different fields, and here we tend

00:01:14.020 --> 00:01:16.380
to talk about it in a relatively specific way, and

00:01:16.380 --> 00:01:19.800
superficially it looks a lot like Supervised learning, in

00:01:19.800 --> 00:01:23.260
that we're going to be given a string of pairs

00:01:23.260 --> 00:01:26.190
of data, and we're going to try to learn some

00:01:26.190 --> 00:01:29.130
functions. But in the function approximation case, a supervized learning

00:01:29.130 --> 00:01:35.250
case, we were given a bunch of X and Y pairs. We were asked to learn F, but

00:01:35.250 --> 00:01:38.140
in reinforcement learning, we were given something totally different.

00:01:38.140 --> 00:01:42.300
Were instead going to be given x's and z's, and

00:01:42.300 --> 00:01:45.030
I'll tell you what the x's and the z's stand for in

00:01:45.030 --> 00:01:47.860
a minute, and then were going to have to learn some f that

00:01:47.860 --> 00:01:50.970
is going to generate y's, and so even though its going to look

00:01:50.970 --> 00:01:53.940
a lot like function approximation, its going to turn out that it's going to

00:01:53.940 --> 00:01:57.690
have a very different character. And that's really what the, the next

00:01:57.690 --> 00:02:00.000
few slides in a little bit of discussion is really about, is

00:02:00.000 --> 00:02:03.010
understanding what that character is. You'll also notice from the title here

00:02:03.010 --> 00:02:04.640
that I have decision making reinforcement

00:02:04.640 --> 00:02:07.580
learning, and that's because reinforcement learning is

00:02:07.580 --> 00:02:10.590
one mechanism for doing decision making. And again, I'll define

00:02:10.590 --> 00:02:13.050
that in just a second. Okay, so you with me, Michael?

00:02:13.050 --> 00:02:15.460
&gt;&gt; I think so. So should y be circled?

00:02:15.460 --> 00:02:17.400
because in some sense, you, you underlined the things we

00:02:17.400 --> 00:02:19.090
were given and you circled the things we needed to

00:02:19.090 --> 00:02:21.330
find, so y is something that we're going to find, right?

00:02:21.330 --> 00:02:22.330
&gt;&gt; Yeah, I suppose that I like that.

00:02:22.330 --> 00:02:23.650
&gt;&gt; All right. Interesting.

00:02:23.650 --> 00:02:25.625
&gt;&gt; Now it's a theta.

00:02:25.625 --> 00:02:30.810
&gt;&gt; [LAUGH] It's a Y trapped inside of a theta and it's yelling, Y?

00:02:30.810 --> 00:02:32.940
&gt;&gt; [LAUGH] I like that. I'm a Y

00:02:32.940 --> 00:02:36.720
trapped in a theta. Hm, I need to write a book

00:02:36.720 --> 00:02:40.290
about that. Okay, good. That's a good point Michael. So before

00:02:40.290 --> 00:02:42.840
we were learning, effectively trying to learn one thing and here

00:02:42.840 --> 00:02:46.060
we're still learning one thing. Because it's going to produce another thing

00:02:46.060 --> 00:02:49.590
for the deterministically, usually. But it's worth pointing out that we

00:02:49.590 --> 00:02:52.160
are going to be figuring how to produce both of these things

00:02:52.160 --> 00:02:54.680
as opposed to be given those things. Good job. OK. Are

00:02:54.680 --> 00:02:56.760
you ready to move forward,l Michael, with an example and a quiz?

00:02:56.760 --> 00:02:57.338
&gt;&gt; Awesome.

00:02:57.338 --> 00:02:58.020
&gt;&gt; Excellent.

