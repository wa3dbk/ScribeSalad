WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:06.000
I don't have any big questions left. Are there any smaller questions you'd like to address?

00:00:06.000 --> 00:00:10.000
All right, Peter. Since you phrase it so eloquently.

00:00:10.000 --> 00:00:17.000
Some students have wondered or they've heard acronyms like "LL," "LR," or "LALR"

00:00:17.000 --> 00:00:20.000
bandied about--perhaps on the forums or mentioned by other students

00:00:20.000 --> 00:00:25.000
who have taken similar topics, and you might wonder, what do those mean?

00:00:25.000 --> 00:00:31.000
Those acronyms are all subsets of context-free languages or context-free grammars.

00:00:31.000 --> 00:00:37.000
They're grammars that are written in a special way to make them easy to parse.

00:00:37.000 --> 00:00:41.000
The parsing approach that I've taught you in this class where we build up the chart

00:00:41.000 --> 00:00:45.000
of parsing states and memoized things can handle any of them.

00:00:45.000 --> 00:00:48.000
It handles LL. It handles LR. It handles LALR.

00:00:48.000 --> 00:00:51.000
And, in fact, it handles context-free grammars.

00:00:51.000 --> 00:00:55.000
I think a lot of those previous approaches--LALR in particular--

00:00:55.000 --> 00:00:58.000
are really historical accidents.

00:00:58.000 --> 00:01:01.000
They were restricted classes of grammars that engineers made back in a time

00:01:01.000 --> 00:01:04.000
when computers were significantly slower,

00:01:04.000 --> 00:01:07.000
and we had to squeeze every drop of blood from the turnip that we could.

00:01:07.000 --> 00:01:12.000
We had to squeeze every ounce of performance that we could out of the hardware available.

00:01:12.000 --> 00:01:18.000
We said, oh, it's better if I, a human, spend a lot of time refactoring my grammer to make it easy

00:01:18.000 --> 00:01:20.000
for the parsing algorithm.

00:01:20.000 --> 00:01:24.000
These days I think your time, the human's time, is more important than the computers.

00:01:24.000 --> 00:01:28.000
I want to be able to write down the grammar naturally as a context-free grammar

00:01:28.000 --> 00:01:30.000
and have it parsed.

00:01:30.000 --> 00:01:33.000
In this course, we don't focus on LL, LR, LALR.

00:01:33.000 --> 00:01:40.000
Those are really historical accidents for performance that aren't relevant anymore in my opinion.

00:01:40.000 --> 00:01:43.000
We handle LL. We handle LR. We handle LALR.

00:01:43.000 --> 00:01:47.000
Everything works well in this class.

00:01:47.000 --> 00:01:53.000
A related question is in this class we covered a parsing approach where we kept

00:01:53.000 --> 00:01:56.000
a chart of parsing states and we memoized things.

00:01:56.000 --> 00:02:01.000
Some students have wondered, Wes, is that secretly dynamic programming?

00:02:01.000 --> 00:02:05.000
Now, some of you may not have heard the term dynamic programming before,

00:02:05.000 --> 00:02:08.000
and it sounds really exciting, like something out of a television commercial.

00:02:08.000 --> 00:02:11.000
I'm dynamic and I'm programming. How does that work out?

00:02:11.000 --> 00:02:16.000
Actually, it's an old term where program means more like table or chart.

00:02:16.000 --> 00:02:22.000
The way to think of this is imagine you're going to a parade or perhaps a symphony

00:02:22.000 --> 00:02:25.000
or a concert or whatnot, and there is a program written that says at 1 p.m. we'll do this

00:02:25.000 --> 00:02:29.000
and at 2 p.m. we'll play this other song and at 3 p.m. we'll do that.

00:02:29.000 --> 00:02:33.000
That's the program for a concert or the program for a schedule of events.

00:02:33.000 --> 00:02:36.000
That's the sort of program that we're talking about in dynamic programming.

00:02:36.000 --> 00:02:38.000
It just means a chart.

00:02:38.000 --> 00:02:40.000
Dynamic there means that it'd updated over time.

00:02:40.000 --> 00:02:44.000
Dynamic programming is then a special keyword used in computer science

00:02:44.000 --> 00:02:49.000
to mean I'm going to solve a problem by taking a big chart

00:02:49.000 --> 00:02:53.000
and writing down answers in it and adding to this chart over time.

00:02:53.000 --> 00:02:57.000
Dynamic programming is really useful when a problem exhibits what's known as

00:02:57.000 --> 00:02:59.000
the optimal substructure property.

00:02:59.000 --> 00:03:05.000
That is, when I can deal with one problem by solving smaller problems and then build

00:03:05.000 --> 00:03:07.000
the solution back up.

00:03:07.000 --> 00:03:11.000
Interesting examples of this in the real world are things like spell checkers,

00:03:11.000 --> 00:03:16.000
protein sequencers, or even trying to figure out the correct or in which to do matrix multiplication.

00:03:16.000 --> 00:03:19.000
It comes up a lot surprisingly.

00:03:19.000 --> 00:03:24.000
It turns out, yes, although I've been avoiding using the words in class,

00:03:24.000 --> 00:03:29.000
our memoization approach to parsing really is an instance of dynamic programming.

00:03:29.000 --> 00:03:35.000
You've learned your first steps about dynamic programming without it even being a big deal.

00:03:35.000 --> 00:03:39.000
Then finally in this grab bag, some students have wondered

00:03:39.000 --> 00:03:44.000
can we compile an interpreted language or interpret a compiled language?

00:03:44.000 --> 00:03:46.000
What do those even mean?

00:03:46.000 --> 00:03:49.000
Well, we've talked quite a bit about interpretation.

00:03:49.000 --> 00:03:53.000
We interpret HTML webpages and JavaScript on the fly.

00:03:53.000 --> 00:03:56.000
When we're running our web browser, we read in the input, think about what it means

00:03:56.000 --> 00:03:59.000
and spit out the answer immediately.

00:03:59.000 --> 00:04:02.000
In practice, it's possible to do some of that in advance--

00:04:02.000 --> 00:04:08.000
to take your source code and build an executable program--some binary code on disk.

00:04:08.000 --> 00:04:11.000
That you can ship to someone else, and when they run it later,

00:04:11.000 --> 00:04:15.000
it will produce the same output but run really quickly.

00:04:15.000 --> 00:04:20.000
In some sense it's like thinking very hard about the problem, optimizing it once and for all,

00:04:20.000 --> 00:04:23.000
and then shipping it to all of your friends.

00:04:23.000 --> 00:04:26.000
Compiling is a lot like packing really well for a trip.

00:04:26.000 --> 00:04:30.000
You could just make a bunch of trips back and forth, carrying all your clothes,

00:04:30.000 --> 00:04:35.000
or you could spend a lot of time in your house beforehand packing a suitcase very carefully,

00:04:35.000 --> 00:04:38.000
cramming it in there, and then just make one trip.

00:04:38.000 --> 00:04:41.000
The question or the tradeoff is, well, how far are you going?

00:04:41.000 --> 00:04:46.000
If you're going across the street, it might actually be faster just to grab things

00:04:46.000 --> 00:04:49.000
and run back and forth across the street if the program is quick or whatnot.

00:04:49.000 --> 00:04:53.000
Conversely if you're going across the country, you probably want to pack things very carefully

00:04:53.000 --> 00:04:56.000
first because the round-trip cost is expensive.

00:04:56.000 --> 00:04:59.000
Compiled languages are very nice when you know

00:04:59.000 --> 00:05:03.000
that the program is going to take a while to run that you're going to ship it to other people.

00:05:03.000 --> 00:05:06.000
Interpreted languages like Python or JavaScript are really nice

00:05:06.000 --> 00:05:10.000
when you know it may only be run one or by one person looking at the answer

00:05:10.000 --> 00:05:14.000
and that rapid prototyping or rapid development is more important.

00:05:14.000 --> 00:05:17.000
You want to be able to try things out and have a lot of flexibility.

00:05:17.000 --> 00:05:21.000
Can you interpret a compiled language or compile and interpreted language?

00:05:21.000 --> 00:05:25.000
In fact, the distinction is really blurring all the time.

00:05:25.000 --> 00:05:28.000
Even Python, one of the languages we use in this course,

00:05:28.000 --> 00:05:30.000
nominally gets interpreted.

00:05:30.000 --> 00:05:33.000
You run things through a Python interpreter. It gives you the answer.

00:05:33.000 --> 00:05:36.000
But actually if you've tried running Python on your home computer, you may have noticed

00:05:36.000 --> 00:05:39.000
that it often creates a bunch of .pyc files.

00:05:39.000 --> 00:05:42.000
That's compiled Python byte code.

00:05:42.000 --> 00:05:47.000
Your Python interpreter will take a look at your human-readable English text source code,

00:05:47.000 --> 00:05:52.000
and if it has changed since last time, compiled it down into Python byte code,

00:05:52.000 --> 00:05:55.000
and then the byte code can be run quickly later.

00:05:55.000 --> 00:05:57.000
It's a lot like packing things into a suitcase.

00:05:57.000 --> 00:05:59.000
Java actually uses the same approach.

00:05:59.000 --> 00:06:03.000
Java source programs are compiled down into Java byte code,

00:06:03.000 --> 00:06:07.000
which is then interpreted by a Java virtual machine later on.

00:06:07.000 --> 00:06:12.000
Even a language like C--a classical compiled language--we compile it down

00:06:12.000 --> 00:06:16.000
into some machine code like X86 assembly or X86 machine code,

00:06:16.000 --> 00:06:20.000
but that's just interpreted by your processor's CPU later on.

00:06:20.000 --> 00:06:24.000
In some sense at the end of the day everything is interpreted.

00:06:24.000 --> 00:06:28.000
The question is just how much of this compilation we want to do beforehand.

00:06:28.000 --> 00:06:32.000
Again, optimization techniques like just-in-time translation or just-in-time compilation--

00:06:32.000 --> 00:06:34.000
you may have heard this phrase JIT--

00:06:34.000 --> 00:06:38.000
to blur the lines between these as time goes by.

00:06:38.000 --> 00:06:44.000
All of the techniques that I'm teaching you--lexing, parsing, looking for errors,

00:06:44.000 --> 00:06:47.000
optimization, interpreting, environments--

00:06:47.000 --> 00:06:52.000
all of these are used in both compiled languages and interpreted languages.

00:06:52.000 --> 00:06:55.000
We'll get to all of those throughout this course,

00:06:55.000 --> 09:59:59.000
and then you'll be well-set to understand either of those two paradigms.

