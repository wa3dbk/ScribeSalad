WEBVTT
Kind: captions
Language: en

00:00:00.370 --> 00:00:05.810
So we mentioned that you could use
Lucas and Kanade between frames and,

00:00:05.810 --> 00:00:11.000
and use the, the, the Shi-Tomasi way of,
of finding features small displacements.

00:00:11.000 --> 00:00:12.820
But what if there
are large displacements,

00:00:12.820 --> 00:00:17.790
what if things have moved a lot
because they're moving quickly?

00:00:17.790 --> 00:00:19.030
Well.

00:00:19.030 --> 00:00:21.450
One thing we do is we do know
that we can build a descriptor.

00:00:21.450 --> 00:00:22.650
Remember the sift descriptor.

00:00:22.650 --> 00:00:25.300
So that if you found a matching point

00:00:25.300 --> 00:00:27.730
I'd be able to say yeah I'm
pretty sure that's a match.

00:00:27.730 --> 00:00:31.130
But the question was how would
I decide where to find it?

00:00:31.130 --> 00:00:34.700
So when we were doing the ransack
method of finding those panoramas

00:00:34.700 --> 00:00:38.540
you remember we essentially com,
compared all of these with all of those.

00:00:38.540 --> 00:00:41.290
Found the putative matches,
selected a bunch, and

00:00:41.290 --> 00:00:44.240
then tried to find something
that gave us a consistent model.

00:00:44.240 --> 00:00:47.930
So you're doing a lot of work
in order to try to globally find

00:00:47.930 --> 00:00:50.330
all of these kinds of things.

00:00:50.330 --> 00:00:52.320
For tracking, what we want is, well,

00:00:52.320 --> 00:00:54.060
first of all we typically
want real time methods.

00:00:54.060 --> 00:00:57.050
Because we want this thing to
operate as things are moving along.

00:00:57.050 --> 00:00:58.720
And in particular, we,

00:00:58.720 --> 00:01:02.090
we want this notion of
a coherent tract result, right?

00:01:02.090 --> 00:01:04.019
So we're not going to try to
match everything in one frame

00:01:04.019 --> 00:01:04.840
to everything in another.

00:01:04.840 --> 00:01:06.420
And then do it again,
and then do it again.

00:01:06.420 --> 00:01:07.710
And do it again, and do it.

00:01:07.710 --> 00:01:09.070
See?
So, you just saw my head

00:01:09.070 --> 00:01:10.660
rotating around.

00:01:10.660 --> 00:01:12.070
I hope you're paying attention.

00:01:12.070 --> 00:01:16.960
So they idea is that you have
this smooth, coherent trajectory.

00:01:16.960 --> 00:01:19.340
And that's what we want to do for
tracking.

00:01:19.340 --> 00:01:20.930
And in order to do that.

00:01:20.930 --> 00:01:22.960
We have to worry about the dynamics.

00:01:22.960 --> 00:01:26.490
That is, how are things moving,
how are they changing?

00:01:26.490 --> 00:01:31.580
So, when we do tracking
with dynamics the key idea

00:01:31.580 --> 00:01:34.440
is we've got some sort
of model of the motion.

00:01:34.440 --> 00:01:38.830
Maybe we're updating that model, like
the velocity and acceleration, but using

00:01:38.830 --> 00:01:43.920
that model we want to predict where the
objects will be in the next frame and

00:01:43.920 --> 00:01:48.120
then we're going to look
around that area, okay?

00:01:48.120 --> 00:01:52.910
And that prediction will allow us to
restrict where we're doing the search,

00:01:53.930 --> 00:01:57.930
and the other thing is if we have a
noisy detection, that is our ability to

00:01:57.930 --> 00:02:02.760
knowing where this thing is not perfect,
we should get a better overall estimate,

00:02:02.760 --> 00:02:06.310
because we're combining a prediction
with the measurement, so

00:02:06.310 --> 00:02:08.550
that's the idea of
tracking with dynamics.

