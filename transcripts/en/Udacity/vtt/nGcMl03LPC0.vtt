WEBVTT
Kind: captions
Language: en

00:00:00.280 --> 00:00:02.750
Alright. So we talked through how it works when you've got

00:00:04.840 --> 00:00:07.689
you're trying to fit your data to a constant function,

00:00:07.689 --> 00:00:10.380
to a zero order polynomial. But let's, let's at least talk

00:00:10.380 --> 00:00:12.300
through how you do this in the more general case. This

00:00:12.300 --> 00:00:14.590
is, this is what I've been doing to, to fit various

00:00:14.590 --> 00:00:18.650
curves to the data at least implicitly. So, what we're

00:00:18.650 --> 00:00:20.720
really trying to do is we've got a set of data,

00:00:20.720 --> 00:00:25.320
x and y. Set n, n examples of x's and their

00:00:25.320 --> 00:00:30.110
corresponding y's. And what we're trying to find is these coefficients,

00:00:30.110 --> 00:00:35.870
C0, C1, C2, C3. Let's say if we're trying to do cubic regression

00:00:35.870 --> 00:00:40.720
where C0 gets added to C1 times x, which gets added to C2 times

00:00:40.720 --> 00:00:45.310
x squared. Which gets added to C3 times X cubed and we're trying to get

00:00:45.310 --> 00:00:48.420
that to look a lot like y. Now we're not

00:00:48.420 --> 00:00:50.730
going to get to exactly equal y but let's pretend for a

00:00:50.730 --> 00:00:53.210
moment that we could. We have a bunch of these

00:00:53.210 --> 00:00:55.630
examples and we want it to work for all of them.

00:00:55.630 --> 00:00:58.930
So we can arrange all of the, all these

00:00:58.930 --> 00:01:02.340
constraints, all these equations into matrix form. If you're familiar

00:01:02.340 --> 00:01:04.709
with linear algebra. So the way that we can

00:01:04.709 --> 00:01:08.410
write this is here are the, here are the coefficients

00:01:08.410 --> 00:01:11.220
that we're looking for, the C's, and here are

00:01:11.220 --> 00:01:13.210
what we're going to multiply them by. We're going to take

00:01:13.210 --> 00:01:17.360
the X one and look at the zeroth power,

00:01:17.360 --> 00:01:21.640
the second power, the third power. And that equation I'll

00:01:21.640 --> 00:01:24.370
use my hands cause that's I always, I always

00:01:24.370 --> 00:01:26.380
need to use my hands when I do matrix

00:01:26.380 --> 00:01:29.990
multiplication. So you're going to across here and down there

00:01:29.990 --> 00:01:33.220
to multiply these and add. And that needs to correspond

00:01:33.220 --> 00:01:37.730
to y1. And same thing this now the second

00:01:37.730 --> 00:01:41.790
row. Multiplied by these coefficients. Need to give us our

00:01:41.790 --> 00:01:44.530
y2 and so forth. Alright. So if we arrange

00:01:44.530 --> 00:01:46.730
all these x values into a matrix, and we'll call

00:01:46.730 --> 00:01:54.350
it, you know, x. And then we have these other guys. And we'll call this w, like

00:01:54.350 --> 00:01:58.450
the coefficents. Obviously w stands for coefficent. And we

00:01:58.450 --> 00:02:01.520
want that to sort of equal This vector of

00:02:01.520 --> 00:02:04.020
y's. And we basically just need to solve

00:02:04.020 --> 00:02:07.190
this equation for the w's. Now, we can't exactly

00:02:07.190 --> 00:02:09.570
solve it because it's not going to exactly equal, but

00:02:09.570 --> 00:02:11.820
we can solve it in a least squares sense.

00:02:11.820 --> 00:02:14.410
So let me just step through the steps for doing that.

00:02:14.410 --> 00:02:17.470
Alright, so let's, so here's how we're going to solve for w.

00:02:17.470 --> 00:02:20.500
So what we're going to do is premultiply by the transpose of

00:02:20.500 --> 00:02:24.500
x. Both sides. I mean really what we wanted to do at

00:02:24.500 --> 00:02:26.270
first is if we are solving for Y, we need to

00:02:26.270 --> 00:02:28.370
multiply by the inverse of X, but this isn't really going

00:02:28.370 --> 00:02:31.470
to be necessarily well behaved. But if we pre mulitplied by

00:02:31.470 --> 00:02:36.170
the X transpose then this thing is going to have a nice inverse.

00:02:37.290 --> 00:02:39.970
So now we can pre multiply by that inverse.

00:02:39.970 --> 00:02:42.300
All right. Now, conveniently because this has a nice

00:02:42.300 --> 00:02:46.470
inverse, the inverses cancel each other. [NOISE] We get

00:02:46.470 --> 00:02:49.080
that the weights we're looking for can be derived by

00:02:49.080 --> 00:02:53.670
taking the x matrix times its own transpose, inverting

00:02:53.670 --> 00:02:56.580
that, multiplying by x transpose and then multiplying it

00:02:56.580 --> 00:02:58.400
by the y. And that gives us exactly the

00:02:58.400 --> 00:03:03.480
coefficients that we need To have done our polynomial regression.

00:03:03.480 --> 00:03:07.170
And it just, it just so happens that we have some nice properties in terms

00:03:07.170 --> 00:03:11.330
of these x transpose x. Not only is it invertible, but it does the right

00:03:11.330 --> 00:03:15.660
thing in terms of minimizing the least squares. It does it as a projection. Now,

00:03:15.660 --> 00:03:17.770
we're not going to go through the process by

00:03:17.770 --> 00:03:19.320
by which we argue that this is true.

00:03:19.320 --> 00:03:21.540
&gt;&gt; Does it have something to do with calculus?

00:03:21.540 --> 00:03:25.630
&gt;&gt; It most likely has something to do with calculus. And we'll get

00:03:25.630 --> 00:03:28.490
back to calculus later. But in this particular case we can, we're just

00:03:28.490 --> 00:03:32.670
using projections and linear algebra. And most importantly the, the whole

00:03:32.670 --> 00:03:36.670
process is just we take the, the data we arrange it into

00:03:36.670 --> 00:03:39.190
this matrix with whatever sort of powers that we care about.

00:03:39.190 --> 00:03:42.550
And then we just compute this quantity and we're good to go.

00:03:42.550 --> 00:03:43.000
&gt;&gt; Okay.

