WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:03.610
Well having only 1 thread issuing memory transactions certainly limits

00:00:03.610 --> 00:00:06.512
the number of bytes delivered and that's our total achieved bandwidth.

00:00:06.512 --> 00:00:12.640
Version 2 with a single thread per a row still will only have a single thread block running on

00:00:12.641 --> 00:00:15.512
a single SM issuing transactions, and again

00:00:15.512 --> 00:00:18.126
this is not going to be enough to fill this big fat pipe.

00:00:18.126 --> 00:00:21.656
Version 3 had plenty of parallelism and plenty of transactions and flights.

00:00:21.656 --> 00:00:27.778
The problem there was the uncoalesced right ack operations limited our useful bytes delivered.

00:00:27.778 --> 00:00:31.755
And our current version of the code, which uses shared memory to achieve

00:00:31.755 --> 00:00:35.070
better coalescing among the threads and get higher numbers

00:00:35.070 --> 00:00:37.657
of useful bytes delivered for every transaction,

00:00:37.657 --> 00:00:43.164
still uses 1 thread per element, and therefore is achieving plenty of transactions to fill the pipeline.

00:00:43.164 --> 00:00:47.753
So where does that leave us? We're still achieving lower bandwidth than we would have expected.

00:00:47.753 --> 00:00:51.757
And we know that we're delivering plenty of useful bytes per transaction.

00:00:51.757 --> 00:00:55.260
So, the problem really must be the average latency.

00:00:55.260 --> 00:00:58.728
There must be something that's keeping the time between transactions

00:00:58.728 --> 00:01:01.993
higher than it should be to fill this pipeline.

