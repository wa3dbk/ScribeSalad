WEBVTT
Kind: captions
Language: en

00:00:00.410 --> 00:00:03.310
But when we date discriminative
classification we said, you know nearest

00:00:03.310 --> 00:00:06.720
neighbor has some power, but, it can be
kind of expensive in terms of storage

00:00:06.720 --> 00:00:09.200
and access, and maybe there
are better ways we can do things.

00:00:09.200 --> 00:00:12.020
And in fact,
we talked about training classifiers, so

00:00:12.020 --> 00:00:15.150
we talked about boosting or SVM.

00:00:15.150 --> 00:00:17.830
So, we can do that for
this example, too, right?

00:00:17.830 --> 00:00:20.870
I have a whole bunch
of images of violins.

00:00:20.870 --> 00:00:23.440
I've got a whole bunch
of images of people.

00:00:23.440 --> 00:00:25.680
I've got a whole bunch
of images of planes.

00:00:25.680 --> 00:00:29.700
I take all those images together,
I find all the visual words.

00:00:29.700 --> 00:00:31.250
All right, that gives me a vocabulary.

00:00:31.250 --> 00:00:34.550
I can build a histogram for
each of the objects.

00:00:34.550 --> 00:00:37.480
And you know, so I've brought
a bunch of training data, so

00:00:37.480 --> 00:00:39.380
I got a bunch of histograms for
planes, I've got histograms for

00:00:39.380 --> 00:00:41.060
cars, histograms for faces.

00:00:41.060 --> 00:00:42.080
And what do I do?

00:00:42.080 --> 00:00:45.310
I just train a support vector machine
to make the decision, you know,

00:00:45.310 --> 00:00:48.120
is this a, a person,
a plane, a car, et cetera.

00:00:48.120 --> 00:00:50.490
And in fact that's
exactly what was done.

00:00:50.490 --> 00:00:52.370
This work comes from 04.

00:00:52.370 --> 00:00:55.430
There was a database, still is a
database referred to as the Caltech 101.

00:00:55.430 --> 00:01:00.190
It was one of the original
datasets of enough images of

00:01:00.190 --> 00:01:04.709
enough object types to start to explore
this notion of database access.

00:01:04.709 --> 00:01:08.240
And, and what they were doing was
they trained exactly a linear SVM,

00:01:08.240 --> 00:01:11.770
we talked about those before,
using a bag of words on vectors and

00:01:11.770 --> 00:01:13.580
there were a couple
of different classes.

00:01:13.580 --> 00:01:16.580
Faces, airplanes, cars,
motorbikes, et cetera.

00:01:16.580 --> 00:01:21.000
And what's being reported here is that
for each of the actual faces, you know,

00:01:21.000 --> 00:01:24.420
out of, you know,
the average percentage of time.

00:01:24.420 --> 00:01:29.390
That it was the best rank was 94, 96,
90 so you can see that it's pretty good.

00:01:29.390 --> 00:01:33.530
And then the other thing that
they report is the mean rank.

00:01:33.530 --> 00:01:37.210
So when I try to find, you know,
whether or not, you know,

00:01:37.210 --> 00:01:40.390
when I show a plane and I say well,
do I think it's a plane,

00:01:40.390 --> 00:01:42.890
do I think its a face,
do I think its a motorbike, et cetera?

00:01:42.890 --> 00:01:46.470
You know, how what is the average
ranking of the correct answer?

00:01:46.470 --> 00:01:48.470
And you can see the value
is 1.0 something.

00:01:48.470 --> 00:01:52.030
Meaning that it almost
always got the answer right.

00:01:52.030 --> 00:01:55.990
But it was just an example of this
bag of words approach that says,

00:01:55.990 --> 00:02:00.620
I don't know anything about parts,
I don't know anything about structure.

00:02:00.620 --> 00:02:04.210
What I know about is images and
I take locations and

00:02:04.210 --> 00:02:07.900
images and I find interesting points,
I build some description.

00:02:07.900 --> 00:02:11.350
Give me a word-like collection
of those descriptors.

00:02:11.350 --> 00:02:15.140
And then for any new image, try to
find the descriptors that are present.

00:02:15.140 --> 00:02:17.140
And that's what's referred
to as bag of words.

