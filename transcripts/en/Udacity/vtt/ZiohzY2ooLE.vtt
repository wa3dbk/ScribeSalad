WEBVTT
Kind: captions
Language: en

00:00:00.510 --> 00:00:04.900
You're now ready to think about really
big computations, computations where,

00:00:04.900 --> 00:00:08.980
for instance, the problem can't fit
in the memory of a single computer.

00:00:08.980 --> 00:00:11.960
Or calculations that need so
many operations, it

00:00:11.960 --> 00:00:14.690
would take hundreds of years to finish
them using only a single computer.

00:00:14.690 --> 00:00:18.860
Now when the computation is
really that big, you might ask,

00:00:18.860 --> 00:00:21.589
can I harness the collective
power of many computers?

00:00:22.760 --> 00:00:24.660
But to design an efficient algorithm for

00:00:24.660 --> 00:00:27.840
such a machine, you need
a suitable abstract machine model.

00:00:27.840 --> 00:00:31.070
And that's the goal for this lesson,
for you to develop just such a model.

00:00:32.159 --> 00:00:34.930
This particular model and
its variants go by many names,

00:00:34.930 --> 00:00:38.190
which you are bound to encounter as
you read the literature on your own.

00:00:38.190 --> 00:00:41.840
These names include the Network Model,
the Distributed Memory Model,

00:00:41.840 --> 00:00:45.850
the Message-Passing Model, the
Communicating Sequential Processes Model

00:00:45.850 --> 00:00:48.450
and probably a zillion
others that I've forgotten.

00:00:48.450 --> 00:00:50.960
Now personally,
I like message-passing and for

00:00:50.960 --> 00:00:52.770
reasons you'll soon see, alpha beta.

00:00:54.030 --> 00:00:55.280
Now if any of that seems confusing,

00:00:55.280 --> 00:00:58.250
don't worry the basic
abstraction is really simple.

00:00:58.250 --> 00:01:02.050
You have a bunch of computers
collectively carrying out a computation.

00:01:02.050 --> 00:01:02.890
To coordinate,

00:01:02.890 --> 00:01:07.400
they communicate with one another by
sending mass messages back and forth.

00:01:07.400 --> 00:01:11.830
This message-passing style stands
in stark contrast to shared memory.

00:01:11.830 --> 00:01:15.660
There, processes or more likely threads,
communicate by reading and

00:01:15.660 --> 00:01:17.790
writing shared variables.

00:01:17.790 --> 00:01:21.440
Now before you start, I think it's
really important to think big.

00:01:21.440 --> 00:01:24.550
That's because distributed memory
computations are all about solving

00:01:24.550 --> 00:01:26.440
problems that are really, really huge.

00:01:27.530 --> 00:01:28.740
How huge, you ask?

00:01:28.740 --> 00:01:31.460
Well, let's start with a quick
warm up exercise to get you

00:01:31.460 --> 00:01:34.080
thinking about computations
at the right scale.

