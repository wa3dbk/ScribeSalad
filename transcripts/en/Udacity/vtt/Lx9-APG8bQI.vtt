WEBVTT
Kind: captions
Language: en

00:00:00.120 --> 00:00:03.260
So the question that
we have to address is

00:00:03.260 --> 00:00:06.560
if we've got these sort of thousands
of features per image, and

00:00:06.560 --> 00:00:09.460
maybe millions or hundreds of
millions of images or patches.

00:00:09.460 --> 00:00:12.820
You know, what's an efficient
way to search to figure out

00:00:12.820 --> 00:00:15.880
which image had about
the same sets of patches or

00:00:15.880 --> 00:00:20.030
at least has a high overlap in the set
of patches that I find in a new image.

00:00:20.030 --> 00:00:23.890
And what we do is we take a little bit
of inspiration from other systems that

00:00:23.890 --> 00:00:27.350
have lots of little instances in them,
namely things like words and

00:00:27.350 --> 00:00:28.790
indices, right.

00:00:28.790 --> 00:00:33.780
So if I've got a book, it would be
really hard to find all the examples of

00:00:33.780 --> 00:00:38.240
where it says Karl Marx in that
book by flipping through that book.

00:00:38.240 --> 00:00:40.850
So what do we do instead,
we build an index.

00:00:40.850 --> 00:00:43.050
Right?
There's an index in the back,

00:00:43.050 --> 00:00:47.770
it's an efficient way to find all the
pages that contain a particular word.

00:00:47.770 --> 00:00:48.580
Okay?

00:00:48.580 --> 00:00:53.500
So what we want to do is we want to
find all the images from a known

00:00:53.500 --> 00:00:56.850
database that have a particular
feature that we find.

00:00:56.850 --> 00:00:59.759
So now what's going to happen is I'm
going to find a bunch of features

00:01:00.770 --> 00:01:03.240
that are in a, new image.

00:01:03.240 --> 00:01:06.740
I'm going to look up the different
images that have those features and

00:01:06.740 --> 00:01:10.810
maybe if I find an image that has a lot
of the same features as my new image,

00:01:10.810 --> 00:01:13.880
then I say, aha,
maybe it's the same kind of thing.

00:01:13.880 --> 00:01:17.380
And this comes to the notion
of what we call visual words.

00:01:17.380 --> 00:01:19.180
Okay?
So, the featured descriptors

00:01:19.180 --> 00:01:21.780
we sometimes refer to
as visual words and

00:01:21.780 --> 00:01:23.910
we're going to get to
code words in a minute.

00:01:23.910 --> 00:01:26.990
But the idea is that, and
I think really this notion of words

00:01:26.990 --> 00:01:30.420
comes from this whole
analogy with text processing.

00:01:30.420 --> 00:01:31.555
Right?
So we've got words

00:01:31.555 --> 00:01:35.690
are the local features and
documents are the entire image.

