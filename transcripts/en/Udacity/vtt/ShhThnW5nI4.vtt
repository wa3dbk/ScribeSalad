WEBVTT
Kind: captions
Language: en

00:00:00.025 --> 00:00:04.995
Finally we need to make some assumptions in order to use one way Anova. The

00:00:04.995 --> 00:00:09.421
first in normality. All the populations from which the samples are from are

00:00:09.421 --> 00:00:14.837
normally distributed. Another is homogeneity of variance. The data come from

00:00:14.837 --> 00:00:19.325
populations that have equal amounts of variability and finally independence of

00:00:19.325 --> 00:00:24.985
observations. The results found from one sample won't affect the others.

00:00:24.985 --> 00:00:31.175
However, we can violate these assumptions under certain conditions. We can

00:00:31.175 --> 00:00:35.872
violate the normality assumption if the sample size is large. We can violate

00:00:35.872 --> 00:00:41.185
the homogeneity of variance assumption. If all the samples have nearly equal

00:00:41.185 --> 00:00:47.302
sample sizes, and the ratio of any two variances does not exceed 4. We have to

00:00:47.302 --> 00:00:51.019
maintain independence of observations but we can use randon assignment to

00:00:51.019 --> 00:00:56.154
conditions to help up meet this assumption. Let's do a quick summary of ANOVA

00:00:56.154 --> 00:01:00.748
to wrap up this lesson. I'm not actually going to rap this time though, we're

00:01:00.748 --> 00:01:05.935
just going to wrap up the lesson. If we have three or more samples and we want

00:01:05.935 --> 00:01:10.022
to know if any two of them are significantly different, we look at both the

00:01:10.022 --> 00:01:16.637
between group variability, and the within group variability. Between group

00:01:16.637 --> 00:01:21.181
variability is a measure of how spaced apart these sample means are from each

00:01:21.181 --> 00:01:27.636
other. And we do that by finding the grand mean and each squared deviation from

00:01:27.636 --> 00:01:33.721
the grand mean for each sample mean. We multiply each sample size by the

00:01:33.721 --> 00:01:40.919
squared deviation of each sample mean from the grand mean. Then we add them up.

00:01:40.919 --> 00:01:46.295
Then we have to look at the within group variability which is essentially the

00:01:46.295 --> 00:01:54.030
square deviation of each value in each sample from the respective sample mean.

00:01:54.030 --> 00:01:59.007
So we add up all sums of squares from their respective sample mean and then we

00:01:59.007 --> 00:02:03.984
have to find the average sum of squares for each by dividing by the degrees of

00:02:03.984 --> 00:02:11.599
freedom. In the case of the between groups, this is the number of samples minus

00:02:11.599 --> 00:02:16.527
1, and for within groups this is the total number of values minus the number of

00:02:16.527 --> 00:02:23.860
groups. This is the same as adding the degrees of freedom for each group. There

00:02:23.860 --> 00:02:28.219
we have our F statistic. And if it falls out here in the critical region, past

00:02:28.219 --> 00:02:33.343
the F critical value, we'll reject the null. After making a statistical

00:02:33.343 --> 00:02:37.745
decision, we can use the multiple comparison test, one of which is Tukey's

00:02:37.745 --> 00:02:43.824
Honestly Significant Difference. Which is a value that if any two sample means

00:02:43.824 --> 00:02:47.118
have a difference greater than that value, they're considered honestly

00:02:47.118 --> 00:02:51.974
significantly different. You've also learned how to determine what proportion

00:02:51.974 --> 00:02:56.169
of the difference between mean is due the independent variable. You've also

00:02:56.169 --> 00:02:58.313
learned how to determine what proportion of the difference between means is due

00:02:58.313 --> 00:03:02.209
the independent variable. That's theta squared and that's a wrap.

