WEBVTT
Kind: captions
Language: en

00:00:00.240 --> 00:00:02.009
Now that we have the characterizations and

00:00:02.009 --> 00:00:05.040
the knowledge representations the four concept's worked out,

00:00:05.040 --> 00:00:09.710
let us see how the AI agent might actually use them. So let's look at the bowl.

00:00:09.710 --> 00:00:13.040
Here was the knowledge representation of the characterization of the bowl.

00:00:13.040 --> 00:00:18.040
The AI agent will abstract some knowledge from this particular example.

00:00:18.040 --> 00:00:21.220
Here is its abstraction. Two things have happened here.

00:00:21.220 --> 00:00:27.050
First, it is abstracting only those things, that are in fact causally related.

00:00:27.050 --> 00:00:31.180
Simple features that have no causal relationship with other things, are not

00:00:31.180 --> 00:00:35.240
important and they can be dropped. So we can add one other element of a notion

00:00:35.240 --> 00:00:39.290
of an explanation. The explanation is a causal explanation. The AI agent is

00:00:39.290 --> 00:00:44.190
trying to build a causal explanation that will connect the instance, the object,

00:00:44.190 --> 00:00:49.780
into the cup. Second, the AI agent creates an abstraction of this

00:00:49.780 --> 00:00:55.430
characterization of the bowl. And so in the bowl, it replaces it with an object.

00:00:55.430 --> 00:01:00.260
So here the bowl carries liquids, because it is concave, and it is abstracted to

00:01:00.260 --> 00:01:04.860
the object carries liquid because it is concave. This is the abstraction that is

00:01:04.860 --> 00:01:07.970
going to play an important role in constructing the causal explanation.

