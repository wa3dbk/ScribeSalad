WEBVTT
Kind: captions
Language: en

00:00:00.160 --> 00:00:04.310
We will start with the model building workflow diagrams you are now

00:00:04.310 --> 00:00:06.100
hopefully becoming familiar with.

00:00:07.110 --> 00:00:11.880
These diagrams will guide us to through model building and validation process

00:00:11.880 --> 00:00:16.809
and help you follow the thought process needed to build robust models.

00:00:18.600 --> 00:00:23.950
At the time of writing this lesson, there has been widespread suspicion

00:00:23.950 --> 00:00:29.750
that Medicare is being severely harmed by some fraudulent charges.

00:00:29.750 --> 00:00:33.580
And that large portions of payouts are allegedly going to

00:00:33.580 --> 00:00:35.799
a very tiny portion of providers.

00:00:37.500 --> 00:00:41.450
Less than a month after the data set was released,

00:00:41.450 --> 00:00:44.610
people already found some interesting things in the data.

00:00:45.670 --> 00:00:51.750
For example, the New York Times in this article by Reed Abelson and Sarah Cohen

00:00:51.750 --> 00:00:58.120
published on April 9th, 2014, writes about how the data reveals a single

00:00:58.120 --> 00:01:03.880
ophthalmologist who was paid $21 million in the course of a single year.

00:01:03.880 --> 00:01:08.500
We have put a link to this article in the instructor's notes.

00:01:08.500 --> 00:01:14.500
To identify and reduce cases of fraud in Medicare, the government

00:01:14.500 --> 00:01:21.170
has released the data to anyone who wants to inspect and see what is in it.

00:01:21.170 --> 00:01:24.010
We could try to answer this call to action.

00:01:24.010 --> 00:01:28.760
Together, we can examine the raw data released by the US government in order to

00:01:28.760 --> 00:01:31.810
detect anomalous behavior.

00:01:31.810 --> 00:01:35.409
Along the way, we'll learn methods for building models.

00:01:37.510 --> 00:01:40.370
So now, we can ask the first question.

00:01:41.960 --> 00:01:47.950
How do we detect if there are anomalous charges in the Medicare data?

00:01:49.570 --> 00:01:54.030
That question immediately leads to the next question,

00:01:54.030 --> 00:01:57.430
how do we define anomalies in data?

00:01:58.460 --> 00:02:03.240
To give you an intuitive understanding, if you have all your data clustered

00:02:03.240 --> 00:02:10.090
together here in one region and you have some points far away like these

00:02:10.090 --> 00:02:16.060
red Xs, we can consider the red points here as outliers.

00:02:17.750 --> 00:02:23.900
Anomalies can also show up as peaks and bumps in distributions.

00:02:23.900 --> 00:02:24.940
In this case,

00:02:24.940 --> 00:02:30.400
we can have an original distribution with a little bump in the tail here.

00:02:30.400 --> 00:02:34.380
This bump might indicate some sort of anomaly in the data.

00:02:35.700 --> 00:02:39.270
Another way we define anomalies in the data is by

00:02:39.270 --> 00:02:41.770
looking at domain specific signatures.

00:02:43.030 --> 00:02:44.630
Imagine, for example,

00:02:44.630 --> 00:02:50.370
a sequence of events in logs indicating an intrusion in a data center.

00:02:51.460 --> 00:02:54.170
We're going to further investigate outliers in

00:02:54.170 --> 00:02:59.729
distributions by looking at simple non-parametrics statistical techniques.

00:03:01.160 --> 00:03:04.430
We're going to start looking at the Medicare data from the Centers for

00:03:04.430 --> 00:03:07.930
Medicare and Medicaid services website.

00:03:07.930 --> 00:03:11.550
The link is provided in the instructor's notes.

00:03:11.550 --> 00:03:15.650
If you click on the link, you will come to the page that looks like this.

00:03:15.650 --> 00:03:17.330
&gt;From the web site, look for

00:03:17.330 --> 00:03:22.090
the link that says Inpatient Charges for Fiscal Year 2012.

00:03:22.090 --> 00:03:27.330
Clicking on that link will take you to the page where you can download the data.

00:03:27.330 --> 00:03:31.200
You're welcome to use the entire data set, especially if you want to

00:03:31.200 --> 00:03:34.830
explore the data further than we do in the lesson here.

00:03:35.960 --> 00:03:39.810
However, to make things easier and faster, we have reduced

00:03:39.810 --> 00:03:44.940
the original data set and put the needed files in the instructor's notes.

00:03:44.940 --> 00:03:50.910
So look for files with Illinois and California in the instructor's notes,

00:03:50.910 --> 00:03:55.140
and that's the files we are going to use for the rest of this lesson.

00:03:55.140 --> 00:03:57.500
As in the previous lessons,

00:03:57.500 --> 00:04:02.480
we will be using the IPython Notebook to perform the analysis.

00:04:02.480 --> 00:04:06.820
Look in the instructor's notes if you have any further questions as to how to

00:04:06.820 --> 00:04:09.440
get started with the Notebook for this lesson.

00:04:10.580 --> 00:04:15.700
We now set up some of the libraries that we will need to use for this lesson.

00:04:17.110 --> 00:04:21.519
We're going to use seaborn and matplotlib for plotting.

00:04:21.519 --> 00:04:25.241
We're going to use Pandas for handling the data set.

00:04:25.241 --> 00:04:29.835
If you scroll down further, you will see a file in

00:04:29.835 --> 00:04:37.025
the Medicare data folder that says Medicare_Data_IL_2012.csv.

00:04:37.025 --> 00:04:40.780
This is a comma separated variable file.

00:04:40.780 --> 00:04:42.890
We created this file specially for

00:04:42.890 --> 00:04:46.970
you so that you don't have to use the entire data set.

00:04:46.970 --> 00:04:50.860
If you're interested in using the entire data set,

00:04:50.860 --> 00:04:56.390
use these commented out codes here to load the entire data set.

00:04:56.390 --> 00:05:01.830
Now we use the read_csv library from Pandas to read the data and

00:05:01.830 --> 00:05:04.780
load it into a data frame.

00:05:04.780 --> 00:05:10.020
As before, to run this piece of code, we just use the play button here.

00:05:11.090 --> 00:05:16.740
Once the data set is finished loading, you will receive a message like this.

00:05:16.740 --> 00:05:22.220
The f _IL is the Pandas data frame.

00:05:22.220 --> 00:05:26.870
We can use the describe function to look at the summary of this data.

00:05:27.930 --> 00:05:30.240
Let's run this piece of code.

00:05:30.240 --> 00:05:34.334
Once this finishes running, you should have a table that looks like this.

00:05:34.334 --> 00:05:42.680
The total number of events we have in the data frame is 387,623.

00:05:42.680 --> 00:05:46.590
You can slide this bar here to look at the rest of the table.

00:05:47.930 --> 00:05:53.090
Now let's look at the top five lines of the data frame.

00:05:53.090 --> 00:05:55.850
We can do that by using the head command.

00:05:57.390 --> 00:06:01.750
Once you finish running that, you will see another table.

00:06:01.750 --> 00:06:06.840
This table shows the actual data that has been loaded to memory.

00:06:06.840 --> 00:06:13.860
The top row gives you the names of various columns in the Pandas data frame.

00:06:13.860 --> 00:06:18.840
Each column consists of a NumPy array.

00:06:18.840 --> 00:06:23.770
If you are not familiar with Pandas data frames, we have linked to a lesson in

00:06:23.770 --> 00:06:29.180
the Intro to Data Science where it will teach you the high-level concepts and

00:06:29.180 --> 00:06:31.860
about Pandas and data frames.

00:06:31.860 --> 00:06:39.130
If you scroll further down, you will see it shows 5 rows and 28 columns.

00:06:39.130 --> 00:06:45.720
The 28 columns indicate there are 28 vectors in the Pandas data frame.

00:06:45.720 --> 00:06:51.010
Use the box below to write a Python code that uses the file for

00:06:51.010 --> 00:06:55.410
California included in your instructor's notes.

00:06:55.410 --> 00:07:01.060
Load it to memory as a Pandas Data Frame and print a summary of the data.

00:07:01.060 --> 00:07:04.670
Once you have finished writing your code in this box provided here,

00:07:04.670 --> 00:07:05.890
click on this box.

