WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:06.000
When we design a Kalman filter, you need effectively 2 things.

00:00:06.000 --> 00:00:10.000
For the state, you need a state transition function,

00:00:10.000 --> 00:00:15.000
and that's usually a matrix, so we're now in the world of linear algebra.

00:00:15.000 --> 00:00:18.000
For the measurements, you need a measurement function.

00:00:18.000 --> 00:00:24.000
Let me give you those for the 1D motion of an object

00:00:24.000 --> 00:00:31.000
We know that the new location is the old location + velocity,

00:00:31.000 --> 00:00:35.000
turns into this matrix. You have a 1 over here and a 1 over here.

00:00:35.000 --> 00:00:41.000
The new velocity should just be the old velocity, which gives us 0 over here and a 1 over here.

00:00:41.000 --> 00:00:46.000
If you multiply this matrix by this vector, this is exactly what you're getting.

00:00:46.000 --> 00:00:51.000
For the measurement, we only observe the first component of the place, not velocity,

00:00:51.000 --> 00:00:55.000
and that uses a matrix like this.

00:00:55.000 --> 00:01:02.000
This matrix would be called F and this H.

00:01:02.000 --> 00:01:07.000
The actual update equations for a Kalman filter are involved,

00:01:07.000 --> 00:01:14.000
and I give them to you, but please, don't memorize them, and I won't prove them for you.

00:01:14.000 --> 00:01:16.000
Even the proof is very involved.

00:01:16.000 --> 00:01:21.000
Every time I use them, I just look them up.

00:01:21.000 --> 00:01:27.000
There's a prediction step where I take my best estimate x,

00:01:27.000 --> 00:01:32.000
multiply it with a state transition matrix--matrix F,

00:01:32.000 --> 00:01:37.000
and I add whatever motion I know--u.

00:01:37.000 --> 00:01:39.000
That gives me my new x.

00:01:39.000 --> 00:01:43.000
I also have a covariance that characterizes my uncertainty,

00:01:43.000 --> 00:01:48.000
and that is updated as follows, where T is the transpose.

00:01:48.000 --> 00:01:53.000
There's also a measurement update step where we use the measurement z.

00:01:53.000 --> 00:02:01.000
We compare the measurement with our prediction where H is the measurement function

00:02:01.000 --> 00:02:04.000
that maps the state to measurements.

00:02:04.000 --> 00:02:07.000
We call this this the error.

00:02:07.000 --> 00:02:15.000
The error is mapped into a matrix s, which is obtained by projecting the system uncertainty

00:02:15.000 --> 00:02:19.000
into the measurement space using the measurement function projection

00:02:19.000 --> 00:02:23.000
+ the matrix R, that characterizes the measurement noise.

00:02:23.000 --> 00:02:27.000
This is then mapped into a variable called K, which is often called the Kalman gain,

00:02:27.000 --> 00:02:30.000
where we invert the matrix s,

00:02:30.000 --> 00:02:36.000
and then finally, we actually update our estimate and our uncertainty

00:02:36.000 --> 00:02:41.000
using what ought to be the most cryptic equation that you've seen in a long time.

00:02:41.000 --> 00:02:46.000
Now I wrote this down so that you have a complete definition,

00:02:46.000 --> 00:02:49.000
but this is something you should not memorize.

00:02:49.000 --> 00:02:54.000
If you really wish to understand this math, it happens to be just a generalization of the math

00:02:54.000 --> 00:02:57.000
I gave you to higher dimensional spaces,

00:02:57.000 --> 00:03:00.000
but I would recommend just not to worry about this.

00:03:00.000 --> 00:03:06.000
There's a set of linear algebra equations that implement the Kalman filter

00:03:06.000 --> 00:03:07.757
in higher dimensions.

