WEBVTT
Kind: captions
Language: en

00:00:00.237 --> 00:00:01.905
Now let's look at the kernel itself.

00:00:01.905 --> 00:00:05.409
Recall that this will look like a serial program that will run on one thread,

00:00:05.409 --> 00:00:09.723
and the CPU is responsible for launching that program on many parallel threads.

00:00:09.723 --> 00:00:12.983
This kernel indeed looks exactly like a serial program.

00:00:12.983 --> 00:00:16.417
So here's our kernel right here, this global void square.

00:00:16.417 --> 00:00:22.659
Here's the interesting things about this short kernel program. First global.

00:00:22.659 --> 00:00:26.295
This is underscore, underscore, global, underscore, underscore.

00:00:26.295 --> 00:00:32.926
That's a C language construct called a "declaration specifier"--for short, deckle speck.

00:00:32.926 --> 00:00:33.966
Don't worry about the name.

00:00:33.966 --> 00:00:39.399
Just know that this is the way that cuda knows this code is a kernel as opposed to CPU code.

00:00:39.399 --> 00:00:41.235
Next we have void.

00:00:41.235 --> 00:00:43.835
Void just means the kernel doesn't return a value.

00:00:43.835 --> 00:00:47.838
Instead it writes the output into the pointer specified in its argument list.

00:00:47.838 --> 00:00:49.877
This kernel takes two arguments.

00:00:49.877 --> 00:00:53.613
These are pointers to the output and the input arrays.

00:00:53.613 --> 00:00:59.752
Recall that both these pointers need to be allocated on the GPU, or else your program will crash spectacularly.

00:00:59.752 --> 00:01:04.524
Now note that I name them with d out and d in.

00:01:04.524 --> 00:01:07.600
That's certainly not foolproof, but if I called it d_

00:01:07.600 --> 00:01:10.269
and I'm consistent about the way I allocate my variables,

00:01:10.269 --> 00:01:14.453
I know that d_ variables are allocated on the GPU.

00:01:14.453 --> 00:01:16.713
Let's walk through the body of the kernel.

00:01:16.713 --> 00:01:18.577
So the first line of the body here.

00:01:18.577 --> 00:01:21.913
Remember how I said that each thread know its own index?

00:01:21.913 --> 00:01:23.616
Here's how we get that index.

00:01:23.616 --> 00:01:27.985
CUDA has a built in variable called thread index, threadIDX,

00:01:27.985 --> 00:01:31.458
and that's going to tell each thread its index within a block.

00:01:31.458 --> 00:01:39.398
ThreadIDX is actually a c struct with 3 members. .x, .y, and .z. The c struct is called a dim3.

00:01:39.398 --> 00:01:43.349
We're just using .x in this code, but we'll explain the others a little bit later.

00:01:43.349 --> 00:01:45.846
Now, we'll launch 64 threads.

00:01:45.846 --> 00:01:50.766
For the first instance of those threads, threadIDX.x will return zero,

00:01:50.766 --> 00:01:55.270
for the second instance 1, and so on, up to 63 for the last element.

00:01:55.270 --> 00:01:59.157
Everything else in this kernel just looks like straightforward C.

00:01:59.157 --> 00:02:01.174
It looks just like a serial program.

00:02:01.174 --> 00:02:02.842
What are we actually doing in this kernel?

00:02:02.842 --> 00:02:07.386
Well, for each thread we're going to first read the array element corresponding

00:02:07.386 --> 00:02:10.018
to this thread index from global memory.

00:02:10.018 --> 00:02:12.819
We're going to store it in this float variable f.

00:02:12.819 --> 00:02:18.141
We're then going to square f, and we're going to write that value back to global memory

00:02:18.141 --> 00:02:21.623
in the output array element that corresponds to our thread index.

