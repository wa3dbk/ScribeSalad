WEBVTT
Kind: captions
Language: en

00:00:00.330 --> 00:00:03.120
Here is one way in which
an intelligent agent can work and

00:00:03.120 --> 00:00:07.110
accomplish environment with a large
number of perception actions possible

00:00:07.110 --> 00:00:10.520
and yet do so relatively efficiently.

00:00:10.520 --> 00:00:13.170
Suppose that this 2 to
the power n percepts,

00:00:13.170 --> 00:00:17.480
could be mapped into k concepts
where each of these k concept

00:00:17.480 --> 00:00:20.760
is an equivalence class with a large
number of these combinations.

00:00:20.760 --> 00:00:25.730
So 2 to the power of n may be very, very
large, but k is a much smaller number.

00:00:25.730 --> 00:00:29.250
So these concepts are now equivalence
classes or these percepts.

00:00:30.430 --> 00:00:35.440
So now instead of indexing my actions
on the combinations of percepts,

00:00:35.440 --> 00:00:39.820
I index my actions on the equivalence
classes that are called concepts, and

00:00:39.820 --> 00:00:41.630
this happens all the time.

00:00:41.630 --> 00:00:45.860
You go to a doctor, for example and you
may go with some signs and symptoms and

00:00:45.860 --> 00:00:50.050
the doctor says, well, I have to decide
whether I'll give you a blue liquid or

00:00:50.050 --> 00:00:52.730
a red liquid, assume that those
are the actions possible.

00:00:52.730 --> 00:00:55.860
And the actions are now indexed,
not as the signs and symptoms or

00:00:55.860 --> 00:00:58.750
the combination of signs and symptoms,
which are potentially very large for

00:00:58.750 --> 00:01:03.380
human beings, but it's a small number
of concepts, the number of diseases,

00:01:03.380 --> 00:01:06.810
which compared to all the combinations
of signs and symptoms, is much smaller.

00:01:07.850 --> 00:01:10.930
&gt;&gt; Another example of this that
would come from computer programming

00:01:10.930 --> 00:01:13.990
would be that we might have a small
number of different ways in which

00:01:13.990 --> 00:01:18.020
a computer program can go wrong,
by a large number of different percepts

00:01:18.020 --> 00:01:20.170
that tell us what has
actually gone wrong.

00:01:20.170 --> 00:01:23.640
So, for example in my percepts, I might
have whether or not I received a null

00:01:23.640 --> 00:01:27.520
pointer error, whether or not I received
a memory allocation error, whether or

00:01:27.520 --> 00:01:31.420
not I received an index larger
than size of an array error.

00:01:31.420 --> 00:01:34.160
All of those are different percepts
I might have, but it might map

00:01:34.160 --> 00:01:37.090
the same underlying concept or something
that has not yet been initialized.

00:01:37.090 --> 00:01:40.680
So I'm taking the number of things that
I can actually see and mapping them to

00:01:40.680 --> 00:01:44.520
a smaller number of ways in which
the program can actually go wrong.

00:01:44.520 --> 00:01:47.960
Then instead of having to map each
individual percept to some number of

00:01:47.960 --> 00:01:52.350
actions, I know that if my error is
that something has not been initialized

00:01:52.350 --> 00:01:53.970
I need to find what hasn't
been initialized and

00:01:53.970 --> 00:01:56.890
there's a much smaller list of
actions involved looking at each

00:01:56.890 --> 00:02:00.840
individual variable and seeing where
the initialization has not taken place.

00:02:00.840 --> 00:02:03.300
&gt;&gt; Now we understand
why classification is

00:02:03.300 --> 00:02:06.710
such an often-studied topic
in artificial intelligence.

00:02:06.710 --> 00:02:09.788
Almost every school of artificial
intelligence has studied

00:02:09.788 --> 00:02:11.810
classification extensively.

00:02:11.810 --> 00:02:15.190
If there were no concept we were
mapping this two to the power

00:02:15.190 --> 00:02:20.460
n combinations of percepts and use two
to the power m combinations of actions,

00:02:20.460 --> 00:02:25.050
then we could think of an intelligent
agent as one large, giant table.

00:02:25.050 --> 00:02:29.490
The rows of the table are all the two
to the n combinations of percepts

00:02:29.490 --> 00:02:33.808
that will be that many rows and the
columns are through the power m actions.

00:02:33.808 --> 00:02:38.270
Given a percept, I know exactly what
action to take if they would tell you

00:02:38.270 --> 00:02:40.870
that, and
it's going to be a very large table.

00:02:40.870 --> 00:02:41.980
We don't know how to use it,

00:02:41.980 --> 00:02:46.020
it will be very costly to use it, and
we don't know how to build such a table.

00:02:47.480 --> 00:02:51.960
What classification is doing is,
it is breaking that large table

00:02:51.960 --> 00:02:56.400
into a large number of small tables,
and that's the power of knowledge.

00:02:56.400 --> 00:03:00.140
When you have knowledge,
you can take some complex problem, and

00:03:00.140 --> 00:03:02.750
break it into a large number of smaller,
simpler problems.

