WEBVTT
Kind: captions
Language: en

00:00:00.210 --> 00:00:02.900
All right,
welcome back to Computer Vision again.

00:00:02.900 --> 00:00:04.750
We're going back to recognition now.

00:00:04.750 --> 00:00:07.850
Remember, before we were talking
about supervised classification?

00:00:07.850 --> 00:00:11.870
Supervised classification is I give you
a bunch of labeled examples, right?

00:00:11.870 --> 00:00:14.230
Typically referred to
as training examples.

00:00:14.230 --> 00:00:16.560
And you're supposed to come up with
a function that'll label some new

00:00:16.560 --> 00:00:17.320
examples.

00:00:17.320 --> 00:00:21.510
And we showed this one where, we have a
bunch of hand-drawn fours and hand-drawn

00:00:21.510 --> 00:00:26.330
nines, and the idea was, given some new
input, is it a four or is it a nine?

00:00:26.330 --> 00:00:29.120
The idea was,
since we know what the desired labels

00:00:29.120 --> 00:00:32.159
are from the training data,
we're going to try to build a classifier

00:00:32.159 --> 00:00:35.874
that's going to minimize the expected
misclassification, or minimize our risk.

00:00:35.874 --> 00:00:39.760
All right, and we talked about
that there were two strategies.

00:00:39.760 --> 00:00:41.290
One was called generative,

00:00:41.290 --> 00:00:44.240
where we probabilistically model
each of the classes and then,

00:00:44.240 --> 00:00:47.460
somehow, picked them, we'll talk
about those again just for a second.

00:00:47.460 --> 00:00:51.710
And then there is this discriminative,
and discriminative says, I don't care so

00:00:51.710 --> 00:00:53.900
much about modeling the classes,

00:00:53.900 --> 00:00:57.330
what I care about is modelling some
sort of boundary between the classes.

00:00:57.330 --> 00:01:00.840
And that makes it easier
to make some decisions.

00:01:00.840 --> 00:01:03.900
So, we talked about the risk of
a particular decision as being,

00:01:03.900 --> 00:01:06.420
if you're making a particular decision,
what's the probability that that

00:01:06.420 --> 00:01:11.880
decision's wrong, and what's the cost
of making that wrong decision?

00:01:11.880 --> 00:01:16.750
So, for example, let's suppose that I'm
going to label something as a four.

00:01:16.750 --> 00:01:18.230
Well, if I'm going to
label it as a four,

00:01:18.230 --> 00:01:20.630
what's the risk associated
with it being a four?

00:01:20.630 --> 00:01:21.800
Well, that risk would be,

00:01:21.800 --> 00:01:27.300
well, you know, what's the probability
that it's actually a nine, okay?

00:01:27.300 --> 00:01:31.470
And what's the cost, to me,
of calling a nine a four, all right?

00:01:31.470 --> 00:01:34.865
So that's the risk of labeling
something a four, right?

00:01:34.865 --> 00:01:38.010
because it actually might have
been a nine, and what's the cost.

00:01:38.010 --> 00:01:40.910
Likewise, suppose I'm going to
label something a nine.

00:01:40.910 --> 00:01:42.950
What's the risk of
labeling something a nine?

00:01:42.950 --> 00:01:46.855
Well the risk of labeling something
a nine is the probability that it was

00:01:46.855 --> 00:01:50.779
actually a four, times the cost of
labeling something a four as a nine.

00:01:50.779 --> 00:01:51.325
Right?

00:01:51.325 --> 00:01:55.248
And, where should my
decision boundary be?

00:01:55.248 --> 00:02:00.165
Well my decision boundary should be
that the risk of either decision would

00:02:00.165 --> 00:02:01.720
be the same.

00:02:01.720 --> 00:02:03.650
Okay, and that was the idea
of the generative model.

00:02:03.650 --> 00:02:07.150
And so that's what's being shown here
is, so here are my, all my real fours so

00:02:07.150 --> 00:02:09.699
I'm pretty sure that they're four,
so I'm going to call them fours.

00:02:09.699 --> 00:02:13.340
But as I'm getting over to
the other side, it might be a nine.

00:02:13.340 --> 00:02:16.280
Here are all my nines, and
as I'm getting closer over here,

00:02:16.280 --> 00:02:17.590
it might be a four.

00:02:17.590 --> 00:02:20.680
And this boundary in the middle,
that's where the risk is the same.

