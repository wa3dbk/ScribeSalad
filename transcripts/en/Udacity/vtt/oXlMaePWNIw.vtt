WEBVTT
Kind: captions
Language: en

00:00:00.090 --> 00:00:01.780
What currently works?

00:00:01.780 --> 00:00:04.390
Well actually, let's talk a little
bit about what used to work, well,

00:00:04.390 --> 00:00:07.240
still does, what worked a while ago,
and what's working now.

00:00:07.240 --> 00:00:09.560
So what worked sort of say yesterday?

00:00:09.560 --> 00:00:12.700
Okay.
Yesterday being proverbially not today.

00:00:12.700 --> 00:00:15.550
All right, so
things like reading license plates,

00:00:15.550 --> 00:00:18.640
well that's pretty easy
because it's a fixed font.

00:00:18.640 --> 00:00:23.295
Zip codes, numbers on checks,
those are getting much better, and

00:00:23.295 --> 00:00:26.790
handwritten recognition of
digits has gotten pretty good.

00:00:26.790 --> 00:00:28.380
Fingerprint recognition.

00:00:28.380 --> 00:00:31.200
The analysis of those patterns,
because the patterns share certain

00:00:31.200 --> 00:00:34.620
types of characteristics, and
we could find those characteristics.

00:00:34.620 --> 00:00:39.090
Face detection, but you'll notice that
here the thing knows who I am, but

00:00:39.090 --> 00:00:41.030
it hasn't yet figured out who Megan is.

00:00:41.030 --> 00:00:41.560
Right?

00:00:41.560 --> 00:00:43.790
Today we do recognition.

00:00:43.790 --> 00:00:44.920
By the way you know,

00:00:44.920 --> 00:00:49.220
these days typically when you pop-up or
put an image let's say on to Facebook or

00:00:49.220 --> 00:00:53.270
some other thing, it'll suggest you
the names of the people that are there.

00:00:53.270 --> 00:00:55.710
And that means that it's
found the faces, and

00:00:55.710 --> 00:00:57.810
it's also recognized who they are.

00:00:57.810 --> 00:01:01.531
Now, it doesn't searches
database of everybody,

00:01:01.531 --> 00:01:04.560
it only searches your friends.

00:01:04.560 --> 00:01:06.330
Right?
So it doesn't have to try to recognize

00:01:06.330 --> 00:01:10.990
this as anybody on the planet, just
the five friends that I happen to have.

00:01:10.990 --> 00:01:11.580
Right?

00:01:11.580 --> 00:01:14.640
So then you might ask, well, how does
it know the picture of those friends?

00:01:14.640 --> 00:01:17.960
Well, other people have
tagged Megan in images.

00:01:20.720 --> 00:01:23.895
Every time you tag an image with a face,
person's name,

00:01:23.895 --> 00:01:27.170
you're actually telling Google, or

00:01:27.170 --> 00:01:31.750
whoever, or Facebook, or whoever you're
doing, how to recognize that person.

00:01:32.950 --> 00:01:36.610
So without meaning, making it sound
nefarious, it is the case that every

00:01:36.610 --> 00:01:41.470
time you tag somebody else in a picture,
you're making it that much easier for

00:01:41.470 --> 00:01:45.480
computers to find that
person in other images.

00:01:45.480 --> 00:01:47.010
You are teaching.

00:01:47.010 --> 00:01:53.170
You are not tagging, you are teaching
the system what Megan looks like.

00:01:53.170 --> 00:01:54.012
So just, just,

00:01:54.012 --> 00:01:58.160
just think about that every time
you identify people in an image.

00:01:58.160 --> 00:01:59.950
We've actually talked
about sift features and

00:01:59.950 --> 00:02:03.690
using the location of sift features
to recognize objects and, you know,

00:02:03.690 --> 00:02:06.430
sort of flat textured things
like the book covers.

00:02:06.430 --> 00:02:07.080
All right.

00:02:07.080 --> 00:02:07.940
Now what just happened?

00:02:07.940 --> 00:02:12.230
This is GoogleNet 2014,
which was part of a competition.

00:02:12.230 --> 00:02:16.070
And you can see here that
given this image, okay,

00:02:16.070 --> 00:02:18.360
it labels the monitor, the bookshelf.

00:02:18.360 --> 00:02:20.870
It even labels this dom,
this, it says domestic cat.

00:02:20.870 --> 00:02:23.690
And it looks to me like this
cat is jumping in the air, so

00:02:23.690 --> 00:02:24.880
that's pretty cool.

00:02:24.880 --> 00:02:29.900
What makes this picture hard, of course
is the very intense color variation.

00:02:29.900 --> 00:02:33.480
So it was able to find, just basically
through the color and texture,

00:02:33.480 --> 00:02:35.000
cause that's the only
thing that's there,

00:02:35.000 --> 00:02:37.240
the fact that there were oranges and
bananas there.

00:02:37.240 --> 00:02:41.030
So this is a pretty intriguing result,
and then here's a result that,

00:02:42.210 --> 00:02:45.560
calls into question
the importance of context.

00:02:45.560 --> 00:02:48.300
And maybe what it means is
that context doesn't matter

00:02:48.300 --> 00:02:50.090
when things are very clear.

00:02:50.090 --> 00:02:50.650
All right?

00:02:50.650 --> 00:02:52.424
So I love this picture.

00:02:52.424 --> 00:02:56.160
I'm not sure you can read this, but
it says hat with wide brim on the top,

00:02:56.160 --> 00:02:58.410
and it says dog on the bottom.

00:02:58.410 --> 00:03:02.840
Now, I don't know how many pictures
there are of dogs with hats and

00:03:02.840 --> 00:03:04.490
wide brims wearing them.

00:03:04.490 --> 00:03:06.830
What scares me is,
there might be tens of thousands,

00:03:06.830 --> 00:03:08.970
because people have way too much
time on their hands or something.

00:03:08.970 --> 00:03:09.680
I don't know.

00:03:09.680 --> 00:03:14.500
But, it is an impressive result that it
was able to recognize the hat on top of

00:03:14.500 --> 00:03:17.970
the dog, which you have to believe
is not a likely position for a hat.

