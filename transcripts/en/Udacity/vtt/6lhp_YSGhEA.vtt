WEBVTT
Kind: captions
Language: en

00:00:00.230 --> 00:00:01.270
Okay, Michael what's the answer?

00:00:01.270 --> 00:00:05.060
&gt;&gt; Well, it's still a half. But I guess we, we really should

00:00:05.060 --> 00:00:07.240
take into consideration those probability. So

00:00:07.240 --> 00:00:08.460
the number of mismatches they have, but

00:00:08.460 --> 00:00:12.600
the actual number of errors, the expected number of errors is like well,

00:00:12.600 --> 00:00:17.956
a 20th plus 20th, so like a 10th. So it's 90% correct, 10% error.

00:00:17.956 --> 00:00:21.600
&gt;&gt; Right. That's exactly right, so, what's important to see here

00:00:21.600 --> 00:00:25.270
is that even though you may get many examples wrong, in some

00:00:25.270 --> 00:00:28.610
sense some examples are more important than others. Because

00:00:28.610 --> 00:00:31.240
some are very rare. And if you think of error,

00:00:31.240 --> 00:00:33.570
or the sort of mistakes that you're making, not as

00:00:33.570 --> 00:00:37.000
the number of distinct mistakes you can make, but rather

00:00:37.000 --> 00:00:40.010
the amount of time you will be wrong, or the

00:00:40.010 --> 00:00:42.270
amount of time you'll make a mistake, then you can

00:00:42.270 --> 00:00:44.150
begin to see that it's important to think about the

00:00:44.150 --> 00:00:47.340
underlying distribution of examples that. You see. You buy that?

00:00:47.340 --> 00:00:47.710
&gt;&gt; Yeah.

00:00:47.710 --> 00:00:50.440
&gt;&gt; Okay, so, that notion of error

00:00:50.440 --> 00:00:53.990
turns out to be very important for boositng because in the

00:00:53.990 --> 00:00:57.360
end, boosting is going to use this trick of distributions in order

00:00:57.360 --> 00:01:00.220
to define what hardest is. Since we are going to have learning

00:01:00.220 --> 00:01:02.840
algorithms that do a pretty god job of learning on a bunch

00:01:02.840 --> 00:01:06.150
of examples. We're going to pass along to them a distribution

00:01:06.150 --> 00:01:09.430
over the examples, which is another way of saying, which examples are

00:01:09.430 --> 00:01:12.350
important to learn, versus which examples are not as important to

00:01:12.350 --> 00:01:15.920
learn. And that's where the hardest notion is going to come in.

00:01:15.920 --> 00:01:18.370
So, every time we see a bunch of examples, we're

00:01:18.370 --> 00:01:20.670
going to try to make the harder ones more important to get

00:01:20.670 --> 00:01:23.090
right. Than the ones that we already know how to solve.

00:01:23.090 --> 00:01:25.550
And I'll, I'll describe in a minute exactly how that's done.

00:01:25.550 --> 00:01:27.630
&gt;&gt; But isn't it the case that this distribution

00:01:27.630 --> 00:01:29.750
doesn't really matter? You should just get them all right.

00:01:29.750 --> 00:01:31.300
&gt;&gt; Sure. But now it's a question of

00:01:31.300 --> 00:01:33.050
how you're going to get them all right. Which

00:01:33.050 --> 00:01:35.580
brings me to my second definition I want to

00:01:35.580 --> 00:01:41.120
make. And that second definition is a weak learner.

00:01:41.120 --> 00:01:43.840
So there's this idea of a learning algorithm, which is

00:01:43.840 --> 00:01:46.940
what we mean by a learner here. As being weak. And

00:01:46.940 --> 00:01:49.200
that definition's actually fairly straightforward

00:01:49.200 --> 00:01:50.500
so straightforward in fact that you

00:01:50.500 --> 00:01:53.070
can sort of forget that it's really important. And all a

00:01:53.070 --> 00:01:56.510
weak learners is, is a learner that no matter what

00:01:56.510 --> 00:02:00.250
the distribution is over your data, will do better than chance

00:02:00.250 --> 00:02:02.770
when it tries to learn labels on that data. So what

00:02:02.770 --> 00:02:06.120
does does better than chance actually mean? Well what it means

00:02:06.120 --> 00:02:08.979
is, that no matter what the distribution over the

00:02:08.979 --> 00:02:12.320
data is, you're always going to have an error rate that's

00:02:12.320 --> 00:02:14.740
less than a half. So that means sort of

00:02:14.740 --> 00:02:17.580
as a formalism, is written down here below. That for

00:02:17.580 --> 00:02:20.040
all D, that is to say no matter what

00:02:20.040 --> 00:02:24.260
the distribution is, your learning algorithm We'll have an expected

00:02:24.260 --> 00:02:27.470
error. That is the probability that it will disagree with

00:02:27.470 --> 00:02:31.560
it through actual concept if you draw a single sample

00:02:31.560 --> 00:02:33.360
that is less than or equal to one half

00:02:33.360 --> 00:02:36.070
minus Epsilon. Now epsilon is a term that you end

00:02:36.070 --> 00:02:39.290
up seeing a lot in mathematical proofs and particularly ones

00:02:39.290 --> 00:02:42.520
involving machine learning. And epsilon just means a really, really

00:02:42.520 --> 00:02:47.020
small number somewhere between a little bigger than 0 and

00:02:47.020 --> 00:02:50.240
certainly much smaller than 1. So, here what this means

00:02:50.240 --> 00:02:53.980
technically is that you're bounded away from 1 1/2. Which

00:02:53.980 --> 00:02:56.560
another way of thinking about that is you always get

00:02:56.560 --> 00:02:58.240
some information from the learner. The

00:02:58.240 --> 00:03:00.830
learner's always able to learn something. Chance

00:03:00.830 --> 00:03:03.790
would be the case where your probability is 1/2 and you actually learn

00:03:03.790 --> 00:03:06.960
nothing at all which kind of ties us back into the notion of information

00:03:06.960 --> 00:03:10.700
gained way back when with decision trees. So does that all make sense Michael?

00:03:10.700 --> 00:03:14.180
&gt;&gt; I'm not sure that I get this right. Let's, maybe we can do

00:03:14.180 --> 00:03:17.910
a quiz and just kind of nail down some of the questions that I've got.

00:03:17.910 --> 00:03:19.820
&gt;&gt; Okay, sure. You got an idea for a quiz?

00:03:19.820 --> 00:03:20.430
&gt;&gt; Sure.

