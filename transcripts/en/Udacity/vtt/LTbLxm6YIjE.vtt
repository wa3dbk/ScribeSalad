WEBVTT
Kind: captions
Language: en

00:00:00.780 --> 00:00:04.030
You obviously need a very good
model train on a lot of data

00:00:04.030 --> 00:00:05.470
to get this kind of result.

00:00:05.470 --> 00:00:08.500
And it's likely that the model that
you're training in the assignments

00:00:08.500 --> 00:00:11.290
is just not trained with
enough data to show this.

00:00:11.290 --> 00:00:12.960
But you can try.

00:00:12.960 --> 00:00:15.540
There are many other ways to learn
embeddings that I won't cover.

00:00:16.550 --> 00:00:19.400
Now, that we have models for
individual words,

00:00:19.400 --> 00:00:23.360
how do we deal with the fact that
text is actually a sequence of words?

00:00:23.360 --> 00:00:27.220
So far, your models have only looked
at inputs that were a fixed size.

00:00:27.220 --> 00:00:30.890
Fixed size means you can always
turn things into a vector, and

00:00:30.890 --> 00:00:32.930
feed it to your neural network.

00:00:32.930 --> 00:00:35.160
When you have sequences
of varying length,

00:00:35.160 --> 00:00:38.770
like speech or text,
you can no longer do that.

00:00:38.770 --> 00:00:39.270
Now what?

