WEBVTT
Kind: captions
Language: en

00:00:00.250 --> 00:00:06.182
In Unit 4, we looked at Sparse Matrix Vector Multiply, SpMv,

00:00:06.182 --> 00:00:11.043
noting that this is one of the most important operations in all of computing.

00:00:11.043 --> 00:00:14.317
What we're going to look at today is how to implement this efficiently.

00:00:14.317 --> 00:00:17.369
So first a quick recap on what SpMv is.

00:00:17.369 --> 00:00:20.751
We wish to multiply a matrix by a vector.

00:00:20.751 --> 00:00:26.675
If this matrix is dense where every entry in the entire matrix is represented in the matrix data structure,

00:00:26.675 --> 00:00:29.129
GPUs can get excellent performance,

00:00:29.129 --> 00:00:32.671
but many interesting matrices are what we call sparse.

00:00:32.671 --> 00:00:36.917
Many, if not most, of the entries in these matrices are 0.

00:00:36.917 --> 00:00:42.415
So we prefer to represent only the non-zeros in this matrix, which gives us 2 advantages.

00:00:42.415 --> 00:00:45.919
One, less storage since we don't have to represent a bunch of zeros,

00:00:45.919 --> 00:00:51.837
and two, less computation, since we're not doing a bunch of multiplications and additions of zeros.

00:00:51.837 --> 00:00:55.890
If you need a refresher on how to multiply a sparse matrix by a dense factor,

00:00:55.890 --> 00:00:58.195
please take a short trip back to Unit 4,

00:00:58.195 --> 00:01:03.697
because what we're going to talk about today is a strategy to build a more efficient SpMv.

00:01:03.697 --> 00:01:08.545
The broad question that we want to answer in thinking about how to make this problem efficiently is

00:01:08.545 --> 00:01:11.271
what is the role of a thread?

00:01:11.271 --> 00:01:14.001
Let's look at this sparse matrix to answer this question.

00:01:14.001 --> 00:01:18.551
Here we're using X's to represent non-zeros and blanks to represent zeros.

00:01:18.551 --> 00:01:21.048
We will consider 2 alternatives.

00:01:21.048 --> 00:01:25.819
The first is that we will assign 1 thread per row of the sparse matrix.

00:01:25.819 --> 00:01:31.059
Here a thread is responsible for computing 1 entry in the output vector,

00:01:31.059 --> 00:01:37.238
and we do this by taking the dot product of this row with this column.

00:01:37.238 --> 00:01:42.894
Second, we will assign 1 thread per element in the sparse matrix; for instance, this element here.

00:01:42.894 --> 00:01:45.875
Here a thread is responsible for doing 1 multiplication;

00:01:45.875 --> 00:01:50.151
in this case, times its corresponding element in the input vector--

00:01:50.151 --> 00:01:54.254
what we call a partial product, and then cooperating with other other threads--

00:01:54.254 --> 00:01:57.784
this thread, for instance, in summing up the partial products.

00:01:57.784 --> 00:01:59.887
So which is better?

00:01:59.887 --> 00:02:02.976
The answer is, it depends, and we'll look at how to do both of them.

