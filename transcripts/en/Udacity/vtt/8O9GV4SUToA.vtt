WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.000
I'd like to take my students on a little journey to Stanford

00:00:05.000 --> 00:00:11.000
and show them our self-driving car that uses sensors to sense the environment.

00:00:11.000 --> 00:00:16.000
So let me dive into the class pretty much right now.

00:00:16.000 --> 00:00:19.000
In our last class, we talked about localization.

00:00:19.000 --> 00:00:24.000
We had a robot that lived in an environment and that could use its sensors

00:00:24.000 --> 00:00:28.000
to determine where in the environment it is.

00:00:28.000 --> 00:00:35.000
Here you can see the Google self-driving car using a road map localizing itself.

00:00:35.000 --> 00:00:39.000
But in addition, what is shown here in red are measurements of other vehicles.

00:00:39.000 --> 00:00:48.000
The car uses lasers and radars to track other vehicles and today we're going to talk about how to find other cars.

00:00:48.000 --> 00:00:53.000
The reason why I would like to find other cars is because we wouldn't want to run into them.

00:00:53.000 --> 00:00:58.000
We have to understand how to interpret sensor data to make assessments,

00:00:58.000 --> 00:01:02.000
not just where these other cars are as in the localization case,

00:01:02.000 --> 00:01:05.000
but also how fast they're moving

00:01:05.000 --> 00:01:09.000
so you can drive in a way that avoids collisions with them in the future.

00:01:09.000 --> 00:01:12.000
That's important--not just for cars.

00:01:12.000 --> 00:01:16.000
It matters for pedestrians and for bicyclists.

00:01:16.000 --> 00:01:20.000
Understand where other cars are an making predictions where they're going to move

00:01:20.000 --> 00:01:24.000
is absolutely essential for safe driving in the Google car project.

00:01:24.000 --> 00:01:26.000
[Tracking]

00:01:26.000 --> 00:01:29.000
So in this class we're going to talk about tracking.

00:01:29.000 --> 00:01:32.000
The technique I'd like to teach you is called a Kalman filter.

00:01:32.000 --> 00:01:37.000
This is an insanely popular technique for estimating the state of a system.

00:01:37.000 --> 00:01:41.000
It's actually very similar to the probabilistic localization method

00:01:41.000 --> 00:01:45.000
we taught in the previous class--Monte Carlo localization.

00:01:45.000 --> 00:01:50.000
The primary differences are that Kalman filters estimate a continuous state

00:01:50.000 --> 00:01:56.000
whereas in Monte Carlo localization we are voiced to chop the world into discrete places.

00:01:56.000 --> 00:02:00.000
As a result, the Kalman filter happens to give us a unimodal distribution--

00:02:00.000 --> 00:02:04.000
and I'll tell you in a second what that means--

00:02:04.000 --> 00:02:08.000
whereas Monte Carlo was fine with multimodal distributions.

00:02:08.000 --> 00:02:13.000
Both of these techniques are applicable to robot localization and tracking other vehicles.

00:02:13.000 --> 00:02:17.000
In fact, in a later class, we're going to learn about particle filters,

00:02:17.000 --> 00:02:20.000
which are yet another way to address the same problem,

00:02:20.000 --> 00:02:23.000
and indeed they are actually continuous and multimodal.

00:02:23.000 --> 00:02:26.000
But for the time being let's look into Kalman filters

00:02:26.000 --> 00:02:29.000
and ignore these other two families of methods.

00:02:29.000 --> 00:02:32.000
Let me start with a example. Consider the car done here.

00:02:32.000 --> 00:02:41.000
Let's assume the it sees as its measurement, an object here, here, here,

00:02:41.000 --> 00:02:46.000
here, and here for the times t = 0, t = 1, t = 2, and t = 3.

00:02:46.000 --> 09:59:59.000
Where would you assume the object would be at t = 4? Check one of those 3 boxes.

