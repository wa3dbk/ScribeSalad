WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.000
Hello, and welcome to the fourth Office Hours.

00:00:02.000 --> 00:00:06.000
We've had a lot of really good discussion in the forums and some great questions.

00:00:06.000 --> 00:00:09.000
Let's start with a question from Michael.

00:00:09.000 --> 00:00:12.000
He asks, "In the last office hours, you mentioned something

00:00:12.000 --> 00:00:15.000
about the possibility of a project at the end of the class.

00:00:15.000 --> 00:00:18.000
What are your thoughts on the students building a robotic car?"

00:00:18.000 --> 00:00:23.000
I just recorded the final class, and I actually spent some time putting everything together

00:00:23.000 --> 00:00:29.000
into a simulation of a car at the level we've been operating--not a real car.

00:00:29.000 --> 00:00:32.000
Honestly, it took me a whole day to put this all together.

00:00:32.000 --> 00:00:38.000
It's substantial work, because at the surface these pieces fit together nicely,

00:00:38.000 --> 00:00:41.000
but when you put them together, you realize that what the planner generates is not quite

00:00:41.000 --> 00:00:44.000
isn't quite exactly what the controller really wants.

00:00:44.000 --> 00:00:47.000
Tuning those parameters was actually a challenge,

00:00:47.000 --> 00:00:51.000
but what I've done is for the final class, I'm giving you the environment first

00:00:51.000 --> 00:00:53.000
and saying solve the problem of driving a car from A to B.

00:00:53.000 --> 00:00:58.000
If you're really so inclined, you can go out and really try it,

00:00:58.000 --> 00:01:02.000
but as the class goes on I give you most of my implementation, leaving bits and pieces out.

00:01:02.000 --> 00:01:05.000
Then you can go and plug those bits and pieces and and hopefully make it work.

00:01:05.000 --> 00:01:11.000
Unfortunately, I can't really give you a real car. That's the real fun thing.

00:01:11.000 --> 00:01:16.000
As we'll see in the final example, the methods that we discussed are the core methods.

00:01:16.000 --> 00:01:20.000
They give you a good path, but they won't give you a path good enough for actual driving.

00:01:20.000 --> 00:01:23.000
There's a lot of work that goes beyond this class that could be done

00:01:23.000 --> 00:01:26.000
to make things smoother and more elegant. Perfect.

00:01:26.000 --> 00:01:32.000
Tangled asked, "In the Unit 4.14 video, you mentioned something about the other cars honking."

00:01:32.000 --> 00:01:34.000
He wants to know if Junior can here.

00:01:34.000 --> 00:01:39.000
Does he have a microphone sensor that affects his actions, and can he honk himself?

00:01:39.000 --> 00:01:42.000
[Sebastian:] None of our cars hear, and none of our cars honk.

00:01:42.000 --> 00:01:49.000
I know in certain parts of the world that's a recipe for not driving confidently and safely in traffic,

00:01:49.000 --> 00:01:54.000
but we chose not to make audio communication part of that experiment.

00:01:54.000 --> 00:01:58.000
George asked, "While it's possible to constantly re-plan

00:01:58.000 --> 00:02:01.000
if enough computational power is available,

00:02:01.000 --> 00:02:04.000
A-star assumes a static and deterministic world."

00:02:04.000 --> 00:02:07.000
Can you comment on some of the possible pitfalls of using A-star?

00:02:07.000 --> 00:02:11.000
And what are some of the alternatives to this algorithm?

00:02:11.000 --> 00:02:14.000
Those are great and really deep questions,

00:02:14.000 --> 00:02:17.000
to which I've dedicated a number or research years, it turns out,

00:02:17.000 --> 00:02:21.000
and I've graduated a number of PhD students on that very topic.

00:02:21.000 --> 00:02:24.000
A-star gives you a taste of how cool planning can be,

00:02:24.000 --> 00:02:27.000
but there are many, many opens problems.

00:02:27.000 --> 00:02:31.000
For example, A-star cannot deal with branching outcomes where you flip a coin,

00:02:31.000 --> 00:02:34.000
and you have to pursue both outcomes. It just doesn't work.

00:02:34.000 --> 00:02:37.000
It cannot deal with information gathering.

00:02:37.000 --> 00:02:40.000
Sometimes in planning what you want to do is take

00:02:40.000 --> 00:02:43.000
a specific action just for the sake of a reducing uncertainty.

00:02:43.000 --> 00:02:47.000
For example, if I am going to a grocery store, and I don't know whether I have money with me,

00:02:47.000 --> 00:02:50.000
I might just check, do I have my money here, and this checking action

00:02:50.000 --> 00:02:55.000
has no other bearing than informing me that my money is in my pocket.

00:02:55.000 --> 00:02:59.000
That is completely not doable with A-star now.

00:02:59.000 --> 00:03:02.000
The dynamic programming stuff that I discussed has that flavor.

00:03:02.000 --> 00:03:05.000
You can actually pursue multiple outcomes and bring them together.

00:03:05.000 --> 00:03:09.000
It is computationally very inefficient, so you have to basically go over the entire state space.

00:03:09.000 --> 00:03:12.000
The fact that we wrote the universal plans is just

00:03:12.000 --> 00:03:15.000
a side effect of pursuing every possible combination.

00:03:15.000 --> 00:03:19.000
The moment the state space gets very large, dynamic programming doesn't scale.

00:03:19.000 --> 00:03:21.000
It's a big, open issue.

00:03:21.000 --> 00:03:23.000
Now, if you go to something like Google Maps, what you'll find is

00:03:23.000 --> 00:03:26.000
that you can do instant path planning between two points.

00:03:26.000 --> 00:03:31.000
What Google has been doing is pre-caching a lot of the principal sub-plans,

00:03:31.000 --> 00:03:37.000
so the remaining planning problem of finding the shortest path becomes mostly a table lookup.

00:03:37.000 --> 00:03:39.000
They've done this in a way that's actually optimal.

00:03:39.000 --> 00:03:41.000
They can prove it's optimal for path planning.

00:03:41.000 --> 00:03:45.000
It's really an amazing achievement that's way beyond A-star.

00:03:45.000 --> 00:03:48.000
The planning field is much more interesting than the lecture alluded.

00:03:48.000 --> 00:03:51.000
I just want to get your juices flowing to have you use one.

00:03:51.000 --> 00:03:53.000
Now, we did use A-star in our world,

00:03:53.000 --> 00:03:56.000
and the way we addressed re-planning in the current environment

00:03:56.000 --> 00:03:58.000
is that we just plan really, really fast.

00:03:58.000 --> 00:04:01.000
We had a version of A-star that was super fast.

00:04:01.000 --> 00:04:05.000
If we saw something new, it would just re-plan, and that was just fine for us.

00:04:05.000 --> 00:04:08.000
You mentioned something about dynamic programming just now,

00:04:08.000 --> 00:04:11.000
and a student had a very good question about that.

00:04:11.000 --> 00:04:14.000
How large is the planning policy for Junior?

00:04:14.000 --> 00:04:17.000
In Junior's case and the Google self-driving car cases,

00:04:17.000 --> 00:04:19.000
we don't do that much planning.

00:04:19.000 --> 00:04:23.000
We basically plan only within the visual horizon of the vehicle horizon of the vehicle itself.

00:04:23.000 --> 00:04:27.000
We don't address the problem of how to get from here to Paris or what streets to take

00:04:27.000 --> 00:04:29.000
We assume that's solved by Google Maps.

00:04:29.000 --> 00:04:34.000
We assume a fixed route in all our driving, but once the fixed route is speced out,

00:04:34.000 --> 00:04:38.000
all the planning that takes place is within the visual range of the robot.

00:04:38.000 --> 00:04:40.000
They are typically 3-dimensional state spaces.

00:04:40.000 --> 00:04:43.000
They're typically x, y, and orientation.

00:04:43.000 --> 00:04:47.000
Now, in some of our experiments we also use velocity as a state variable,

00:04:47.000 --> 00:04:51.000
because sometimes you want to take a little detour so you can straighten and be faster,

00:04:51.000 --> 00:04:54.000
but they are relatively low-dimensional spaces.

00:04:54.000 --> 00:05:00.000
Okay. Another question from George was about prohibitively expensive left turns.

00:05:00.000 --> 00:05:03.000
Are the costs of actions--are these a dynamic variable

00:05:03.000 --> 00:05:06.000
that's constantly being updated or are they static within the car?

00:05:06.000 --> 00:05:09.000
The way we've handled the cost of action is we have a version that looks

00:05:09.000 --> 00:05:14.000
at the global picture--like go from A to B and find the cost there--

00:05:14.000 --> 00:05:17.000
then zooming back to the local picture.

00:05:17.000 --> 00:05:21.000
And the local picture variable is to actually consider cars right now at this moment

00:05:21.000 --> 00:05:24.000
whereas in the global picture we assume a static world,

00:05:24.000 --> 00:05:27.000
and we make a fixed cost for left turns.

00:05:27.000 --> 00:05:30.000
Now, as we go to the local picture, we do a lot of local roll outs,

00:05:30.000 --> 00:05:33.000
local look-ahead plans--not dissimilar from A-star--

00:05:33.000 --> 00:05:38.000
and then fill in the actual cost of left turns and replace them with the assume cost.

00:05:38.000 --> 00:05:40.000
That's sometimes needs a different action.

00:05:40.000 --> 00:05:43.000
There situations where we are planning to do a lane shift but we can't

00:05:43.000 --> 00:05:45.000
because it's just too expensive right now.

00:05:45.000 --> 00:05:49.000
We'd rather endure being stuck behind a slower car until the lane shift is cleared.

00:05:49.000 --> 00:05:53.000
There's an interplay between two levels of planning going on.

00:05:53.000 --> 00:05:56.000
A student wants to know about multi-goal environments.

00:05:56.000 --> 00:06:00.000
An obvious example of a multi-goal environment would be a parking lot.

00:06:00.000 --> 00:06:02.000
I want to get to an empty parking spot.

00:06:02.000 --> 00:06:04.000
That's a great question I should've asked you the students,

00:06:04.000 --> 00:06:07.000
because it has a really nice and obvious answer, which is--here's the answer.

00:06:07.000 --> 00:06:11.000
In A-star, you can certainly designate multiple states to be goal states.

00:06:11.000 --> 00:06:15.000
Nothing prohibits this. You just have to make sure your heuristic is admissible.

00:06:15.000 --> 00:06:19.000
It takes a value that is underestimating or at least estimating correctly

00:06:19.000 --> 00:06:22.000
the distance to any of those goal states. Then it's just fine.

00:06:22.000 --> 00:06:25.000
The same is true for dynamic programming. You can certainly have multiple goal states there.

00:06:25.000 --> 00:06:29.000
Nothing in the formulation is a problem.

00:06:29.000 --> 00:06:32.000
Talking about heuristic functions, a student had a question,

00:06:32.000 --> 00:06:34.000
and I think a lot of people are wondering,

00:06:34.000 --> 00:06:39.000
since this is really where A-star gets its speed in the choice of the heuristic function,

00:06:39.000 --> 00:06:42.000
are they deduced algorithmically or are they just done with intuition or trial and error?

00:06:42.000 --> 00:06:44.000
How do we decide?

00:06:44.000 --> 00:06:47.000
That's a fantastic question.

00:06:47.000 --> 00:06:49.000
That's actually a really deep question as well.

00:06:49.000 --> 00:06:55.000
In the car domain, we actually calculate heuristic function,

00:06:55.000 --> 00:06:59.000
and we have two heuristic functions we kind of superimpose.

00:06:59.000 --> 00:07:03.000
Both of them get at the gist of the problem, but are much easier to compute.

00:07:03.000 --> 00:07:06.000
Suppose we have an environment with obstacles,

00:07:06.000 --> 00:07:10.000
and your planning space is 3-dimensional--your x, your y, and your orientation.

00:07:10.000 --> 00:07:13.000
One way to do your heuristic is to ignore the rotational degree of freedom

00:07:13.000 --> 00:07:16.000
and assume you're moving a disk in any direction.

00:07:16.000 --> 00:07:19.000
Obviously, moving a robot in any direction is easier

00:07:19.000 --> 00:07:22.000
than being constrained by the filters or the car.

00:07:22.000 --> 00:07:26.000
This becomes now a 2-dimensional problem, and by going from 3 dimensions to 2 dimensions,

00:07:26.000 --> 00:07:28.000
we can solve the entire problem in no time.

00:07:28.000 --> 00:07:35.000
We plan in 2D and use the 2D planning result as a heuristic for the 3D planner.

00:07:35.000 --> 00:07:38.000
The reason why it works is because 2D planning is so much faster than 3D planning.

00:07:38.000 --> 00:07:43.000
That's on that is basically ignoring the physical constraints of the car

00:07:43.000 --> 00:07:47.000
and going to a simpler car model which can move in any direction any time.

00:07:47.000 --> 00:07:53.000
The second heuristic we're using looks at the 3D problem but without obstacles.

00:07:53.000 --> 00:07:58.000
We can pre-plan the optimal action of a 3D robot that has turning constraints

00:07:58.000 --> 00:08:03.000
in the 3D space--x, y, and orientation--to any goal location in advance--

00:08:03.000 --> 00:08:07.000
we do this once and it's true forever--without any obstacles.

00:08:07.000 --> 00:08:11.000
What this gets us is that sometimes to get in a certain target orientation,

00:08:11.000 --> 00:08:13.000
you have to take a certain turn, and that turn has to be taken no matter what,

00:08:13.000 --> 00:08:15.000
and obstacles will only make it worse.

00:08:15.000 --> 00:08:18.000
If you compute this obstacle-free heuristic,

00:08:18.000 --> 00:08:20.000
you sort of get an underestimate that gets only worse with obstacles.

00:08:20.000 --> 00:08:22.000
You have an admissible heuristic.

00:08:22.000 --> 00:08:25.000
We toss both of their heuristics in as heuristics in A-star,

00:08:25.000 --> 00:08:30.000
and we get a speed-up of a planner easily of a factor of 10^10 in practice.

00:08:30.000 --> 00:08:32.000
That's very interesting. Great.

00:08:32.000 --> 00:08:34.000
So it's actually--I'm giving this as an example.

00:08:34.000 --> 00:08:38.000
I don't want you to really implement those right now, but that shows you how deep this question really is.

00:08:38.000 --> 00:08:41.000
If you can come up with good ways of cheating and solving

00:08:41.000 --> 00:08:44.000
the problem by lessening constraint and do it much faster,

00:08:44.000 --> 00:08:47.000
that tends to be a great heuristic for A-star.

00:08:47.000 --> 00:08:51.000
All right. Thanks a lot. We had a lot of great questions.

00:08:51.000 --> 00:08:53.000
I'm sure we'll have a lot next week.

00:08:53.000 --> 00:08:55.000
Can you give us a little preview of what's coming in Units 5 and 6?

00:08:55.000 --> 00:08:57.000
Yes, first I want to thank you for these questions.

00:08:57.000 --> 00:09:01.000
I really appreciate how deep they are, and how much you connect with the material.

00:09:01.000 --> 00:09:03.000
I think that's great.

00:09:03.000 --> 00:09:05.000
I honestly personally much prefer them over questions

00:09:05.000 --> 00:09:09.000
such as, "When can I buy my next self-driving car?"

00:09:09.000 --> 00:09:12.000
I think is really deep material I'm trying to teach you,

00:09:12.000 --> 00:09:14.000
and I love the fact that many of you are diving in and really deeply,

00:09:14.000 --> 00:09:18.000
because that's what I want to enable you to do, to apply it in a deep way.

00:09:18.000 --> 00:09:21.000
So keep these questions coming.

00:09:21.000 --> 00:09:26.000
In Unit 5 and 6 I'll dive into control.

00:09:26.000 --> 00:09:32.000
Control is now the art of turning these abstract, discrete, and chucky paths

00:09:32.000 --> 00:09:35.000
into actual steering motion.

00:09:35.000 --> 00:09:38.000
It's a continuous thing, because your steering is continuous, and time is continuous.

00:09:38.000 --> 00:09:42.000
We're going to go away from the discrete world and into the continuous world.

00:09:42.000 --> 00:09:46.000
In Unit 6 I try to toss everything together.

00:09:46.000 --> 00:09:52.000
In Unit 6 we program, hopefully, a robotic car with my help

00:09:52.000 --> 00:09:54.000
where we go all the way to localization at the same time

00:09:54.000 --> 00:09:56.000
and path planning at the same time and control

00:09:56.000 --> 00:10:01.000
and hopefully generate some actual trajectories by our simulated car.

00:10:01.000 --> 00:10:04.000
Can't wait. I'm sure the students feel the same way. Thanks a lot.

00:10:04.000 --> 00:10:07.000
See you in class.

