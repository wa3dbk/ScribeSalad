WEBVTT
Kind: captions
Language: en

00:00:00.330 --> 00:00:08.050
Given a behavior spec for a protocol say TCP/IP, can a stack be synthesized

00:00:08.050 --> 00:00:14.200
as a composition of the ensemble micro protocols? Given 60

00:00:14.200 --> 00:00:19.500
micro protocols in the ensemble suite, there are way too many combinations for a

00:00:19.500 --> 00:00:26.110
brute force approach. Instead. In the ensemble approach, the user heuristic

00:00:26.110 --> 00:00:29.736
algorithm for synthesizing the stack given

00:00:29.736 --> 00:00:34.342
the desired behavioral spec and designer's knowledge

00:00:34.342 --> 00:00:40.320
of the micro protocols. The result is a protocol stack which is functional, but

00:00:40.320 --> 00:00:43.389
not optimized for performance. Of course, as

00:00:43.389 --> 00:00:46.489
operating system designers, we're always worried about

00:00:46.489 --> 00:00:49.470
perf, performance. And we naturally have to

00:00:49.470 --> 00:00:51.410
think about how to optimize the protocol

00:00:51.410 --> 00:00:53.210
stack, so that it is not only

00:00:53.210 --> 00:00:57.110
functional, but also performant. In particular, the

00:00:57.110 --> 00:01:00.520
fact that we've assembled this protocol stack

00:01:00.520 --> 00:01:02.860
like Lego blocks. Putting together all these

00:01:02.860 --> 00:01:06.500
micro protocols leads to layering and layering

00:01:06.500 --> 00:01:09.690
leads to inefficiencies. Now this is where

00:01:09.690 --> 00:01:14.100
the analogy to VLSI component based design,

00:01:14.100 --> 00:01:16.680
breaks down. And the reason is because in

00:01:16.680 --> 00:01:19.280
VLSI component based design, even though we

00:01:19.280 --> 00:01:23.040
are building a complex chi, like a CPU.

00:01:23.040 --> 00:01:27.140
By putting together components, the components just

00:01:27.140 --> 00:01:29.370
fit together very nicely. There is, there is

00:01:29.370 --> 00:01:32.800
no inefficiency in going between these components.

00:01:32.800 --> 00:01:36.600
But in software components unfortunately, they have interfaces.

00:01:36.600 --> 00:01:39.058
And interfaces usually mean that, that there

00:01:39.058 --> 00:01:42.780
is well defined boundaries between these components and

00:01:42.780 --> 00:01:45.490
so to cross the component boundary, you may have

00:01:45.490 --> 00:01:49.350
to copy parameters at here to interface specifications of the

00:01:49.350 --> 00:01:52.660
components and so on. All of those things leads to

00:01:52.660 --> 00:01:57.200
inefficiencies and this where the VLSI component based design idea

00:01:57.200 --> 00:01:59.380
breaks down little bit when we just put together

00:01:59.380 --> 00:02:02.130
the components of software in order to build the, the

00:02:02.130 --> 00:02:04.660
large scale system. So we have to do the extra

00:02:04.660 --> 00:02:08.144
work that is needed in order to optimize the component-based

00:02:08.144 --> 00:02:11.650
design so that it can perform well. Fortunately there

00:02:11.650 --> 00:02:14.760
are several sources of optimization that are possible. For

00:02:14.760 --> 00:02:19.740
instance I mentioned that OCaml has implicit garbage collection.

00:02:19.740 --> 00:02:22.870
Now it is good that it has implicit garbage collection

00:02:22.870 --> 00:02:25.620
as a fall-back. But, maybe we don't want to use

00:02:25.620 --> 00:02:26.890
it all the time and we want to be

00:02:26.890 --> 00:02:29.620
explicit about how we manage our own memory that

00:02:29.620 --> 00:02:33.310
can be more efficient, that is a source of optimization.

00:02:33.310 --> 00:02:37.930
I mentioned that OCaml has ability for doing

00:02:37.930 --> 00:02:41.150
marshaling and unmarshaling of arguments to go across

00:02:41.150 --> 00:02:45.140
layers, but is also a very good thing to do, in order to have a component-based

00:02:45.140 --> 00:02:48.460
design. But, when you're going across layers, these

00:02:48.460 --> 00:02:51.550
things can add overheads and this is another

00:02:51.550 --> 00:02:54.800
source of optimization that is possible by avoiding

00:02:54.800 --> 00:02:58.790
these marshalling and unmarshalling across the layers but collapsing

00:02:58.790 --> 00:03:02.320
the layers. Another opportunity that exists especially in networking

00:03:02.320 --> 00:03:05.020
systems, is the fact that there's going to be

00:03:05.020 --> 00:03:08.580
communication and computation. If you think about TCPIP Protocol,

00:03:08.580 --> 00:03:11.400
it has to necessarily buffer the packets that it's sending

00:03:11.400 --> 00:03:14.180
out. Because if the packets are lost for some

00:03:14.180 --> 00:03:17.100
reason, it may have to re-transmit it. This is again,

00:03:17.100 --> 00:03:21.420
a situation where we can overlap this buffering which

00:03:21.420 --> 00:03:24.310
is computation on the node that is sending the packet

00:03:24.310 --> 00:03:26.940
with the actual transmission. So, we can overlap that.

00:03:26.940 --> 00:03:29.880
That's another opportunity for optimization.

00:03:29.880 --> 00:03:31.980
Another opportunity is compressing the

00:03:31.980 --> 00:03:35.380
header, especially when we have this layering, at every

00:03:35.380 --> 00:03:38.660
layer it might add a new header specific to that

00:03:38.660 --> 00:03:41.230
layer, and that may have common fields for instance,

00:03:41.230 --> 00:03:43.960
size of the packet or check sum for the packet

00:03:43.960 --> 00:03:46.230
and so on. Those are common things that you can

00:03:46.230 --> 00:03:49.340
eliminate when we are going across these layers. So the

00:03:49.340 --> 00:03:53.090
header compression is another possibility for optimization. Another thing

00:03:53.090 --> 00:03:56.280
that we always have to worry about, is making

00:03:56.280 --> 00:04:00.100
sure that the code that we execute fits in

00:04:00.100 --> 00:04:03.260
the caches and this has been something that we've talked

00:04:03.260 --> 00:04:05.620
about all along when we talked about single node

00:04:05.620 --> 00:04:09.500
systems to parallel systems. That locality enhancement, making sure that

00:04:09.500 --> 00:04:12.450
the working set of whatever code that is executing

00:04:12.450 --> 00:04:15.310
on a processor fits in the cache is very important.

00:04:15.310 --> 00:04:19.269
So, this again is an opportunity by identifying common

00:04:19.269 --> 00:04:22.440
code path across the different layers of the protocol

00:04:22.440 --> 00:04:26.780
stack, and co-locating that common code path across the

00:04:26.780 --> 00:04:29.610
layers. In order to make sure that we can

00:04:29.610 --> 00:04:33.170
enhance locality for processing is another source of optimization

00:04:33.170 --> 00:04:35.190
that is possible. This is all good. So there

00:04:35.190 --> 00:04:37.500
are lots of opportunities for optimization but do it

00:04:37.500 --> 00:04:40.470
by hand manually, that's tedious. So how do we

00:04:40.470 --> 00:04:44.790
automate the process of optimization so that we don't have to do it manually?

