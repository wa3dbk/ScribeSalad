WEBVTT
Kind: captions
Language: en

00:00:00.260 --> 00:00:04.213
One method of saving a GPU computations is to bake the lighting into the

00:00:04.213 --> 00:00:08.397
surfaces themselves. Say I have a scene with a bunch of a defused subjects, each

00:00:08.397 --> 00:00:12.562
with its own material color and with the surface normals stored at the vertices.

00:00:12.562 --> 00:00:16.724
If i can compute the shade of the object once and store this color instead of

00:00:16.724 --> 00:00:21.108
the normal. I can save on lighting calculations each frame. As before assume

00:00:21.108 --> 00:00:25.195
every light is very far away, but that it can change direction, just as the

00:00:25.195 --> 00:00:29.275
sun's angle to the ground changes direction over time. The vertex shader

00:00:29.275 --> 00:00:33.496
normally takes as input the position of the object, in other words, the vertex's

00:00:33.496 --> 00:00:37.445
location. And it also takes in the normal and lights that want to be applied to

00:00:37.445 --> 00:00:44.009
the surface. The output is the screen position and an RGB color. Instead of

00:00:44.009 --> 00:00:49.436
storing the surface normal, under what exact conditions could I safely compute

00:00:49.436 --> 00:00:54.592
the lighting once, and store an RGB color at each vertex? Your first choice is,

00:00:54.592 --> 00:01:00.763
if the object orientation does not change. By object orientation I mean whether

00:01:00.763 --> 00:01:07.655
the object is rotating. If the eye position and lights' directions do not change

00:01:07.655 --> 00:01:12.357
is your second choice. If the lights' directions and object orientation do not

00:01:12.357 --> 00:01:17.805
change. And finally if the eye position and object orientation do not change.

00:01:17.806 --> 00:01:24.364
So, which of these answers is the one that allows you to precompute an RGB per

00:01:24.364 --> 00:01:31.293
vertex and use that, instead of having to do lighting calculations each frame?

