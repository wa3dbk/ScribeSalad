WEBVTT
Kind: captions
Language: en

00:00:00.033 --> 00:00:01.918
Now you know what this is really useful for?

00:00:01.918 --> 00:00:05.497
Sometimes you need to perform a computation on a really big hunk of data,

00:00:05.497 --> 00:00:08.653
maybe so big that it won't even fit into the GPU memory.

00:00:08.653 --> 00:00:14.176
No problem, you say. I'll break up the data into chunks that will fit on GPU memory.

00:00:14.176 --> 00:00:19.763
I'll copy each chunk over, do my processing, and then copy each chunk back.

00:00:19.763 --> 00:00:22.938
Then I'll do the same thing with the next chunk and so on.

00:00:22.938 --> 00:00:26.236
And this will work fine, and it will get the job done.

00:00:26.236 --> 00:00:31.310
But the problem is if this is a high-end GPU, it can easily have several gigabytes of memory.

00:00:31.310 --> 00:00:36.046
And so these copy operations where you're copying several gigabytes of data,

00:00:36.046 --> 00:00:41.115
enough to fill the GPU memory, do your processing, and then copying several gigabytes of data back,

00:00:41.115 --> 00:00:43.629
these copy operations can end up taking a significant amount of the time

00:00:43.629 --> 00:00:45.275
of your total computation.

00:00:45.275 --> 00:00:46.968
You see our problem.

00:00:46.968 --> 00:00:51.194
If this is the timeline, we spend some time copying, then we spend some time processing,

00:00:51.194 --> 00:00:55.399
then we spend some time copying back, and the process repeats.

00:00:55.399 --> 00:00:58.357
So here's where asynchronous copies can come to the rescue.

00:00:58.357 --> 00:01:02.777
Instead, we can break up our data into chunks that are half the size

00:01:02.777 --> 00:01:06.570
and we can do an asynchronous copy, filling half the GPU.

00:01:06.570 --> 00:01:10.968
Then we can launch some kernels on the GPU to start processing that data

00:01:10.968 --> 00:01:16.113
and immediately do another asynchronous copy, filling the rest of the GPU data,

00:01:16.113 --> 00:01:19.361
and immediately start processing that data.

00:01:19.361 --> 00:01:22.301
When the first chunk of data completes, we'll copy it back

00:01:22.301 --> 00:01:28.036
and start copying the next half size chunk of data, all while this one is still completing.

00:01:28.036 --> 00:01:29.378
So you get the idea.

00:01:29.378 --> 00:01:31.971
We're going to copy over half the data at a time

00:01:31.971 --> 00:01:36.112
and immediately start processing it while we copy the next half of the data.

00:01:36.112 --> 00:01:38.271
Now the timeline looks like this.

00:01:38.271 --> 00:01:45.072
And the important point is that we're managing to overlap data transfers and computation.

