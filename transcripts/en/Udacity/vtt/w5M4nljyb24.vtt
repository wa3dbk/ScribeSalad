WEBVTT
Kind: captions
Language: en

00:00:00.240 --> 00:00:03.370
Now if you look at the memory footprint of

00:00:03.370 --> 00:00:06.650
a process. And the amount of time it takes to

00:00:06.650 --> 00:00:10.280
load all of its working sect into the cache.

00:00:10.280 --> 00:00:13.190
The, the bigger the memory footprint, the more time it's

00:00:13.190 --> 00:00:16.760
going to take for the processor to get the working

00:00:16.760 --> 00:00:19.900
set of a particular thread into the cache. So that

00:00:19.900 --> 00:00:22.160
the cache is warm enough, and the process of

00:00:22.160 --> 00:00:25.390
the thread can do its work. Without having to have

00:00:25.390 --> 00:00:30.380
those hiccups where it has to go to the memory in order to fetch the contents in

00:00:30.380 --> 00:00:33.330
the cache. So what this suggests is that it's

00:00:33.330 --> 00:00:37.430
important to pay attention to cache affinity in scheduling.

00:00:37.430 --> 00:00:39.950
And so the variance of cache affinity scheduling

00:00:39.950 --> 00:00:42.910
that we talked about are all excellent candidates to

00:00:42.910 --> 00:00:45.990
run on a multiprocessor. And in fact, the minimum

00:00:45.990 --> 00:00:50.850
intervention, or minimum intervening scheduling policy, and the minimum

00:00:50.850 --> 00:00:54.460
intervening scheduling with queuing, both of those are

00:00:54.460 --> 00:00:57.890
very good policies to use when you have a

00:00:57.890 --> 00:01:02.060
fairly light to medium load on a multiprocessor.

00:01:02.060 --> 00:01:05.400
Because that is the time when it is likely

00:01:05.400 --> 00:01:09.730
that a thread, when it is run on a processor, if it has an affinity for that

00:01:09.730 --> 00:01:12.530
particular processor, the contents of the cache are going

00:01:12.530 --> 00:01:16.890
to contain the memory contents for that particular thread.

00:01:16.890 --> 00:01:19.070
But on the other hand, if you have a very

00:01:19.070 --> 00:01:22.960
heavy load in the system, then it is likely that

00:01:22.960 --> 00:01:26.260
by the time a thread is run on a processor,

00:01:26.260 --> 00:01:30.200
on which it supposedly having an affinity, all of the

00:01:30.200 --> 00:01:32.110
cache may have been polluted because the load is very

00:01:32.110 --> 00:01:35.200
heavy. So, in between the time that a thread got

00:01:35.200 --> 00:01:37.900
run on a particular processor, next time it runs on

00:01:37.900 --> 00:01:42.040
the same processor, maybe it's cache contents have been highly polluted

00:01:42.040 --> 00:01:44.250
by other threads. And therefore, if the load

00:01:44.250 --> 00:01:48.340
is very heavy then maybe a fixed processor scheduling

00:01:48.340 --> 00:01:51.280
may work out to be much better than

00:01:51.280 --> 00:01:55.300
the variants of minimum intervening scheduling policies. So, the

00:01:55.300 --> 00:01:57.680
moral of the story is that you really

00:01:57.680 --> 00:02:01.230
have to pay attention to both how heavily loaded

00:02:01.230 --> 00:02:04.760
your processor is, or system is and also what

00:02:04.760 --> 00:02:07.080
is the kind of workload that you are catering

00:02:07.080 --> 00:02:09.370
to, both those things play a part in

00:02:09.370 --> 00:02:11.830
deciding what what we will be best scheduling policy

00:02:11.830 --> 00:02:13.740
and it may not always be the case

00:02:13.740 --> 00:02:17.730
that the same scheduling policy applies in all circumstances.

00:02:17.730 --> 00:02:21.350
So, a real agile operating system may choose

00:02:21.350 --> 00:02:25.080
to vary the scheduling policy based on the load

00:02:25.080 --> 00:02:29.020
as well as the current set of threads that

00:02:29.020 --> 00:02:32.230
need to run on the system. Another interesting wrinkle

00:02:32.230 --> 00:02:35.420
to taking a scheduling policy is the idea of

00:02:35.420 --> 00:02:40.660
procrastination. And that is, normally we think of the scheduler

00:02:40.660 --> 00:02:43.060
when the processor is looking for work, it's going

00:02:43.060 --> 00:02:45.280
to the, to the run queue and saying well I

00:02:45.280 --> 00:02:47.350
need to, to do something.and let me pick the

00:02:47.350 --> 00:02:51.170
next thread to run on myself. That's what a processor

00:02:51.170 --> 00:02:54.790
is going to do. Perhaps procrastination may help. Why would

00:02:54.790 --> 00:02:58.700
procrastination help? First of all, how do we implement procrastination?

00:02:58.700 --> 00:03:01.000
Well, what the processor can do is, it is actually

00:03:01.000 --> 00:03:03.830
ready to do, do some work. Now, what it does

00:03:03.830 --> 00:03:06.680
is it, it's going to insert an idle loop. Why would

00:03:06.680 --> 00:03:09.930
it insert an idle loop? It'll insert an idle loop

00:03:09.930 --> 00:03:13.400
because it has, it's looking in the, the scheduling queue

00:03:13.400 --> 00:03:16.350
and it sees that there is no thread in the

00:03:16.350 --> 00:03:20.620
scheduling queue that has run on it before. And therefore,

00:03:20.620 --> 00:03:23.820
if it schedules any one of those threads though all

00:03:23.820 --> 00:03:26.860
of those threads are not going to find any of

00:03:26.860 --> 00:03:29.880
their working set in the cache of the processor.

00:03:29.880 --> 00:03:31.870
And therefore the processor says okay, now let me

00:03:31.870 --> 00:03:35.630
just spin my wheels for a while, not schedule anything.

00:03:35.630 --> 00:03:38.670
It is likely that a thread that has its

00:03:38.670 --> 00:03:42.580
cache content in that processor becomes runable again. And

00:03:42.580 --> 00:03:45.220
then you can schedule that, and that might be

00:03:45.220 --> 00:03:48.510
a win, in terms of performance. So in other words,

00:03:48.510 --> 00:03:51.110
procrastination may help boost performance. We saw that

00:03:51.110 --> 00:03:54.800
already in the synchronization algorithms where we talked about

00:03:54.800 --> 00:03:58.460
inserting delays in the scheduling algorithm in order to

00:03:58.460 --> 00:04:00.590
reduce the amount of contention in the connection of

00:04:00.590 --> 00:04:03.070
the network. It's the same sort of principle. Often

00:04:03.070 --> 00:04:07.390
times you'll see in system design, procrastination actually helps

00:04:07.390 --> 00:04:11.360
in boosting performance. It helps in the synchronizational rhythms,

00:04:11.360 --> 00:04:13.580
it helps in scheduling and later on when we

00:04:13.580 --> 00:04:15.810
talk about file systems you'll see that it

00:04:15.810 --> 00:04:17.579
helps in the design of file systems also.

