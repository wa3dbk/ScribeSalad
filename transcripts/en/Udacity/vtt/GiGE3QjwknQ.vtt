WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.205
Let's scroll up a little more to look at the second half of the problem.

00:00:03.205 --> 00:00:06.209
Now, that we've got all the preliminaries out of the way,

00:00:06.209 --> 00:00:08.711
how do we actually launch a kernel on the GPU?

00:00:08.711 --> 00:00:13.183
Here's a new piece of syntax in Cuda, the Cudalaunch operator.

00:00:13.183 --> 00:00:18.099
the Cuda launch operator is indicated by these three less than signs

00:00:18.099 --> 00:00:21.916
and these three greater than signs with some parameters in the middle.

00:00:21.916 --> 00:00:26.930
This line says launch the kernel name square on one block of 64 elements.

00:00:26.930 --> 00:00:32.869
Then the arguments to the kernel are two pointers, d out and d in.

00:00:32.869 --> 00:00:40.377
This code tells the CPU to launch on the GPU 64 copies of the kernel on 64 threads.

00:00:40.377 --> 00:00:45.429
Note that we can only call the kernel on GPU data, not CPU data.

00:00:45.429 --> 00:00:49.084
Since we named our GPU data to start with d_,

00:00:49.084 --> 00:00:52.082
we can visually see that we've done the right thing.

00:00:52.082 --> 00:00:57.193
Then when we're done with the kernel, the results are in d_out on the GPU,

00:00:57.193 --> 00:01:03.633
and this cudaMemcpy call will move memory from device to host and place it in h_out.

00:01:03.633 --> 00:01:06.370
The next thing we do is print it out, okay?

00:01:06.370 --> 00:01:09.410
We're just walking through the h_out array.

00:01:09.410 --> 00:01:11.119
We're printing four things per line.

00:01:11.119 --> 00:01:13.986
We're putting tabs in and then a new line after 4,

00:01:13.986 --> 00:01:17.762
and then we free the memory that we allocated on the GPU and return 0.

00:01:17.762 --> 00:01:19.527
That's all the CPU code.

00:01:19.527 --> 00:01:23.834
There's a fair amount in boilerplate in here. It looks fairly similar for most programs.

00:01:23.834 --> 00:01:27.361
Most programs are going to have you create some data on the CPU,

00:01:27.361 --> 00:01:29.608
allocate some data on the GPU,

00:01:29.608 --> 00:01:31.747
copy memory from CPU to GPU,

00:01:31.747 --> 00:01:34.378
launch some kernels that will run on the GPU,

00:01:34.378 --> 00:01:36.648
copy the results back to the CPU,

00:01:36.648 --> 00:01:39.612
and then continue to process them, print them, and so on.

