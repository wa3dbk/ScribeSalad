WEBVTT
Kind: captions
Language: en

00:00:00.430 --> 00:00:03.690
Clustered object offers several advantages. First of

00:00:03.690 --> 00:00:06.320
all, the object reference is the same on

00:00:06.320 --> 00:00:09.330
all the nodes, so that's very very important.

00:00:09.330 --> 00:00:12.800
Regardless of which node a particular server is

00:00:12.800 --> 00:00:16.400
executing, they all have the same object reference.

00:00:16.400 --> 00:00:19.020
But under the covers, you can now have

00:00:19.020 --> 00:00:23.270
incremental optimization of the implementation of the object.

00:00:23.270 --> 00:00:25.940
According on the usage pattern, you can have

00:00:25.940 --> 00:00:28.240
different levels of replication of the same

00:00:28.240 --> 00:00:31.920
object, so it allows for incremental optimization. And

00:00:31.920 --> 00:00:35.150
you can also have different implementations of

00:00:35.150 --> 00:00:38.880
the same object, depending on the usage pattern.

00:00:38.880 --> 00:00:40.870
And it also allows for the potential

00:00:40.870 --> 00:00:45.500
for dynamic adaptations of the representations. The advantage

00:00:45.500 --> 00:00:47.570
of course of the replication is that, the

00:00:47.570 --> 00:00:52.990
object references can access the respective replicas independently.

00:00:52.990 --> 00:00:55.438
And this means that you have less locking of

00:00:55.438 --> 00:00:59.220
shared data structures. Let's think about the process object

00:00:59.220 --> 00:01:01.698
as a concrete example. So if you think about

00:01:01.698 --> 00:01:04.194
the process object, it's one per CPU and with

00:01:04.194 --> 00:01:07.732
mostly read only. And, and therefore page fault handling

00:01:07.732 --> 00:01:11.008
can start on all of these different processors, independent

00:01:11.008 --> 00:01:14.060
of one another. And if they touch different regions

00:01:14.060 --> 00:01:18.260
of the address space, then the path taken by the

00:01:18.260 --> 00:01:22.070
page fault handling for all these different threads can be

00:01:22.070 --> 00:01:25.080
different. So what that means is that, page fault handling

00:01:25.080 --> 00:01:28.280
for instance, will scale in this case using this as

00:01:28.280 --> 00:01:31.870
a concrete service with the number of processes. It'll scale to

00:01:31.870 --> 00:01:34.656
the number of processes. And this is important because, page

00:01:34.656 --> 00:01:37.500
fault handling is something that is going to happen often, and so

00:01:37.500 --> 00:01:39.880
you want to make sure it scales with the number of

00:01:39.880 --> 00:01:43.380
processes. On the other hand, if we want to get rid

00:01:43.380 --> 00:01:46.120
of a region, then the destruction of region

00:01:46.120 --> 00:01:49.220
may take more time because the region may

00:01:49.220 --> 00:01:52.610
have multiple representations, and all of the representations

00:01:52.610 --> 00:01:56.180
of that particular region has to be gotten

00:01:56.180 --> 00:01:58.210
rid of. And so destruction of a region

00:01:58.210 --> 00:02:00.980
may take more time but that's okay because

00:02:00.980 --> 00:02:03.640
you don't expect region destructions to happen as

00:02:03.640 --> 00:02:08.430
often as handling page faults to service the ongoing

00:02:08.430 --> 00:02:11.838
needs of the thread. So, the principle again is to make sure

00:02:11.838 --> 00:02:15.030
that the common case is optimized, the common case is page fault

00:02:15.030 --> 00:02:20.250
handling. Region creation, region destruction. All of those things happen

00:02:20.250 --> 00:02:25.530
more rarely and it is okay if those functionalities take a little bit more time.

