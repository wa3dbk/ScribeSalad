WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.440
Interviewer: So this is really interesting and very powerful, but it raises a lot of questions

00:00:04.440 --> 00:00:08.189
that certainly deal with intercepting people's cellular communication

00:00:08.189 --> 00:00:12.000
could be used for evil. Presumably you're not using it for evil.

00:00:12.000 --> 00:00:14.170
So what's the motivation for doing this and

00:00:14.170 --> 00:00:18.410
and kind of how can you do this in an ethical way?

00:00:18.410 --> 00:00:22.290
Carson: We're clearly not doing this to do evil ourselves.

00:00:22.290 --> 00:00:27.380
However, we do this because it is already used to do evil by others.

00:00:27.380 --> 00:00:33.700
For at least 10 years industrial-scale GSM cracking equipment has been available

00:00:33.700 --> 00:00:38.120
and there's been very little talk about the system so far.

00:00:38.120 --> 00:00:44.100
So this is an attempt to shine that light onto evil that is ongoing

00:00:44.100 --> 00:00:49.590
spying on citizens, spying on host countries from embassies

00:00:49.590 --> 00:00:56.590
spying in war zones on civilian populations that we want to uncover

00:00:56.590 --> 00:01:02.020
and the result of this discussion that we've been having very publicly

00:01:02.020 --> 00:01:06.210
was to GSM networks over the past two years is hopefully that these networks

00:01:06.210 --> 00:01:11.400
now implement protections against what they perceive mostly as a publicity threat.

00:01:11.400 --> 00:01:16.400
Because we are not actually doing anything evil but we say we could.

00:01:16.400 --> 00:01:22.790
It is the ultimate convincing argument that you can intercept

00:01:22.790 --> 00:01:26.290
the phones of even the phone company's executives.

00:01:26.290 --> 00:01:31.540
So the ethical part of hacking includes both not doing evil

00:01:31.540 --> 00:01:37.980
but convincing everybody to do the counter, in this case deploy

00:01:37.980 --> 00:01:43.020
technical countermeasures or at least to warn customers that cellphones

00:01:43.020 --> 00:01:47.110
are not as secure as companies would like them to be.

00:01:47.110 --> 00:01:49.330
It always hard to say what would have happened had we not done this

00:01:49.330 --> 00:01:54.370
but it may be time coincidental, it may be because of this research

00:01:54.370 --> 00:01:59.310
networks are starting to upgrade or have been upgraded these past years.

00:01:59.310 --> 00:02:06.160
More in newer networks, that is everywhere outside of the western world

00:02:06.160 --> 00:02:12.590
but also in Europe and hopefully the US soon will start rolling out countermeasures.

00:02:12.590 --> 00:02:16.350
Often times they find that these countermeasures are little more than

00:02:16.350 --> 00:02:22.470
configuration changes, software patches, things that are overdue for many years.

00:02:22.470 --> 00:02:27.350
Technology twenty years old that has been upgraded many times

00:02:27.350 --> 00:02:32.100
adding MMS and fast-internet connections and visual voice mail

00:02:32.100 --> 00:02:35.650
and all these things but the security hasn't been patched, even once.

00:02:35.650 --> 00:02:38.070
Same works for the T-Mobile network here.

00:02:38.070 --> 00:02:42.820
Same works against every network in Europe right now

00:02:42.820 --> 00:02:47.340
pretty much every network outside of Europe. A few have been patched now.

00:02:47.340 --> 00:02:51.660
The most secure network that we have seen recently was in Egypt.

00:02:51.660 --> 00:02:57.260
Given that it's now not just defending your customers from ongoing evil

00:02:57.260 --> 00:03:00.940
but also a possible publicity threat you're avoiding

00:03:00.940 --> 00:03:05.580
there's a lot to gain for the networks and at the same it doesn't cost them very much.

00:03:05.580 --> 00:03:12.410
So it just took a few research years to create the information base for them to act upon.

00:03:12.410 --> 00:03:14.680
Interviewer: Thanks very much, Carson, this has been really interesting

00:03:14.680 --> 00:03:17.940
and very cool what you showed us, thanks. Carson: Thank you.

