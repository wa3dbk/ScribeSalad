WEBVTT
Kind: captions
Language: en

00:00:00.080 --> 00:00:01.640
We're going to talk
a little more about this.

00:00:01.640 --> 00:00:04.430
But, basically,
what I just talked about, for example,

00:00:04.430 --> 00:00:08.100
whether you're doing the whole histogram
the histogram of the whole image,

00:00:08.100 --> 00:00:10.470
which doesn't work very well,
but you could do it.

00:00:10.470 --> 00:00:15.460
Or if you build like these orientations
of gradients in each of the quadrants,

00:00:15.460 --> 00:00:18.720
you're building a model,
a description of that instance.

00:00:18.720 --> 00:00:21.420
By the way, you take each of those four,
those histograms before and

00:00:21.420 --> 00:00:24.320
you just string them into one
great big feature vector.

00:00:24.320 --> 00:00:26.240
That's your description.

00:00:26.240 --> 00:00:29.020
So now what you have to
do is you have train, or

00:00:29.020 --> 00:00:32.170
sometimes referred to as learn,
a classifier.

00:00:32.170 --> 00:00:36.140
Given a bunch of those feature vectors
describing koalas and given a bunch of

00:00:36.140 --> 00:00:40.760
them describing pandas, figure out how
to discriminate one from the other.

00:00:40.760 --> 00:00:43.650
So here's the basic description,
all right?

00:00:43.650 --> 00:00:47.940
So let's suppose we're trying
to learn cars versus not cars.

00:00:47.940 --> 00:00:49.660
So how many classes is that?

00:00:49.660 --> 00:00:50.610
&gt;&gt; Two.

00:00:50.610 --> 00:00:52.740
&gt;&gt; Sorry, how many classes are that?

00:00:53.980 --> 00:00:54.780
How many is that?

00:00:55.790 --> 00:00:56.620
It is six.

00:00:56.620 --> 00:00:59.530
There are six classes, but
the number of classes is six.

00:00:59.530 --> 00:01:01.730
Actually, the number of classes is two.

00:01:01.730 --> 00:01:02.340
I don't know.

00:01:02.340 --> 00:01:06.340
It's called a binary classifier,
because there are two classes.

00:01:06.340 --> 00:01:09.602
So, for example, suppose I have
a little picture here of a car, and

00:01:09.602 --> 00:01:11.042
I have to decide, is it a car?

00:01:11.042 --> 00:01:12.834
And what do you think,
you think that's a car?

00:01:12.834 --> 00:01:13.400
&gt;&gt; Yes.

00:01:13.400 --> 00:01:14.167
&gt;&gt; Good, she got it right.

00:01:14.167 --> 00:01:14.690
Yes.

00:01:14.690 --> 00:01:15.750
It's a car.

00:01:15.750 --> 00:01:16.583
Okay?

00:01:16.583 --> 00:01:18.120
Now here's another picture.

00:01:18.120 --> 00:01:19.299
Okay?

00:01:19.299 --> 00:01:20.630
Taken.

00:01:20.630 --> 00:01:22.542
Oh, somewhere in China I think?

00:01:22.542 --> 00:01:23.460
I don't remember where.

00:01:23.460 --> 00:01:24.010
Sorry.

00:01:24.010 --> 00:01:25.375
So, is that a car or not a car?

00:01:25.375 --> 00:01:26.610
&gt;&gt; No.
&gt;&gt; No.

00:01:26.610 --> 00:01:27.410
Very good.

00:01:27.410 --> 00:01:30.480
What we need are methods of doing that.

00:01:30.480 --> 00:01:33.696
Now, there has been a huge
effort in machine learning and

00:01:33.696 --> 00:01:37.783
applied to computer vision over
the last really 15, 20 years,

00:01:37.783 --> 00:01:41.360
of methods of doing
discriminative classification.

00:01:41.360 --> 00:01:43.620
What you see listed here
are a whole bunch of methods,

00:01:43.620 --> 00:01:48.370
a couple of references below them
of how to go about doing that.

00:01:48.370 --> 00:01:50.120
We're going to talk about three of them.

00:01:50.120 --> 00:01:53.440
I've just highlighted them here,
nearest neighbor, SVMs, boosting.

00:01:53.440 --> 00:01:55.725
There are others as well.

00:01:55.725 --> 00:01:59.840
[COUGH] the general approach, and
there's a huge literature on this now,

00:01:59.840 --> 00:02:03.820
especially with these large scale
object recognition competitions, of

00:02:03.820 --> 00:02:07.740
what's the best feature vector you can
use, learning different feature vectors,

00:02:07.740 --> 00:02:09.758
sparse representations,
a bunch of other things.

00:02:09.758 --> 00:02:11.600
And then, given those representations,

00:02:11.600 --> 00:02:14.930
what are the methods that you should
use to make the classification?

00:02:14.930 --> 00:02:16.590
Here are the three that
we're going to talk about.

00:02:16.590 --> 00:02:19.330
If you take more machine learning,
just remember later

00:02:19.330 --> 00:02:23.940
you could apply those methods
to those other representations.

00:02:23.940 --> 00:02:29.180
Our fundamental assumption
is going to be someone and

00:02:29.180 --> 00:02:31.330
hopefully that's somebody
you don't have to pay.

00:02:31.330 --> 00:02:35.040
But somebody's going to give you
a database of lots of examples of

00:02:35.040 --> 00:02:36.720
the things you want to find and

00:02:36.720 --> 00:02:39.875
lots of examples of the things
you don't want to find.

00:02:39.875 --> 00:02:42.860
And then you're going to
train the classifier.

00:02:42.860 --> 00:02:46.680
Now once you do that, you have to
come up with some way of test,

00:02:46.680 --> 00:02:47.800
given some new image.

00:02:47.800 --> 00:02:48.930
How do you test it?

00:02:48.930 --> 00:02:51.490
So remember we talked about you have
to generate these new candidates and

00:02:51.490 --> 00:02:52.890
you have to score them.

00:02:52.890 --> 00:02:55.042
So here's the basic idea.

00:02:55.042 --> 00:02:57.346
You start off with a window,
and then, and

00:02:57.346 --> 00:03:00.100
Kristen is really good at
this animation, right?

00:03:00.100 --> 00:03:03.120
And you might take that window
of a particular size, and

00:03:03.120 --> 00:03:04.940
you scan it all over.

00:03:04.940 --> 00:03:07.955
And what you do is you apply your car,

00:03:07.955 --> 00:03:12.180
non-car classifier to every
one of those windows.

00:03:12.180 --> 00:03:13.170
And you say do I see any cars?

00:03:13.170 --> 00:03:13.760
Do I see any cars?

00:03:13.760 --> 00:03:15.140
Do I see any cars?

00:03:15.140 --> 00:03:18.060
Not very clever, but
it just works very well.

00:03:18.060 --> 00:03:19.840
Right?
Because the classifiers are quick and

00:03:19.840 --> 00:03:20.990
they're accurate.

00:03:20.990 --> 00:03:23.985
So, as opposed to having a different
way of trying to do detection versus

00:03:23.985 --> 00:03:27.790
labeling, I, basically,
do detection by labeling.

00:03:27.790 --> 00:03:29.350
There is a problem, of course, though.

00:03:29.350 --> 00:03:30.590
I picked a window.

00:03:30.590 --> 00:03:33.370
Well, suppose I'm nearer to a car.

00:03:33.370 --> 00:03:36.300
Does the picture get,
of the car get bigger or smaller?

00:03:36.300 --> 00:03:37.290
That one's an easy one Megan.

00:03:37.290 --> 00:03:40.570
If I get car, bigger does,
closer does it look bigger or smaller?

00:03:40.570 --> 00:03:41.070
&gt;&gt; Bigger.

00:03:41.070 --> 00:03:42.180
&gt;&gt; Bigger, very good.

00:03:42.180 --> 00:03:43.380
So what do I have to do?

00:03:43.380 --> 00:03:45.890
Well I just have to try bigger windows.

00:03:45.890 --> 00:03:48.220
And I slide those all over the place.

00:03:48.220 --> 00:03:50.520
And if this feels kind of
date intensive, you're right.

00:03:50.520 --> 00:03:52.140
And there's various tricks to doing it.

00:03:52.140 --> 00:03:55.030
But that's the general idea is that you
take these different sized windows and

00:03:55.030 --> 00:03:57.310
you apply them to different
places in the image.

