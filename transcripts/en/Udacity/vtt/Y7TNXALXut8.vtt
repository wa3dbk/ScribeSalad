WEBVTT
Kind: captions
Language: en

00:00:00.170 --> 00:00:02.200
So let's take our conversation about the validity of field

00:00:02.200 --> 00:00:05.676
values a little further and look at auditing a cross-field

00:00:05.676 --> 00:00:08.380
constraint. So, remember this is a constraint where we have

00:00:08.380 --> 00:00:11.640
multiple fields per item, that must be in agreement in some

00:00:11.640 --> 00:00:14.960
way. Once again, let's look at a Wikipedia page for

00:00:14.960 --> 00:00:18.290
city. In this case Bern in the country of Switzerland.

00:00:18.290 --> 00:00:20.330
So here we have a nice example of a city

00:00:20.330 --> 00:00:26.940
that has values for population, area and one for population density.

00:00:26.940 --> 00:00:29.450
Any time you have a situation like this, where

00:00:29.450 --> 00:00:32.790
you can essentially check at least one field against

00:00:32.790 --> 00:00:35.310
another, you have a nice way of validating field

00:00:35.310 --> 00:00:40.010
values throughout your entire dataset. So, the cross-field constraint here

00:00:40.010 --> 00:00:42.920
is that population divided by area gives us the

00:00:42.920 --> 00:00:46.570
population density. And we'll employ this as one check

00:00:46.570 --> 00:00:50.040
in auditing our data for the city's collection. So

00:00:50.040 --> 00:00:52.390
here I've written a little program to do exactly that.

00:00:52.390 --> 00:00:55.300
And it does something like calculate the population density based

00:00:55.300 --> 00:00:59.920
on the individual values for population and area. And compare that

00:00:59.920 --> 00:01:04.410
to the population density specified within the dataset itself. And we're

00:01:04.410 --> 00:01:06.080
just going to make sure the difference isn't more than ten to

00:01:06.080 --> 00:01:09.750
account for rounding errors and that sort of thing. Now,

00:01:09.750 --> 00:01:11.870
this is just a first pass of this and just an

00:01:11.870 --> 00:01:13.600
example to show you the type of thing that we might

00:01:13.600 --> 00:01:17.030
do in auditing a cross-field constraint. All right, let's run this.

00:01:18.170 --> 00:01:21.630
We should only see output here. Yep. And we've got a number

00:01:21.630 --> 00:01:24.180
of bad population densities or possibly

00:01:24.180 --> 00:01:26.810
bad population densities. So what I usually

00:01:26.810 --> 00:01:29.880
do in situations like this is, I pick one and I basically just

00:01:29.880 --> 00:01:32.080
go look at the data and see if I can figure out what's

00:01:32.080 --> 00:01:35.100
going on. Okay, this one stood out to me, so let's go take

00:01:35.100 --> 00:01:37.530
a look at that. Now, in the interest of time, I've already pulled

00:01:37.530 --> 00:01:40.770
this one up in our original dataset. And I've actually hidden some of

00:01:40.770 --> 00:01:43.490
the fields here, so it's easier to see the values that we actually

00:01:43.490 --> 00:01:46.360
care about in this case. So, here's the area

00:01:46.360 --> 00:01:50.990
field, populationDensity and the populationTotal. Now what we want is

00:01:50.990 --> 00:01:54.480
for this value divided by this value to be pretty

00:01:54.480 --> 00:01:57.310
close to this value. And if you look at this,

00:01:57.310 --> 00:01:59.560
you can see that there's no way that can possibly

00:01:59.560 --> 00:02:03.150
happen given the size of this. Okay and as I

00:02:03.150 --> 00:02:06.035
look at the rest of these values here. I also

00:02:06.035 --> 00:02:09.192
see some values that appear to me to be impossibly

00:02:09.192 --> 00:02:12.479
large as the area of land for a given city. Especially

00:02:12.479 --> 00:02:14.816
given that when I look at the Wikipedia page and as

00:02:14.816 --> 00:02:17.552
I look at Wikipedia pages for other cities, I notice that

00:02:17.552 --> 00:02:21.329
area is actually measured in square kilometers. So there's no way

00:02:21.329 --> 00:02:24.946
I have this many square kilometers. However if I look at

00:02:24.946 --> 00:02:27.826
Yoakum, Texas, I can see that it's value for area is

00:02:27.826 --> 00:02:31.650
12 square kilometers. My guess is that this is a rounded

00:02:31.650 --> 00:02:34.310
value. If I go back and look at this data and

00:02:34.310 --> 00:02:38.010
if I interpret this instead of kilometers as not

00:02:38.010 --> 00:02:42.450
even meters, but millimeters then this makes sense. Now from

00:02:42.450 --> 00:02:45.020
my perspective having a land area specified in millimeters is

00:02:45.020 --> 00:02:47.845
a little crazy. But I can see reasons why the

00:02:47.845 --> 00:02:50.730
dbpedia folks might have set things up that way. But

00:02:50.730 --> 00:02:52.530
if I think about shifting the decimal point for this

00:02:52.530 --> 00:02:56.710
value appropriately so, that it describes square kilometers, instead of

00:02:56.710 --> 00:02:59.468
square millimeters. Then I end up with a value that's

00:02:59.468 --> 00:03:04.060
11.7 square kilometers, which is pretty close to this value, right

00:03:04.060 --> 00:03:07.570
here. And these values were collected some time ago. So, I'm

00:03:07.570 --> 00:03:10.710
willing to bet that our problem here, that we're seeing in

00:03:10.710 --> 00:03:14.680
auditing this cross-field constraint. Is really one of having made a faulty

00:03:14.680 --> 00:03:17.550
assumption about the land area. And that in fact is what

00:03:17.550 --> 00:03:20.030
the problem is. And now of course, in order to verify

00:03:20.030 --> 00:03:21.870
this, we'd want to look through a number of other fields

00:03:21.870 --> 00:03:24.640
here. And actually maybe do a bit of Googling around to really

00:03:24.640 --> 00:03:28.200
be sure that is exactly what's going on here. And that it's

00:03:28.200 --> 00:03:30.555
just an issue of units as opposed to an actual problem with the

00:03:30.555 --> 00:03:34.600
cross-field constraint, that we know has to exist between these three fields.

00:03:34.600 --> 00:03:36.100
And that's an example of auditing

00:03:36.100 --> 00:03:38.624
a cross-field constraint in our Cities dataset.

