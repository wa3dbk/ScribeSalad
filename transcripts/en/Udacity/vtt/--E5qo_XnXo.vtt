WEBVTT
Kind: captions
Language: en

00:00:00.470 --> 00:00:01.960
Now that you have trained
your first model.

00:00:01.960 --> 00:00:04.790
There is something very
important I want to discuss.

00:00:04.790 --> 00:00:08.109
You might have seen in the assignment
that we had a training set

00:00:08.109 --> 00:00:11.510
as well as a validation set and
a test set.

00:00:11.510 --> 00:00:13.280
What is that all about?

00:00:13.280 --> 00:00:17.090
Don't skip that part, it has to do
with measuring how well you're doing,

00:00:17.090 --> 00:00:19.450
without accidentally shooting
yourself in the foot.

00:00:19.450 --> 00:00:22.280
And it is a lot more subtle
than you might initially think.

00:00:22.280 --> 00:00:26.330
It's also very important because as
we'll discover later, once you know how

00:00:26.330 --> 00:00:30.780
to measure your performance on a problem
you've already solved half of it.

00:00:30.780 --> 00:00:33.540
Let me explain why measuring
performance is subtle.

00:00:33.540 --> 00:00:35.860
Let's go back to our
classification task.

00:00:35.860 --> 00:00:38.430
You've got a whole lot
of images with labels.

00:00:38.430 --> 00:00:42.540
You could say, okay, I'm going to run
my classifier on those images and

00:00:42.540 --> 00:00:44.150
see how many I got right.

00:00:44.150 --> 00:00:47.790
That's my error measure, and then you
go out and use your classifier on new

00:00:47.790 --> 00:00:51.080
images, images that you've
never seen in the past.

00:00:51.080 --> 00:00:53.240
And you measure how many you get right,
and

00:00:53.240 --> 00:00:56.910
your performance gets worse,
the classifier doesn't do as well.

00:00:56.910 --> 00:00:58.330
So what happened?

00:00:58.330 --> 00:01:02.601
Well imagine I construct a classifier
that simply compares the new image to

00:01:02.601 --> 00:01:06.598
any of the other images that I've
already seen in my training set, and

00:01:06.598 --> 00:01:08.520
just return the label.

00:01:08.520 --> 00:01:11.480
By the measure we defined earlier,
it's a great classifier.

00:01:11.480 --> 00:01:14.660
It would get 100% accuracy
on the training sets.

00:01:14.660 --> 00:01:19.820
But as soon as it sees a new image
it's lost, it has no idea what to do.

00:01:19.820 --> 00:01:21.570
It's not a great classifier.

00:01:21.570 --> 00:01:25.425
The problem is that your classifier
has memorized the training set and

00:01:25.425 --> 00:01:28.070
it fails to generalize to new examples.

00:01:28.070 --> 00:01:30.260
It's not just a theoretical problem.

00:01:30.260 --> 00:01:33.380
Every classifier that you will
build will tend to try and

00:01:33.380 --> 00:01:35.230
memorize the training sets.

00:01:35.230 --> 00:01:37.720
And it will usually do that very,
very well.

00:01:37.720 --> 00:01:42.260
Your job, though, is to help it
generalize to new data instead.

00:01:42.260 --> 00:01:45.550
So, how do we measure
the generalization instead of measuring

00:01:45.550 --> 00:01:48.570
how well the classifier
memorized the data?

00:01:48.570 --> 00:01:52.610
The simplest way is to take a small
subset of the training set.

00:01:52.610 --> 00:01:56.070
Not use it in training and
measure the error on that test data.

00:01:57.170 --> 00:01:59.970
Problem solved,
now your classifier cannot cheat

00:01:59.970 --> 00:02:03.670
because it never sees the test data so
it can't memorize it.

00:02:03.670 --> 00:02:07.050
But there is still a problem because
training a classifier is usually

00:02:07.050 --> 00:02:08.930
a process of trial and error.

00:02:08.930 --> 00:02:12.170
You try a classifier,
you measure its performance, and

00:02:12.170 --> 00:02:14.840
then you try another one,
and you measure again.

00:02:14.840 --> 00:02:16.630
And another, and another.

00:02:16.630 --> 00:02:20.610
You tweak the model, you explore
the parameters, you measure, and

00:02:20.610 --> 00:02:24.780
finally, you have what you think
is the prefect classifier.

00:02:24.780 --> 00:02:28.480
And then after all this care you've
taken to separate your test data from

00:02:28.480 --> 00:02:32.600
your training data and only measuring
your performance on the test data,

00:02:32.600 --> 00:02:35.520
now you deploy your system in
a real production environment.

00:02:35.520 --> 00:02:36.910
And you get more data.

00:02:36.910 --> 00:02:39.500
And you score your performance
on that new data, and

00:02:39.500 --> 00:02:41.990
it doesn't do nearly as well.

00:02:41.990 --> 00:02:43.960
What can possibly have happened?

00:02:43.960 --> 00:02:47.580
What happened is that your
classifier has seen your test data

00:02:47.580 --> 00:02:49.890
indirectly through your own eyes.

00:02:49.890 --> 00:02:53.990
Every time you made a decision about
which classifier to use, which parameter

00:02:53.990 --> 00:02:59.050
to tune, you actually gave information
to your classifier about the test set.

00:02:59.050 --> 00:03:01.590
Just a tiny bit, but it adds up.

00:03:01.590 --> 00:03:03.540
So over time, as you run many and

00:03:03.540 --> 00:03:07.620
many experiments, your test data
bleeds into your training data.

00:03:07.620 --> 00:03:09.140
So what can you do?

00:03:09.140 --> 00:03:11.100
There are many ways to deal with this.

00:03:11.100 --> 00:03:12.590
I'll give you the simplest one.

00:03:12.590 --> 00:03:16.320
Take another chunk of your training
sets and hide it under a rock.

00:03:16.320 --> 00:03:19.330
Never look at it until you
have made your final decision.

00:03:19.330 --> 00:03:23.440
You can use your validation set
to measure your actual error and

00:03:23.440 --> 00:03:26.330
maybe the validation set will
bleed into the training set.

00:03:26.330 --> 00:03:29.850
But that's okay because you're
always have this test set

00:03:29.850 --> 00:03:32.560
that you can rely on to actually
measure your real performance

