WEBVTT
Kind: captions
Language: en

00:00:01.710 --> 00:00:05.610
I'd like to show you an example of
supervised machine learning from my

00:00:05.610 --> 00:00:10.610
robotics past, this robot you
see here is called Latgr or

00:00:10.610 --> 00:00:13.560
learning applied to ground robotics.

00:00:13.560 --> 00:00:17.670
It is using keeners neighbor
to learn how to navigate.

00:00:17.670 --> 00:00:22.150
Let me talk a little bit about
what comes in and what goes out.

00:00:22.150 --> 00:00:26.310
It has a sensor in front of it that
sees the world in front of it.

00:00:26.310 --> 00:00:31.750
It can see along a number of
directions where there are obstacles or

00:00:31.750 --> 00:00:33.500
where the road is clear.

00:00:33.500 --> 00:00:38.340
So, the input is,
in which directions are their obstacles.

00:00:38.340 --> 00:00:42.640
And also,
it has the direction towards the goal.

00:00:42.640 --> 00:00:46.530
So in this case, the robots trying to
get to a goal that's off the left, but

00:00:46.530 --> 00:00:51.620
these bushes that line the path are sort
of preventing it from getting there.

00:00:51.620 --> 00:00:56.390
So x, in our case,
are these perceptions.

00:00:56.390 --> 00:00:58.130
What do I see around me?

00:00:58.130 --> 00:01:00.350
And what's the direction to the goal?

00:01:00.350 --> 00:01:05.990
And y, or the output, Is,
which direction to steer.

00:01:05.990 --> 00:01:09.471
So let's let it go for a while and
see how well it can navigate based on

00:01:09.471 --> 00:01:11.929
a little bit of training
that it's been given.

00:01:15.032 --> 00:01:17.006
It's doing pretty good here so far.

00:01:19.306 --> 00:01:25.610
But, it hasn't been trained quite well
enough and boom, it goes off the path.

00:01:25.610 --> 00:01:27.890
This is where learning comes in.

00:01:27.890 --> 00:01:32.190
We back it up over that area
where it messed up, and

00:01:32.190 --> 00:01:36.070
we switch the learning switch on,
and we're essentially tell it,

00:01:36.070 --> 00:01:40.600
okay, watch what we do, that's
the correct thing to do in this case.

00:01:40.600 --> 00:01:46.168
So it takes all those examples of x's
and y's, x's being the perception and

00:01:46.168 --> 00:01:50.707
y being the way it should respond,
adds that to its memory, and

00:01:50.707 --> 00:01:54.752
now when it's running live,
it consults this memory.

00:01:54.752 --> 00:01:57.248
It says oh, I see this,
what should I do?.

00:01:57.248 --> 00:02:02.433
It finds the k nearest neighbors to
that current observation and looks at

00:02:02.433 --> 00:02:08.220
what they say, and they essentially vote
on what direction the robot should go.

00:02:09.590 --> 00:02:12.260
Now after we've trained it for
about a half hour or

00:02:12.260 --> 00:02:16.880
so, it's able to navigate through
difficult scenarios really quite easily.

00:02:17.910 --> 00:02:22.500
So keep in mind, this robot's driving
autonomously, it's just consulting its

00:02:22.500 --> 00:02:27.220
memory for when I saw this,
what was the right answer, why?

00:02:27.220 --> 00:02:30.860
Supervised learning, and
it's able to get around quite well.

00:02:31.860 --> 00:02:34.750
Here's another more
complicated scenario.

00:02:34.750 --> 00:02:37.690
The goal where it's trying to get
is on the other side of that tree.

00:02:38.800 --> 00:02:43.400
So that's supervised learning for
a robot and, again,

00:02:43.400 --> 00:02:50.000
the model maps these perceptions x to y,
what it should do.

00:02:50.000 --> 00:02:54.870
And finance instead of Y being
which way the robot should go,

00:02:54.870 --> 00:02:57.780
it's often a prediction about
what a future price is.

00:02:58.900 --> 00:03:01.020
Okay, enough about robots,
let's move on.

