WEBVTT
Kind: captions
Language: en

00:00:00.190 --> 00:00:05.580
So now let's look at branch prediction accuracy and how it affect performance.

00:00:05.580 --> 00:00:12.680
Our CPI can be written as one, which is the CPI we get with ideal pipe lining,

00:00:12.680 --> 00:00:17.975
plus the cycles we add on average per instruction because of branch

00:00:17.975 --> 00:00:23.830
mis-predictions. And that can be written as how often we have missed predictions

00:00:23.830 --> 00:00:29.040
times the penalty we pay in terms of cycles every time we have

00:00:29.040 --> 00:00:34.160
a missed prediction. Note that this part is determined by predictor accuracy.

00:00:34.160 --> 00:00:37.250
It really says how often do we mispredict.

00:00:37.250 --> 00:00:42.420
This part is determined by our pipeline. Where in the pipeline we figure out

00:00:42.420 --> 00:00:48.230
that we have mispredicted. That's approximately how many cycles we pay.

00:00:48.230 --> 00:00:52.490
Let's look at a more specific example. Let's look at the processor that

00:00:52.490 --> 00:00:57.340
resolves branches in its third stage of the pipeline. And at the processor that

00:00:57.340 --> 00:01:02.200
resolves branches in its tenth stage of the pipeline. This is actually much

00:01:02.200 --> 00:01:07.310
closer to what modern processors do. let's also look at different accuracies for

00:01:07.310 --> 00:01:11.850
predictors. We will look at the predictor that is 50% accurate for

00:01:11.850 --> 00:01:17.690
branches and 100% accurate for all other instructions.

00:01:17.690 --> 00:01:21.690
And we will look at the predictor that ID 90% accurate for

00:01:21.690 --> 00:01:26.580
branches and 100% accurate for all other instructions and in all of

00:01:26.580 --> 00:01:31.780
this we will be assuming that about 20% of all instructions are branches.

00:01:31.780 --> 00:01:37.370
This is pretty common in programs. Now, let's compute our CPIs.

00:01:37.370 --> 00:01:43.815
here we have a CPI of 1 plus how many mispredictions did we get per instruction.

00:01:43.815 --> 00:01:50.400
We get 50% this prediction for branches.

00:01:50.400 --> 00:01:57.480
So we get 0.5 of branches are mis-predicted, but branches are only 0.2 of

00:01:57.480 --> 00:02:03.070
all instructions. So these two really are the mis-predictions per instruction,

00:02:03.070 --> 00:02:08.250
it's really the mis-predictions per branch times branches per instruction and

00:02:08.250 --> 00:02:13.730
this is multiplied by the penalty that we get per misprediction. If we resolve

00:02:13.730 --> 00:02:19.310
branches in the third stage at that time we have two stages of the pipeline

00:02:19.310 --> 00:02:25.585
where wrong stuff is already fetched. So the penalty will be two cycles.

00:02:25.585 --> 00:02:28.960
Note that it will resolve the branch in the first stage, then there would be

00:02:28.960 --> 00:02:33.710
no penalty because next cycle we can fetch the correct instruction. So

00:02:33.710 --> 00:02:38.850
branch is being resolved in some stage means really that we pay one cycle less

00:02:38.850 --> 00:02:43.890
than that in penalties. And we get an overall CPI of 1.2 here.

00:02:45.080 --> 00:02:49.650
If we resolve the branches in the tenth stage, this part is the same,

00:02:49.650 --> 00:02:54.780
the accuracy of the predictor and the frequency of branches, but the penalty now

00:02:54.780 --> 00:03:01.540
would be nine cycles. So we have 1 plus 0.5 times 0.2

00:03:01.540 --> 00:03:08.620
times 9 in this case for the overall CPI of 1.9.

00:03:08.620 --> 00:03:13.980
This is a significantly worse CPI than we were getting here. Now let's look at

00:03:13.980 --> 00:03:20.740
the more accurate branch prediction. Now what we have is 1 plus mispredictions

00:03:20.740 --> 00:03:26.990
per instruction are going to be how many mispredictions we have per branch.

00:03:26.990 --> 00:03:32.851
We had 90% accurate, that means we have 10% mispredictions times

00:03:32.851 --> 00:03:37.910
0.2 because not all instructions are branches, times 2,

00:03:37.910 --> 00:03:43.480
which is our penalty. And we add that with 1.04, so

00:03:43.480 --> 00:03:48.380
this is a significant improvement from a more accurate predictor.

00:03:48.380 --> 00:03:55.126
Let's look now at this processor. Here we have 1 plus 0.1 times

00:03:55.126 --> 00:04:00.920
0.2 times 9, and when we compute this,

00:04:00.920 --> 00:04:06.830
we get 1.18. What we can conclude from this, is that a better branch

00:04:06.830 --> 00:04:12.770
vector will help us regardless of whether we have a shallow or a deep pipeline,

00:04:12.770 --> 00:04:18.279
but the amount of help from a better predictor changes depending on

00:04:18.279 --> 00:04:24.200
how deep the pipeline is. Here we have a speed up of 1.15 when

00:04:24.200 --> 00:04:30.040
we go from worse to better predictor in a shallow pipeline, but

00:04:30.040 --> 00:04:35.060
here we have a speed up of 1.61 when we go from the same worse

00:04:35.060 --> 00:04:40.020
predictor to the same better predictor in a deeper pipeline. As you can see,

00:04:40.020 --> 00:04:45.440
the deeper the pipeline, the more dependent it is on having a good predictor for

00:04:45.440 --> 00:04:49.710
good performance. And that is really why research in

00:04:49.710 --> 00:04:54.080
branch vectors continues to this day, although our predictors and

00:04:54.080 --> 00:04:59.690
now pretty good. They're significantly better than 90% accurate for branches.

00:04:59.690 --> 00:05:05.610
However, our pipelines are deep, so we still benefit from further improvements.

