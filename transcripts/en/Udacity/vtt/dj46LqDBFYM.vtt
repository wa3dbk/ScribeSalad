WEBVTT
Kind: captions
Language: en

00:00:00.080 --> 00:00:02.510
Okay, let's take a look at some formal measures of

00:00:02.510 --> 00:00:06.520
data quality. There are essentially five measures of data quality that

00:00:06.520 --> 00:00:08.600
I'd like to talk about. This is the model we'll

00:00:08.600 --> 00:00:11.973
use in this course. And regardless of who's talking about data

00:00:11.973 --> 00:00:15.170
quality, and what labels they apply to measures data quality.

00:00:15.170 --> 00:00:17.915
They're going to fall roughly into these five categories that we'll talk

00:00:17.915 --> 00:00:21.510
about. So first let's talk about validity. With validity, we're

00:00:21.510 --> 00:00:25.100
measuring the degree to which entries in our data set conform

00:00:25.100 --> 00:00:28.320
to a defined schema, or to other constraints we

00:00:28.320 --> 00:00:31.630
might have. As we move through this lesson, we'll discuss

00:00:31.630 --> 00:00:34.130
each of these in more detail. Here, I'm just

00:00:34.130 --> 00:00:37.230
going to provide an overview. We can also look at

00:00:37.230 --> 00:00:40.330
accuracy. This is the degree to which entries conform

00:00:40.330 --> 00:00:42.750
to gold standard data. What I mean by that, is

00:00:42.750 --> 00:00:46.440
probably best expressed with an example. So, do all street

00:00:46.440 --> 00:00:50.230
addresses in a data set that we're cleaning, actually exist?

00:00:50.230 --> 00:00:53.050
In order to test that type of accuracy question,

00:00:53.050 --> 00:00:55.540
we would need some gold standard. That is, some set

00:00:55.540 --> 00:01:00.350
of data that we actually trust. Completeness is pretty straightforward,

00:01:00.350 --> 00:01:02.540
do we have all the records we should have? While

00:01:02.540 --> 00:01:06.480
explaining it, is pretty straightforward, actually measuring completeness is a

00:01:06.480 --> 00:01:09.410
very difficult thing to do. We also want to look

00:01:09.410 --> 00:01:12.610
for consistency within our data. In many systems, we will

00:01:12.610 --> 00:01:15.270
have multiple records, that have some overlap in the data

00:01:15.270 --> 00:01:18.250
they contain. We want to ensure that there is consistency among

00:01:18.250 --> 00:01:23.400
the fields, that represent the same data across systems. And finally

00:01:23.400 --> 00:01:27.545
uniformity, this one's easy. Do all our values for distance, for

00:01:27.545 --> 00:01:30.990
example, use the same units? Is it miles, or is it kilometers?

