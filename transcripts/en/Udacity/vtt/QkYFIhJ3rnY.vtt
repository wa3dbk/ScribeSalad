WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.000
[Sebastian Thrun - Professor CS373, Andy Brown - Course Manager CS373]

00:00:02.000 --> 00:00:04.000
[Andy:] Welcome to our first office hours. We've seen a lot of really good discussion in the forums.

00:00:04.000 --> 00:00:10.000
Now we have Professor Thrun here with me--I'm Andy the moderator in the CS373 forum.

00:00:10.000 --> 00:00:14.000
We're going to divide the questions into the course content questions,

00:00:14.000 --> 00:00:17.000
and we're going to after that talk about some other questions--

00:00:17.000 --> 00:00:20.000
things that are specific to Sebastian's work.

00:00:20.000 --> 00:00:24.000
First course content question that a lot of people seemed to have questions about was

00:00:24.000 --> 00:00:27.000
when we're talking about the sensing, you introduce these multipliers called

00:00:27.000 --> 00:00:31.000
pHit and pMiss, and you assign values 0.6 and 0.2.

00:00:31.000 --> 00:00:34.000
People were confused about where those numbers came from.

00:00:34.000 --> 00:00:38.000
[Sebastian:] This is something I just put in ad hoc when I explained it,

00:00:38.000 --> 00:00:42.000
and later on they've become the measurement probabilities,

00:00:42.000 --> 00:00:47.000
but I didn't want to start talking about probabilities without programming them first.

00:00:47.000 --> 00:00:52.000
pHit would be what's the probability of, say, being next to a door and really seeing it,

00:00:52.000 --> 00:00:56.000
and pMiss will be the probability of being next to a door and not seeing it.

00:00:56.000 --> 00:00:58.000
There is usually actually four of those.

00:00:58.000 --> 00:01:01.000
There are four measurement combinations--

00:01:01.000 --> 00:01:04.000
the probability of seeing the right measurement under there is a door

00:01:04.000 --> 00:01:06.000
and if there is no door,

00:01:06.000 --> 00:01:09.000
the probability of seeing the wrong measurement under these two assumptions,

00:01:09.000 --> 00:01:11.000
but two of them are sufficient for the math.

00:01:11.000 --> 00:01:15.000
[Andy:] In a related question about your own work, how do you assign these?

00:01:15.000 --> 00:01:20.000
You said it was done ad hoc in this little example, but in really designing a robot car,

00:01:20.000 --> 00:01:23.000
how do you decide on what these values are going to be?

00:01:23.000 --> 00:01:26.000
Is it done experimentally? Is it based on the parameters of the sensors?

00:01:26.000 --> 00:01:29.000
[Sebastian:] That's where a lot of meat comes in, and it's certainly meat I didn't really cover in class.

00:01:29.000 --> 00:01:31.000
I do cover it in my book.

00:01:31.000 --> 00:01:33.000
It depends a lot on the sensor.

00:01:33.000 --> 00:01:37.000
So if we use a camera, I use a different model than if we use a range finder.

00:01:37.000 --> 00:01:39.000
We use a lot of laser range finders.

00:01:39.000 --> 00:01:42.000
If I was using a laser range finder--they measure distances--

00:01:42.000 --> 00:01:46.000
and it's not pHit/pMiss anymore, it's the probability of measuring

00:01:46.000 --> 00:01:49.000
a certain distance in a certain location.

00:01:49.000 --> 00:01:52.000
The very first approximation is physics.

00:01:52.000 --> 00:01:57.000
You can actually derive what the typical noise in the sensor and characterize those.

00:01:57.000 --> 00:02:01.000
But when you just use physics, you often have a very poor confidence on the actual uncertainty,

00:02:01.000 --> 00:02:04.000
so when tuning those parameters, you often do this very experimentally.

00:02:04.000 --> 00:02:08.000
We go in and try out certain parameters to see which ones work

00:02:08.000 --> 00:02:12.000
and then often soften them to make them fit the math.

00:02:12.000 --> 00:02:18.000
[Andy:] The next question a lot of people had was does this method we're using

00:02:18.000 --> 00:02:21.000
depend on the robot already having a map of its environment?

00:02:21.000 --> 00:02:24.000
[Sebastian:] Localization does depend on having a map of the environment.

00:02:24.000 --> 00:02:27.000
Everything I taught so far assumes there is a map.

00:02:27.000 --> 00:02:30.000
There is an entire field called simultaneous localization and mapping--

00:02:30.000 --> 00:02:36.000
or for short, SLAM--that addresses the general problem of acquiring a map at the same time .

00:02:36.000 --> 00:02:39.000
I haven't covered this in class.

00:02:39.000 --> 00:02:44.000
[Andy:] Those were two of the most heavily voted course content questions.

00:02:44.000 --> 00:02:48.000
In a real localizer--I guess you sort of addresses this--but what are we looking for?

00:02:48.000 --> 00:02:51.000
We're not looking for doors. We're looking for--?

00:02:51.000 --> 00:02:54.000
[Sebastian:] In the Google self-driving car, which is a good example,

00:02:54.000 --> 00:02:58.000
we actually have a map of the ground that is not that dissimilar from the way

00:02:58.000 --> 00:03:01.000
Google Earth project images on the ground.

00:03:01.000 --> 00:03:05.000
Then if you think about the robot having a laser camera, but a camera, that

00:03:05.000 --> 00:03:08.000
produces local maps, and these local maps have some of the same features

00:03:08.000 --> 00:03:11.000
like lane markings, as our global map.

00:03:11.000 --> 00:03:14.000
And then the probability match question is one we take the local map,

00:03:14.000 --> 00:03:17.000
superimpose it over the global map, and see where it matches the best.

00:03:17.000 --> 00:03:20.000
It's a search usually in x and y space.

00:03:20.000 --> 00:03:24.000
It's also a little search on orientation space, because you might have your orientation slightly wrong.

00:03:24.000 --> 00:03:28.000
The likelihood function that replaces our pHit and pMiss

00:03:28.000 --> 00:03:32.000
is then usually a correlation function that says how well does the local map

00:03:32.000 --> 00:03:35.000
that you see right now match the global map.

00:03:35.000 --> 00:03:38.000
When you shift it to the right position, it usually matches much, much better,

00:03:38.000 --> 00:03:41.000
and as a result you get a much larger probability.

00:03:41.000 --> 00:03:44.000
[Andy:] Some people were worrying about whether changing road conditions,

00:03:44.000 --> 00:03:47.000
whether weather or lighting conditions, things like that,

00:03:47.000 --> 00:03:50.000
would greatly affect the usability of the robot car.

00:03:50.000 --> 00:03:53.000
[Sebastian:] That's a great question, and we discuss this every day.

00:03:53.000 --> 00:03:57.000
Turns out that in certain weather conditions the car is relatively robust right now.

00:03:57.000 --> 00:04:01.000
Rain, for example, changes the total appearance of the street,

00:04:01.000 --> 00:04:04.000
and we can adjust this with a single constant factor that adjusts

00:04:04.000 --> 00:04:06.000
the total brightness of the laser map.

00:04:06.000 --> 00:04:11.000
Other things like a complete snow-covered street we have no solution right now it turns out.

00:04:11.000 --> 00:04:13.000
What we're doing right now is we just don't drive in snow.

00:04:13.000 --> 00:04:16.000
We live in California. There's not much snow here.

00:04:16.000 --> 00:04:19.000
When there is snow, we just tell the driver not to use the system.

00:04:19.000 --> 00:04:21.000
That's something we have to work on.

00:04:21.000 --> 00:04:26.000
I think as we move into things like snow and very massive changes, we have to reference other features.

00:04:26.000 --> 00:04:29.000
Maybe there trees around or other structures or rocks.

00:04:29.000 --> 00:04:32.000
Typically, snow comes in the mountains so maybe there's mountainous structure.

00:04:32.000 --> 00:04:36.000
And we have to toss some of that information into the system.

00:04:36.000 --> 00:04:39.000
[Andy:] People are getting very excited in the forums.

00:04:39.000 --> 00:04:41.000
They want to actually build their own robotic car.

00:04:41.000 --> 00:04:44.000
Some questions have been how much is it going to cost?

00:04:44.000 --> 00:04:50.000
If I can't do it because the cost is too high, can I get some Legos and build a robotic car that way?

00:04:50.000 --> 00:04:52.000
[Sebastian:] There are a lot of kits you can buy.

00:04:52.000 --> 00:04:56.000
I love Lego Mindstorm, is which a wonderful way to experiment with these things.

00:04:56.000 --> 00:04:59.000
There are a lot of low-cost robot platforms you can buy.

00:04:59.000 --> 00:05:02.000
I don't really recommend to hack into your car.

00:05:02.000 --> 00:05:09.000
The reason is the moment you start snipping wires, your car might actually become unsafe.

00:05:09.000 --> 00:05:12.000
If you do work with a car, make sure you never, ever

00:05:12.000 --> 00:05:15.000
drive this car manually again or you know what you're doing.

00:05:15.000 --> 00:05:18.000
We've actually been really tapping into cars,

00:05:18.000 --> 00:05:21.000
and we've done things like decoding and understanding

00:05:21.000 --> 00:05:25.000
how you use an electric steering booster to turn this in to steering motor

00:05:25.000 --> 00:05:30.000
so that the car would be able to steer on computer command not just on human command.

00:05:30.000 --> 00:05:34.000
But it's a lot of work, and it's actually very risky, so don't do it yourself.

00:05:34.000 --> 00:05:38.000
Rather go and buy yourself a Lego Mindstorm or something similar and play with it.

00:05:38.000 --> 00:05:41.000
You can actually study a lot of the same stuff using a Lego kit.

00:05:41.000 --> 00:05:45.000
If you make a Lego robot move from the kitchen to the living room, that's actually really impressive.

00:05:45.000 --> 00:05:51.000
[Andy:] One last question is for the people who are especially enthusiastic about robotics and AI.

00:05:51.000 --> 00:05:55.000
How do you get involved in this field? What can someone do after taking this course?

00:05:55.000 --> 00:05:57.000
[Sebastian:] So take this class.

00:05:57.000 --> 00:06:02.000
As you know, we've been handing the CVs of our top students onto various companies

00:06:02.000 --> 00:06:07.000
like Amazon and Twitter and Facebook and Google.

00:06:07.000 --> 00:06:09.000
That's one way to get involved.

00:06:09.000 --> 00:06:11.000
That doesn't work for everybody.

00:06:11.000 --> 00:06:16.000
The way I got involved is, for one, I had a lot of toys that you could program.

00:06:16.000 --> 00:06:19.000
I had a computer. I had little things to move around.

00:06:19.000 --> 00:06:23.000
There was a construction set in Germany which I could play with as a kid.

00:06:23.000 --> 00:06:26.000
Then I really started becoming a scientist.

00:06:26.000 --> 00:06:29.000
I started publishing papers.

00:06:29.000 --> 00:06:32.000
I started solving problems that the literature left open--

00:06:32.000 --> 00:06:35.000
look into those and see if I could make a contribution.

00:06:35.000 --> 00:06:40.000
At the age of about 22, I had my first big, big paper that was at a major conference.

00:06:40.000 --> 00:06:44.000
That kind of started me to get into the field and got me really hooked.

00:06:44.000 --> 00:06:50.000
The nice thing is I think there are many, many problems around you that require the same technology.

00:06:50.000 --> 00:06:54.000
There's tracking problems, estimation problems all over the place, right?

00:06:54.000 --> 00:06:57.000
So if you can't afford a robot, why not just by a web camera and put it in your kitchen

00:06:57.000 --> 00:07:01.000
and have it, for example, track whether your cooking is good or bad?

00:07:01.000 --> 00:07:04.000
That's something that everybody can do with the same technology.

00:07:04.000 --> 00:07:10.000
Like today, most cooks occasionally boil water over and it makes your stove wet.

00:07:10.000 --> 00:07:12.000
Can you build a system that prevents this?

00:07:12.000 --> 00:07:14.000
That's a robotic task that uses the same technology.

00:07:14.000 --> 00:07:18.000
If you do this and do this really, really well, you might start a business.

00:07:18.000 --> 00:07:21.000
You might find other people to work with you.

00:07:21.000 --> 00:07:25.000
You might show it to a professor, and if they got excited about it, they might publish it at a conference.

00:07:25.000 --> 00:07:27.000
There are many, many ways into the system, honestly.

00:07:27.000 --> 00:07:29.000
Just be creative about it.

00:07:29.000 --> 00:07:32.000
[Andy:] It sounds like you're emphasizing you have to think like a roboticist.

00:07:32.000 --> 00:07:34.000
That's, I think, what this class is going to help to do.

00:07:34.000 --> 00:07:36.000
[Sebastian:] Yeah, what I'm trying to do is make people think like roboticists.

00:07:36.000 --> 00:07:40.000
I'm extremely excited that in this class you get to program it yourself.

00:07:40.000 --> 00:07:44.000
That's a new thing. When I was a student, I didn't have that possibility.

00:07:44.000 --> 00:07:46.000
In our previous class you could do it.

00:07:46.000 --> 00:07:49.000
We are not at the point where you can drive your own robot around yet.

00:07:49.000 --> 00:07:53.000
I hope to get to this point where we have a good robot simulator so you can play with this.

00:07:53.000 --> 00:07:57.000
But we have enough stuff you can just buy.

00:07:57.000 --> 00:08:00.000
Most importantly a camera--like a camera on a phone.

00:08:00.000 --> 00:08:04.000
You can do localization on a hand-held phone in a room using images.

00:08:04.000 --> 00:08:09.000
If you do a really fantastic job, you can start a company and sell it to one of the major players.

00:08:09.000 --> 00:08:12.000
It's an open problem to the present day how to do this really well.

00:08:12.000 --> 00:08:15.000
There's a lot of technology available today that allows you

00:08:15.000 --> 00:08:19.000
to think like a roboticist and still solve the interesting problems--with this class, I hope.

00:08:19.000 --> 00:08:22.000
[Andy:] All right. Well, thank you very much.

00:08:22.000 --> 00:08:24.000
[Sebastian:] Okay. Thank you.

00:08:24.000 --> 00:08:28.000
[CS 373: Programming a Robotic Car - Taught by Professor Sebastian Thrun]

00:08:28.000 --> 00:08:31.000
[Udacity - udacity.com]

