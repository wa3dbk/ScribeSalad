WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.250
NVIDIA called and said, "We'd like you to come here

00:00:02.250 --> 00:00:07.835
and start looking at how we can apply this in a more product-orientated sense."

00:00:07.835 --> 00:00:09.836
Yeah, NVIDIA was a great partner in the research.

00:00:09.836 --> 00:00:12.181
They were giving us access to the hardware and some of the early specs

00:00:12.181 --> 00:00:15.791
so we could think about where they were going and how it influenced our research.

00:00:15.791 --> 00:00:20.139
When we were all said and done, I got the opportunity to come to NVIDIA and do it for real.

00:00:20.139 --> 00:00:23.100
I started the CUDA group with one other guy.--it was just the two of us--

00:00:23.100 --> 00:00:28.025
and we hired in a compiler and library and QA guys, and we slowly built our way up,

00:00:28.025 --> 00:00:33.053
this time really taking the learnings from Brook and starting over a little bit,

00:00:33.053 --> 00:00:37.257
also influencing some of the hardware design, the hardware architecture.

00:00:37.257 --> 00:00:41.206
What could we do the generalize the architecture just a little bit to make it a little easier,

00:00:41.206 --> 00:00:43.625
to eliminate those roadblocks that we discovered with Brook,

00:00:43.625 --> 00:00:46.682
and then eventually come up with our sort of CUDA 1.0?

00:00:46.682 --> 00:00:49.431
So how long did you take from the day you got there and you started on this project

00:00:49.431 --> 00:00:50.958
to the time it launched?

00:00:50.958 --> 00:00:55.627
It was probably a good 2 years of development work that we were pushing to do this work.

00:00:55.627 --> 00:01:00.156
A lot of it was spec writing, kind of coming up with paper specs, writing some sample code examples,

00:01:00.156 --> 00:01:02.088
seeing if it was usable, easy to use,

00:01:02.088 --> 00:01:07.459
picking between a variety of different approaches for how to express the parallelism.

00:01:07.459 --> 00:01:10.669
Eventually we latched on to a very basic idea of threading

00:01:10.669 --> 00:01:16.336
because we knew that most C and C++ programmers understood the concept of a thread,

00:01:16.336 --> 00:01:19.253
at least at the simplest level, and if we could latch on to that

00:01:19.253 --> 00:01:21.876
we could actually present a program model that was familiar.

00:01:21.876 --> 00:01:24.938
Very early on in the CUDA project we did a road show.

00:01:24.938 --> 00:01:28.351
We went out and we talked to every customer who was willing to talk to us, saying,

00:01:28.351 --> 00:01:31.262
"Tell us your problems around computing. How can we help you?"

00:01:31.262 --> 00:01:33.796
And one of the big sentiments was they didn't want to learn a new language.

00:01:33.796 --> 00:01:38.630
And while it was tempting as a researcher to come up with the new parallel programming language

00:01:38.630 --> 00:01:42.127
of the world, they just wanted an easy way to get access to the performance,

00:01:42.127 --> 00:01:45.045
and they had a bunch of C or C++ or Fortran programmers.

00:01:45.045 --> 00:01:48.131
So when we set out to start CUDA, we made sure it's not a new language.

00:01:48.131 --> 00:01:51.182
It's just a couple of simple extensions to C and C++

00:01:51.182 --> 00:01:56.144
so that anyone who knows those languages plus has a basic understanding of threading

00:01:56.144 --> 00:01:59.000
could get access to the GPU's performance.

