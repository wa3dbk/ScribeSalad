WEBVTT
Kind: captions
Language: en

00:00:00.220 --> 00:00:02.900
Let's summarize things and
wrap up this lecture.

00:00:02.900 --> 00:00:05.181
I just want to repeat the points so

00:00:05.181 --> 00:00:09.580
you so reinforcement learning is
something that we can use in trading.

00:00:09.580 --> 00:00:15.260
The problem for reinforcement learning
algorithms is a Markov decision problem.

00:00:15.260 --> 00:00:17.746
And reinforcement learning
algorithms solve them.

00:00:17.746 --> 00:00:23.060
A Markov decision problem
is defined by S, A, T, and

00:00:23.060 --> 00:00:29.470
R, where S is the potential states,
A are the potential actions,

00:00:29.470 --> 00:00:35.010
T is a transition probability, which is
given I'm in state s, I take action a,

00:00:35.010 --> 00:00:41.420
what's the probability I'll end up in
state S', and R is the reward function.

00:00:41.420 --> 00:00:46.190
The goal for reinforcement learning
algorithm is to find a policy, pi,

00:00:46.190 --> 00:00:51.110
that maps a state to an action that we
should take, and its goal is to find

00:00:51.110 --> 00:00:56.780
this pi such that it maximizes
some future sum of the reward.

00:00:56.780 --> 00:01:00.300
We talked about that being
either infinite horizon,

00:01:00.300 --> 00:01:02.800
fixed horizon, or discounted sum.

00:01:03.990 --> 00:01:05.740
We can map our task for

00:01:05.740 --> 00:01:11.413
trading to reinforcement learning and
it works out like this.

00:01:11.413 --> 00:01:15.075
S, our states,
are features about stocks and whether or

00:01:15.075 --> 00:01:16.595
not we're holding a stock.

00:01:16.595 --> 00:01:20.245
Actions are buy, sell, or do nothing.

00:01:20.245 --> 00:01:24.395
The transition function here
is the market, and finally,

00:01:24.395 --> 00:01:28.535
the reward function is how much
money we get at the end of a trade.

00:01:28.535 --> 00:01:34.170
So, we can apply reinforcement learning
algorithms to find this policy.

00:01:34.170 --> 00:01:36.750
We've mentioned a few of
those algorithms, for example

00:01:36.750 --> 00:01:41.400
policy iteration, and value iteration,
and Q learning, but we haven't

00:01:41.400 --> 00:01:46.090
talked in detail what they are, and
that's the subject of lessons coming up.

00:01:46.090 --> 00:01:48.970
Okay, that's it for reinforcement
learning, I'll see you again soon.

