WEBVTT
Kind: captions
Language: en

00:00:00.240 --> 00:00:06.210
The directory entry has one dirty bit
that indicates that the block is dirty

00:00:06.210 --> 00:00:11.170
in some cache in the system, and for
every cache in the system, the directory

00:00:11.170 --> 00:00:16.816
entry has one bit that indicates whether
the block is present in that cache.

00:00:16.816 --> 00:00:19.820
If the presence bit is 1 for
a particular cache,

00:00:19.820 --> 00:00:24.748
that means that we think that
cache has a copy of the block.

00:00:24.748 --> 00:00:28.220
If the presence bit is 0,
that means that we know for

00:00:28.220 --> 00:00:34.150
sure that that cache does not have
the block in a state that is not I.

00:00:34.150 --> 00:00:38.601
So let's say we have one
block caches at core 0 and

00:00:38.601 --> 00:00:42.120
1, and let's say this is
the directory entry for block B,

00:00:42.120 --> 00:00:47.120
where this is the dirty bit and
these are the presence bits for

00:00:47.120 --> 00:00:52.440
cores zero, one, two, three,
four, five, six, and seven.

00:00:52.440 --> 00:00:54.740
So, this is an eight core system, so

00:00:54.740 --> 00:00:59.070
we need eight bits to represent
presence of the block in the caches.

00:00:59.070 --> 00:01:05.610
Initially, the block is not dirty and
is not present in any of the caches.

00:01:05.610 --> 00:01:08.420
Let's say that core zero
reads from the block B.

00:01:08.420 --> 00:01:12.790
The block is not in its cache, so it's
treated like it's in the invalid state.

00:01:12.790 --> 00:01:15.500
We put the read request out.

00:01:15.500 --> 00:01:19.660
Normally, this read request
will be put out on the bus.

00:01:19.660 --> 00:01:24.900
And because no other cache has this,
the memory would respond.

00:01:24.900 --> 00:01:26.648
But now we don't have snooping anymore.

00:01:26.648 --> 00:01:28.110
So all requests for

00:01:28.110 --> 00:01:34.100
a block would be sent first to
the home slice of the block.

00:01:34.100 --> 00:01:38.370
And we determine what is the home slice
by looking at the address of the block.

00:01:38.370 --> 00:01:42.680
Different blocks are distributed
among different slices so

00:01:42.680 --> 00:01:44.660
that we get an even load
between the slices.

00:01:44.660 --> 00:01:49.496
So let's say we determine that for
block B, this is the slice where we go,

00:01:49.496 --> 00:01:54.180
and once the request gets there,
we look at the directory entry for it.

00:01:54.180 --> 00:01:58.370
The directory entry says that the block
is not anywhere in the system.

00:01:58.370 --> 00:02:01.120
So now we can get the data from memory,

00:02:01.120 --> 00:02:06.120
and send the data back to the cache 0,
and

00:02:06.120 --> 00:02:10.139
we need to tell the cache 0 everything
that the bus would normally tell it.

00:02:10.139 --> 00:02:12.420
So we tell it that it
has exclusive access,

00:02:12.420 --> 00:02:14.400
because there are no other sharers.

00:02:14.400 --> 00:02:16.060
And we give it the data.

00:02:16.060 --> 00:02:21.020
That response gets back to cache 0,
and now if it has the exclusive state,

00:02:21.020 --> 00:02:25.290
it can put the block in that state and
put the data for B here.

00:02:25.290 --> 00:02:29.030
When the directory sends
the data to Cache 0,

00:02:29.030 --> 00:02:32.760
it changes the presence bit for
that cache to 1.

00:02:32.760 --> 00:02:36.800
Also, we sent the data
with exclusive access.

00:02:36.800 --> 00:02:41.690
If cache 0 modifies the data, it doesn't
have to notify the directory back, so

00:02:41.690 --> 00:02:43.700
we also set the dirty bit.

00:02:43.700 --> 00:02:45.960
The dirty bit here will
not cause a write-back.

00:02:45.960 --> 00:02:50.540
It will cause us to find if
a cache needs to do a write-back.

00:02:50.540 --> 00:02:53.060
So now why does this
work better than a bus?

00:02:53.060 --> 00:02:58.570
Well because while cache 0 was doing
this with this directory slice,

00:02:58.570 --> 00:03:00.820
cache 1 could have done
something like that for

00:03:00.820 --> 00:03:05.250
another block, with another directory
slice, completely independently.

00:03:05.250 --> 00:03:10.672
However, if cache 1 tries to write to
B at about the same time when read

00:03:10.672 --> 00:03:15.570
B was occurring, we would send our write
request to the same directory entry.

00:03:15.570 --> 00:03:17.850
And now, between these two messages,

00:03:17.850 --> 00:03:20.790
the directory controller
needs to select one.

00:03:20.790 --> 00:03:24.083
In this case it shows
read request first, so

00:03:24.083 --> 00:03:28.670
officially, this read
happened before this write.

00:03:28.670 --> 00:03:31.450
So the core here gets to
read the block B, and

00:03:31.450 --> 00:03:36.000
only then, the write gets
processed by the directory.

00:03:36.000 --> 00:03:38.620
So when this write request arrives here,

00:03:38.620 --> 00:03:44.000
again, this write request would be
placed on the bus, seen by this cache.

00:03:44.000 --> 00:03:46.400
As a result,
this cache would invalidate, and

00:03:46.400 --> 00:03:49.600
we will get the block
in the modified state.

00:03:49.600 --> 00:03:52.890
With the directory, we send the request
to the directory controller.

00:03:52.890 --> 00:04:00.140
It sees that the block is present and
possibly dirty in this case, cache 0.

00:04:00.140 --> 00:04:05.321
So what now happens is
the directory forwards the write

00:04:05.321 --> 00:04:09.609
request for
B to the caches that are present.

00:04:09.609 --> 00:04:12.820
In this case it forwards it to cache 0.

00:04:12.820 --> 00:04:17.709
Cache 0 now sees this request just as
if it was snooped from the bus, and

00:04:17.709 --> 00:04:22.110
because it has the data in the exclusive
state it can choose to respond with

00:04:22.110 --> 00:04:26.930
the data or it just may keep quiet and
confirm the invalidation.

00:04:26.930 --> 00:04:31.550
So, what happens here is once the write
request has been given to this cache,

00:04:31.550 --> 00:04:36.600
we need to send the acknowledgement,
at least, if not the data, back

00:04:36.600 --> 00:04:41.130
to the directory controller that says
that we are done invalidating our copy.

00:04:41.130 --> 00:04:44.370
So this point we have
invalidated our copy.

00:04:44.370 --> 00:04:46.750
When the acknowledgement arrives here,

00:04:46.750 --> 00:04:49.870
the directory controller
can change this to 0.

00:04:49.870 --> 00:04:54.440
If the data didn't arrive,
then we can erase the dirty bit.

00:04:54.440 --> 00:04:58.188
And now because we don't have the data
still, we will read the memory and

00:04:58.188 --> 00:04:59.548
send the data to cache 1.

00:04:59.548 --> 00:05:04.738
And because we are acknowledging a write
request, we again set the dirty bit,

00:05:04.738 --> 00:05:09.848
and now the presence factor gets a 1 for
the bit that corresponds to cache 1,

00:05:09.848 --> 00:05:13.270
and now we get to set M here and
write to the B here.

00:05:13.270 --> 00:05:18.980
So as you can see, this is how the
caches can do their normal coherence,

00:05:18.980 --> 00:05:21.980
but now instead of everybody
seeing everything,

00:05:21.980 --> 00:05:24.710
that we need to send
a request to the directory,

00:05:24.710 --> 00:05:28.630
which then sends out the messages
that need to be sent.

00:05:28.630 --> 00:05:32.990
Only to those caches that
actually might have the block.

00:05:32.990 --> 00:05:35.560
So if a block is shared
by only two cores,

00:05:35.560 --> 00:05:38.230
then we will be only sending
a very few messages.

00:05:38.230 --> 00:05:42.840
In contrast, the bus would force us to
basically broadcast to all of the cores.

00:05:42.840 --> 00:05:46.975
So this also saves a lot of bandwidth
because we're using point to point

00:05:46.975 --> 00:05:48.658
network links to send just this.

00:05:48.658 --> 00:05:51.805
Meanwhile, other cores could be doing
something like this with another

00:05:51.805 --> 00:05:55.080
directory entry,
completely independently over a network.

