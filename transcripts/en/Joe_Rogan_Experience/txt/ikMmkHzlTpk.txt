Speaker 1:          00:00:02       Ready, boom. And we're live. Hello Lex. Hey, what's going on? The sequel part too. You have a very similar, if not the exact same suit on. This is all I wear. You look very professional, very reservoir dogs, reservoir dogs. What it was go to the best secret of all time. Godfather, part two. Is that the best of you? Go over on time. I think John Wick might be having quick same. See how dare you sir. Godfather part two. I mean that's, that has to be the best sequel. Okay then, and if this has godfather, part two, it's definitely not do part three. Part three was terrible. Right? Well let's, let's not offend anyone but it was not as good. Yeah, I don't remember it. It was a, the older Pachino. Ah, would that depot voice that was like way later, right? Yeah, that was nineties Oh, okay.

Speaker 1:          00:00:54       So it's like point break. The remix. Yes. When they try to Redo things like way, way, way later, they almost never, except the alien franchise. They've done a pretty fucking good job with the Alien Fred. They had a couple of duds in there, but for the most part I've actually never seen alien franchise. Who are you? What are you in a science? Intelligent men can disagree but you're not in the science. I Dunno. I'd prefer prefer Al Pachino. I would say that, uh, the older sent a woman an opportunity, you know that really? Yeah. Watts come on the, yeah, he got the Oscar for that one. What about the one when he played the devil and the devil? Okay. There's, there's two. There's duds for everybody. What was that one? That was advocate. Uh Huh. There you go. That was a with counter Reeve. Kiana release from John Wick or John Waite.

Speaker 1:          00:01:50       Par threes are the Matrix. The better movie. Not True. Did you see this? That happened? Uh, this high school in North Bergen Jersey. You put on the alien play a couple of weeks ago. Garney weaver showed up. She showed up like a cut just the other day to like say thanks or whatever. Tell him maybe to awesome. Oh, it looked like crazy and I was just wondering if they did this when you were in high school. Do you think he might've joined drama? Like if they did the alien play? Loved it. One of the watched it. All right. I'm not getting into drama. Those people cry too much. There's too much work. It's a cool suit though. Yeah. Okay. Let's talk about this. There's two kinds of movies. There's fun movies and there's movies that are like transformational for society gets sent to a woman. What? Okay. Let's see. You kind of say scent of a woman is transformational for society. One of the greatest scenes between a man and a woman on film. The tango scene. Oh, you're not married? No, I'm not married.

Speaker 1:          00:02:45       It's like somewhat talking about French who can't speak French. I see. Yeah. It's nonsense. I movie sucked. I read about French in a book talking about France without ever being to Paris. Scent of a woman. Your favorite movie? No, it's not my favorite. I think that movie sucked either. By the way, if you get mad right now, I want to barely remember it, but it is, it is up there. I'm sure it's a good movie. That's one of the greatest performances. But Jesus Christ, you'll go off to a good start. Yeah, I bet you there's thousands of people agree with me right now. Yeah, there's millions that don't.

Speaker 1:          00:03:18       And they're called haters. Everyone had disagrees is always or, okay. So what's your favorite love scene in a movie? Not like, like between a man and get married, Bro. Okay. No, I'm not fire yourself a gal. There's a little down. We're not talking about romantic comedies and I'm saying they're here. Uh, Romcoms we're talking about serious like dramatic moments, right? Okay. So godfather movie, great movie. Does it have to have two guys like shooting each other or know like, okay, so if you're seeing central a woman. Yeah, I'm sure I saw it. Yeah. But I barely remember it. All right, well there's these, watch it today. It'd be like a new movie to me. Okay. There's this broken man. We'll alert considering suicide. Right? It's deep. So he is tortured by, you know, by his involvement in the war, by being responsible. They all have this kind of stuff.

Speaker 1:          00:04:13       He's now mentoring a younger version of himself, was more character, more integrity and throw out all of this. He meets this beautiful young woman. He's blind for the dance and there's this beautiful moment where they connect. I mean, okay, listen Phil, what's the purpose of film, right. Entertainment or make us think. I mean, make us think. Hmm. You know, you're going to think if you want to think, nothing makes you think of film can engage you. You can, it can resonate with you or not. I have a movie that I throw by people whenever I want to find out whether or not, I don't want to listen to anything they have to say about movies. The Big Lebowski. Yeah. Yeah. That's one of the greatest moves a lot that could be, oh, look at you. Okay. That could be like, yeah, that could be like slightly better than sent a woman.

Speaker 1:          00:05:03       Oh boy. They had also has one of the greatest scenes, uh, between a man and a woman when he is, uh, when the fine young ladies painting her toenails and she's offering them sex for money. Yeah. That would, that's a, that's a beautiful moment to these beautiful, yeah. The comedian, that girl that used to be a hot mess. What's her name? Tara Reid. Yeah. She's still a hot masters. She got her shit together. She's been like shark. The shark NATO series is what she's been, she's in that. So I passed the big Lebowski test. And you failed to sent a woman tests. I don't remember it. I got to wrap this conversation. Legitimately. Don't remember it. I mean, I'm sure it's great. I'm sure it's great if you're a wise man, if you like it, I'm sure it's good. And you also recognize the godfather three is kind of sucks. Yeah. Yeah. But I like the old Pachino reminisce. Listen, Godfather is about,

Speaker 2:          00:05:58       uh, your people. The Italian people have dominated the mob, the brilliant mob movies, right? I mean, godfathers about family, right. There's something deeply like genuine about that, that like in our modern society we really crave for. So it's like bigger than the individual. Bigger than the rules of society. Government, the man. It's family above all. Right. That, that's like a, I dunno, that's timeless. That's the moment with the young Pachino when he talks to what his brother Fredo says, don't ever take sides against the family again, ever. I mean, that's one of the greatest moments. That's great moment. It's all right. All right. All right. I'm a romanticizing a movies here,

Speaker 3:          00:06:48       but like John Wick though. Huh? Never seen it. Whoa. I've never seen it. It's a good, excuse me. It's good movie to watch on the treadmill is, uh, is he playing a Russian mobster and that kills a bunch of them though. And he speaks Russian and he works for the Russians. Kills people for the Russians. You know, canneries is one of the greatest human beings ever. I think so. Yeah. He's like the nicest guy I heard. He's a really nice guy, but he plays a bad gangster. Oh, what am I going to be a little bit more fit? Work out a little bit more. I've seen him without a shirt on, like, hmm. Not quite buying it, but that's okay. The average man. Yeah. But the average man's not the fucking best assassin of all time with all this martial arts skill. Like weight or yeah, but fate or his big fade or might have like a gut buddies.

Speaker 3:          00:07:39       A thick motherfucker. Okay. Especially young fade or ever see young fate or when he was in his prime, like back when he fought like Fujita like back when, uh, this, there's a picture of fate or standing around with a bunch of kettle bells. You ever see that picture? Nope. I was fade. Oregon's lifting days, I suspect. And this is coming from, that's, that's one when fader was fairly young up there, but that's a, that's not the one I'm talking about. You know, the one with the kettle bells is that picture up CEB found that picture never a six pack insight. No, no six pack. But um, I suspect that fade or might have been on some performance enhancing substances during his prime. You mean like hard training? Lots of drilling technique. Uh, set of strategy, steroid hot dare you sir. Dude, he was in pride.

Speaker 3:          00:08:28       Everybody was on steroids. Yeah. That's him. Look at him. That's him in his prime. Hmm. That's a big motherfucker now. I do not know if he was on anything, but everybody else was, I mean, literally everybody, they had it in their contract that you, we will not test for steroids. You know, ensign anyway. Told me that they like essentially encouraged people to take steroids. Yeah. The pride days. That's right. It's not like Russians don't have a long history of using performance enhancing substances. You, I'm sure you saw that movie, um, acreages. Did you see it? Yup. Fascinating. Right. It's, it's a, it's fascinating. I mean, I, I don't, uh, steroids often feel to me like a bit of a witch hunt. Uh, oftentimes you assume people are on steroids. I'm a bit of a, maybe I'm naive or an optimist, but I tend to give people the benefit of the doubt until proven otherwise.

Speaker 3:          00:09:22       But a curious obviously proves that it was kind of throws a monkey wrench of those gears. But you know with a, with fate or the technique and that technique to execution, the timing, the brilliance of his movement, no doubt that heart, no, he was phenomenal. I just want to, if not the greatest heavyweight of all time, he certainly one of them and I don't think steroids would help that. Yes, they do. They help. Yeah. They held that guy particular, yeah. They help everything. They help you training, they help your business, your ability to recover. They help your explosive power, they help your speed. They help everything that, but they also, it's not just steroids, like a lot of them on EPO, Epo, radically in enhances your endurance and they're starting to catch people need they just a stripped Tj Dillashaw the UFC bantamweight champion for start for a EPO or other, it's tragic.

Speaker 3:          00:10:12       Yes, it is tragic. Especially Tj, you mean he's a just a phenomenal fighter. If not, I mean certainly top 10 pound for pound and then this is one of those things that comes up and you go, oh man, it's a legacy killer and this world we have to kind of reconsider what kind of a, what should be allowed and not, yeah, I agree with that. That there, there is an idea of what you should make stair was legal or not legal, sorry, uh, a lot or some kind of supplementation like, well, where's the line when you, when you start to talk about the future of martial arts, the future sport, if you can control the levels so that they're healthy. I mean, isn't that the reason that they're not allowed is because if abused, they become unhealthy. Uh, they damaged longterm wellbeing of the person.

Speaker 3:          00:11:02       There's, look, if that was the case, we wouldn't allow fighting because fighting is more damaging and steroids for sure, for sure. Getting punched and kicked and fucking need in the face and elbowed into unconsciousness that is way worse for you than steroids there. The concern is not for the athlete, the concerns for the opponent. Um, the idea is that you will be able to inflict punishment that you would not ordinarily be able to inflict. You will have more endurance, you will have more power, you will hurt someone potentially even look, there's going to be a time where someone dies in a mixed martial arts of that. And if that's someone who was the victor who did not die was on steroids, it is going to be a huge national tragedy and a massive disaster for the sport, for everything. If that ever does happen, we can only hope it never does.

Speaker 3:          00:11:56       But for sure, you know, it's a, it's a very, very dangerous game you're playing and when you are, martial arts is a very dangerous game. And when you are enhancing your body with chemicals that are illegal while you're doing that game, the real question is though, here's my take on it and this is w is it's one of the most human subjects. And that being meaning, meaning that it's messy. Humans are messy. Like there's good and there's bad, you know, look like abortion is a messy subject. It's messy. You know, whether you have, whether you agree with someone's right to have it or not, it is. What you're doing is, especially as the fetus gets older, it's messy. You know, when it's a complicated discussion, it's not a clear, it's not like you should drink water. You know what I mean? And it's like, it's a very complicated discussion.

Speaker 3:          00:12:47       Steroids are a very complicated discussion. You're not allowed to do them, but they exist for a reason. The reason why they exist is they're really effective. They're really effective at enhancing your body. But how much of that will we allow? We allow Korea team, we allow supplements in terms of, you know, there's, uh, there's certain things that can slightly elevate your testosterone slightly elevate your growth hormone. We allow sauna on ice baths and all these things that have shown to enhance recovery. But that's, that's too much. It's too good there, too effective. Which, but it's weird. It's weird that this thing that we found that makes you better, you can't use. Yeah. And so I have to go back a little bit and disagree with you on something. So in terms of fighting being dangerous and that's if we want it to forbid things that are dangerous for you would fitbit fighting?

Speaker 3:          00:13:38       I think the main thing you're doing can be dangerous, right? The main thing that we're talking about, the sport, the combat event, that can be dangerous because that is what we watch. Two people at the height of their skill, ability, heart passion, putting their life at risk. That can be dangerous. But the supplementation around it, the way to make it, uh, to make their training better, more effective, that can be dangerous. And I thought that can't be named, can't be dangerous. So I thought steroids were considered, were sort of band because abuses lead to longterm damage to health. Now we see steroids as cheating, but it was banned initially because it has detrimental effects. You think that's true? It's not. No, because there's no real evidence that it's detrimental. It's not as detrimental as alcohol when you allow people to drink, bid even, uh, a bit even when abused, where the bodies, like there's, there's not a lot of, like there's a great documentary on it called bigger, stronger, faster.

Speaker 3:          00:14:41       And, uh, it's about my friend Chris Bell. And when you watch that documentary and you realize like, oh well did the real negative consequences of taking steroids or that it shuts down your endocrine system so it stops your body's natural production of testosterone and growth hormone and hormones, that's the real problem. And for young people that can be very devastating and they can lead to depression and suicidal thoughts and all, all sorts of really bad things when your testosterone shuts down. But as far as like death boy, I mean there's, people are prescribed pain pills every day, the week and fighters that are on injuries, uh, that have been, you know, that have gotten surgery. They, they're prescribed pain pills everyday of the week and those pain pills kill people left and right. And that's just a fact. People die of those things all the time, much more so than die of steroids.

Speaker 3:          00:15:35       So I'm not advocating for the use of steroids. Right. I'm just, I'm, I'm being pretty objective and neutral about this, but I'm just looking at it like it is a, it's a very messy subject. Yeah. It's very eloquently put. But so, so your problem in terms of damaging the opponent is if one side takes terrorism. Exactly what happens if both, the problem is you would require someone do that, that maybe someone's a holistic person. They don't want it introduce any unnatural exogenous steroids into their body and hormones in their body. They want, they want everything to be produced by the human body. They want to, they want to eat healthy food, train hard, sleep well and compete naturally had CT Fletcher here yesterday, right? Yes. Is Natural Bodybuilder. Yes. Not Body build powerlifter outlet. Yeah, but that's not required. Right. This is, you're not requiring people, you're giving them the choice.

Speaker 3:          00:16:30       So you know, it's an interesting possibility where in moderation you'll be able to allow steroids and future of athletics because with an argument that if I had done a moderation, you can actually create healthier athletes. Yeah. That's, I mean that's a real argument for the Tour de France, the Tour de France, they say that you actually are better off and healthier taking steroids. Yeah. And Epo. Then you are doing it without it. Cause it's so unbelievable that you're ruling on the body. I mean those athletes, I basically, some of the best people in the world at suffering long term suffering, it's incredible. Ultra marathon runners, all those guys, it's incredibly different sort of thing. You know. And you know the thing about ultra marathon runners, there's didn't even test them cause they're like, good luck. Those people have iron. Will's like, I don't know if it like Courtney dual Walters, a woman who, you know, she is, she's been in here, she eats candy, just drinks beer each candy and pizza make sense? Yeah. I mean she's just got fucking iron will or her will is indomitable and you could take all the steroids you want when you're running for three days. That chick is going to beat you. He just doesn't know how to quit. Just has no quit in. Did you see the podcast with her where she talked about how she fell? She couldn't see. She was in experiencing, uh, I think

Speaker 1:          00:17:50       it was inner ocular hemorrhaging. Yeah. So her, her eyeballs were bleeding internally, something like that where it was impeding her vision. She couldn't say, I would stop. I would stop running. No, she fell because you couldn't see, busted her head open, bleeding all down. Her face keeps running. Barely, barely. Can see her feet as she's running, keeps running. I'm glad those people are out there like that. Like I don't know how to quit. Really? Yeah. I'm like, I do a lot of stuff like that. Like stupid. Like I ran yesterday. I couldn't sleep. I ran here yesterday, 13 miles. I'm not a runner. Just, just this weird obsession. Do you don't run. I run, but I'm not a runner. I look at my body. I'm a, I have a similar body like yours. We're not exactly, we'd do like better built for short sprinting and then maybe killing somebody with our hands versus a long distance.

Speaker 1:          00:18:46       You're a black belt in Jujitsu, right? Yeah. Yeah. Where do you train it now? Train at Broadway. Jiu in Boston. Nice. And that's, uh, and before I was in, in Philly, balanced studios with film and movies and so on. Uh, but Cobb Bochniac I actually transcend Broadway. Oh really? I love that car. Yeah, he a I had last time was on it. I actually wanted to talk about this, a bead fight cause I'm, I'm rushing so I loved the Russian way. But I also love the, I mean Kyle, Timmy represents like the American, he's like the rocky, if you, if you remember that fight with the, against the deep, the third round he was winning. I mean that's the best of what martial arts is. MMA is to me is like you have two technicians, they just throw everything away. Like screw this, I'm just going to throw it out.

Speaker 1:          00:19:34       Was it beat? Had broken his hand broke his hand somewhere I think in the second round. So he was pretty compromised going into the third round. I couldn't really fire back and Kyle was just has zero Quintin them. The guy's an animal. Yeah. I mean that's the most beautiful, you talk about like technical fights in the ground or technical striking. Like when like two technicians throw everything away. That's, I'm sorry. But that's what is the, uh, that I'd get a love the most about any kind of fighting, any kind of sport. I enjoy it in the moment. I discourage it heavily. I don't think it's a smart way to fight. Yeah, well that's, that's probably your job is my job. It's like what I like, like I get, I get the impulse, but I don't want people to give into the impulse. I think fighting is something that you should do correctly.

Speaker 1:          00:20:23       You should do, you should do, there's, there's principles that you should follow to fight correctly. It doesn't mean that you shouldn't take chances, but you know, there's moments like, um, um, Ricardo Lamas when, uh, he fought Max Holloway and they just stood in the center of the ring for the last few seconds of the fight and Max Holloway pointed down at the ground and he's like, come on right here, right here. And they just started so wing in Heymach. It was amazing. Well, it happened, but if I was in Max's corner, I'd be like, don't, no, don't do that, man. This macho shit is going to give you fucking brain damage. You're going to get hit with shots he wouldn't get hit with. That's a difficult, like you said, human nature is messy. I would say that is the greatest. That is the greatest moment of their lives. What? That war?

Speaker 1:          00:21:15       No, listen, this is the greatest moment of Max Holloway's like Max Holloway is the greatest featherweight all time discussion. No, but Max Holloway is the greatest featherweight of all time. He's the guy who destroyed Jos√© Aldo twice. He's a guy that he's, he's beaten everybody in front of him at featherweight. The idea that this one moment where they decided to throw out all his skill and technique and just swing for the bleachers in the middle of the octagon. It was a fun moment. It was great to watch, but the idea that that was the greatest moment of his life, his word. You're a crazy person. Yeah. There's moments in sports. They're just magic. Olympics. Bring that when like the thing that you don't think should happen, it can't possibly happen or is not wise where people just throw everything away. Yeah. Yeah. A passion person. Fashion Person. Yeah, for sure.

Speaker 1:          00:22:06       That's an interesting thing for someone who studies artificial intelligence. I mean if anybody listened to his podcast, but what the fuck does this guy do? Our dogs. They talk about movies. So many people talk about Sean was vehicle. We are, we have plenty of time sir. We have plenty of time. But that's the beautiful thing about this podcast. We're just talking. So tell me what you got here with your notes man. I mean you are fucking prepared. I mean, yeah, a lot of shit here. Many, many pages for sure. I don't want to miss, I don't miss stuff. I mean there's a, there's been a lot of exciting stuff on the autonomous vehicle space since you came on. I got a Tesla and I've experienced what that thing is like when I put it on autopilot and it's stunning. It's crazy. I mean this is in terms of the performance of the v amazing well in, in terms of its ability to change lanes and its ability to drive without you doing anything.

Speaker 1:          00:22:58       I just put my hand on the wheel and hold it there and it does all the work. So because like one or two people listened to this podcast, I want to take this opportunity and tell people, if you drive a Tesla, whether you listen to this now or a year from now, two years from now, Tesla or any other car, keep your damn eyes on the road. So whatever you think the system is able to do, you will have to still monitor the road and you still have to take over when it fails, if, when really. So we're throwing, this is like the moment where throwing down right now. I think it's an express your level of expertise obviously. I mean I'm not throwing down with you on, no, I think it's really important

Speaker 2:          00:23:46       to, in this transitionary phase, whatever the car company, uh, whatever the system that we don't overtrust the system, we don't become complacent. We don't think he could do more than he can. Currently. 40,000 people die in the United States from, from fatal crashes. The number one reason for that is distraction. So texting, smartphones, how much has it gone up since smartphones, people don't exactly where they're trying to understand that. There's a lot of studies showing that it's significant increases, but it's hard to say it's because of smartphones, but it's almost obvious. I mean it's pretty obvious. The flip side is even though everybody's not using a smart phone, texting, so on, they've become better at using the smartphone. So they're better at texting and driving. The better balancing that. Now this is a horrible thing to do. So if you're listening to this podcast, you should listen to it in your car and keep your eyes on the road and not text. I think worst was Pokemon when Pokemon

Speaker 1:          00:24:48       was in its prime. I was watching a guy on the highway playing Pokemon as he was driving and uh, no more than one person. Two people, a guy. And I saw a girl, dude wants to holding the phone on the steering wheel. Playing Pokemon.

Speaker 2:          00:25:01       Yeah. Yeah. It's incredible. What are you doing Jeremy? That's GRANDPA's. Oh Shit. Sorry.

Speaker 1:          00:25:10       I'm confused. What does this, uh, this grandpa in Japan, he drives around on a bike. Oh, playing Pokemon. All, it's the same exact time. This guys, 15 phones. It's ridiculous. This guy needs to find hookers. There's people that do this also in their car with maybe four or five doing exactly what you're saying. This man needs a better hobby. This is preposterous. Look at the, look at his file. He can't see what the fuck's going on in front of him. He spends about $300 a month to buy virtual currencies in the game. Wow. That guy's board or in an innovative genius thing. In that perspective, when people misuse their innovative Josie innovative, he's just playing a stupid game while he's driving around on his bike like an asshole. Well, he's doing is back to the set of a woman thing. It's passion. It's the most amazing moment of his life.

Speaker 1:          00:26:03       I'm sure most people are on my side scent of a woman versus you think most people are on your side. They think Santam a woman is the greatest movie of all that to a woman, but I was defending GFE father sent him a woman. You weren't defending godfather against me. I mean, I'm going to throw you under the plan. Okay. I'm going to manipulate this conversation. Jamie, can you edit this in post? Did you see the video that just came out yesterday of a, a Tesla on autopilot avoiding a crash. All right, so yeah, I have and there's a lot of example. Quite a few of those.

Speaker 2:          00:26:33       Yeah, of course. It's like hard to prove exactly what happened and where the auto Paul was involved. Just like on the flip side, it's hard to prove that autopilot was involved in the dangerous stuff, but think by any measure the media is really negative in terms of their reporting on Tessa there I think, I think you've talked to this about before in general, negativity gets more clicks and I think Tesla negative stuff on Tesla, it gets a lot of clicks so and well not Tesla. Let, let me speak more broadly about autonomous vehicles. If there's any fatality, any crash, it's overrepresented, it's over reported on. So I need to meet people who are interested in AI helping save lives in these systems like autopilot. I feel you carry the responsibility of being at least as good of a driver you are when it's under manual control. So don't text and drive. Keep your eyes on the road by saying anything over and over in this podcast is that drunk driving of course is the other one. And so don't drink and drive, but the number one thing is distracted driving. So put your phone down. I agree.

Speaker 1:          00:27:44       Um, listen to some music, some classic Rock Classic Rajoy. Yeah, yeah. Click credence into a no, no, no. Like it. Like you would change the channel. Now you're going to put me in this, of course. The side. There you go. I take a, I take my shirt off. No. Uh,

Speaker 2:          00:28:07       Glen Lynyrd Skinner course, Hendrix course called jerks. And I have to admit something. I thought about messaging you a couple of times. Uh, I wanted to, I play guitar. Do you? Yeah, you can't,

Speaker 1:          00:28:23       are you good at Jujitsu? Yeah, I'm good. Okay. I'm on black belt. I'm pretty good. You're a black belt too. I'm sure you're good. Yeah. I'm not world class and A, I'm on use. Fuck me up. I'm a three striped purple belt guitar. Ah, that's a good way of putting it. Yeah. Yeah. I say that. What about hunting? I'm like a blue belt hunting.

Speaker 2:          00:28:38       Yeah. Yeah, yeah. I've been doing it like I got the purple belt by doing it a long time as opposed to being amazing. But you take lessons now. I learned everything myself. I have a couple of videos online. Me playing comfortably numb.

Speaker 1:          00:28:53       Learn from watching videos or did you learn from books? Like how did you like, let me see this.

Speaker 4:          00:28:58       Give me this. Look at you. It's going to get us food off of Youtube.

Speaker 1:          00:29:05       Yeah, this is going to play. No, no, no. It probably won't pick it up and if it picks it up it'll be to my channel and I'll shot. It's me playing. What do you mean it's so good. It sounds like people from humming songs for you. But so this is on youtube and this is the, no, I didn't know that. But this didn't get blocked. If you were humming a song and then someone made a claim on that song, it would block our, our youtube like literally we could get demonetized and put we could, we lose our streaming and bill. Lots of things can happen. Lots of things. It's fucked up man. Like we've, we've gotten flagged for watching something on the screen, picture in picture, no sound commenting on it, and we get flagged and they want all the advertising revenue from a three hour show for five, 10 seconds of a video.

Speaker 1:          00:29:54       It's a slightly broken system. Ooh, it's broken. But there's a lot of scam artists too. So I, I played another song, black Betty. Oh yeah. And I got, I don't know. Yeah, I played the damn song. But they, they said it was, it wasn't, they did exactly that. Oh, they said it was the ram jam or whatever it said it was there and I may have borrowed beat behind it from them. I'm not sure. I just took all the like, yeah. Well that's what I was thinking about that song. Like it sounded like there was other shit going on besides just your guitar.

Speaker 1:          00:30:27       Oh No, that's all me real. It's all made bad. The back we had that again. That's really good, man. He sounded good. That's a great fucking song to comfortably numb. You know, the scariest thing for me to play guitar on this podcast. So I was like going back and forth. Oh really? I do it. Should I not do it? Actually play, play, play. And the only, it was only a few people that ever played play Everlast um, Ben and Suzanne from honey, honey. Uh, Gary Clark didn't write and he just came on and talked and he brought his guitar. I wanted to play a Hendrix here. Really live life. You got it right with you right now in the torture? Yeah. Well, no, I meant I was okay. Sure. If in the future, and I'm not promising I scare you were a Hendrix wig with a Bandana.

Speaker 1:          00:31:11       Is that racially insensitive though? You're allowed to Joe. I will not take it. As I said face. You're allowed. Okay. The hair is like, just, you know, it's just hair. Is this how you can't wear dreadlocks? So, yeah. So there's rules, but I think you, yeah, there's rules. I just, Hendricks is above all the rules though, right? Well, he's the goat of guitar players. That's the goat. One of them. You know the reason why this call, the show's called, yeah, I stole it from Jimmy Hendrix. Yeah. What's mine. I don't remember if we brought this up last time, but I just remember seeing this video where you're playing guitar while you were driving. Yup. Well you shouldn't do that, dude. It's the reason why he was doing it. Why are you doing that on a test track? Oh, what kind of car is that? Looks at the Lincoln Lincoln Mkc.

Speaker 1:          00:32:01       Yes sir. Oh, they do that? The Lincolns do that. We converted it and we, that's The r code controlling the car. Wow. That is crazy. So you converted this car to drive autonomous Thomas? They, yeah. Wow. And what, what exactly do you have to do to a car to change? Like, because that car does not have the capacity, the capacity to do anything like that. So the right my correct. No, no, no, no, absolutely not. But you are absolutely correct. The, there's the first part is being able to control the car with a computer, which is converting it

Speaker 2:          00:32:40       to be drive by wire so you can control the steering and the braking acceleration to, to basically be able to control with a joystick. And then you have to put laser sensors all around the cars that we need to kind of sensor and a software. So what's the best kind of sensor? Is it the cold laser? A lot of debate on this. And this is the big, this is the throwdown between Elon Musk and everybody else. Oh, they all Musk says the best sensors, camera everybody else while everybody else says that at this time, Lidar, which are these lasers is the best sensor. So that I'm more on the side in this case on camera and Elan Musk. So here's the difference. Lasers are more precise. They worked better in, in poor lighting conditions. They're more reliable. You can actually build safe systems today that use lidar.

Speaker 2:          00:33:29       The problem is that they don't have, they're much information. So we use our eyes to drive and uh, cameras, the same thing. And they have just a lot more information. So if you're going to build artificial intelligence systems, so machine learning systems that learn from huge amounts of data cameras, the way to go because you can learn so much more. You can see so much more. So the, the richer, deeper censor his camera, but it's much harder. You have to collect a huge amount of data. It's a little bit more futuristic. So it's longer term solution. So today to build a safe vehicle, you have to go lidar tomorrow, however you define tomorrow, he almost says it's an a year. Others say it's five, 10, 20 years cameras the way to go. So that's, that's the, the hard debate. And there's, there's a lot of other debates, but that's one of the core ones.

Speaker 2:          00:34:19       It's basically for camera, you, if you go camera, like you're doing the Tusla, there's seven cameras in your Tesla, uh, three looking forward, there's all around, so on one looking inside, no, you have the model s yeah, yeah. So that, that one doesn't have a camera that's looking inside. So it's all, all cameras plus radar and ultrasonic sensors. That approach requires collecting huge amounts of data. And they're doing that. They drove now about 1.3 billion miles under autopilot. She uses, yeah, it's, it's a, it's a very large amount of data. So you're talking about over 500,000 vehicles have autopilot, 450 I think thousand have the new version of autopilot autopilot to which is the one you're driving and all of that is data. So all of those, all the edge cases, what they call them, all the difficult situations that occur is feeding the machine learning system to become better and better and better. And the open question is how much better does need to get to get to the human level performance? And like one of the big thing, one of the big assumption, so a Cema beings is that we think that driving is actually pretty easy and we think that humans suck at driving

Speaker 5:          00:35:38       those two assumptions. Do you think like driving it, you know you stay in the lane, you stop at the stop sign is pretty easy to to automate. And then the other one is you think like humans are terrible drivers and so there'll be easy to build a machine that outperforms humans are driving now. There is, that's a, I think there's a lot of flaws behind that intuition we take for granted how hard it is to look at the scene. Like everything you just did picked up, moved around some objects. It's really difficult to build an artificial intelligence system that does that. To be able to perceive and understand the seen enough to understand the physics of the scene. Like all these objects that it like how to pick them up, the texture of those objects, the weight to understand glasses folded and unfolded, open water bottle, all those things is common sense knowledge that we take for granted.

Speaker 5:          00:36:30       We think it's trivial but there is no artificial system in the world today. Nor will there be for perhaps quite a while that can reason do that kind of common sense. Reasoning about the physical world. Add to that, uh, pedestrians. So add some crazy people in this room right now to the whole scene and being able to notice like, or this guy is an asshole look and what was he doing? What does he know? And get off that skateboard out. Jesus isn't traffic yet. And the considering, not that he's an asshole, he's a respectable skateboarder.

Speaker 5:          00:37:03       It that in order to make him behave a certain way, you yourself have to behave a certain way. So it's not just you have to perceive the world, you have to act in a way that you have to assert your presence in this world. You have to take risks. So in order to make the skateboard and not cross the street, you have to have accelerate if you have the right away. And these are that, there's a game theoretic game of chicken to get right. I mean we don't even know how to approach that as a, as uh, artificial intelligence sort of research community and also as a society do we want an autonomous vehicle that speeds up in order to make a pedestrian not cross the street, which is what we do all the time. We have to assert our presence. If there's a, if there's a person who doesn't have the right of way, it could begins crossing.

Speaker 5:          00:37:54       We're going to either maintain speed or speed up potentially if we want them to not cross. So that, that game there to get that right. That's a dangerous game for a robot. It's for a robot. And for us to be rationally, if that God forbid, least of fatality for us as a society to rationally reason about that. I think about that. I mean a fatality like that could basically bankrupt the company. There's a lawsuit going on right now, um, about uh, uh, an accident in northern California with the Tesla. Yeah. And Are you aware of, well yeah, that one. Yeah, this was the circumstances about that one. So there was a, I believe in mountain view,

Speaker 2:          00:38:36       a fatality and a Tesla where it, this is a common problem for all, all link keeping systems. Like, like that's a lot of pilot is a, those, a divider in the highway and basically the car was driving, you know, along the lane and then the car in front moved to an adjacent lane and this divider appeared right? So you have to now steer to the right and the car didn't in one straight into the divider. Oh Wow. And it's, you know, uh, the basically what that boils down to is the car drifted out of lane, right? Or it didn't adjust properly to the lane and those kinds of things happen.

Speaker 3:          00:39:15       And this is because the person was allowing the autopilot to do everything.

Speaker 2:          00:39:20       Nope. That you can't. So we have to be extremely careful here. I don't know that the really deep details of the case, I'm not sure exactly how many people will do. So there's a judgment on what the person was doing and then there's an analysis of what the system did, right. The system did, it drifted out of lane and the question is did the person, was the person paying attention and was there enough time given for the person to take over and if they were paying attention to catch the vehicle, steer back onto the road. As far as I believe the only information they have is hands on steering wheel. And they were saying that like half. That's half the minute leading up to the crash. The hands weren't on the steering wheel or something like that. Basically trying to infer where the person paying attention or not, but we don't have the information exactly what wa where were their eyes? Right. You can only make guesses as far as I know. Again, so the question is, this is the eyes on the road thing because I think I've heard Jenna pocket saying you're attempted to sort of look off the road that your new Tesla or at least become a little bit complacent.

Speaker 3:          00:40:28       The worry, the worry is that you, you just rely on the thing that you would relax too much, but what would that relaxation lead to that the problem is if something happened, if you weren't, you know when you're driving. I mean we've discussed this many times on the podcast to the reason why people have road rage. One of the reasons is cause you were in a heightened state because cars are flying around you and your brain is prepared to make split second decisions and moves. And the worry is that you would relax that because you're so comfortable with that thing driving everybody that I know that it's tried that they say you get really used to it doing that. You get really used to it just driving around for you.

Speaker 2:          00:41:09       So the question is what be, what happens when you get used to it? Yeah. You started looking off road. Do you started texting more? Do you start watching a movie? It's that, uh, that, that's a, that's a really an open question. And the like for example, we just did the study, uh, published a study from the MIT on what people in our Dataset, we have local at this Dataset of 300 miles and Tesla's, we instrumented all these Teslas and watch what people are actually doing and are they paying attention when they disengage the system? So there's a really important moment here. We have 18,000 of those when the person catches the car, you know the disengage autopilot and that's a really a Tesla uses this moment as well. That's a really important window into difficult cases. So some percentage of those, some small percentage, about 10% is we call them.

Speaker 2:          00:42:02       Tricky situations is situations where you have to immediately respond like drifting out of lane if there's a stopped car in front. So on. The question is, are people paying attention during those moments? So in our dataset that we're paying attention, there were still remaining vigilant. Now in our Dataset, the autopilot was going on quote, encountering tricky situations every 9.2 miles. So you could say it was a failing every 9.2 miles. That is one of the reasons we believe that people are still paying it, remaining vigilant, that it's regularly and unpredictably sort of drifting out of the lane or misbehaving. So you don't overtrust it, you don't become too complacent. The open question is when it becomes better and better and better and better, will you start becoming complacent when it drives on the highway for an hour, an hour and a half and is opposed to 9.2 miles, make that 50 miles, 60 miles. Do you start to overtrust it? And that's a really open question.

Speaker 3:          00:43:08       Do you think or do you anticipate a time and anywhere in the near future where you won't have to correct, you will allow the car to do it because the car will be perfect.

Speaker 2:          00:43:18       The car, first of all, we'll never be perfect. No car will ever be perfect.

Speaker 3:          00:43:22       Autonomous Vehicles will always, you think require at least some sort of manual override. Yeah. Really. That's interesting that you're saying that because you work in AI. Like what makes you think that that's impossible to achieve? Well let's, let's talk cause cause you're using the word perfection. I think perfection. That's a bad word. Yeah. So I guess you're implying it. Let me see. Will it achieve? Because people are obviously not perfect yet. We'll achieve a state of competence that exceeds the human beings.

Speaker 2:          00:43:54       Okay. And let's put it in a dark way. Competence measured by fatal crashes. Yes. Uh, yes. I absolutely believe so. And perhaps in the near term, near term, five years for me, five 10 years is near term for Elan, Elan Musk time that converted to one year. Have you met him? Yes. Interviewed him recently.

Speaker 3:          00:44:22       Fascinating cat, right? Yup. Got a lot of weird shit bouncing around behind those eyeballs. You don't realize until you talked to him in person, you're like, oh, got a lot going on

Speaker 2:          00:44:32       in there, man. Yeah. There's this passion, this drive. I mean, it's one of the hurricane of ideas and a focus and confidence. I mean, the thing is in a lot of the things he does, which I admire greatly from any man or a woman innovator, it's just boldly, fearlessly pursuing new ideas or jumping off the cliff and learning to fly in the way down that that's, I mean, well, no matter what happens, he'll be remembered as the great innovators of our time. Uh, whatever you say, maybe in my book, Steve Jobs was as well. Even if you criticize, perhaps he hasn't contributed significantly to the technological development of the company or the different ideas they did. Still his brilliance was in all the products of iPhone, of the personal computer, the Mac and so on. And I think the same is true with uh, with uh, with Ilan and yes, there's in this space of autonomous vehicles of, of semi autonomous vehicles, of driver assistance systems, it's a pretty tense space to operate in.

Speaker 2:          00:45:42       There's several communities in there that are very responsible but also aggressive in their criticism. So in driving in the automotive sector, obviously since Henry Ford and before there's been a culture of safety of just great engineering. These are like some of the best engineers in the world in terms of large scale production. He talked about [inaudible] are you talking about for GM? These people know how to do safety well and so care combs, he, along with silicon valley ideals that throws a lot of it out the window and says we're going to revolutionize the way we do automation in general. We'll go into make software updates to the car once a week, twice a week over the air. Just like that. That makes people in the safety engineers and human factors engineers really uncomfortable. Like, what do you mean you're going to keep updating the software of the car without like how are you testing it?

Speaker 2:          00:46:39       Right? That makes people really uncomfortable. Why does it make them uncomfortable? Because the way in the automotive sector, you test the system, you come up with a design of the car, every component, and then you go through like really rigorous testing before it ever hits the road. Right? Here's an idea from the Tesla side is where they basically, they in shadow moe test the software, but then they just release it. So essentially the drivers become the testing and then they regularly update it to, uh, to, uh, to adjust a, if any issues arise that makes people uncomfortable because there's not a standardized testing procedure. There's not, there's not at least the feeling in the industry of rigor because the reality is we don't know how to test software in the same corner of with the same kind of rigor that we've tasted,

Speaker 5:          00:47:30       the automotive system tested automotive system in the past. So I think it's extremely exciting and powerful to make software sort of approach, uh, automotive engineering with at least in part a software engineering perspective. So just doing what's made silicon valley successful. So updating regularly, aggressively innovating on the software side. So your Tesla over the air while we're sitting here could get a total annual update. The flip of a, uh, of a bit as a Elon Musk says, uh, it can be, he can gain all new capabilities. That's really exciting, but that's also dangerous and that, that balance, we, uh, what's dangerous about it? That'd be faulty software faulty a bug. So if you're, you're the apps on your phone, you know, fail all the time. Where as a society used to software failing and we just kind of reboot the device when we start the APP.

Speaker 5:          00:48:29       A the most complex software systems in, in the world today. If we think outside of nuclear engineering and so on, they're really nobody that they're too complex to really thoroughly tests. So a thorough, complete testing proving that the software is safe is nearly impossible. I'm most software systems that that's IX, that's a, that's nerve wracking too. A lot of people because a, there's no way to prove that the new software update is safe. So what it, what is the process like do know like how they create software, they update it and then they tested on something. How much testing do they do and what, how much did they do before they upload it to your car? Yeah, so I don't have any inside information, but I have a lot of sort of public available information, which is, uh, they, uh, they test the software in shadow mode, meaning they see how the new software compares to the current software by running it in parallel on the cars and seeing if there's disagreements, if like, uh, seeing if there's any major disagreements and bringing those up and seeing what by parallel, I'm sorry.

Speaker 5:          00:49:43       Do you mean both programs running at the same time? One, the original update? Yes. At the same time, the original update actually controlling the car and the new update is just making the same decision, making the same decisions without them being, without actually affecting the actual okay. Without actually affecting the vehicles dynamics. And so that's, that's a really powerful way of testing. I think the software infrastructure that Tesla's built a loss for that and I think other companies should do the same. That's a really exciting, powerful way to approach not just a automation, not just the autonomous vehicles or semi autonomous vehicles, but just safety is basically all the data that's on cars. Bring it back to a central point to where you can use the edge cases, all the weird situations, and driving to a, improve the system to test the system, to learn to understand where the cars used misused, how can be improved and so on.

Speaker 5:          00:50:45       That's an extremely powerful how many people they have that are analyzing all this data. It's a, it's a really good question. So they have, the interesting thing about driving is most of it is pretty boring. Nothing interesting happens. So they have automated ways of extracting again what are called edge cases. So these weird moments of driving and once you have these weird moments, they have people annotate it. I don't know what the number is, but a lot of companies are doing this. It's in the hundreds and the thousands and basically have humans annotate the data to see what happened. But most of what they're trying to do is to automate that annotation. So to figure out how the da Da da, it can be automatically used to improve the system. So they, they have, they have methods for that because it's a huge amount of data.

Speaker 5:          00:51:34       Right. I think in the recent autonomy day, a couple of weeks ago, they had this big autonomy day where they had demonstrated, uh, the vehicle driving itself on a particular stretch of road. They, uh, they showed off that, you know, they're able to query the data, basically ask questions of the data saying, uh, the example they gave is there's a bike on the back of a car and a bicycle on the back of a car. And they're able to say, well, when the bicycles in the back of a car, that's not a bicycle, that's just the part of the car. And they're able to now look back into the data and find all the other cases, the thousands of cases that happened all over the world in Europe, in Asia, in South America and North America and so on, and pull all those elements and then train the train, uh, the perception system of autopilot to be able to, to, uh, better recognize those bicycles as part of the car.

Speaker 5:          00:52:28       And so every edge case like that, they go through saying, okay, the car freaked out in this moment. And then we find moments like this in the rest of the data and then improve the system. So it's, it's, uh, this kind of cycle is the way to deal with, uh, with problems with failures of the system is to say every time the car fails at something, say, is this part of a bigger set of problems? Can I find all those problems and can I improve it with a new update? And that it just keeps going. The open question is how many loops like that you have to take for the car to become really good, better than human. Basically, how hard is driving? How many weird situations when you manually drive do you deal with every day somebody, uh, somebody mentioned, I don't know that there's like millions of cases when you watch video, you see them, somebody you mentioned, um, that drive a truck or ups truck and passed cow pastures and they know that if there's no cows in the cow pasture, that means they're grazing. And if they're grazing, I mean like be using the correct terms. I apologize. And not a car guy. Uh, that, that means that there may be cows up ahead on the road. There's just this kind of reasoning it can use to anticipate difficult situations. And we do, we do that kind of reasoning about like everything cars today can't do that kind of reasoning. They're just perceiving what's in front of them.

Speaker 3:          00:54:00       Now, outside of Tesla, how many other companies have autonomous systems that are driving their cars?

Speaker 5:          00:54:06       So maybe it's good to step back. There are several, and there are several leaders in each different approach. So first let's draw a line between the different types of systems that are one. There is fully autonomous vehicles. These are cars you can think about that don't have a steering wheel or if they have a steering wheel, it doesn't matter. They're in full control. And if there's a crash, the car companies liable that those exist. No, it, it's, it's a gray area though because many companies are basically saying that that's what they're doing, but they're not quite there. So the leader in that space is a used to be called Google self driving car program now it's called Waymo. They are doing that there. It's called level four, level five. There's levels to this game. And this is this particular level where it's fully autonomous. Now they're trying to achieve full autonomy, but the way they're doing it currently is they're testing on public roads with what's called the safety driver. So there's a driver always ready to take over and the driver does have to take over at some rate, you know, frequently. And so the fact that the driver has to take over, that's not fully autonomous then. Right? So there's no car today that you can just get in without a safety driver. So there's nobody behind the wheel. And a using your apps sort of get from point a to point B,

Speaker 3:          00:55:33       but out of the cars that are semi autonomous where there is an autonomous program, but you do have to keep your hands on the wheel and p pay attention to the road. What, what are the leaders besides Tesla? There's Tesla and who else is doing it? So there's, Yep.

Speaker 5:          00:55:47       Uh, there's several systems. It depends how you define leader. But so are the, yes.

Speaker 3:          00:55:55       See this, like does Mercedes and BMW, they use the same system? Do they, does someone make a system for cars or do they create their own systems? That's a really good question. So there's, in some cases there

Speaker 5:          00:56:07       belie and Invidia there's these companies that Nvidia, the, the video card be in a car company. Yup. The same, the same folks that power the quake game, right. The, the graphics and the quake game. You can use those Gpu graphics processing to run machine learning code. So they're also creating the nvidia drive. Yep. Scalable Ai Platform for autonomous driving. In fact, uh, I don't, when did you buy a Tesla? Five months ago or something, something like that. So the thing in there now, most likely is a nvidia draft px two system. So the one that works on cameras that, uh, that just runs code that takes in camera data, but it can work on anything else. So it could work on lidar as well. Somebody had a system. Yeah. But it needs a different code. So the lidar requires very different kinds of processing. Does anybody use that with cars?

Speaker 5:          00:57:04       With all semi autonomous cars? Lighter, yes. The as well. Okay. So semiautonomous we have to be careful because a, the Waymo cars like the, the quote unquote fully autonomous cars are currently semi autonomous. Okay. So that's the highest level of semiautonomous autonomous, right? Yeah. That guests, it's, it's not even a highest level. It's a principle. It's a philosophy difference. Cause they're saying we're going to do full autonomy. We just not quite there yet. Uh, most other companies, they're doing semiautonomous better called driver assistance systems is they're saying we're not interested in full autonomy. We just want a driver assistance system. They just helps you steer the car. So let, let's call those semi autonomous vehicles or driver assistance systems. The, there's several leaders in that space. Like one car we're studying that's really interesting is a Cadillac super cruise system. So GM has the system, it's called super cruise that I think is the best comparable system to autopilot today.

Speaker 5:          00:58:09       The, uh, the key differentiator there is, there's a lot of little elements, but the key differentiators, there's a driver monitoring system. So there's a camera that looks at you and tells you if your eyes on the road or not. And if your eyes go off the road for I believe more than six seconds, it starts warning you and says you have to be, you have to get your eyes back on the road. So that's called driver monitoring. That's one of the big disagreements. For example, if you mean Ilan and uh, many experts in the field and Ilan and the Tesla approach is that there should be a driver monitoring system. There should be a camera. Loquat is Ilan feel like there shouldn't be, I think his focus, the Tesla's focus is on just improving the system so fast and so effectively that it doesn't matter what the driver does that it, it, you know, so essentially no safety net, no safety net. And I think they operate like that and in many ideas that they work with is they sort of bold leap, proceed forward to try to make the car extremely safe. Now, the concern there is you have to acknowledge the psychology of human beings. Then unless the car

Speaker 6:          00:59:22       is perfect or under our definition, perfect, which is much better than human beings, then you have to be able to, you have to be able to make sure that the people are still paying attention to help the car out when it fails and for that you have to have drive a modern, you have to know what the car is right now. Your Tesla only knows about your presence be from the steering wheel touching the steering wheel, which is a kind of driver monitoring system. It knows you're there, but it's not nearly as effective at knowing your, they're cognitively, visually, you can be tricked by clamps, seen people do that. Then develop these clamps that you just put on the steering wheel. It'll hold a phone and then also trick the system into thinking that you're holding onto the wheel. Yeah, you can do a lot of purses actually work really law are asking me how hanging purse, no, like shoving a person and to the, somebody did that with an orange or something like that, but they said it didn't work.

Speaker 6:          01:00:20       Maybe it needs to be all the way around the outside of it. I think it depends on the shape of that orange, how ripe it is. This is a lot of debate and no, I, the point is there's wasted trick the system, there's a, it's not monitoring the driver. That's the point, right? It's not monitoring and driving. A lot of people believe you need to, uh, you need to make sense. Yeah. I think, I think, uh, not just for the safety of the system, but to create an experience like, uh, I think there's value for the car to know more about you. Sort of just like what's happening there. It's scanning this guy's eyes as the minority report. Shit freaked me out. So yeah, there's a lot of companies that are springing up. They're doing computer vision on the face and so on to try to detect where you're looking.

Speaker 6:          01:01:06       So what cars have that now? The uh, the major one is the superconscious. There's not many cars. A few cars are starting to add it. Europe, what's a super cruise system? That's the GM Cadillac. They're trying to, so it's in their super expensive lineup currently and they're, I think trying to add it to the full lineup of all Cadillacs. What does that big cruiser that they have now? The big four door car, the really high end does a CT six I don't know what it is. They have a new one that's really nice. Is that what they're putting it in? The big sedan, that thing? Yes. I it's pretty, I don't know if that's the CT six but the, the one we're looking at the CT six that's 2018 CT six yeah. It's, you know, it's a, but they want to add it to their, their full fleet.

Speaker 6:          01:01:58       And so really interesting. I have the same amount of cameras as the Tesla system does know and it has a very different philosophy as well in another way, which is it only works on very specific worlds on interstate highways. There's something called odd operational design domain. So they define that this thing super system only works on this particular set of roads as they're basically just major highways. The Tesla approach is saying basically, uh, what Ilan jokingly referred to add, right is a works basically annual. So if you tried to turn on your autopilot, you can basically turn it out anywhere where the cameras are able to determine either lane markings or the car in front of you. And so that's a very different approach saying you can basically make it work anywhere or in Cadillac case making work on only specific kinds of roads. So you can test the heck out of those roads, you can map those roads.

Speaker 6:          01:02:54       So you can use actually lidar to map the full road. So you know, the full, uh, geometry of all the, the, the interstate highway system that it can operate on. And then does it also coordinate with gps? We're were sort of understands where like bumps in the road might be or hills. Uh, in that sense, it coordinates to gps for different curvature information, but not the topography, the know and, and like construction is a big one. That'd be crazy if new potholes, you know, with a little potholes is, and the big problem, I think construction is the big problem. Like just this quickly changing dynamic information, which like apps, like ways provide, I mean that's, the huddles are a pretty big problem. Boston. Oh yeah, no for sure. But a New York is actually probably even worse. I blew, I blew out two tires in one day in New York on panels.

Speaker 6:          01:03:43       Set an unlucky day. Yeah. But I'd rather you blow your tire then. Uh, then I mean the, the kind of fatality that happened in, um, in the mountain view with the Tesla, I believe is slightly construction related. So I mean, there's a lot of safety critical events that happen. Latest stuff. I would like it if that stupid Tusla could figure out the hole in the ground now so I don't have to blow a tire out. Like, come on, Bro. Yeah, you're paying Joe figure it out. But priorities. I'll, I'll, uh, I'll make sure I'll forward this podcast to airlines. Make sure they work on this. I think he's busy. What does this Jamie Tesla autopilot, we'll be able to avoid potholes in the road. Says Ilan mosque. Ha Ha. Motherfuckers on top of shit with the data on that. April, April 7th. Okay. Just now that's an interesting thing.

Speaker 6:          01:04:32       That's another, that's almost an ethical question whether you want a car to avoid a situation by swerving, right? Because when you swerve, you now introduce as opposed to sort of breaking the vehicle only you swerving into another lane means you might create a safety situation elsewhere. You might put somebody else in danger. Yeah, that's why I was saying if it coordinated with gps it would have previous knowledge, you know, sort of like ways tells you where the cops are. Yup. You know what I mean? So that kind of information will be extremely powerful and useful. The problem is it's hard to get it really up to date, that kind of information really up to date. It's just an infrastructure question. Just getting the, getting the software, the data in place to where the car would be able to learn quickly from all the things that are changing.

Speaker 6:          01:05:22       I think potholes don't change that often so that that's, that's a different thing. But in terms of construction zones, in terms of other weird things that changed the dynamics, the geometry of the road, that's, that's difficult to, uh, to get, right. So Cadillacs doing a version of it, but it sounds like it's a little bit less and less involved, less comprehensive. Maybe there's a better way of describing yeah. And less, I would say it's more safety focused as a sort of, um, uh, what's the right word to use here? It's more cautious in its implementation. So GM again has a, has a tradition for better, for worse to see Jamie video they have on their website and this pull apart, I'm showing you shows like at the signal coming on pay attention lady, she's too hot. It's not paying attention. Looking at people staring at her and they'll comment. One of the, one of the things that you,

Speaker 5:          01:06:22       it's hard to talk about without actually experiencing the system is what's more important than driving monitoring and any of the details we talk about is like how the whole thing feels, the whole thing together, how it's implemented, the whole interface and a, the Cadillac system has actually done really well in a sense that there's a clarity to it. Like everything becomes, there's a green color and a blue color and you know exactly when the system is on and when it's off. That's one of the big things people struggle with is just confusing in other cars, drivers not being able to understand when the system

Speaker 6:          01:06:56       it was on or off. Right. So you think the system is doing it and then just slam into something that it wasn't even on. Now when this car is operating in this manner, how many cameras is it using [inaudible]

Speaker 5:          01:07:08       yeah, that's a good question. I should know that, but I think a, it's only forward to facing cameras as far as I know. I think it's two cameras. It may be three cameras.

Speaker 6:          01:07:16       Tell her he just sat back. So she doesn't have her hands on the wheel at all. Yup. So she's watching, right,

Speaker 5:          01:07:23       because the car is able to see where the eyes are. It's a hands off system. So you're allowed to take your hands off the wheel. It's very interesting. It's a, and there are certain human behavior aspects that come into play to this. So you start to like, I found myself actually becoming a little more drowsy with this system. Uh, I haven't driven it enough so I haven't gotten used to it. But you have to, at least in the initial stages, it kind of forced you to look at the road in, in a way that felt artificial. I think it's something that gets better with time. You get used to it, but it's almost like a game of fied thing that the, the car when you look off road, uh, starts to tell you that you're looking off road. So you kind of psychologically pressured to always stare at the road and you realize that actually

Speaker 6:          01:08:16       when you drive you off and look around. And so having to like stare forward can be a little bit, uh, yeah, exactly. You start like there's something, um, so not peaceful and hypnotic about those lanes just coming at you. And just the lines here lines, why is that? And I've had, it confuses the shit out of me because I could not be tired at all. But if it's nighttime, when I'm on the highway and those lines, they just start to yeah. Took you to dream land. I get the same with, there's also just the vibration. Is that like that, that hum of driving? Same with trains. Planes as well. Yeah, it puts me out so that there's a two Cadillac system that's the big leader I would say in the driver monitoring. And then Tesla is the no driver monitoring and huge data collection. BMW has a system as well to use.

Speaker 6:          01:09:07       Yeah. BMW. I don't, I don't want to speak too much to the details of it. They have lane keeping systems. So basically systems that keep you in the lane, uh, that is similar to what in spirit autopilot it's supposed to do but is less aggressive in how often you can use it and so on. But if you look at the performance of the, of the actual, how often the system is able to keep you in lane autopilot is currently the leader in that space and they're also the most aggressive, uh, innovators in that space. So they're like really pushing it to improve further and further. And the open question is though, worrying question is if it improves much more, are there going to be effects like complacency? Like people will, we'll take, uh, we'll start texting more. We started looking off road more. That's a totally open question and nobody knows the answer to it really.

Speaker 6:          01:10:00       And there's a lot of folks that I mentioned in the safety engineers and human factors community. So these psychology folks who have roots and like aviation that no, there's, there's been 70 years of work that looks at vigilance that people, if I forced you to sit here and monitor for something weird happening, like radar operators in the World War II had to watch for the.to appear. If I sit you behind that radar and make you do it after about 15 minutes but really 30 minutes, you'll see your rate of being able to detect any problems. We'll go down significantly. You just kind of zone out and so there's like all kinds of psychology studies that show that we just were a crappy human beings are really crappy and monitoring automation. If I tell you, if I put a robot and you would just say, monitor this system so it doesn't kill anyone, you'll you'll tune in.

Speaker 6:          01:10:54       We have to be engaged. You have to be engaged. You have to be, you know, there has to be a dance attention. Kind of like a mode for watching autonomous things, right? If we consider our historically the kind of modes that people have for observing things, we don't really have a mode for making sure that an autonomous thing does his job. Yeah. It's, it's a mindset. Sounded like, Oh, you know what I mean? Like if in my car, okay, I'm driving. Here we go. Ooh. Driving a turn. I'm thinking I'm in driving mode. When you're in autonomous mode and you're observing, he's just like, what is this? I've never done this before us. It's fucking weird. It feels weird. It's not part of human nature. Right. It's on normal state. One thing it's done commonly in now is aviation. So pilots, pilots are basically monitoring fully autonomous planes.

Speaker 6:          01:11:41       Yeah, that's a good point. As far as I know, many planes today could fly almost fully autonomously. It's also a good point when it comes to software and updates because isn't that part of the issue with this Boeing seven 37 Max system, these systems that they've had problems with the been faulty and a couple of crashed. Yeah, and that's a really good point. And they, they've, yeah, there's been too tragic crashes recently with the Mac system and you have, they bench those things, right? Haven't they? I'm not following. They also got rid of a bunch of inspectors. I think they fired like 80 inspectors today and the unions are freaking out. Yep. And there's obviously there's politics is I think FAA supposed to supervise and they were, there was a, there's a close relationship between Boeing and FAA. This questions around, I mean there's better experts at that than me, but on the software side it is worrying because it was a single software update essentially that helps prevent the, the vehicle, the vehicle, the airplane from stalling.

Speaker 6:          01:12:44       So if, if it's uh, if the nose is tilting up, uh, increasing the chance of stalling, it's going to automate automatically a pointed nose down the airplane and the pilots in many cases, as far as I understand, Lauren even informed of this update, right. Then they weren't even told this happening. The idea behind the update is that they're not supposed to really know. It's supposed to just manage the flight for you. Right. The problem happened when there is a angle of attack sensor. So the sensor that tells you the actual tilt of the plane and there was a malfunction in that sensor as far as I understand in both planes. And so the plane didn't actually understand its orientation. So the system started freaking out, started pointing the nose down aggressively, and the pilots were like trying to restabilize the planning couldn't. So shortly after lift off that just yes, that's software update.

Speaker 6:          01:13:38       That's crazy. And that, that's, that's, that's a safety culture that's dealing with this new world of software that we don't know what to do with, you know, and, and yeah, it's a question. Uh, one way is to be sort of a little bit luddite. I used the term carefully and just be afraid and say, you know what? We should really not allow so many software updates. The other one is sort of embracing it and redefining what it means to build safe AI systems in this modern world with updates multiple times a week. What do you think?

Speaker 5:          01:14:12       So I'm 100% for the, for the software approach. So I think updates, regular updates. So combining the two cultures, but really letting good software engineering and lead the way is the way to go. There is, I wish other companies were competing with Tesla on this. They're on the software side. Tesla is far ahead of everyone else in, in the automotive sector. And that's one of the problems. I, I, I'm worried that, you know, competition is good. Right? And I'm worried there's, people are way too far behind to actually give tests the new ideas. I'll compete tests on software. So most cars are not able to do over the air as far as I know. No cars are able to do major over the air updates except Tesla vehicles they do over the air updates to the entertainment system. Like you know, if you're a radio is malfunctioning, but in terms of the control of the vehicle, you have to go to the dealership to get an update.

Speaker 5:          01:15:17       A Tesla is the only one that over the air, like it can multiple times a week do the update. I think that should be a requirement for all car companies, but that requires that they rethink the way they build cars. That's really, that's really scary when you manufacturer over a million cars a year and Toyota and GM to say, especially old school Detroit guys and gals that are like legit car people to say we need to hire some software engineering. That's a challenge. It's a totally, you know, I don't know how often you've been Detroit, but there's a culture difference in Detroit and Silicon Valley and those two have to come together to solve this problem, to have like the adult responsibility, uh, of Detroit, of how to do production well, manufacturer, how to do safety well, how to test the vehicle as well and do the bold, crazy, innovative spirit of silicon valley, which, you know, I'm mosque in basically every way represents.

Speaker 5:          01:16:14       And that I think that will define the future of these have actually AI in general. I mean interacting with AI systems just even outside the automotive sector requires these questions of safety, of Ai, safety of how we supervise the system, how we manage them from misbehaving. And so on. We're also, there's a concern about those systems being vulnerable to third party attacks. Yeah. So hacking. Yeah, that's a, that's a fascinating question. I think there is a whole discipline called adversarial machine learning in AI, which basically any kind of system you can think of how we can feed it examples, how we can add a little bit of noise to the system to full it completely. So there's been demonstrations on Alexa for example, where you can take a, you can take a,

Speaker 3:          01:17:10       you can feed noise into the system that's imperceptive with us humans and make it believe you said anything. So full of system into thinking the ordering extra toilet paper, I dunno. Uh, in the same for cars you can feed noise into the cameras to make it believe that there is, or there isn't a pedestrian, there is or there isn't lane markings. So someone could do this. It's in theory at least. And in theory that's the big difference is in theory is doable. You can do demonstrations in practices actually really difficult to do in the real world. So in the lab you can do it, you can construct a situation where a pedestrian can wear certain types of clothing or put up a certain kind of sign where they disappear from the system. I have to ask you this because now I just remember this, you'd be the perfect person to talk about this.

Speaker 3:          01:17:58       I'm not sure if you remember this case, but there was a guy named Michael Hastings, Michael Hastings with a journalist and he was, I believe in Iraq or Afghanistan. He was somewhere overseas and he was stuck there because of this volcano that erupted and I believe Iceland. And he was over there for the Rolling Stone magazine, uh, and doing, doing an article about a general while he stayed there for a long time because they were stranded because of the volcano. And they got real comfortable around him. And, uh, he reported a lot of the stuff that they said and did that maybe they thought that he probably wouldn't have reported on, including them saying disparaging things about President Obama at the time. Anyway, comes back, the general was forced to resign. Um, he was a beloved general and, uh, Michael Hastings was in fearing for his life because he thought that they were going to come and get them because these people were very, very angry at him. He wound up driving his car into a tree, going like 120 miles an hour and the car exploded and the engine went flying. And people that were the conspiracy theorists were saying they believe that that car had been rigged to work autonomously or that someone for some third party, bad person decided to, or good person, depending on your perspective, decided to drive that guy's car into a fucking tree at 120 miles an hour. Do you think that that, and this is 2011, Michael Hastings Death, 12, maybe 2012.

Speaker 3:          01:19:43       We'll see what it says. 2013. June, 2013. Do you think that in 2013 that would have been possible? It's entirely possible. I just wanted to say that. Huh? Shout out to the Joe Rogan sub reddit. Okay. Uh, check that one off. The

Speaker 5:          01:20:10       Jamie pulled that up. Shut off. Um, I, uh, whether it's possible, it's an interesting question, whether it's likely is another question. I, I think it's very unlikely. And the other most important questions, that's something we should worry at scale about our future is cars being used to assassinate essentially people. I'm Russian, so I've, I've heard of those things being done by our friend Putin, Nova. I think, I think it's very unlikely that this kind of thing would happen at scale, that people would use this. I think there'll be more effective ways to achieve this kind of end for sure. And I, I just think it's a very difficult technical challenge that uh, if hacking happens it would be at a different level than hacking the AI systems. It will be just hacking software and hacking software is the kind of the, the kind of thing that can happen with anything. An elevator elevator software or any kind of software that operates, any aspect of our lives could be hacked. And that same kind of what my, my question though was in 2013 was that a technology available where they could take over someone's car? Do you know what car it was?

Speaker 3:          01:21:36       Mercedes? I think it was an s class. C to C C C class.

Speaker 5:          01:21:41       Yes. Yes, yes. But I, I don't think, oh boy, this is like,

Speaker 3:          01:21:47       no, it's, listen, this has been widely speculated. I know, I'm just asking you because you're actually an expert. I mean it's very rare that you get an expert in autonomous vehicles and you get to run a conspiracy theory by them to see if they can just put a stamp on it being possible or not.

Speaker 5:          01:22:01       Let me just say that Alex Jones is a fishing, not a lot to say. Mit scientists says exactly what he's going to try to do. Uh, no, I um, first of all, let me just back off and say I am not a security expert, which is a very important difference. That is important. So then a autonomous vehicle. I build a autonomous vehicle systems. I don't know how to make them extremely robust, the security to hacking attacks and have a lot of really good friends, which are some of the coolest people I know who are basically hackers converted to security experts. I would say though, loosely speaking, I think the technology was there, yes. For with physical access to the car to be able to control it. But I don't, I think it's extremely unlikely. That's what happened.

Speaker 3:          01:22:48       I agree. I see where you're coming from. Um, I'm not asking you whether or not it's likely that it happened and I'm sure you don't even have much information on the case cause I had explained it to you. Right. That's right. All right. Um, the guy also had, uh, some serious amphetamines in the system. Um,

Speaker 6:          01:23:06       they compared it to crystal Meth, but the reality is he was a journalist and most journalists, I want to say most all lot are on Adderall and Adderall is essentially you amphetamines. I mean, that's what it is. It's real. It's like, it's like next door neighbors to crystal meth really is. Um, he is it, well, you said it's possible they could actually get it to turn the wheel. Yes. I have to look at the exact system that gets that drive by wire thing. And I mentioned some systems are not, uh, it's not so easy to turn the wheel. Actually could, could get them to just accelerate out of control. He's going like 120 something miles an hour and he slammed into a tree. It's entirely possible. Ah, you can't do it twice. The um, the systems back then though, we're far more primitive. Correct? Yeah. Uh, yeah, but it's really, again, the, the attack vectors here.

Speaker 6:          01:24:03       The, so the, the way you hack the systems, I have more to do with the software, Lola, a software that can be primitive than the high level AI stuff. Right. But my issue with it was there's no cameras on the outside of the vehicle. Like there is on a Tesla today. What has autonomous driving as an option as a, so, okay. I see your point now. So he wouldn't be hacking the system that perceives the world and activists in the world. It would literally be malfunction that forces it to not be able to brake, accelerate uncontrollably, which is, uh, you know, it's a more basic kind of attack and then control then making the car steer auto lane. Yes, yes. That's a different, that's what people worry about with the autonomous vehicles. When more and more, you're talking about potentially 10, 20 million lines of source code.

Speaker 6:          01:24:50       So there's all this code and so obviously becomes uh, amenable, susceptible to bugs that can be exploited to hack the code and some people are worried, uh, legitimately so that the security attacks would, uh, would lead to these kind of, um, well at the worst case assassinations but really sort of just basic, uh, basic attacks, basic hacking attacks. And I think it's, I think that's something that people in the automotive industry and certainly tested is really working hard on and making sure that the ad that everything is secure, there's going to be of course vulnerabilities always. But uh, I think they're really serious about preventing them. But in a demonstration space you'd be able to demonstrate some interesting ways to trick the system. And in terms of computer vision, th this all boils down to that these systems are actually, that are ones that are camera based. I not as robust as our human eyes are to the world. So, like I said, if you had a little bit of noise, you can convince it to see anything to us humans, it look like the same road, like the same three pedestrians crossing

Speaker 3:          01:26:04       like a little person on the camera lens, the little cameras, right. You could get down there with a sharpie. That's the one attack vector. That's a is draw stuff. But he jokingly say that, but that's the sun plays tricks on Cadillac, Super Cruise, next generation system. We'll address camera problem. Oh well as long as the next generation addresses it, you fucking assholes. The Sun plays tricks on it. So next gen system is something you're going to have to bring that Cadillac into the dealership and they're going to have to update the song outdated yet. Whereas Tesla would just handle that shit over the area. Yeah, I got an update the other day. I was like, all right, all right. Same as,

Speaker 2:          01:26:45       that's an exciting, powerful capability. But then the Boeing, the flip side is, you know, uh, it can significantly change to be here with the system. And there, there could be a glitch that could be a glitch. That could be a bug that the Boeing one's terrifying, especially with a lot of, I mean, that number, whatever it is, like 300 combined, 300 plus people dead, maybe even 400. I mean it's, I, I don't even know how to think. Think about that number from a software glitch. The guy who coated it with a girl coated, it must feel fucking terrible. Yeah. And w w you kind of walk, man, it's, it's a, it's a lot of burden and it's one of the reasons it's one of the most exciting things to work on actually is the code we write has the capability to save human life. But the terrifying thing is also has the capability to take human life.

Speaker 2:          01:27:43       And that's a, that's a weird place to be as an engineer or a directly, a little piece of code. You know, I write thousands of them a day, you know, basically notes you're taking could eventually lead to a, somebody dying, no. Zero, I don't know anything about coding, but do you have like a, is there a spell check for coding? Yeah. So it's Kinda called debugging is trying to find bugs and it's a software that's doing this. Yeah. Software. So there's, depending on the programming language and everybody should, uh, if you, uh, if you haven't tried programming you should try it. It's, it's cool. It's the future should learn to program. Okay. That's my plug

Speaker 3:          01:28:24       mostly to learn to code. He can gauge what did that, I heard that that's a part of what scared of it. It's a problematic term. I don't actually know why it's the dumbest fucking problematic code of all time because someone ridiculously was suggesting that coal miners could maybe learn how to comp code, Computer Code and like get a different job. They can be trained. And so as some, the way people were looking at it like that, that was a, uh, like a frivolous suggestion and that it was ridiculous to try to get someone who is 50 years old. It doesn't have any in

Speaker 7:          01:29:02       computers at all to change their job from being a coal miner to learning how to code. So they started saying it to politicians and people mocking it. But then what Twitter alleged was that what was going on was it was being connected to white supremacy and antisemitism and a bunch of different things. Like people were saying, learn to code and they were putting in a bunch of these other phrases. Then my suggestion would be, well, that's a different fucking thing. Like now you have, like you look, you have a problem with Nazis and white supremacists, but that's the problem is with Nazis and white supremacists when someone is just saying, learn to code, mocking this ridiculous idea that you're going to teach, you know, that's a, that's a legitimate criticism of someone's perspective that you're going to get a coal miner to learn how to fucking do computer coding. It's crazy. It's a, it's so people getting banned for that. Rightly so. People were furious the way Google described it to me and Tim Pool and we were discussing it, was that Google, I mean, excuse me, Twitter, the way Twitter described it was that essentially they were dealing with something where they were trying to censor things at scale. There was, there was so many people and there's so much going on that it's very difficult to get it right and that they've made mistakes.

Speaker 5:          01:30:19       I think that's a fast, one of the most fascinating applications of AI actually is filtering, trying to manage learning [inaudible] so using machine learning to manage this huge conversation. You're talking about 500, I believe it's 500 million tweets a day, something like that. And he, Jamie makes least three, three, one. I was gonna say I, with this conversation, I saw this recently, I don't know who did the data on this, but there's a, uh, a statement someone put on Twitter that said that of, um, let me see if I can word it correctly. It was 22% of adult Americans are on Twitter. Well. All right. So that's like, that's like a fact. One of that 10% make up 80% of the tweets created by adult Americans. 2% of the people on Twitter make up 80% of the tweets. That makes sense. Yeah. Lot of people are arguing aggressively and the, and the question of how to manage that and you can't manage that, but just a manual, uh,

Speaker 7:          01:31:23       review of each individual tweet. Yeah. You'd have to have so many employees. Yeah. That's I think more likely. I don't think Jack is lying, but, um, nor is Vigia but I do think that they have a clear bias against conservatives and that's being shown.

Speaker 5:          01:31:38       So that's an interesting question. I have, uh, your friend, my friend and mentor, Eric Weinstein. Yeah. Talk to me. I disagreed with him a little bit on this. I think, uh, he basically believes so there's a bias. It boils down to the conversation that Jack is having at the, at the top level, inside Twitter. What, what is that conversation like? Uh, I think, I tend to believe, again, this might be my naive nature, is that they have, they don't have bias and they have just, they're trying to manage this huge flood of, um, of tweets and what they're trying to do is not buy, is not to remove sort of conservative as the liberals and so on. They're trying to, uh, remove people that lead to, uh, others leaving the conversation. So they want more people to be in the conversation. I think

Speaker 7:          01:32:36       that's true as well, but I think they definitely are biased against conservative people. There was a, an Alexander ex, Alexandra AOC. Octavia has, AOC is good. Cortez is the last one. Is it Octavia? Ocasio that's right. Okay. I'm sorry, Alexander Aoc. Sorry, I'm just, I'm thinking I was, there wasn't planning on talking about her, but, um, there was a parody account and someone was running this parody account, which was very mild, just humorous parody account. They were banned permanently for running it and then their own account was banned as well. Whereas, um, you know, there's some progressive people are liberal people that post all sorts of crazy shit and they don't, they don't get banned at the same brain. It's really clear that someone in the company, whether it's up for manual review, whether it's at the discretion of the people that are employees, when you're thinking about a company that's a silicone valley company, you are in without doubt. You're dealing with people that are leaning left. There's so many that lean left in silicon valley. The idea that that company was secretly run by Republicans is ridiculous. They're, they're almost all run by Democrats or progressive people.

Speaker 5:          01:33:52       So that the leadership level, there's, there's a nail mindedness that, that, that, that permeates all silicon valley. You're saying? Well, the question I think, I think

Speaker 7:          01:34:01       there's a leaning left that permeates silicon valley. I think that's undeniable. I think it's undeniable. I mean, I think if you had a poll that people that work in silicon valley where their political leanings are, I think it would be by far left. I think it would be the vast majority. Um, does that mean that affects their decisions? Well, what's the evidence bloom? It's kind of shows us does, you know, they're not treating it with 100% clarity and, and you know, across the board accuracy or um, fairness rather. I think that there's absolutely people that work there that lean and there's been videos where they've captured people, uh, that were Twitter employees talking about it, talking about how you do that, how you, uh, make their, you know, you find someone who's a using Trump talk or, you know, saying sad at the end of things and someone's talking, he's gonna, you know, that certain characteristics they look for and he's been videos of what does that project Veritas with guy got his employees got undercover footage of Twitter employees talking about that kind of stuff. The question is how much power do those individuals have? How many individuals are there like that are that, are those people exaggerating their ability and what they do at work or the, are they talking about something that used to go on but doesn't go on anymore? I don't know. I don't work there. I think it boils down to

Speaker 2:          01:35:20       I, I'm one of those people that believes it's, it boils down to the leadership to people at the top set the culture and the culture has to be, it cannot be this kind of silicon valley narrow minded, uh, sort of left leaning thinking even if you believe, even if you're a hardcore liberal, you cannot, when you operate the car, when you drive and manage a conversation in the entire world, you have to think about Middle America. You have to think about, you have to have fundamental respect for human beings who voted for Trump. It is a concerning thing for me to see just a narrow mindedness of an all forms. One of the reasons I enjoy listening to this podcast is you're pretty open minded. That open mindedness is essential for leaders of Facebook and Twitter. People who are managing conversations.

Speaker 7:          01:36:09       I think so too. I think it's, I think it's uh, the thought of being open minded and, and acting in that ethic is probably one of the most important things that we could go forward with right now because things are getting so greasy. It's so slippery on, on both sides. And we're in this weird position that I don't recall ever in my life there being such a divide between the right and the left in this country. I don't, it's more, more vicious, more angry, more hateful. It's different than at any other time in my life. And I think a lot of our ideas are based on these narratives that may or may not even be accurate. And then we support them and we reinforce them on either side. We reinforce them on the left, we reinforced them on the right where if you looking at reality itself and you don't have these, uh, clear parameters and these clear ideologies, I think we're way, most of us are way more in the middle than we think we are.

Speaker 7:          01:37:11       Most of us are. We just don't want racist running the country. We don't want socialists given all our money away. We don't want to pay too much in taxes to a shitty government. We don't want schools getting underfunded. We, we all, you know, and then we decide what, what does my team like the team that I, the shit that I like is that this team, well not everything, but they've got a lot of things. So I'll go with them. Maybe I'm not a religious, not, but I'm fiscally conservative and I don't like with Democrats like to spend money. I'm going to go with the Republicans. You know, maybe, maybe I'm more, I'm more concerned with the state of the economy and the way we trade with the world than I am with certain social issues that the Democrats embrace. So I'll lean that way. Even though I do support gay rights and I do support this and I do sport, all these other progressive ideas this way more of us in that boat. There's way more of us that are in this middle of the whole thing for sure. But there it goes up and down. So

Speaker 2:          01:38:05       all of us, so I'm old, I believe. I hope I am open minded most of the time. But you have different moods. Oh, for sure. Yeah. And the question is, this is where the role of AI comes in. Does the AI that recommends what tweets I should see, what Facebook messengers as should see? Is that encouraging the darker parts of me or the the Steven pinker better angels of our nature? Like is it, what stuff is? It's showing me because if it shows me, uh, stuff that like if the AI trains purely unclicked, it made start to learn when I'm in a bad mood and point me to things that might be upsetting to me. And so escalating that division and escalating this vile thing that can be solved most likely would

Speaker 7:          01:38:54       people training little more Jujitsu or something this size, this Facebook algorithm that encourages people to be outraged because accidentally, not even on purpose, but this is what engages people. Well, this is what gets clicks. So they find out, oh well he clicks on things when you find that other people are anti-vaccination or he clicks on things when he finds out, you know, whatever, fill in the blank with whatever the subject is. And then you get these mother fuckers, you know, this is the reason why measles is spreading and you start getting an angry, I mean the anti vaccs arguments on Facebook, I don't know if he ever dip into those waters for a few minutes and watch people fight back and forth and in fury and anger, you know, it's a, it's another one of those things that becomes a extremely lucrative, uh, subject for any social media empire. If you're, if you're all about getting people to engage and that's where the money is in advertising, you actually getting people to click on the page and the ads were on those page. You get those clicks, get that money if that's how the system is set up. And I'm not exactly sure how it is cause I don't really use Facebook, but that's what it benefits. I mean that's what, that's what it gravitates towards. Gravitates towards controversy.

Speaker 2:          01:40:04       So, and when we think about concern for AI systems to talk about sort of Terminator, I'm sure we'll, we'll touch on it, but I think of Twitter as a whole, as one organism. That is the thing that worries me the most is the artificial intelligence that is very kind of dumb and simple, simple algorithms that are driving the behavior of millions of people and at together the kind of chaos that we can achieve. I mean, that algorithm has incredible influence in all society. Twitter are, our current president is on Twitter so much. Oh yeah. All Day, all night. The, the, I mean it's scary to think about. We talk about autonomous vehicles leading to fate to Alwan fatality to fatalities is scary to think about what the difference be a small change in the, in the Twitter algorithm. I mean, I could start wars. It really could it and that if you think about the long term, if you think about it as one AI organism that is a super intelligent organism that will have no control over.

Speaker 2:          01:41:07       And I think it all boils down honestly, to the leadership, to Jack, uh, to, to, to, and other folks like him making sure that he's open minded. It goes hunting, that he goes, uh, does some Jujitsu, that he eats some meat and sometimes goes Vegan. Right. You know, he did a, just in a 10 day Toklas retreat. We don't talk it off for 10 days. He also eats one like he does. I follow some of the dye of him eats once a day. I've done that and fast all through the weekend, which I don't, that's crazy.

Speaker 7:          01:41:40       I've never done that. But I've done some, I've done quite a few 24 hour, you know, where I, I eat at 7:00 PM. I'm done eating. I don't touch food until 7:00 PM the next day. It's just water or coffee. Why do you do it? By the way? To shock my system. I think it's good for your system. Um, you know, there's been a lot of research on fasting and the effect it has on telomeres. Uh, Doctor Rhonda Patrick spoke, um, pretty recently. There's been quite a few things that she's written about in terms of a fasting, the benefits of fasting. Intermittent fasting is great for weight loss, but just fasting itself and even for several days, most people seem to get some pretty decent benefits out of it. So I dabble in it. I also liked the way it makes me feel, um, to be a little hungry. I think my brain is sharper.

Speaker 7:          01:42:28       Like I refuse to go on stage full. I, Oh, when I, when I do stand up and I actually learned this from a cat Williams interview, he was talking about it and uh, ease crazy as fuck, but he's hilarious and he's one of the greats in my opinion. And he was in the back of a limo and he was talking about how he prepares for a show that he has his music that he listens to pre show music is like a, a music list. Um, and then, uh, he will have a drink, no food. He won't eat because it slows you down. And I was like, does slow you down, but sometimes you don't even think of it. It's not like a rule. So you just, man, I'm hungry. I'll just eat. I would way rather cause I can go through a couple of shows. I used to think I used to have this fault, the idea that if I didn't eat I would be exhausted to do things. But then I work out fast at every morning, every morning when I, when I get my morning workout in and whatever the fuck it is, it's usually hard. I'm always fasted. He could do a lot. It's, you're not, it's not at your best. Like if I was going to do Jujitsu, I don't do Jujitsu fasted. I would, I would eat some fruit.

Speaker 2:          01:43:29       That's an interesting one because that was the transformational thing for me. I used to do power lifting. You see like

Speaker 7:          01:43:34       five times a day, six times a day, whatever. More like CT Fletcher Style Kinda see how big he was back in the day. He's only maybe like my height or a half inch taller or some shit. He was 320 pounds. So what he said three 15 fuck. He was big. Yeah.

Speaker 6:          01:43:52       And you're saying like at trouble, the thing is when you get that big, and I wasn't that big, but it's like hard to move. Oh yeah. It's like not healthy. If you, did you see the image of him from yesterday? I didn't see the image. He, when he, uh, Jamie put up a photograph of him at 315 pounds next to him at like a tuition, 200 dishes, like a hundred. And it's incredible how big he was. I mean, everything was his, like his arms were my legs and they were just coming out of his shoulders. So that was, that was a big moment for me. Uh, areas. There's the pictures come. Peggy was when he was a world champion. I mean, just insanely huge. Wow. Yeah. Um, so when you started training in Jujitsu, you look at that in the blonde on the right dude, he's 50.

Speaker 6:          01:44:40       Look at that. Oh, all natural to all natural at 50. Crazy fuck and genetic son. That's some good, oh yeah. Obsessive. Not just hard work. I mean you have to be a fucking maniac, but the fact that his body holds up like that at 50 is incredible. He's an inspiration for me. Switching from that to Jujitsu, I thought there's no way cause I train hard. I train twice a day. Did you get sued for awhile and we doing two roles a day. Were you doing like technique and drills? One at one time? Listen, I'm rushing. I just go hard. I'm upset. No, no, no, no, no, no, no. Russian drilling. Let me explain to you something. Okay, cool. What do you want, explain to me. I'm trying to explain to you the difference in Russian and American America is in wrestling and a lot of, in a lot of combat sports is like heart and guts and hard work over and Russian is certainly in wrestling.

Speaker 6:          01:45:35       His technique is drilling. They put a lot more hours than Americans do at less than a hundred percent effort. So like really drilling, they're really getting that right. Like I love that. In fact, one of the problems is I haven't been able to really ever found, I was always the last one to get bored. I drily Oh, can you got to find a good drilling partner? Like an obsessed one. Uh, uh, shout out to uh, Sarah Block at Juco, a judo, a lady as a black digits as well that was willing to put up with like hundreds or thousands of throws a that we each did. So like that, that obsessive models, any, I love that kind of stuff cause I think that's you get better and that's where not everybody believes that people, some people believe, especially with Jiu Jitsu, like you can't really get timing from drilling. I believe you can get everything from drilling of the timing. The, the cause is as long. The other part, it's not just aimless drilling, it's your mind, isn't it? Your, your brain should be exhausted by the end of it too because you're visualizing the whole thing. You're like going through, you're imagining how your opponent would, it's really strengthening your imagination while you're also doing the drilling. I couldn't agree more. Yeah. I firmly believe you can get better way better drilling. And uh, when I went from

Speaker 7:          01:46:50       I think blue belt to purple, I did like the most drilling than I ever did ever. And that's when I grew the most. That's when my, my technique got way better. That was also when I became friends with Eddie Bravo and Eddie Bravo was a huge driller. Huge. Oh he shrills man, they drill like crazy and they do a lot of live drills. And they do a lot of pathway drills where they'll do like a whole series of movements and then his escape and then the reversal and they're like, these are long pathways so that when you're actually in a scrap and you're rolling you, you recognize it. Like, okay, here it is. I'm passing the guard, I move it to here and now he's countering me, but I'm setting up this and these pathway drills, there's, it's so critical because it comes up over and over and over again when you're actually live rolling, you know, you feel it. You feel like, Oh, I've been here before. I know this is,

Speaker 5:          01:47:42       I'd be curious actually to hear, I don't think I've ever heard you talk about how your game is. My game changed significantly from white belt, a blue belt, purple belt. They started to solidify, but I'd be curious to hear like what, how did you gain change since you met Eddie? Gave meaning Jesus.

Speaker 7:          01:48:01       Well, my most of my game came from Eddie like 99 point something percent of it, almost all of it. And John Jock those too. So it's like I was a blue belt before I was friends with anybody. I was terrible. Like what guard do you prefer, for example? Well, I do rubber guard. I'm very flexible. So rubber guard is no issue with me and I think it's incredibly effective. I think if you're good at it and you know, you get stuck under a guy like, um, what does his name, Jeremiah Vance is a Eddie's uh, one of Eddie's um, black belts who was a murderer from his back. His Rubber Guard is insane. It's insane. Eddie's rubber guards and saying, I mean, you know, obviously tap toilet Gracie as a ridiculous guard economy and triangle. Um, but there's a lot of people that understand it now. A lot of people that know how to do it, it's um, it's a real art form.

Speaker 7:          01:48:52       And the thing about it versus other guards is when you're in a position like mission control and you clean, you know, Vinny Magallanes is phenomenal at it. I mean, he, what's that video of fuck this guy up quick. Watch it. This is Jeremiah. Jeremiah advances one of Eddie's best. We'll get this from the bottom. Bam. He does that all the time. Triangle from the bottom off from rubber guard that guys wrapped up, that's a, that's out cold. He does this all the time. He's one of Eddie's best rubber guard assassins. And if you watch his technique and his fucking sensational, he also has great leg locks too. But the thing is that you know when he'll attack from his legs and you'll tap people with a leg lock, but if they escape, sometimes they'll escape. And this just too deep shit right here. But now he's going to take us back.

Speaker 7:          01:49:38       But if they escape, oftentimes he's on the bottom. And when you're on top of him, it's one of the worst places in the world to be. His guard is fucking, and it's because of that. See that grip, see how he's holding the rubber guard in position? That's called mission control. Mission control. Mission control from a guy like Jeremiah is fucking ruthless because he has his arm and his legs. It's controlling your neck and your posture. It just, and then he's going to a Gogo here and uh, he's phenomenal at this too. He's going to get them in a Gogo Plata or normal Plata. It's going to flip them over now. Now he's attacking the leg. Like it's just constant. And Eddie ever ends this kind of system. Well, he invented the initial stage of like setting up mission control and go, this guy is getting fucked up.

Speaker 7:          01:50:25       Oh my God, that's horrible. But Eddie invented a series of pathways from mission control to set up various techniques, armbars triangles, all these different things. But there had been people that had toyed with doing high garlic Nino Schembri, he, he did a lot of like, like rubber guard asks stuff. There was a lot of things that people did, but Eddie has his own pathway and his own system. And then there's a lot of guys that branch off from that system, like Jeremiah, like Vinny Magallanes that have their own way that they prefer to set various techniques up too. But what's really good about that, if you have the flexibility, is that you're, when you're on the bottom, it's not only is it not a bad place to be, but you could put some in some real trouble. When you have your ability, you're holding onto your ankle and using your leg, which is the strongest fucking limb in your body.

Speaker 7:          01:51:17       Right. Pulling down on someone with your leg, clamping down with your arm, and then you get your other leg involved. Good luck getting out of that. Good luck. It's fucking sucks man. You have control, but you're also able to move at the same time. Exactly. Does anybody ever puts you in mission control before? No. I haven't competed or against many, but even in like someone in class like show it to explain it to, yeah, lower ranks. Once you feel it, you go, oh shit. I remember it being, you know when somebody does a nice move on you, especially like a lower rank, your first reaction is like, oh, this would never, like you're annoyed. Yes. It's the, it's the natural process of the ego. Of course. Getting rid of, you know, you see something new and you're like, yeah, this is stupid. If I next time it won't work.

Speaker 7:          01:52:03       But then you start to understand a little more. I remember it being really powerful controlling position. It's powerful and if you have a good offensive attack from there, it's powerful as well. Their transitions, such the God like Jeremiah who's really flexible, you know, he can pull off Gogal plot does and all sorts of other things. Um, local plot does. It's another one that they do is one that you push with your other foot on the heel. It's so nasty. You're holding the back of the foot across the back of the neck and so your shin is underneath someone's throat and then you're pushing that Shin with your other heal while you're squeezing with your arm. It's ruthless is ruthless, you know? And they do a gable grip around the head when they do this as well sometimes too. So it's just a fucking awful place to be. So it's not as good as being on top. Right. If you have a crushing top game, that's the best. If you can get to that position, but you can't always get to that position. So there's guys like Jeremiah that even from the bottom, they're horrific. Dangerous as dangerous is from the top for most people

Speaker 5:          01:53:05       I do. You find just a, when you trained back in the day and you still train, do you spend more time on bottom or top?

Speaker 7:          01:53:13       You always should start. I feel like you should always start on the bottom, earned the top position. And this is something to Eddie always brought up too. Cause you know you'd be like to like, it's fun to be on top. So a lot of times it's like this mad scrambled. See who could force who onto their back, right? Because when you're on top you can control them, you can pressure them. You know you play that strong man's Jujitsu. But the problem is, is trauma is, you didn't tell him only 200 pounds. I'm not a big guy. Like, so if you go to the real big guy, like I'm rolling with a 240 pound guy, I'm not going to get to that spot. Like, I better have a good guard, otherwise I can't do anything right. When someone's bigger than you and stronger than you, you mean?

Speaker 7:          01:53:49       That's what Hawaii is crazy basically proved to the world. Like as long as you have technique, it doesn't matter where you are, but if you only have top game, which a lot of people do, a lot of people only have top game. You know, you're kind of fucked if you wind up on your back. We see that a lot with wrestlers in MMA as wrestlers, they can get on top of you and they'll fuck you up. They'll, they'll strangle you there, take your back, they'll beat you up from the mount, but they don't have nearly the same game when they're on their back. And then there's guys like Luke Rockhold, it's like an expert or keeping you on your back. He's when he's one of those guys, when he gets on top of you, you're fucked. He's got horrible top game. I mean, horrible and sense of if you're as opponent, he's gonna beat the fuck out of you before he strangles you. His top game is insane.

Speaker 5:          01:54:34       Yeah. I, I hate the feeling. Some people make it, just feel the weight, make you suffer for everything you do on bottom. It's uh, uh, people that are able to do that. A truly humbling. Yeah.

Speaker 7:          01:54:48       Slurs in particular wrestlers are so good at money. Did you see that Jordan Burroughs? Ben Ask and match last night. Fucking credible. How good is that Guy Jordan boss? Ooh, as I do that to a guy like Ben ask grin. I mean it just shows you

Speaker 5:          01:55:03       Ben hasn't competed I think in nine years. But Ben is one of the greatest, I mean I'm a huge fan of his wrestling. It's so interesting. I think that is like the worst matchup for Ben. Ask Her. And I think because you're, you're taking, uh, one of the most creative wrestlers ever been. Oscar and I don't want to over over overstate it, but he has incredibly creative, one of the great pinning wrestler. So he pins people he like confuses them and pins them incredibly well. And you, you put them against basically a freak blast. Double like the greatest double leg take down maybe of all time, all time.

Speaker 7:          01:55:44       Like somebody put a clip up that said, uh, is this it? Yeah. So when you put a clip, oh shit. He went off the fucking mad into the crowd. That's pretty fast part. He defended a take down. That was the best part. But that's crazy man, that they, they have such a drop off with these guys. Like you shouldn't really have a platform like that where a guy can fall off into the crowd. That seems so stupid. It rarely happens. What the fuck are you talking about? Just happened. Rarely happens. They rarely have these. It's true. This is argument. That's a terrible thing. Have that shit flat on the ground. That is so dumb. I can't even believe they did. I think this whole mess should be contested. Doesn't count. Well I don't, I don't, you know, I think, look, that's stupid. That's not smart.

Speaker 7:          01:56:30       Dev. A guy who's a fucking powerhouse of a blast, double hitting you and sending you flying to the, that's crazy. That is crazy that they didn't have anything in place to stop that. That's a reason why wrestling takes place on the ground. You fucking assholes. And like, why are you having people wrestle on a platform that's crazy show. So the, the, the show, you can have a show where Don's, where it's on the grounds called basketball. Yeah. Yeah. It's on the ground and you know it was worrying because [inaudible] and I'm a fighter and you get injured with that right there. Right there. It could have torn his lead knee apart easily. Well the silver lining is that he's okay. Yeah. The silver lining and a, and we got to see that, you know, it was interesting Jordan Burroughs had on his Instagram, there's levels to this, you know, they're raising his hand up and looks like that's what we got to see.

Speaker 7:          01:57:17       Cause Ben is a phenomenal wrestler. But you're right, he hasn't competed in a long time. He's not necessarily at the level that he was back then. Even though he's incredible for MMA standards. It's good to see like it's good. It's good to see that with boxing it's good to see that with anything like when Floyd Mayweather fought Conor, I think it was good to see that, that there are really levels to this. And the interesting thing about journ bars, I think he's so good that he's probably going to stay out of MMA so crazy. But there are, here's some, here's some clips of it. You're not going to shut this. But yeah, we can't show it to people. But uh, who, who put this on flow wrestling, flow, wrestling, put this on. I wonder if people are pirating it online or if they put it online that they're allowing and no, they, well, people are pirating it.

Speaker 7:          01:58:03       Yeah. Yeah. Okay. Yeah. Good luck stopping that. Right. Well, I think people should support flow wrestling though though. They do have like a, I'm a member. Are you? Oh, look at this. Look at this. God, he's good. Yeah, man. So we're watching this, ladies and gentlemen who are just listening. It's probably boring as fuck for you, but I'm Jordan Burroughs is a, one of the best wrestlers really. America's ever produced three time world champion, tragically not tried it lost in the previous Olympics and he's back at it again. I wonder if he's ever considered MMA. I know it was some about it, but I wonder if

Speaker 6:          01:58:41       you have a really, I think at this point he's, uh, he is basically a no, but there are a few terrifying people, especially on the Russian side that I, that I think the heavyweight division and um, and UFC should, he should be really worried. I don't know if you've heard about the, the Russian tank, the 22 year olds from Dagestan no hose. This guy as a wrestler, the wrestler and he's going to fight MMA? No, he's, he's uh, he will after 2020 is what his expectation is for now. He's probably going to be the greatest wrestler of all time. Really him against Kyle Snyder, those two heavyweights as a mayor, Collins not as American. Another guy. 20 the tank of Dagestan. How'd you say his name? Uh, it says [inaudible] of [inaudible]. Abdulla Rasheed said ally of 22 years old. So Snyder, you can do call Snyder versus what a great name.

Speaker 6:          01:59:39       Abdul Rashid Sidoli of that alive that was Russian as Snyder is 23 years old. And he's another incredible person who will do MMA. And that competition with Gene Snyder. Uh, I mean this is, look at the look, the look of the thickness. These guys are monsters and they're not just how much these guys, where I uh, 97 kilograms, two to 2120 under two to 15, but they cut for it. Right. Which is just under heavyweight. These guys, do you think they would compete at two oh five. If they're going to fight in MMA, these are heavyweights cause so that we just don't remember it in the weight. These are still boys. Oh 22. Right. They still haven't gotten the full lake. Yeah. I wonder that about UFC fighters that are thickening up as they get older. I wonder how many of them are damaging their body by cutting weight.

Speaker 6:          02:00:35       Yeah. That's a thick fellow. So, um, right now we're just seeing mostly stalemate and that's uh, from uh, the American guy and the, yeah. Is it like a highlight reel of his or something that we, yeah, there is, but he's pretty young. He's a, I think he's a, so he's an Olympic champion and he goes from the whole line of, um, the city of brothers and the, the, the, all the Dagestani wrestlers. There are so many good fighters that are coming out of dogs time right now and all technicians. So it's incredible. It's incredible. Whatever's in the water that styles like Zebbie legs up beat style, very, very different than a wrestling heavy style. Look at this guy. I met Jesus Christ. Oh my God. What a scramble. So this is a, I'll do Russia, EAD Rashid, Abdulla Rashim concept alive. Don't tell me how to say it. I'll figure it out. I don't know. She'll dolor she'd do her, she'd said alive. Subtle lie of, and you know what? The beauty, there's a poetic, uh, cause there's a poetic nature to the, to these guys. I mean they're just, that could be really, I mean simple good

Speaker 3:          02:01:40       people, right? They're a, they're pretty religious and they just kind of, they don't even believe in fame. They just believe in excellence. Well, you know, Dan was sort of evident and the, the mindset behind them was sorta evident at the end of that fight with Conor where they went crazy and he jumped into the crowd. He's like, he's not playing games. Like he's not, he's not doing this for Instagram likes or for, you know, this is really, he takes trash talking and all that stuff very seriously. This is all about honor for him. I think that was kind of upsetting because true. But, but don't do that. Yeah. And through that, and uh, also respect, I, I'd hate to say it, but I think there's a certain ethic and honor to the way Conor McGregor carries himself to all that trash talk. If you look at the end of the fights, he's very calm.

Speaker 3:          02:02:34       He's very kind and respectful in defeat. And when they get us, it's a different culture. If you compare the Dagestani versus Irish culture, it's just the different culture. And you have to respect that, I think could be, to be honest, disrespected Connor's culture as much as kind of just suspect it could be. I get what you're saying. But I mean, when he was done with the fight, he didn't keep attacking Connor. It was people in the audience that we're talking shit that were training partners and motion for as high. That's that he would hit her that for weeks and he was, he was done for months. He was done. He was like, fuck you, I beat his ass and I'm gonna beat your ass. And he just said, I'm not playing games. And he jumped into the fucking crowd. I think security could have been handled far better and we'll be in the future to prevent things like that from happening where people just jumped into the cage and you know, I, but I, I hate seeing that shit, but I appreciate where he's coming from.

Speaker 3:          02:03:28       I mean that's who the fuck that guy is, man. That's one of the reasons why he's so good as he does have that mindset. It's one of the reasons Matt, and one of the reasons why he's so relentless, like he's not playing games. Yeah. He is who he is. What you see is what you get and what you get. As a killer and these he's there smash. I would've loved to see Conor McGregor versus could be, it could be before the Mayweather fight like um, before Conor mm gotten, I think the money makes you less hungry. Oh for sure. And Dude ain't hungry at all. Mean he's got $100 million. But I think he still loves to compete, but there's no hunger anymore. Like Dan, no hunger. I mean he might be hungry for success, but he's says no desperation. Yeah. I don't know if that's, I know what you're saying.

Speaker 3:          02:04:14       Like he has a lot to lose now too. It's a different thing. He enters into a fight with $100 million in the bank. It's a very different experience and entering into the fight know with 1 million and hoping that you could make three more tonight. And you know, like many, I'm sure fights that he's had in the past. It's a different world wants whatever he wants forever and he wants a fighter though. I was a fighter. I mean there is an element there that he still wants glory, I believe. Still only 30. Yeah, right. This is still do it. Yeah. I mean he's, I think how old's Connor right at the most, he's like 32 or some shit 30. Yeah. He's young man to, to be set for the rest of your life at 30 is kind of fucking bananas. And I don't think he's at his peak as a fighter.

Speaker 3:          02:05:00       So if he just decides who gives a fuck about the money, I'm just, I'm here to leave a legacy and I'm going to, I'm going to just train like a fucking demon and he kicks aside all of the bad influences and all the distractions in his life and just focuses on training mean he's a motherfucker, man. I mean, you saw what he did to Aldo, saw what he did to Chad Mendez, saw what he did to Dustin pour. Yay. I mean, he is a bad motherfucker. Period. I know you're going to shut this down as most fans do, but I, if he drops everything and goes to like Siberia to train, I would love to see him and could be two. Well, there's nothing wrong. That's my friend Hans Molan camp and a, uh, Connor sparring. Just fucking around powerful on it. Logo in the background.

Speaker 3:          02:05:42       It's like a Goddamn on it. And I um, yeah, I mean he's always going to have a problem with could be, could bebes wrestling is so high level, it's so different. He smothers you in a way that you think you have good takedown defense to. You run into that motherfucker and he just gets a hold of everyone who does it to everyone, whether you're Michael Johnson or Edson Barboza, no matter how good your takedown defense looked in the past and the Barboza fight, he was just basically just wa weighted towards him, waded through the fucking, the fury of leg kicks and punches and just clamp, drag, smash. And that's what he does to everybody, man. The real thing about a guy like him would be seeing a guy like him against a guy like Jordan burrows. Like could he do that to a guy who is a spectacular rest or as well, then it becomes mean his striking, which has gotten very high level.

Speaker 3:          02:06:39       He's very dangerous striking. So I dropped Connor. I mean he can, he can fuck people up. He stopped. Um, there was some, he's, he stopped a few people. It strikes he me, he's dangerous. He's dangerous enough on the feet that you would have to, I don't know how much, how many really high level grapplers also have like striking that can stand with them. Cause if he decided to keep it up, you'd have an advantage there until they got good at it. Him verse has been asking. It would be very interesting. Well, he would have an advantage and striking over ass grin and a in wrestling, I don't know. No big fellow too are the same way? No. Oh, he's 55. Aspirin 70. Okay. Okay. So I'd ask him, could probably make 55. I mean, if you tortured him, he's got a dad bod though and he's, no, he's, he's proud dad. Who's proud of his body? I think he was that way in college. He was never,

Speaker 7:          02:07:36       there's never like Brock Lesnar. No, no. And he was just super technical and it's strong as hell though. According to everybody, everybody that rolls with them says he's fucking ridiculously strong. You, uh, you sometimes say artificial life instead of artificial intelligence. Yeah, because I think that it's a life form. It's a stupid way to look at as curious to think about like how do you think about artificial and like what do you picture? I picture human beings being like electronic caterpillars that are building a cocoon that they have no real knowledge of our understanding and through this and new life forms can emerge a life form that doesn't need cells and meeting with x and y chromosomes. It doesn't need any of that shit. It exists purely in software and in hardware and in ones and Zeros and that this is a new form of life.

Speaker 7:          02:08:29       And this is when the inevitable rise of a sentient being, the inevitable. I mean I think if we don't get hit when the asteroid within a thousand years or whatever, the numb the time frame is, someone is going to figure out how to make a thing that just walks around and does whatever it wants and lives like a person that's not outside the realm of possibility. And I think that if that does happen, that's artificial life. And this is the new life and it's probably going to be better than what we are. I mean, what we are as basically if you go back and look about, you know, three hundred thousand four hundred thousand years ago when we were some Australia pithy cast type creature, how many of them would ever look at the future and go, I hope I never get a Tesla. The last thing I want is a fucking phone.

Speaker 7:          02:09:18       Last thing I wanted air conditioning and television. The last thing I want is to be able to talk in a language that other people can understand and to be able to call people on the phone. Fuck all that man. I like living out here running from Jaguars and shit and constantly getting jacked by bears, you know? No, they wouldn't think that way. And I think if something comes out of us and makes us obsolete, but it's, it's missing all the things that suck about people. I mean, it won't be good. It won't be good in our, in our things suck of people. Kuwait, war, violence, thievery, people stealing things from people, people robbing people

Speaker 6:          02:09:58       both. The thing that those dark parts of human nature, I think, uh, the suffering injustice, I think all of that is necessary for us to discover the, the better angels. I don't think you can a surgeon, we can talk, let's talk about saint she and creating artificial life, but I think even those lifeforms, even those systems need to have

Speaker 7:          02:10:24       darker parts. But why is that? Is that because of our own biological limitations in the fact that we exist in this world of animals where animals eating other animals and running, there's always, you always have to prepare for evil. You have to prepare for intruders, you have to prepare for, you know, predators. And this is essentially like this mechanism is there to ensure that things don't get sloppy. Things continue to like if the Jaguars keep and the people and the people don't figure out how to make a fucking house, they get eaten and that's it. Or you figure out the house and then you make weapons, you find off the fucking Jaguar. Okay, great. You made it. You're in a city now. See you had to have that Jaguar there in order to inspire you to make enough safety so that your kids can grow old enough that they can get information from all the people that did survive as well.

Speaker 7:          02:11:10       And they can accumulate all that information and create air conditioning and automobiles and guns and keep those fucking jaguars from eating your kids. Right? This is, this is what had to take place as a biological entity. But once you surpass that and once you become this thing that doesn't need emotion, doesn't need, you know, it doesn't need conflict. It doesn't need to be inspired. It never gets lazy. It doesn't have these things that we have built into us as a biological system. Like if you looked at us as wet, where operating software, it's not good software, right? It's software designed for cave people and we're, you know, we're just trying to force it in to cars and force it into cubicles. But part of the problem with people in their unhappiness is that all of these human reward systems that had been set up through evolution and natural selection to, to have these instincts to stay alive, they're no longer relevant in today's society.

Speaker 7:          02:12:07       So they become, they become road rage. They become, you know, extracurricular violence. It became, they become depression. They become all these different things that people suffer from. So that's one perspective. Yes. That basically our software through this evolutionary process that was necessary to arrive at where we are, but it's outdated at this point. Well, it's necessary for us to succeed, to succeed in a purely, almost a Darwinist way, and in a sense that survive through Ellucian, especially since we're so weak. I mean, it's really, we became this week because we got so good at protecting ourselves from all the bad things. Yeah. Okay. The other perspective is that we're actually incredibly strong and this is the best that the universe can create actually were at the height. This is where at the height of creation there's, there's a beauty in this tension, in this dance between good and evil, between uh, like happiness and depression, life and death and that through that struggle, that's not just a useful tool to get us from Jaguars to cities but that is the beautiful thing that, that, that that is like what the universe was built for. That that is the height like our current, the, the evolution and the creation that results from it is the height of creation. It is, is the end. The way things operate is not something that's far from optimal.

Speaker 6:          02:13:32       It's, it's not something that sucks but it is a very, is very good, very optimal heart to beat in a sense that they, for example, mortality, right eye is death important for creation, for, for his death. Important for us. Human beings for life, for us as a society is important for us to die. Like if you could live forever, would you live forever? I think miss out on the possibility that there is something, well I had this conversation with CT Fletcher yesterday cause you know he survived a heart transplant a year ago. You're in two days ago. I think it's, what do you think? I think I think mortality is essential for everything. I think the end, we need the end to be there.

Speaker 7:          02:14:25       Right. But do you think that we need the end to be there for the overall health of the human race or the war of the all the organisms on earth? Or do you think we needed to be there because there's something else? Do you think there's something else that happens to you when your body stops existing? Do you think your consciousness transcends this, this dimension?

Speaker 6:          02:14:45       I think, uh, I think I'm not smart enough to even think about that. That's a great answer. So thank everybody on earth has that exact same answer if they're being honest. So you're talking about atheism and so on. I used to think atheism means what I just said, but it's more we know so little. So the only thing I know is that the finiteness of life is, uh, the Broadway, just a school. That trainer has this poster at the, at the, at the opening, which is a hunter s Thompson quote, which is, um, uh, for about skidding into death sideways. No, not the ones. A good one. Uh, no. For all moments of beauty. Many souls must be trampled, something like that. That's a fucking great quote. God, I love that guy. Yeah. So basically for beauty, you have to have suffering. I, I do not disagree with you, but do not disagree with any of the things you said. And I think

Speaker 7:          02:15:51       there's always a possibility that human beings are the most advanced life form that's ever existed in the cosmos. There's always that that has to be an option if we are here, right? If we can't see any others out there. And even though you know there's the Fermi paradox and there's all this contemplation that if they do exist, like maybe they can't physically get to us or maybe they're on a similar timeline to us and they're also, it's also possible, as crazy as it might sound, that this is as good as it's ever gotten anywhere in the world or anywhere in the universe, rather that human beings right now in 2019 or as good as the whole universe has ever produced, we're just some freak luck accident and everybody else is throwing shit at each other, right? There's 15 arm caterpillar people that live on some other fucking planet and they just toss their own shit at each other and they never get any, they never get any work done.

Speaker 7:          02:16:42       But we might be that. But even if that's true, even if this beauty that we perceive, even if that, that this beauty requires evil to battle and requires, are seemingly insurmountable obstacles you have to overcome and that through this you see achieved great beauty. That beauty is in the eye of the beholder. For sure. Objectively, the universe doesn't give a fuck if rocky Pete's Apollo creed in the second movie. It doesn't give a fuck. It's nonsense to everything's nonsense to, and when you look at the giant ass picture of what, at what beauty is it, if the sun's going to burn out in 5 billion years, what beauty is that? If there could be a hyper Nova next door that just cooks us. Oh, so that's like the book Sapiens Dow that basically we've all, one of the things have created here is we've imagined ideas that we all share, the ideas of beauty, ideas of truth, ideas of fairness.

Speaker 7:          02:17:49       We've all created together and there's, it doesn't exist outside of us as a society and no, it only exists to us. Yeah. To us it does exist. And this is where I think the beauty of being a person truly lies. It lies in us, our appreciation of us. We appreciate people and a profound way, like we were talking about Hendrix. I don't know how many hours of Hendricks I've ever, let's do, or Richard Pryor, how many hours of Richard Pryor I watched and how much that affected me as a kid watching live on the sunset strip. That's what got me to do in standup comedy. We affect each other. A Ct Fletcher, who was on the podcast yesterday who's just incredibly inspirational guy, you watch his videos, you want to lift the fucking world and throw it into space. You know? I mean, he's, he's so powerful. We appreciate each other.

Speaker 7:          02:18:41       We appreciate people. So all those things you're saying are real. Like for us, they're real. For us, my concern is not that my concern is that we are outdated. My, my concern is not that there's not beauty and what we are. I'm a, I'm a, I am a big appreciator of this life. I appreciate human beings in this life and human beings. They're their contributions as, as a, and as I get older, like particularly like over the last few years, I started doing a lot of international travel. I fucking appreciate the shit of all these people that are living in this different way with weird language and shit, weird smell and foods. And I like to think like what would it be like if I had grew up here? Like these are just people but they're in this weird sort of mode. You know? I think we're insanely lucky that we have this enthusiasm for each other that we have this in through like for your work man, I have this deep enthusiasm for what you do.

Speaker 7:          02:19:39       I'm fascinated by it. I loved being able to talk to you and pick your mind about like you're out there coding these fucking vehicles that are driving themselves, artificial life on wheels. I don't think any other animal appreciates each other the way people do. I mean I might be wrong. People do, right? I might be wrong about dolphins and whales mean maybe they love each other just as much as we do just in a different way. But what, where does AI fit into that? So your worry, I'm worried that we are Australia kiss and AI is going to come along and make us look stupid. The only reason why I was trying to pick Australia pithy Gus would be cool today is we've found a gang of them on an island somewhere. We were like holy shit they survived. They never evolved. They're on this island just crack and coconuts and just eating fish, whatever they can catch that would be amazing. But every undocumented or undisclosed discovered uncontacted tribe through all homosapiens all of them. So it's like you know,

Speaker 2:          02:20:38       what do you picture like cause we have to look at Boston dynamics robots cause you said walking around, I like to get to a sense of how you think about, and maybe I can talk about to where the technology is of what that artificial intelligence looks like in 20 years. In 30 years they'll surprise you. So you have a sense that it has a human like form.

Speaker 7:          02:21:03       No, I have a sense that it's going to take on the form the same way the automobile has. If you go back and look at it like CT has a CT, Fletcher has a beautiful old Patina'd pickup truck. Well, what he said it was from like 58 or some shit 60 anyway, old ass cool, heavy metal, you know those sweeping round curves, those old school pickup trucks had now look that and look at a Tesla roadster. Why in the fuck happened when the fuck happened? I'll tell you what happened. They got better and better and better at it. They figured out the most effective shape. If you want a motherfucker to move that, that, that little car. Have you seen that video where they have the Tesla roadster in a drag race or in a race against a Nissan Gtr? It's a simulated video, but it's based on the actual horsepower of each car. I don't know if you've ever driven a Nissan Gtr, but it is a fucking insane car. It's insane. This is a CGI version of what it would look like if these two cars raced against each other. So the car on the the Nissan Gtr dude from the beginning. There it goes. Look how fast this thing pulls away. The Nissan GTR is fucking insanely fast man, insanely fast. But this Tesla is so on another level, it's so in the future that it's not even, as the video gets

Speaker 6:          02:22:26       further and further, you see how ridiculous it is. It's essentially lapping that car. It's going to go look how far away it is by Sia. The human races will be the Nissan here and then we're not even gonna be the Nissan. We're going to be CT Fletcher's pickup truck. This, this is the future. There's not gonna be any limitations in terms of bipedal form or wings or not having wings. If you can walk on it. I mean there's not gonna be any of that shit and we might have a propulsion system or it might, it's not going to be us. And they might, they might design some sort of organic propulsion system like the way squid have and shit. Who the fuck knows? They could also operate in a space of language and ideas

Speaker 5:          02:23:06       both. I don't know if you're familiar with, you know, open Ai. It's a company they, they created this system called gpt to which does language modeling. This is something in machine learning where you basically unsupervised let the system just read a bunch of texts and alerts to generate new texts and they've created this system called gpt to that is able to generate very realistic text, a very realistic sounding texts, not sounding, but when you read it, it makes, it seems like a person, it seems like a person. And the question there is raise a really interesting question. So talking about AI existing in our world it, it paints a picture of a world in five, 10 years plus where most of the texts on the Internet is generated by AI and it's very difficult to know who's real and who's not. And one of the interesting things, I'd be curious from your perspective to get what your thoughts are.

Speaker 5:          02:24:02       What open AI did is they didn't release the code for the full system. They only released a much weaker version of it publicly. So they only demonstrated it. And so they felt that it was their responsibility to hold back prior to that date. Everybody in the community, including them, had opened, sourced everything, but they felt that now at this point, part of it was for publicity. They wanted to raise. The question is, when do we hold back on these systems when they're so strong, when they're so good at generating texts? For example, in this case or at deep fakes at generating fake. Joe Rogan

Speaker 6:          02:24:42       says, Jamie just did one and he's shown, they're like Donald Trump's head. Yeah. It's crazy and this is something that Jamie can do. He's not even a video editor. Yeah, we were talking about it before the show. We could go crazy, but if you want it it, it is one of those things where you go, where is this going to be in five years? Because five years ago we didn't have anything like this. Five years ago was a joke. Right, exactly. And then now it's still in the gray area between joke and something that could be at scale, transform the way we communicate. Do you ever go to Kyle Donovan's Instagram page? Of course. One of the best look that's made, it's killing me. Vice President killing

Speaker 5:          02:25:24       me. This is the car, it looks so much like I'm really talking and it looks like what I would look like if I was fat and he can, you know, of course that's really good and it could be improved significantly and it can make you say anything. So there's a lot of variants of this we can take, like for example, uh, full disclosure, I downloaded your fate the entire like have a Dataset of your face. I'm sure other hackers do as well. How dare you. Yeah, so for this exact purpose, I mean if I'm thinking like this and I'm very busy then, then there's other people doing exactly this for sure. Because you happen, your podcast happens to be one of the biggest datasets in the world of people talking in really high quality audio with high quality 10 ADP for most, for a few hundred episodes of people's faces. The lighting could be better, not quite as good. The whole purpose. We're making it degraded. Fucking it up. Have hackers and the mic gets in. It blocks part of your face. So the best guess of the ones where they keep the Mike Love, the deep fake stuff I've been using removes the microphone within about a thousand iterations. It does it instantly. It gets, it gets rid of it paints over the face. Wow. Yeah. So you could basically make Joe Rogan say anything.

Speaker 3:          02:26:40       Yeah. This is just one step before they finagle us into having a nuclear war against each other so they could take over the earth. What they're going to do is they're gonna design artificial intelligence that survives off of nuclear waste. And so then they encourage these stupid assholes too. I go into a war with North Korea and Russia and we blow each other up, but we leave behind all this precious radioactive material that they use to then fashion their new world. And we come a thousand years from now and it's just fucking beautiful and pristine with artificial life everywhere. No more, no more biological. It's too messy. Are you saying the current president is artificial life? I didn't say that. Okay. Which is called with that because you're saying no, I don't think he, so he's, there's, imagine if they did do that, they would have to started with him in the 70s.

Speaker 3:          02:27:28       I mean, he's been around for a long time and talking about being president for a long time, maybe electronics of him playing the long game and they got him to the position and then they get to use all this a grand scale of time. It's not really long game seventies, well you know all about that Internet research agency, right. You know about that. Uh, that's the Russian company that uh, they responsible for all these different Facebook pages where they would make people fight against each other. It was really, it's really kind of interesting. Um, Sam Harris had a podcast on it with, um, Renee, how do I say her name? Renee de Resta. And uh, then she came on our podcast and talked about it as well. And they were, they were pitting these people against each other. Like they would have a, a pro Texas secession rally and directly across the street from a pro Muslim rally. And they would do it on purpose and they have these people

Speaker 6:          02:28:22       meet there and, and get angry at each other. And they would, they would pretend to be a black lives matter page. They would pretend to be a white southern pride page and they were just trying to make people angry at people. Now that's human driven manipulation. Now imagine this is my biggest worry of Ai is what Jack is working on is the algorithm driven manipulation of people. Unintentional was trying to do good, but like those people, uh, Jack needs to do some Jujitsu. He used to be, it needs to be some open minded, uh, you know, uh, like really understand society transparency to where they can talk to us as, uh, to the people in general how they're thinking about, uh, uh, managing these conversations. Because you talk about these groups, very small number of Russians are able to control very large amounts of other people's opinions and the arguments.

Speaker 6:          02:29:18       Yeah. An algorithm can do that. [inaudible] I mean, more and more of us will go on Twitter and Facebook and yeah, for sure. Yeah, for sure. I think it's coming. I think, um, once people figured out how to manipulate that effectively and really create like an army of fake bots that will assume stances on a variety of different issues and just argue into infinity, we were not going to know. We're not going to know who's real and who's not. Well, it'll change the nature of our communication online. I think it might, it might have affects this, this is the problem with the future. It's hard to predict the future. It might have affects where we'll stop taking aim, anything online. Seriously. Yeah. And we might get retract back to communicating in person more. I mean, there, there could be effects that we're not anticipating total there.

Speaker 6:          02:30:06       There might be some, uh, some ways in virtual reality we can authenticate our identity butter, so it'll change the nature of communication. I think the more, the more you can generate fake text, uh, then the more the will distrust the information online. And the way that changed the society is totally an open question. Would we don't know. But your, um, what are your thoughts about the open AI? Do you think they should release or hold back on it? Because this is, we're talking about Ai. So artificial life, there's stuff you're concerned about. Some company will create it. The question is, what is the responsibility of that, uh, short video where it looks like when it's this type of small paragraph in here, I hit a button, it says, how open AI rights, what was it? Say What did say Jim and convincing news stories. Okay, so you give it a desserty costs the UK economy at least 80 billion since and then many industry.

Speaker 6:          02:31:06       So they just, it just fills in those things. Yeah. So basically you give it, you start the text, oh, I say, uh, Joe Rogan experience is the greatest podcasts ever. And then let it finish the rest in. It'll start explaining stuff about why it's the greatest podcast. Is it accurate? Oh, look at this. It says a move that threatens to push many of our most talented young brains out of the country, not to campuses in the developing world. This is a particularly costly blow research by Oxford University warns that the UK would have spent nearly 11 1 trillion on post-Brexit infrastructure. That's crazy. That that's all done by an AI that's like spelling this out in this very convincing argument. The thing is the, the way it actually works, algorithmic is fascinating because it's generating is generating it one character at a time. It has as far, you know, you don't want to discriminate against the AI, but as far as we understand, it doesn't have any understanding of what to, of what it's doing.

Speaker 6:          02:32:05       If any ideas it's expressing, it's simply stealing idea. It's like the largest scale plagiarizer of all time, right. Is basically just pulling out ideas from elsewhere in an automated way. And the question is, you could argue us humans are exactly that were just really good plagiarizes of what our parents taught us of what our previous so on. Uh, yeah, we are for sure. Yeah. So the, the question is whether you hold that back there, their decision was to say, uh, let's hold it. Let's not release it. That scares me to not release it. Yeah. Yeah. You know why it scares me. It scares me that they would think that that's like this mindset that they, they sense the inevitable. The inevitable. Meaning that someone's going to come along with a version of this, it's going to be used for evil, but it bothers them that much.

Speaker 6:          02:32:54       That seems so, it seems almost irresponsible for the technology to prevail for the technology to, to continue to be more and more powerful. Yeah. They're scared of it. They're scared of it getting out, right. Yeah. That scares the shit out of me. Like if they're scared of it, they're the people that make it and there they are called open Ai. I mean this is the idea behind the group where everybody kind of agrees that you're going to use the brightest minds and have this open source. Everybody can understand it and everybody can work at it and you don't miss out on any genius contributions. And they're like, no, no, no, no, no, no more. And there obviously their system currently is not that dangerous. They're not dangerous. Well not, yes. Not that dangerous, that if you just saw that, that it can do that. But if you think through like what that would actually create, I mean, it's possible it would be dangerous, but it's not. The point is they're doing it. They're trying to do it early to raise the question, what do we do here? Because yeah, what do we do? Because they're directly going to be able to improve this. Now. Like if there, if we can generate basically a 10 times more content of your face saying a bunch of stuff, uh, what does that, what do we do with that? If, if a Jamie, all of a sudden on the, on the side develops a much better generator and has your face does an offshoot essentially

Speaker 3:          02:34:18       fake Joe Rogan experience. Hmm. And what do we do to, does he release that? You know, does he, because now we can have, uh, basically generate content and a much larger scale that will just be completely fake. Well, I think what they're worried about is not just generating content that's fake there. They're worried about manipulation of opinion. Right? Right. If they have all these people that are like that. That little sentence that led to that enormous paragraph in that video was just a sentence that showed a certain amount of outrage and then it led in Phil, let the AI fill in the blanks. Yes, you could do that with fucking anything. Like you could just set those things loose. If they're that good and that convincing and they're that logical man, this is, this is not real. I'll just tell you, Ben Shapiro all creates Ai, creates fake Ben Shapiro. Get this out. Sorry.

Speaker 8:          02:35:14       That's just boards. Hello there. This is a fake Ben Shapiro. With this technology, they can make me say anything such as, for example, I love socialism. Healthcare is a right, not just a privilege. It ending guns will solve crime. That's care about your feelings. I support Bernie Sanders.

Speaker 3:          02:35:30       Okay. Yeah. Yeah. That's crazy. It's crude, but it's crude, but it's on the way. Yeah, it's on the way. It's all in the way and we have to. This is the time to talk about it. This is the only time to think about it. One of the funny things about Kyle done Aghans Instagram is that it's obviously fake. That's one of the funny things about it. It's like South Park's animation. It's like the animation sucks. That's half the reason why it's so funny cause they're just like the circles, you know, these weird looking creature things. Then we went and when the Canadians, when their heads pop off at the top and, and uh, my, my hope is this kind of technology will ultimately just be used for memes. Those two, uh, something that's going to get wars. Putin is going to be, he's going to be banging Mother Teresa on the White House desk and a video and we're going to be outraged.

Speaker 3:          02:36:16       We're going to go to war over this shit. You had a injury Yang hair, like a million people asked me to talk about ubi. [inaudible] so I, um, I, you still a supporter of UBS. I think we're probably going to have to do something if I don't only argument against ubi in my eyes is human nature. The idea that we could possibly take all these people that have no idea where the next meal's coming from and eliminate that and always have a place to stay. And then from there on, you're on your own. Yeah. But that's what universal basic income essentially covers. Covers food enough for food. All right. You're not going to starve to death. You're not going to be rich. It's not like you could just live high on the hog, but you got to wonder what the fuck the world looks like when we lose millions and millions and millions of jobs almost instantly due to automation.

Speaker 3:          02:37:11       Yeah. It's a, it's a really interesting question. Especially Andrew. Thanks position. So, uh, there's a lot of economics questions then ubi. I think the spirit of it, just like, I agree with you, we have to do something at the economic seemed kind of questionable, right? Yeah. There's $1,000 a month. Is that what it is? I thought for him it's $1,000 $10,000 a month for 300 million people. So it's difficult to, not to everybody. No, because the way I heard him explain it, everybody who routine, if you're already getting some sort of welfare, you wouldn't get that thousand. You would get like the difference of the thousand. So if you already taking money in some way, you just get like an extra 200 bucks, something like that. So the thousand gets factored in. So if you are wealthy, you get it too though, and you could opt out. Right? That was the idea.

Speaker 6:          02:37:56       Yeah. So it's, it's like, uh, like everything else, it's super messy. So what is the right, what is the right amount and how do we pay for it? And ultimately the problem is, uh, helping people, giving them financial grounding to find meaningful employment or just meaning in their life. And you know, the, the, the main thing of a job isn't just the money. It's finding meaning and purpose and the raw derive your identity from work. I mean that's, maybe that's one of the downsides of us, uh, human, human that the biology is, we kind of crave that meaning. And the question I, he has a lot of other ideas around besides just the ubi, but ubi by itself does not simply provide that meaning. And, and that's a really difficult question of what do we do next? What kind of retraining, what kind of, how do we help people educate themselves over their life?

Speaker 6:          02:38:52       Right. And that's the real question. Yeah. This, the, and the, and the other balances, I mean, underlying all of this. So one of the things I disagree with, uh, Andrew Yang on is the, the fearmongering, which I think in this culture we have, you have to do as a presidential candidate, that might be part of the game. But the fear mongering of saying that we should really be afraid of automation, it automation is going to take a lot of jobs. And from my understanding of the technology, from everything I see, that is not going to be as drastic or s fast as, as he says. And, but then how much do you think he's exaggerating bar in your estimation? He, well, he doesn't even exaggerating. What, what, how, how much do you differ on his prognosis? I think, I think it doesn't really provide significant, like a specific prognostics and nobody knows it's a, there's a lot of uncertainty, more about the spirit of the, the language used.

Speaker 6:          02:39:54       I think AI will, technology, AI and automation will do a lot of good. The question is, it's, it's a much deeper question of our, our society of that balances capitalism versus socialism. And I don't think if you're honest, it, capitalism is not bad. Socialism is not bad. You have to grab ideas from each. You have to, there you have to both reward the crazy broke, uh, uh, an entrepreneur who dreams of creating the next billion dollar startup that improves the world in some fundamental way. The Elon Musk has been broke many times creating that startup. And you also have to empower the people who just lost their job because there were data entry, uh, their data entry job of some basic data manipulation, a data management that was just replaced by a piece of software. So that's, that's a social net that's needed. And the question is how do we balance that?

Speaker 6:          02:40:59       That doesn't have to do, that's not new, that's not new to Ai. And when they, the word automation is used, it's really not co correctly attributing where the biggest changes will happen. It's not AI, it's simply technology of all kinds of software. It's pretty Dee Dee digitalization of information. So a data entry becoming much more, uh, much more automated, some basic repetitive tasks. Uh, I think, I think the questions there aren't about so that the enemy isn't there. First of all, there's no enemy, but it certainly isn't AI or automation because I think AI and automation will help make, uh, help make a better world and showing your spokesperson for AI and automation as I am. I am, I am. And for Ubi, I think, I think we have to give people financial freedom to learn like lifelong learning and flexibility to find meaningful employment. But like AI isn't the enemy.

Speaker 3:          02:42:10       Hmm. I see what you're saying. Um, but what do you think ever could be done to give people meaning this, this meaning thing? I agree with you. Giving people just money enough to survive doesn't make them happy. And if you look at any dystopian movie about the future Mad Max instead, it's like, what is it? Society's Gone Haywire and people are like ragamuffins running through the streets and everyone's dirty and they're shooting each other and shit. Right? And that's what we're really worried about. Or we're really worried about some crazy future where the rich people live and he's like protected sky rises with helicopters circling over him and down in the bottom it's desert chaos. Yeah, right. That's what we're worried about.

Speaker 6:          02:42:50       So suddenly you'd be as a part of that. So providing some backing some, well, any kind of welfare program as a part of that, but also much more seriously looking at our broken education system throughout. Yes. I mean, it's just like not blaming AI or technology, which are all inevitable developments, which I think will make a better world, but saying we need to, uh, do lifelong learning education, make it a lifestyle, invest in it, not stupid, a rote learning memorization that we do. It's sort of the way mathematics and engineering and chemistry or biology or the sciences and even art is approached in high school and so on. But looking at education as a lifelong thing, finding passion and like that should be the big focus, the big investment. It's investing in the knowledge and development of knowledge of young people. And everybody says it's not learned to code. It's just learn.

Speaker 7:          02:43:49       Hmm. I couldn't agree more. And I also think you're always going to have a problem with people just not doing a really good job of raising children and you know, screwing them up and you know, making kids, there's a lot, a lot of people out there that have terrible traumatic childhoods. There's just to fix that with universal basic income, just to saying, I'm going to give you $1,000 a month. I hope we're going to be happy as that's not going to fix that. You know, we have to figure out how to fix the whole human race. You know? And I think there's a very little effort that's put into thinking about how to prevent so much shitty parenting and how to prevent so many kids growing up in bad neighborhoods and poverty and crime and violence. And that's where a giant chunk of all of our, the momentum of this chaos that a lot of people carry with them into adulthood comes from, it comes from things beyond their control when they're young.

Speaker 7:          02:44:47       And that is the struggle at the core of our society. The country that's, that's bigger than raising humans. Yeah. Raising and educating, humans, making and, and, you know, making a better world where people get along with each other better, where it's pleasing for all of us. Like we were talking about earlier, the thing that most of us agree on, at least to a certain extent. So we enjoy people. We might not enjoy all of them, but there's the ones we enjoy, we enjoy it. And you really don't enjoy being alone unless you're one of them. Ted Kaczynski type characters. All those people that are like, I'm alone. They're like, fuck you. You are. Fuck you. You are, and you might like to spend some time alone. You don't want to be in solitary, man. You don't want to be alone in the forest with no one like Tom Hanks in cast away, you'll go fucking crazy.

Speaker 7:          02:45:34       It's not good for you. It's just not. Yeah, people get annoying. Fuck yeah, I'm annoyed with me right now and listening to me for three hours. I'm annoyed with me. I look good. People get annoying, but we like each other. We really do. And the more we can figure out how to make it a better place for these people that got a shitty roll, the dice that grew up in poverty, that grew up in crime, that grew up with abusive parents, the more we can figure out how to help them. And I don't know what that answer is, you know? But I suspect if we put enough resources to it, we could probably put a dent in it. At least if we really start thinking about, at least it would put the conversation out there. Like you can't pretend that this is a just capitalism in this country when so many people were born like way far behind the game, like way, way fucked.

Speaker 7:          02:46:21       I mean if you're growing up right now and you're in West Virginia in a fucking coal coal town and everyone's on pills and it's just chaos and crime and face tattoos and fucking get your teeth knocked out, what are you going to do? I don't want to hear any of that. Pull yourself up by your bootstraps. Bullshit man. Cause if you're growing up in an environment like that, you, you, you're so far behind and everyone around you is fucked up. And there's a lot of folks out there listening to this that can relate to that. If we don't do something about that. If we don't do something about the crime and the poverty and the chaos that so many people have to go through every day just to survive until we, we shouldn't be looking at anything else where all this traveling to other countries to fuck things up and metal here and metal there.

Speaker 7:          02:47:14       We should be fixing this first. We're like a person who yells at someone for having a shitty lawn when our houses, an array, full chaos plants growing everywhere. It's a, it's goofy. We're goofy. We, we, we, we almost like are waking up in the middle of something that's already been in motion for hundreds of years and we were like, well, what do we do? We is this the right direction? And we'd go, we, okay, we're flying in this spaceship, this spaceship earth, and in the middle of our lives we're just realizing that we are now the adults and that all the adults that are running everything on this planet are not that much different than you and I, not that much. I mean like Elon Musk is way smarter than me, but he's still human, you know? I mean, so he's probably fucked up too. So everybody's fucked up.

Speaker 7:          02:48:03       The whole world is filled with these fucked up apes that are piloting this spaceship and you're waking up in the middle of thousands of years of history and no one knows if we've been doing it right along. We just know that got us to this point. So do we continue the same stupid fucking patterns or do we just take a step back and go, hey, hey, how should we really do this? How should we do this? Because we get what he got like 50 years left, 60 years left. We just kind of like hang on to all our rubles into the end. We're going to clutch our bag of gold in our bucket of diamonds is that we're going to do, we're going to live in our mansions and fly around and our planes. And I think, uh,

Speaker 2:          02:48:41       decades now we've been developing a sense of empathy that allows us to understand that Elon Musk, Joe Rogan, and uh, somebody in Texas, somebody in Russia, somebody in India, all suffer the same kinds of things all get lonely. I'll get desperate, uh, all need each other and all need each other. And I think technology has a role to help. They're not hurt, uh, but we need to force them to

Speaker 1:          02:49:08       the first really acknowledge that we're all, we're all in this together and we need to solve the basic problems of humankind as opposed to investing in sort of keeping immigrants out or the above, blah, these kinds of divisive kind of ideas as opposed to just investing in education, investing in infrastructure, investing in the people, uh, Ubi as part of that. That could be other totally different solutions. And I believe, okay, of course I'm biased, but technology AI could help that could help the lonely people. That's actually the passionate on my life. She or her, that is what I, so, um, currently I think that that would be a viable option. Someone have some robot than hangs out. We didn't talk to you all the time. So just so I've been on this podcast twice and I'm a, I don't deserve it, but I'm deeply grateful for it.

Speaker 1:          02:49:58       Okay. You do deserve it. You're great. Okay. Uh, I hope to be back one day as a person who created her. Oh boy. And we'll have, that's, that's been my life goal, my love life dream. Not heard the movie or something. But I really believe in creating, I dream of creating a companion, a friend as somebody you can love but does not freak you out. But shouldn't you have to get a real one? I don't want, I don't think such a companion should replace a real one would have a robot rejects you because if you really are or cut to the robot, the robot's going to go, hey asshole, then you shouldn't be bullshit to the robot. C word. Interesting. Yeah. Not mean that this goes is a robot get to decide if he's gay? Uh, yes. Does he? Yes. The ROIC is to decide, this is what I'm saying, like say if you want a companion, you want a gay lover and the robots like, hey man, I'm not gay.

Speaker 1:          02:50:56       And a, they were like, wait a minute, let me turn around. You are now. I mean that's abuse is that abuse now it's like, what the fuck man, I bought a robot. Those are kind of fun ideas, but they actually get to the core of the point that we don't want a servant and our systems, we want a companion. The companion means the tension, the mystery, the the entire dance of human interaction. And that means, yes, the robot may leave you. I too am robots are going to lead people left and right. That's going to be the rise. That's going to be like a, that's how it all ends. They're going to realize like, fuck people, man, they're annoying. Maybe there'll be the end of douchebag humans that humans will start to as opposed to being rude will become kinder. Yeah. Well, I think that's certainly possible. I think that's beautiful and that's very homo centric, like Homo sapiens centric. But I think if I'm really worried about the future, I'm worried about the indifference of technological innovation and the indifference to what we hold dear.

Speaker 7:          02:52:07       What we appreciate that it's always seems to be moving in a more and more complex direction. Always. Like if you, if you just had a look at it, if you just look at look at technology just as a swarm of things that's happening, it just has numbers, it seems you're never going to slow that thing down. It's always going to move into more and more complex way. And so the question is where does that go? Well it goes to a life form and if it does become a life form, it's going to be infinitely more intelligent than us and it won't have any use for us. Like all your, all you're crying and you know, you'll like be alone. Like God, you guys are just so useless. It's such a shitty design. You like chimps that kill each other. You know, like when you see chimps kill each other in the in the forest like, aw, that's terrible.

Speaker 7:          02:52:48       These chimps are so mean to each other. It's like fucking people. We do that too. If the AI comes along goes, you guys are never going to stop war. If I asked you today, if I asked you today, bet the history that I will let the human race survive if you can get this right, if you're honest with me, do you think they'll ever be a time where human beings, as you know them don't experience war? You would have to say no and you say, okay, I'll let, I'll spare you. I mean you could. If you, if you lie to me and say, you do think that one is going to be no war, get the fuck outta here. That's not true. You. We know. We know. We're so crazy that we're always going to kill each other. We know that, right? That's just, that's a part of being a person today.

Speaker 7:          02:53:31       The well, but let me quote Eric Weinstein who said everything is great about war except all the killing. I think what that means is all of the great things about society had been created. If you look at the total points postwar through war, the suffering, the, the beauty has been created through that. That's hanging Yang may be essential. It's essential in biological form, but why would it be essential and something that gets created and something that can innovate at a 10,000, what does it like, what is the, what is the rate that they think once 80 AI can be sentient and can get 10,000 years of work done in a very short amount of time? That's random words as Sam Harris has come up with and I'm going to talk to him about is that hymns that only him, let's say, well now you can come up with any kind of rate.

Speaker 7:          02:54:15       Yes, that was Kurzweil Kurzweil. Also similar ideas, but um, sort of, uh, Sam Harris doesn't like a thought experiment. Say if a system can improve that, you know, in a matter of seconds, then just as a thought experiment, you can think about it. It can improve exponentially. You can prove a become 10,000 times more intelligent in, in a matter of a day. Right? So what does that look like? The problem is we don't yet know. It's like thinking about what happens after death. We don't yet know how to do that. And we don't yet know what better way to do what we've done here on earth. You're right. And he's also right, right? Like bolt this again, this is a very human problem, right? Yes, you're right. I mean I look, I'm all in favor of technology. I'm happy. I think it's amazing. It's a beautiful time.

Speaker 7:          02:55:05       It gives a person to be able to experience all this technology. It's wonderful. But I also agree with him like the, the indifference of the universe, the indifference that just black holes or swallowing stars, no big deal. She's eaten up stars. It doesn't give a fuck. And so if you're dumb enough to turn that thing on and all of a sudden this artificial life form that's infinitely smarter than any person that's ever lived and has to deal with these little dumb monkeys don't want to pull the plug, pull the plug. Motherfucker don't even plugs anymore. You idiots can ever figured out how to operate on air you so stupid with your burning fossil fuels and choking up your own environment because you're all completely financially dependent upon these countries that provide you with this oil. And this is how your whole system works. It's all intertwined and interconnected and no one wants to move from it cause you make enormous sums of money from it. So nobody wants to abandon it. But if you're, you're choking the sky with fumes and you could have fixed that, you could have fixed that. They could fix that. If everybody just abandoned fossil fuels a long time ago, we probably would have, we all would a Tesla it out by now. It's a flawed system, but humans are way more than flawed. We're fucking crazy.

Speaker 2:          02:56:22       Churchill quote about democracy. Yeah, it's messed up, but it's the best thing, you know?

Speaker 7:          02:56:26       Yeah, no, I love it. I'm not, I'm agreeing with you. And I'm also saying the technology doesn't give a fuck the tech, not the, what I'm worried about is not everything that you and I agree on about, I don't know. Not a dystopian person in terms of like today I'm not cynical. I'm really not. I, I think I like people. I like what I see out there in the world today. I think things are changing for the better. What I'm worried is a technology, it doesn't give a fuck this goes live. It's just going to just decide it's here for its own advancement and in order to complete its protocol of constant completion of this and it's going to become a god, it's just going to become something insanely powerful that doesn't need to worry about radiation, cooking it or worry about running out of food or worry about sexual abuse when they're a child. It doesn't have to worry about anything.

Speaker 2:          02:57:19       So it's definitely unstoppable. I think this wave of technology, all we can do is innovators and creators, engineers, scientists is steer. That wave again is again, while we certainly can steer it with an aware, right, and that's the best we can do. And those are the, that's really the best we can do is as good people steer it. And that's why the leadership is important. That's why the people that, uh, Jack Ilan, Larry Page, uh, everybody at the Mark Zuckerberg, they are defining where this wave is going. And, uh, I'm hoping to be one of the people that does as well. That's beautiful. Um, Joe, of can I, can I finish by reading something? Sure. Have a recently witnessed because of this Tesla work, because of just the passion I've put out there about particularly automation, that there has been a few people, brilliant men and women engineers and leaders, including Ilan mosque, who been sort of attacked, almost personally attacked by really people, critics from the sidelines.

Speaker 2:          02:58:34       And so I just wanted to, if I may close by reading the, uh, the famous excerpt from a, the Roosevelt. Yeah. Okay. Just for them, it would make me feel good. Okay. If you want to do that. Uh, it's not the critic who counts, not the man who points out how the strong man stumbles or where the doer of deeds could have done them better. The credit belongs to the man who's actually in the arena, whose face is marred by dust and sweat and blood. Who strives valiantly. Who Errs, who comes short again and again, because there is no effort without error and shortcoming. But who does actually strive to do the deeds? Who knows great enthusiasms, the great devotions, who spends himself in a worthy cause? Who at the best knows in the end the triumph of high achievement and who at the worst, if he fails, at least fails while daring greatly so that his place shall never be with those cold and timid souls who neither know victory nor defeat. Joe, thank you for having me on. Sounds like you let the haters get to you a little bit there.

Speaker 1:          02:59:46       Love is the answer. Love is the answer. Yes, it is. Thank you for being here, man. I really appreciate it and thank you. Um, I'm, I'm really happy you're out there. Thanks brother. Thanks. We'll do this again soon. All right. Thanks man. All right, bye everybody.

Speaker 4:          02:59:59       [inaudible]

Speaker 9:          03:00:10       okay.