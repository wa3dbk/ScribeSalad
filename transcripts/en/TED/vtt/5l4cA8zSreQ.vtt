WEBVTT
Kind: captions
Language: en

00:00:15.260 --> 00:00:17.260
Erez Lieberman Aiden: Everyone knows

00:00:17.260 --> 00:00:20.260
that a picture is worth a thousand words.

00:00:22.260 --> 00:00:24.260
But we at Harvard

00:00:24.260 --> 00:00:27.260
were wondering if this was really true.

00:00:27.260 --> 00:00:29.260
(Laughter)

00:00:29.260 --> 00:00:33.260
So we assembled a team of experts,

00:00:33.260 --> 00:00:35.260
spanning Harvard, MIT,

00:00:35.260 --> 00:00:38.260
The American Heritage Dictionary, The Encyclopedia Britannica

00:00:38.260 --> 00:00:40.260
and even our proud sponsors,

00:00:40.260 --> 00:00:43.260
the Google.

00:00:43.260 --> 00:00:45.260
And we cogitated about this

00:00:45.260 --> 00:00:47.260
for about four years.

00:00:47.260 --> 00:00:52.260
And we came to a startling conclusion.

00:00:52.260 --> 00:00:55.260
Ladies and gentlemen, a picture is not worth a thousand words.

00:00:55.260 --> 00:00:57.260
In fact, we found some pictures

00:00:57.260 --> 00:01:02.260
that are worth 500 billion words.

00:01:02.260 --> 00:01:04.260
Jean-Baptiste Michel: So how did we get to this conclusion?

00:01:04.260 --> 00:01:06.260
So Erez and I were thinking about ways

00:01:06.260 --> 00:01:08.260
to get a big picture of human culture

00:01:08.260 --> 00:01:11.260
and human history: change over time.

00:01:11.260 --> 00:01:13.260
So many books actually have been written over the years.

00:01:13.260 --> 00:01:15.260
So we were thinking, well the best way to learn from them

00:01:15.260 --> 00:01:17.260
is to read all of these millions of books.

00:01:17.260 --> 00:01:20.260
Now of course, if there's a scale for how awesome that is,

00:01:20.260 --> 00:01:23.260
that has to rank extremely, extremely high.

00:01:23.260 --> 00:01:25.260
Now the problem is there's an X-axis for that,

00:01:25.260 --> 00:01:27.260
which is the practical axis.

00:01:27.260 --> 00:01:29.260
This is very, very low.

00:01:29.260 --> 00:01:32.260
(Applause)

00:01:32.260 --> 00:01:35.260
Now people tend to use an alternative approach,

00:01:35.260 --> 00:01:37.260
which is to take a few sources and read them very carefully.

00:01:37.260 --> 00:01:39.260
This is extremely practical, but not so awesome.

00:01:39.260 --> 00:01:42.260
What you really want to do

00:01:42.260 --> 00:01:45.260
is to get to the awesome yet practical part of this space.

00:01:45.260 --> 00:01:48.260
So it turns out there was a company across the river called Google

00:01:48.260 --> 00:01:50.260
who had started a digitization project a few years back

00:01:50.260 --> 00:01:52.260
that might just enable this approach.

00:01:52.260 --> 00:01:54.260
They have digitized millions of books.

00:01:54.260 --> 00:01:57.260
So what that means is, one could use computational methods

00:01:57.260 --> 00:01:59.260
to read all of the books in a click of a button.

00:01:59.260 --> 00:02:02.260
That's very practical and extremely awesome.

00:02:03.260 --> 00:02:05.260
ELA: Let me tell you a little bit about where books come from.

00:02:05.260 --> 00:02:08.260
Since time immemorial, there have been authors.

00:02:08.260 --> 00:02:11.260
These authors have been striving to write books.

00:02:11.260 --> 00:02:13.260
And this became considerably easier

00:02:13.260 --> 00:02:15.260
with the development of the printing press some centuries ago.

00:02:15.260 --> 00:02:18.260
Since then, the authors have won

00:02:18.260 --> 00:02:20.260
on 129 million distinct occasions,

00:02:20.260 --> 00:02:22.260
publishing books.

00:02:22.260 --> 00:02:24.260
Now if those books are not lost to history,

00:02:24.260 --> 00:02:26.260
then they are somewhere in a library,

00:02:26.260 --> 00:02:29.260
and many of those books have been getting retrieved from the libraries

00:02:29.260 --> 00:02:31.260
and digitized by Google,

00:02:31.260 --> 00:02:33.260
which has scanned 15 million books to date.

00:02:33.260 --> 00:02:36.260
Now when Google digitizes a book, they put it into a really nice format.

00:02:36.260 --> 00:02:38.260
Now we've got the data, plus we have metadata.

00:02:38.260 --> 00:02:41.260
We have information about things like where was it published,

00:02:41.260 --> 00:02:43.260
who was the author, when was it published.

00:02:43.260 --> 00:02:46.260
And what we do is go through all of those records

00:02:46.260 --> 00:02:50.260
and exclude everything that's not the highest quality data.

00:02:50.260 --> 00:02:52.260
What we're left with

00:02:52.260 --> 00:02:55.260
is a collection of five million books,

00:02:55.260 --> 00:02:58.260
500 billion words,

00:02:58.260 --> 00:03:00.260
a string of characters a thousand times longer

00:03:00.260 --> 00:03:03.260
than the human genome --

00:03:03.260 --> 00:03:05.260
a text which, when written out,

00:03:05.260 --> 00:03:07.260
would stretch from here to the Moon and back

00:03:07.260 --> 00:03:09.260
10 times over --

00:03:09.260 --> 00:03:13.260
a veritable shard of our cultural genome.

00:03:13.260 --> 00:03:15.260
Of course what we did

00:03:15.260 --> 00:03:18.260
when faced with such outrageous hyperbole ...

00:03:18.260 --> 00:03:20.260
(Laughter)

00:03:20.260 --> 00:03:23.260
was what any self-respecting researchers

00:03:23.260 --> 00:03:26.260
would have done.

00:03:26.260 --> 00:03:28.260
We took a page out of XKCD,

00:03:28.260 --> 00:03:30.260
and we said, "Stand back.

00:03:30.260 --> 00:03:32.260
We're going to try science."

00:03:32.260 --> 00:03:34.260
(Laughter)

00:03:34.260 --> 00:03:36.260
JM: Now of course, we were thinking,

00:03:36.260 --> 00:03:38.260
well let's just first put the data out there

00:03:38.260 --> 00:03:40.260
for people to do science to it.

00:03:40.260 --> 00:03:42.260
Now we're thinking, what data can we release?

00:03:42.260 --> 00:03:44.260
Well of course, you want to take the books

00:03:44.260 --> 00:03:46.260
and release the full text of these five million books.

00:03:46.260 --> 00:03:48.260
Now Google, and Jon Orwant in particular,

00:03:48.260 --> 00:03:50.260
told us a little equation that we should learn.

00:03:50.260 --> 00:03:53.260
So you have five million, that is, five million authors

00:03:53.260 --> 00:03:56.260
and five million plaintiffs is a massive lawsuit.

00:03:56.260 --> 00:03:58.260
So, although that would be really, really awesome,

00:03:58.260 --> 00:04:01.260
again, that's extremely, extremely impractical.

00:04:01.260 --> 00:04:03.260
(Laughter)

00:04:03.260 --> 00:04:05.260
Now again, we kind of caved in,

00:04:05.260 --> 00:04:08.260
and we did the very practical approach, which was a bit less awesome.

00:04:08.260 --> 00:04:10.260
We said, well instead of releasing the full text,

00:04:10.260 --> 00:04:12.260
we're going to release statistics about the books.

00:04:12.260 --> 00:04:14.260
So take for instance "A gleam of happiness."

00:04:14.260 --> 00:04:16.260
It's four words; we call that a four-gram.

00:04:16.260 --> 00:04:18.260
We're going to tell you how many times a particular four-gram

00:04:18.260 --> 00:04:20.260
appeared in books in 1801, 1802, 1803,

00:04:20.260 --> 00:04:22.260
all the way up to 2008.

00:04:22.260 --> 00:04:24.260
That gives us a time series

00:04:24.260 --> 00:04:26.260
of how frequently this particular sentence was used over time.

00:04:26.260 --> 00:04:29.260
We do that for all the words and phrases that appear in those books,

00:04:29.260 --> 00:04:32.260
and that gives us a big table of two billion lines

00:04:32.260 --> 00:04:34.260
that tell us about the way culture has been changing.

00:04:34.260 --> 00:04:36.260
ELA: So those two billion lines,

00:04:36.260 --> 00:04:38.260
we call them two billion n-grams.

00:04:38.260 --> 00:04:40.260
What do they tell us?

00:04:40.260 --> 00:04:42.260
Well the individual n-grams measure cultural trends.

00:04:42.260 --> 00:04:44.260
Let me give you an example.

00:04:44.260 --> 00:04:46.260
Let's suppose that I am thriving,

00:04:46.260 --> 00:04:48.260
then tomorrow I want to tell you about how well I did.

00:04:48.260 --> 00:04:51.260
And so I might say, "Yesterday, I throve."

00:04:51.260 --> 00:04:54.260
Alternatively, I could say, "Yesterday, I thrived."

00:04:54.260 --> 00:04:57.260
Well which one should I use?

00:04:57.260 --> 00:04:59.260
How to know?

00:04:59.260 --> 00:05:01.260
As of about six months ago,

00:05:01.260 --> 00:05:03.260
the state of the art in this field

00:05:03.260 --> 00:05:05.260
is that you would, for instance,

00:05:05.260 --> 00:05:07.260
go up to the following psychologist with fabulous hair,

00:05:07.260 --> 00:05:09.260
and you'd say,

00:05:09.260 --> 00:05:12.260
"Steve, you're an expert on the irregular verbs.

00:05:12.260 --> 00:05:14.260
What should I do?"

00:05:14.260 --> 00:05:16.260
And he'd tell you, "Well most people say thrived,

00:05:16.260 --> 00:05:19.260
but some people say throve."

00:05:19.260 --> 00:05:21.260
And you also knew, more or less,

00:05:21.260 --> 00:05:24.260
that if you were to go back in time 200 years

00:05:24.260 --> 00:05:27.260
and ask the following statesman with equally fabulous hair,

00:05:27.260 --> 00:05:30.260
(Laughter)

00:05:30.260 --> 00:05:32.260
"Tom, what should I say?"

00:05:32.260 --> 00:05:34.260
He'd say, "Well, in my day, most people throve,

00:05:34.260 --> 00:05:37.260
but some thrived."

00:05:37.260 --> 00:05:39.260
So now what I'm just going to show you is raw data.

00:05:39.260 --> 00:05:43.260
Two rows from this table of two billion entries.

00:05:43.260 --> 00:05:45.260
What you're seeing is year by year frequency

00:05:45.260 --> 00:05:48.260
of "thrived" and "throve" over time.

00:05:49.260 --> 00:05:51.260
Now this is just two

00:05:51.260 --> 00:05:54.260
out of two billion rows.

00:05:54.260 --> 00:05:56.260
So the entire data set

00:05:56.260 --> 00:05:59.260
is a billion times more awesome than this slide.

00:05:59.260 --> 00:06:01.260
(Laughter)

00:06:01.260 --> 00:06:05.260
(Applause)

00:06:05.260 --> 00:06:07.260
JM: Now there are many other pictures that are worth 500 billion words.

00:06:07.260 --> 00:06:09.260
For instance, this one.

00:06:09.260 --> 00:06:11.260
If you just take influenza,

00:06:11.260 --> 00:06:13.260
you will see peaks at the time where you knew

00:06:13.260 --> 00:06:16.260
big flu epidemics were killing people around the globe.

00:06:16.260 --> 00:06:19.260
ELA: If you were not yet convinced,

00:06:19.260 --> 00:06:21.260
sea levels are rising,

00:06:21.260 --> 00:06:24.260
so is atmospheric CO2 and global temperature.

00:06:24.260 --> 00:06:27.260
JM: You might also want to have a look at this particular n-gram,

00:06:27.260 --> 00:06:30.260
and that's to tell Nietzsche that God is not dead,

00:06:30.260 --> 00:06:33.260
although you might agree that he might need a better publicist.

00:06:33.260 --> 00:06:35.260
(Laughter)

00:06:35.260 --> 00:06:38.260
ELA: You can get at some pretty abstract concepts with this sort of thing.

00:06:38.260 --> 00:06:40.260
For instance, let me tell you the history

00:06:40.260 --> 00:06:42.260
of the year 1950.

00:06:42.260 --> 00:06:44.260
Pretty much for the vast majority of history,

00:06:44.260 --> 00:06:46.260
no one gave a damn about 1950.

00:06:46.260 --> 00:06:48.260
In 1700, in 1800, in 1900,

00:06:48.260 --> 00:06:51.260
no one cared.

00:06:52.260 --> 00:06:54.260
Through the 30s and 40s,

00:06:54.260 --> 00:06:56.260
no one cared.

00:06:56.260 --> 00:06:58.260
Suddenly, in the mid-40s,

00:06:58.260 --> 00:07:00.260
there started to be a buzz.

00:07:00.260 --> 00:07:02.260
People realized that 1950 was going to happen,

00:07:02.260 --> 00:07:04.260
and it could be big.

00:07:04.260 --> 00:07:07.260
(Laughter)

00:07:07.260 --> 00:07:10.260
But nothing got people interested in 1950

00:07:10.260 --> 00:07:13.260
like the year 1950.

00:07:13.260 --> 00:07:16.260
(Laughter)

00:07:16.260 --> 00:07:18.260
People were walking around obsessed.

00:07:18.260 --> 00:07:20.260
They couldn't stop talking

00:07:20.260 --> 00:07:23.260
about all the things they did in 1950,

00:07:23.260 --> 00:07:26.260
all the things they were planning to do in 1950,

00:07:26.260 --> 00:07:31.260
all the dreams of what they wanted to accomplish in 1950.

00:07:31.260 --> 00:07:33.260
In fact, 1950 was so fascinating

00:07:33.260 --> 00:07:35.260
that for years thereafter,

00:07:35.260 --> 00:07:38.260
people just kept talking about all the amazing things that happened,

00:07:38.260 --> 00:07:40.260
in '51, '52, '53.

00:07:40.260 --> 00:07:42.260
Finally in 1954,

00:07:42.260 --> 00:07:44.260
someone woke up and realized

00:07:44.260 --> 00:07:48.260
that 1950 had gotten somewhat passÃ©.

00:07:48.260 --> 00:07:50.260
(Laughter)

00:07:50.260 --> 00:07:52.260
And just like that, the bubble burst.

00:07:52.260 --> 00:07:54.260
(Laughter)

00:07:54.260 --> 00:07:56.260
And the story of 1950

00:07:56.260 --> 00:07:58.260
is the story of every year that we have on record,

00:07:58.260 --> 00:08:01.260
with a little twist, because now we've got these nice charts.

00:08:01.260 --> 00:08:04.260
And because we have these nice charts, we can measure things.

00:08:04.260 --> 00:08:06.260
We can say, "Well how fast does the bubble burst?"

00:08:06.260 --> 00:08:09.260
And it turns out that we can measure that very precisely.

00:08:09.260 --> 00:08:12.260
Equations were derived, graphs were produced,

00:08:12.260 --> 00:08:14.260
and the net result

00:08:14.260 --> 00:08:17.260
is that we find that the bubble bursts faster and faster

00:08:17.260 --> 00:08:19.260
with each passing year.

00:08:19.260 --> 00:08:24.260
We are losing interest in the past more rapidly.

00:08:24.260 --> 00:08:26.260
JM: Now a little piece of career advice.

00:08:26.260 --> 00:08:28.260
So for those of you who seek to be famous,

00:08:28.260 --> 00:08:30.260
we can learn from the 25 most famous political figures,

00:08:30.260 --> 00:08:32.260
authors, actors and so on.

00:08:32.260 --> 00:08:35.260
So if you want to become famous early on, you should be an actor,

00:08:35.260 --> 00:08:37.260
because then fame starts rising by the end of your 20s --

00:08:37.260 --> 00:08:39.260
you're still young, it's really great.

00:08:39.260 --> 00:08:41.260
Now if you can wait a little bit, you should be an author,

00:08:41.260 --> 00:08:43.260
because then you rise to very great heights,

00:08:43.260 --> 00:08:45.260
like Mark Twain, for instance: extremely famous.

00:08:45.260 --> 00:08:47.260
But if you want to reach the very top,

00:08:47.260 --> 00:08:49.260
you should delay gratification

00:08:49.260 --> 00:08:51.260
and, of course, become a politician.

00:08:51.260 --> 00:08:53.260
So here you will become famous by the end of your 50s,

00:08:53.260 --> 00:08:55.260
and become very, very famous afterward.

00:08:55.260 --> 00:08:58.260
So scientists also tend to get famous when they're much older.

00:08:58.260 --> 00:09:00.260
Like for instance, biologists and physics

00:09:00.260 --> 00:09:02.260
tend to be almost as famous as actors.

00:09:02.260 --> 00:09:05.260
One mistake you should not do is become a mathematician.

00:09:05.260 --> 00:09:07.260
(Laughter)

00:09:07.260 --> 00:09:09.260
If you do that,

00:09:09.260 --> 00:09:12.260
you might think, "Oh great. I'm going to do my best work when I'm in my 20s."

00:09:12.260 --> 00:09:14.260
But guess what, nobody will really care.

00:09:14.260 --> 00:09:17.260
(Laughter)

00:09:17.260 --> 00:09:19.260
ELA: There are more sobering notes

00:09:19.260 --> 00:09:21.260
among the n-grams.

00:09:21.260 --> 00:09:23.260
For instance, here's the trajectory of Marc Chagall,

00:09:23.260 --> 00:09:25.260
an artist born in 1887.

00:09:25.260 --> 00:09:28.260
And this looks like the normal trajectory of a famous person.

00:09:28.260 --> 00:09:32.260
He gets more and more and more famous,

00:09:32.260 --> 00:09:34.260
except if you look in German.

00:09:34.260 --> 00:09:36.260
If you look in German, you see something completely bizarre,

00:09:36.260 --> 00:09:38.260
something you pretty much never see,

00:09:38.260 --> 00:09:40.260
which is he becomes extremely famous

00:09:40.260 --> 00:09:42.260
and then all of a sudden plummets,

00:09:42.260 --> 00:09:45.260
going through a nadir between 1933 and 1945,

00:09:45.260 --> 00:09:48.260
before rebounding afterward.

00:09:48.260 --> 00:09:50.260
And of course, what we're seeing

00:09:50.260 --> 00:09:53.260
is the fact Marc Chagall was a Jewish artist

00:09:53.260 --> 00:09:55.260
in Nazi Germany.

00:09:55.260 --> 00:09:57.260
Now these signals

00:09:57.260 --> 00:09:59.260
are actually so strong

00:09:59.260 --> 00:10:02.260
that we don't need to know that someone was censored.

00:10:02.260 --> 00:10:04.260
We can actually figure it out

00:10:04.260 --> 00:10:06.260
using really basic signal processing.

00:10:06.260 --> 00:10:08.260
Here's a simple way to do it.

00:10:08.260 --> 00:10:10.260
Well, a reasonable expectation

00:10:10.260 --> 00:10:12.260
is that somebody's fame in a given period of time

00:10:12.260 --> 00:10:14.260
should be roughly the average of their fame before

00:10:14.260 --> 00:10:16.260
and their fame after.

00:10:16.260 --> 00:10:18.260
So that's sort of what we expect.

00:10:18.260 --> 00:10:21.260
And we compare that to the fame that we observe.

00:10:21.260 --> 00:10:23.260
And we just divide one by the other

00:10:23.260 --> 00:10:25.260
to produce something we call a suppression index.

00:10:25.260 --> 00:10:28.260
If the suppression index is very, very, very small,

00:10:28.260 --> 00:10:30.260
then you very well might be being suppressed.

00:10:30.260 --> 00:10:33.260
If it's very large, maybe you're benefiting from propaganda.

00:10:34.260 --> 00:10:36.260
JM: Now you can actually look at

00:10:36.260 --> 00:10:39.260
the distribution of suppression indexes over whole populations.

00:10:39.260 --> 00:10:41.260
So for instance, here --

00:10:41.260 --> 00:10:43.260
this suppression index is for 5,000 people

00:10:43.260 --> 00:10:45.260
picked in English books where there's no known suppression --

00:10:45.260 --> 00:10:47.260
it would be like this, basically tightly centered on one.

00:10:47.260 --> 00:10:49.260
What you expect is basically what you observe.

00:10:49.260 --> 00:10:51.260
This is distribution as seen in Germany --

00:10:51.260 --> 00:10:53.260
very different, it's shifted to the left.

00:10:53.260 --> 00:10:56.260
People talked about it twice less as it should have been.

00:10:56.260 --> 00:10:58.260
But much more importantly, the distribution is much wider.

00:10:58.260 --> 00:11:01.260
There are many people who end up on the far left on this distribution

00:11:01.260 --> 00:11:04.260
who are talked about 10 times fewer than they should have been.

00:11:04.260 --> 00:11:06.260
But then also many people on the far right

00:11:06.260 --> 00:11:08.260
who seem to benefit from propaganda.

00:11:08.260 --> 00:11:11.260
This picture is the hallmark of censorship in the book record.

00:11:11.260 --> 00:11:13.260
ELA: So culturomics

00:11:13.260 --> 00:11:15.260
is what we call this method.

00:11:15.260 --> 00:11:17.260
It's kind of like genomics.

00:11:17.260 --> 00:11:19.260
Except genomics is a lens on biology

00:11:19.260 --> 00:11:22.260
through the window of the sequence of bases in the human genome.

00:11:22.260 --> 00:11:24.260
Culturomics is similar.

00:11:24.260 --> 00:11:27.260
It's the application of massive-scale data collection analysis

00:11:27.260 --> 00:11:29.260
to the study of human culture.

00:11:29.260 --> 00:11:31.260
Here, instead of through the lens of a genome,

00:11:31.260 --> 00:11:34.260
through the lens of digitized pieces of the historical record.

00:11:34.260 --> 00:11:36.260
The great thing about culturomics

00:11:36.260 --> 00:11:38.260
is that everyone can do it.

00:11:38.260 --> 00:11:40.260
Why can everyone do it?

00:11:40.260 --> 00:11:42.260
Everyone can do it because three guys,

00:11:42.260 --> 00:11:45.260
Jon Orwant, Matt Gray and Will Brockman over at Google,

00:11:45.260 --> 00:11:47.260
saw the prototype of the Ngram Viewer,

00:11:47.260 --> 00:11:49.260
and they said, "This is so fun.

00:11:49.260 --> 00:11:52.260
We have to make this available for people."

00:11:52.260 --> 00:11:54.260
So in two weeks flat -- the two weeks before our paper came out --

00:11:54.260 --> 00:11:57.260
they coded up a version of the Ngram Viewer for the general public.

00:11:57.260 --> 00:12:00.260
And so you too can type in any word or phrase that you're interested in

00:12:00.260 --> 00:12:02.260
and see its n-gram immediately --

00:12:02.260 --> 00:12:04.260
also browse examples of all the various books

00:12:04.260 --> 00:12:06.260
in which your n-gram appears.

00:12:06.260 --> 00:12:08.260
JM: Now this was used over a million times on the first day,

00:12:08.260 --> 00:12:10.260
and this is really the best of all the queries.

00:12:10.260 --> 00:12:13.260
So people want to be their best, put their best foot forward.

00:12:13.260 --> 00:12:16.260
But it turns out in the 18th century, people didn't really care about that at all.

00:12:16.260 --> 00:12:19.260
They didn't want to be their best, they wanted to be their beft.

00:12:19.260 --> 00:12:22.260
So what happened is, of course, this is just a mistake.

00:12:22.260 --> 00:12:24.260
It's not that strove for mediocrity,

00:12:24.260 --> 00:12:27.260
it's just that the S used to be written differently, kind of like an F.

00:12:27.260 --> 00:12:30.260
Now of course, Google didn't pick this up at the time,

00:12:30.260 --> 00:12:33.260
so we reported this in the science article that we wrote.

00:12:33.260 --> 00:12:35.260
But it turns out this is just a reminder

00:12:35.260 --> 00:12:37.260
that, although this is a lot of fun,

00:12:37.260 --> 00:12:39.260
when you interpret these graphs, you have to be very careful,

00:12:39.260 --> 00:12:42.260
and you have to adopt the base standards in the sciences.

00:12:42.260 --> 00:12:45.260
ELA: People have been using this for all kinds of fun purposes.

00:12:45.260 --> 00:12:52.260
(Laughter)

00:12:52.260 --> 00:12:54.260
Actually, we're not going to have to talk,

00:12:54.260 --> 00:12:57.260
we're just going to show you all the slides and remain silent.

00:12:57.260 --> 00:13:00.260
This person was interested in the history of frustration.

00:13:00.260 --> 00:13:03.260
There's various types of frustration.

00:13:03.260 --> 00:13:06.260
If you stub your toe, that's a one A "argh."

00:13:06.260 --> 00:13:08.260
If the planet Earth is annihilated by the Vogons

00:13:08.260 --> 00:13:10.260
to make room for an interstellar bypass,

00:13:10.260 --> 00:13:12.260
that's an eight A "aaaaaaaargh."

00:13:12.260 --> 00:13:14.260
This person studies all the "arghs,"

00:13:14.260 --> 00:13:16.260
from one through eight A's.

00:13:16.260 --> 00:13:18.260
And it turns out

00:13:18.260 --> 00:13:20.260
that the less-frequent "arghs"

00:13:20.260 --> 00:13:23.260
are, of course, the ones that correspond to things that are more frustrating --

00:13:23.260 --> 00:13:26.260
except, oddly, in the early 80s.

00:13:26.260 --> 00:13:28.260
We think that might have something to do with Reagan.

00:13:28.260 --> 00:13:30.260
(Laughter)

00:13:30.260 --> 00:13:33.260
JM: There are many usages of this data,

00:13:33.260 --> 00:13:36.260
but the bottom line is that the historical record is being digitized.

00:13:36.260 --> 00:13:38.260
Google has started to digitize 15 million books.

00:13:38.260 --> 00:13:40.260
That's 12 percent of all the books that have ever been published.

00:13:40.260 --> 00:13:43.260
It's a sizable chunk of human culture.

00:13:43.260 --> 00:13:46.260
There's much more in culture: there's manuscripts, there newspapers,

00:13:46.260 --> 00:13:48.260
there's things that are not text, like art and paintings.

00:13:48.260 --> 00:13:50.260
These all happen to be on our computers,

00:13:50.260 --> 00:13:52.260
on computers across the world.

00:13:52.260 --> 00:13:55.260
And when that happens, that will transform the way we have

00:13:55.260 --> 00:13:57.260
to understand our past, our present and human culture.

00:13:57.260 --> 00:13:59.260
Thank you very much.

00:13:59.260 --> 00:14:02.260
(Applause)

