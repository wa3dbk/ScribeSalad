WEBVTT
Kind: captions
Language: en

00:00:15.651 --> 00:00:18.237
We are today talking
about moral persuasion:

00:00:18.261 --> 00:00:22.243
What is moral and immoral
in trying to change people's behaviors

00:00:22.267 --> 00:00:24.720
by using technology and using design?

00:00:24.744 --> 00:00:26.576
And I don't know what you expect,

00:00:26.600 --> 00:00:28.553
but when I was thinking about that issue,

00:00:28.577 --> 00:00:32.616
I early on realized what I'm not able
to give you are answers.

00:00:33.203 --> 00:00:35.974
I'm not able to tell you
what is moral or immoral,

00:00:35.998 --> 00:00:38.545
because we're living
in a pluralist society.

00:00:38.569 --> 00:00:42.811
My values can be radically
different from your values,

00:00:42.835 --> 00:00:46.012
which means that what I consider
moral or immoral based on that

00:00:46.036 --> 00:00:49.648
might not necessarily be
what you consider moral or immoral.

00:00:50.029 --> 00:00:53.243
But I also realized
there is one thing that I could give you,

00:00:53.267 --> 00:00:55.800
and that is what this guy
behind me gave the world --

00:00:55.824 --> 00:00:56.974
Socrates.

00:00:56.998 --> 00:00:58.393
It is questions.

00:00:58.417 --> 00:01:01.050
What I can do and what
I would like to do with you

00:01:01.074 --> 00:01:03.019
is give you, like that initial question,

00:01:03.043 --> 00:01:06.453
a set of questions
to figure out for yourselves,

00:01:06.477 --> 00:01:10.118
layer by layer, like peeling an onion,

00:01:10.142 --> 00:01:15.162
getting at the core of what you believe
is moral or immoral persuasion.

00:01:15.559 --> 00:01:19.600
And I'd like to do that
with a couple of examples of technologies

00:01:19.624 --> 00:01:24.604
where people have used game elements
to get people to do things.

00:01:25.343 --> 00:01:28.383
So it's at first a very simple,
very obvious question

00:01:28.407 --> 00:01:29.603
I would like to give you:

00:01:29.627 --> 00:01:32.314
What are your intentions
if you are designing something?

00:01:32.668 --> 00:01:36.041
And obviously, intentions
are not the only thing,

00:01:36.065 --> 00:01:39.243
so here is another example
for one of these applications.

00:01:39.267 --> 00:01:42.354
There are a couple of these kinds
of Eco dashboards right now --

00:01:42.378 --> 00:01:43.838
dashboards built into cars --

00:01:43.862 --> 00:01:46.694
which try to motivate you
to drive more fuel-efficiently.

00:01:46.718 --> 00:01:48.491
This here is Nissan's MyLeaf,

00:01:48.515 --> 00:01:51.579
where your driving behavior
is compared with the driving behavior

00:01:51.603 --> 00:01:52.754
of other people,

00:01:52.778 --> 00:01:56.055
so you can compete for who drives a route
the most fuel-efficiently.

00:01:56.079 --> 00:01:58.556
And these things are
very effective, it turns out --

00:01:58.580 --> 00:02:02.519
so effective that they motivate people
to engage in unsafe driving behaviors,

00:02:02.543 --> 00:02:04.305
like not stopping at a red light,

00:02:04.329 --> 00:02:07.044
because that way you have
to stop and restart the engine,

00:02:07.068 --> 00:02:09.791
and that would use quite
some fuel, wouldn't it?

00:02:10.338 --> 00:02:14.747
So despite this being
a very well-intended application,

00:02:14.771 --> 00:02:17.146
obviously there was a side effect of that.

00:02:17.170 --> 00:02:19.718
Here's another example
for one of these side effects.

00:02:19.742 --> 00:02:24.526
Commendable: a site that allows parents
to give their kids little badges

00:02:24.550 --> 00:02:27.208
for doing the things
that parents want their kids to do,

00:02:27.232 --> 00:02:28.548
like tying their shoes.

00:02:28.572 --> 00:02:30.816
And at first that sounds very nice,

00:02:30.840 --> 00:02:32.990
very benign, well-intended.

00:02:33.014 --> 00:02:36.784
But it turns out, if you look into
research on people's mindset,

00:02:36.808 --> 00:02:38.295
caring about outcomes,

00:02:38.319 --> 00:02:40.092
caring about public recognition,

00:02:40.116 --> 00:02:43.977
caring about these kinds
of public tokens of recognition

00:02:44.001 --> 00:02:45.995
is not necessarily very helpful

00:02:46.019 --> 00:02:48.326
for your long-term
psychological well-being.

00:02:48.350 --> 00:02:51.026
It's better if you care
about learning something.

00:02:51.050 --> 00:02:52.955
It's better when you care about yourself

00:02:52.979 --> 00:02:55.553
than how you appear
in front of other people.

00:02:56.021 --> 00:03:01.062
So that kind of motivational tool
that is used actually, in and of itself,

00:03:01.086 --> 00:03:02.994
has a long-term side effect,

00:03:03.018 --> 00:03:04.828
in that every time we use a technology

00:03:04.852 --> 00:03:08.026
that uses something
like public recognition or status,

00:03:08.050 --> 00:03:10.426
we're actually positively endorsing this

00:03:10.450 --> 00:03:13.860
as a good and normal thing
to care about --

00:03:13.884 --> 00:03:16.748
that way, possibly having
a detrimental effect

00:03:16.772 --> 00:03:20.627
on the long-term psychological
well-being of ourselves as a culture.

00:03:20.651 --> 00:03:23.295
So that's a second, very obvious question:

00:03:23.319 --> 00:03:25.630
What are the effects
of what you're doing --

00:03:25.654 --> 00:03:29.778
the effects you're having
with the device, like less fuel,

00:03:29.802 --> 00:03:32.507
as well as the effects
of the actual tools you're using

00:03:32.531 --> 00:03:34.205
to get people to do things --

00:03:34.229 --> 00:03:35.800
public recognition?

00:03:35.824 --> 00:03:38.745
Now is that all -- intention, effect?

00:03:38.769 --> 00:03:41.903
Well, there are some technologies
which obviously combine both.

00:03:41.927 --> 00:03:44.714
Both good long-term and short-term effects

00:03:44.738 --> 00:03:47.547
and a positive intention
like Fred Stutzman's "Freedom,"

00:03:47.571 --> 00:03:49.778
where the whole point
of that application is --

00:03:49.802 --> 00:03:53.527
well, we're usually so bombarded
with constant requests by other people,

00:03:53.551 --> 00:03:54.707
with this device,

00:03:54.731 --> 00:03:58.211
you can shut off the Internet
connectivity of your PC of choice

00:03:58.235 --> 00:03:59.683
for a pre-set amount of time,

00:03:59.707 --> 00:04:01.678
to actually get some work done.

00:04:01.702 --> 00:04:04.853
And I think most of us will agree
that's something well-intended,

00:04:04.877 --> 00:04:07.097
and also has good consequences.

00:04:07.121 --> 00:04:08.767
In the words of Michel Foucault,

00:04:08.791 --> 00:04:10.731
it is a "technology of the self."

00:04:10.755 --> 00:04:13.592
It is a technology
that empowers the individual

00:04:13.616 --> 00:04:15.431
to determine its own life course,

00:04:15.455 --> 00:04:16.974
to shape itself.

00:04:17.410 --> 00:04:20.394
But the problem is,
as Foucault points out,

00:04:20.418 --> 00:04:22.203
that every technology of the self

00:04:22.227 --> 00:04:25.672
has a technology of domination
as its flip side.

00:04:25.696 --> 00:04:30.299
As you see in today's modern
liberal democracies,

00:04:30.323 --> 00:04:35.006
the society, the state,
not only allows us to determine our self,

00:04:35.030 --> 00:04:36.181
to shape our self,

00:04:36.205 --> 00:04:38.196
it also demands it of us.

00:04:38.220 --> 00:04:40.181
It demands that we optimize ourselves,

00:04:40.205 --> 00:04:42.045
that we control ourselves,

00:04:42.069 --> 00:04:44.780
that we self-manage continuously,

00:04:44.804 --> 00:04:48.697
because that's the only way
in which such a liberal society works.

00:04:48.721 --> 00:04:52.989
These technologies want us
to stay in the game

00:04:53.013 --> 00:04:55.786
that society has devised for us.

00:04:55.810 --> 00:04:58.097
They want us to fit in even better.

00:04:58.121 --> 00:05:00.699
They want us to optimize
ourselves to fit in.

00:05:01.628 --> 00:05:04.707
Now, I don't say that
is necessarily a bad thing;

00:05:05.293 --> 00:05:09.621
I just think that this example
points us to a general realization,

00:05:09.645 --> 00:05:13.448
and that is: no matter what technology
or design you look at,

00:05:13.472 --> 00:05:16.493
even something we consider
as well-intended

00:05:16.517 --> 00:05:19.483
and as good in its effects
as Stutzman's Freedom,

00:05:19.507 --> 00:05:22.214
comes with certain values embedded in it.

00:05:22.238 --> 00:05:24.174
And we can question these values.

00:05:24.198 --> 00:05:26.142
We can question: Is it a good thing

00:05:26.166 --> 00:05:29.650
that all of us continuously
self-optimize ourselves

00:05:29.674 --> 00:05:31.685
to fit better into that society?

00:05:31.709 --> 00:05:33.201
Or to give you another example:

00:05:33.225 --> 00:05:35.701
What about a piece
of persuasive technology

00:05:35.725 --> 00:05:38.916
that convinces Muslim women
to wear their headscarves?

00:05:38.940 --> 00:05:40.992
Is that a good or a bad technology

00:05:41.016 --> 00:05:43.579
in its intentions or in its effects?

00:05:43.603 --> 00:05:47.857
Well, that basically depends on
the kind of values you bring to bear

00:05:47.881 --> 00:05:50.118
to make these kinds of judgments.

00:05:50.142 --> 00:05:51.670
So that's a third question:

00:05:51.694 --> 00:05:53.222
What values do you use to judge?

00:05:53.848 --> 00:05:55.189
And speaking of values:

00:05:55.213 --> 00:05:58.569
I've noticed that in the discussion
about moral persuasion online

00:05:58.593 --> 00:06:00.230
and when I'm talking with people,

00:06:00.254 --> 00:06:02.921
more often than not,
there is a weird bias.

00:06:03.463 --> 00:06:06.359
And that bias is that we're asking:

00:06:06.383 --> 00:06:09.196
Is this or that "still" ethical?

00:06:09.220 --> 00:06:11.870
Is it "still" permissible?

00:06:11.894 --> 00:06:13.092
We're asking things like:

00:06:13.116 --> 00:06:15.305
Is this Oxfam donation form,

00:06:15.329 --> 00:06:18.377
where the regular monthly
donation is the preset default,

00:06:18.401 --> 00:06:20.480
and people, maybe without intending it,

00:06:20.504 --> 00:06:24.316
are encouraged or nudged
into giving a regular donation

00:06:24.340 --> 00:06:25.829
instead of a one-time donation,

00:06:25.853 --> 00:06:27.196
is that "still' permissible?

00:06:27.220 --> 00:06:28.583
Is it "still" ethical?

00:06:28.607 --> 00:06:30.086
We're fishing at the low end.

00:06:30.879 --> 00:06:33.353
But in fact, that question,
"Is it 'still' ethical?"

00:06:33.377 --> 00:06:35.158
is just one way of looking at ethics.

00:06:35.182 --> 00:06:40.074
Because if you look at the beginning
of ethics in Western culture,

00:06:40.098 --> 00:06:43.630
you see a very different idea
of what ethics also could be.

00:06:43.970 --> 00:06:47.967
For Aristotle, ethics
was not about the question,

00:06:47.991 --> 00:06:50.263
"Is that still good, or is it bad?"

00:06:50.287 --> 00:06:53.715
Ethics was about the question
of how to live life well.

00:06:54.216 --> 00:06:56.397
And he put that in the word "arÃªte,"

00:06:56.421 --> 00:06:59.176
which we, from [Ancient Greek],
translate as "virtue."

00:06:59.200 --> 00:07:00.840
But really, it means "excellence."

00:07:00.864 --> 00:07:06.295
It means living up to your own
full potential as a human being.

00:07:06.937 --> 00:07:08.593
And that is an idea that, I think,

00:07:08.617 --> 00:07:11.314
Paul Richard Buchanan
put nicely in a recent essay,

00:07:11.338 --> 00:07:13.481
where he said,
"Products are vivid arguments

00:07:13.505 --> 00:07:15.628
about how we should live our lives."

00:07:16.086 --> 00:07:18.663
Our designs are not ethical or unethical

00:07:18.687 --> 00:07:23.277
in that they're using ethical
or unethical means of persuading us.

00:07:23.661 --> 00:07:25.231
They have a moral component

00:07:25.255 --> 00:07:29.482
just in the kind of vision
and the aspiration of the good life

00:07:29.506 --> 00:07:30.854
that they present to us.

00:07:31.441 --> 00:07:34.944
And if you look into the designed
environment around us

00:07:34.968 --> 00:07:36.140
with that kind of lens,

00:07:36.164 --> 00:07:38.617
asking, "What is the vision
of the good life

00:07:38.641 --> 00:07:41.379
that our products, our design,
present to us?",

00:07:41.403 --> 00:07:43.679
then you often get the shivers,

00:07:43.703 --> 00:07:46.031
because of how little
we expect of each other,

00:07:46.055 --> 00:07:49.945
of how little we actually
seem to expect of our life,

00:07:49.969 --> 00:07:52.003
and what the good life looks like.

00:07:53.110 --> 00:07:56.133
So that's a fourth question
I'd like to leave you with:

00:07:56.157 --> 00:08:00.519
What vision of the good life
do your designs convey?

00:08:01.249 --> 00:08:02.621
And speaking of design,

00:08:02.645 --> 00:08:06.835
you'll notice that I already
broadened the discussion,

00:08:06.859 --> 00:08:11.303
because it's not just persuasive
technology that we're talking about here,

00:08:11.327 --> 00:08:15.404
it's any piece of design
that we put out here in the world.

00:08:15.428 --> 00:08:16.828
I don't know whether you know

00:08:16.852 --> 00:08:20.407
the great communication researcher
Paul Watzlawick who, back in the '60s,

00:08:20.431 --> 00:08:22.942
made the argument
that we cannot not communicate.

00:08:22.966 --> 00:08:25.567
Even if we choose to be silent,
we chose to be silent,

00:08:25.591 --> 00:08:28.547
and we're communicating something
by choosing to be silent.

00:08:28.571 --> 00:08:31.306
And in the same way
that we cannot not communicate,

00:08:31.330 --> 00:08:32.861
we cannot not persuade:

00:08:32.885 --> 00:08:34.896
whatever we do or refrain from doing,

00:08:34.920 --> 00:08:39.285
whatever we put out there
as a piece of design, into the world,

00:08:39.309 --> 00:08:41.356
has a persuasive component.

00:08:41.380 --> 00:08:43.253
It tries to affect people.

00:08:43.277 --> 00:08:47.024
It puts a certain vision of the good life
out there in front of us,

00:08:47.048 --> 00:08:48.673
which is what Peter-Paul Verbeek,

00:08:48.697 --> 00:08:51.413
the Dutch philosopher of technology, says.

00:08:51.437 --> 00:08:55.385
No matter whether we as designers
intend it or not,

00:08:55.409 --> 00:08:57.551
we materialize morality.

00:08:57.575 --> 00:09:00.378
We make certain things
harder and easier to do.

00:09:00.402 --> 00:09:02.613
We organize the existence of people.

00:09:02.637 --> 00:09:03.788
We put a certain vision

00:09:03.812 --> 00:09:07.216
of what good or bad or normal or usual is

00:09:07.240 --> 00:09:08.391
in front of people,

00:09:08.415 --> 00:09:10.815
by everything we put
out there in the world.

00:09:11.247 --> 00:09:14.333
Even something as innocuous
as a set of school chairs

00:09:14.357 --> 00:09:16.404
is a persuasive technology,

00:09:16.428 --> 00:09:21.118
because it presents and materializes
a certain vision of the good life --

00:09:21.142 --> 00:09:23.999
a good life in which teaching
and learning and listening

00:09:24.023 --> 00:09:27.122
is about one person teaching,
the others listening;

00:09:27.146 --> 00:09:31.199
in which it is about
learning-is-done-while-sitting;

00:09:31.223 --> 00:09:32.818
in which you learn for yourself;

00:09:32.842 --> 00:09:35.262
in which you're not supposed
to change these rules,

00:09:35.286 --> 00:09:37.733
because the chairs
are fixed to the ground.

00:09:38.888 --> 00:09:41.799
And even something as innocuous
as a single-design chair,

00:09:41.823 --> 00:09:43.395
like this one by Arne Jacobsen,

00:09:43.419 --> 00:09:45.195
is a persuasive technology,

00:09:45.219 --> 00:09:48.262
because, again, it communicates
an idea of the good life:

00:09:48.735 --> 00:09:53.660
a good life -- a life that you,
as a designer, consent to by saying,

00:09:53.684 --> 00:09:57.191
"In a good life, goods are produced
as sustainably or unsustainably

00:09:57.215 --> 00:09:58.826
as this chair.

00:09:58.850 --> 00:10:00.827
Workers are treated as well or as badly

00:10:00.851 --> 00:10:03.423
as the workers were treated
that built that chair."

00:10:03.762 --> 00:10:06.063
The good life is a life
where design is important

00:10:06.087 --> 00:10:09.008
because somebody obviously took
the time and spent the money

00:10:09.032 --> 00:10:10.816
for that kind of well-designed chair;

00:10:10.840 --> 00:10:12.244
where tradition is important,

00:10:12.268 --> 00:10:15.434
because this is a traditional classic
and someone cared about this;

00:10:15.458 --> 00:10:18.148
and where there is something
as conspicuous consumption,

00:10:18.172 --> 00:10:21.128
where it is OK and normal to spend
a humongous amount of money

00:10:21.152 --> 00:10:22.303
on such a chair,

00:10:22.327 --> 00:10:24.900
to signal to other people
what your social status is.

00:10:24.924 --> 00:10:28.241
So these are the kinds of layers,
the kinds of questions

00:10:28.265 --> 00:10:30.235
I wanted to lead you through today;

00:10:30.259 --> 00:10:33.293
the question of: What are the intentions
that you bring to bear

00:10:33.317 --> 00:10:34.877
when you're designing something?

00:10:34.901 --> 00:10:38.153
What are the effects, intended
and unintended, that you're having?

00:10:38.177 --> 00:10:40.978
What are the values
you're using to judge those?

00:10:41.002 --> 00:10:42.975
What are the virtues, the aspirations

00:10:42.999 --> 00:10:45.027
that you're actually expressing in that?

00:10:45.400 --> 00:10:47.257
And how does that apply,

00:10:47.281 --> 00:10:49.267
not just to persuasive technology,

00:10:49.291 --> 00:10:51.339
but to everything you design?

00:10:51.912 --> 00:10:53.203
Do we stop there?

00:10:53.815 --> 00:10:54.982
I don't think so.

00:10:55.291 --> 00:10:59.729
I think that all of these things
are eventually informed

00:10:59.753 --> 00:11:01.176
by the core of all of this,

00:11:01.200 --> 00:11:04.291
and this is nothing but life itself.

00:11:04.594 --> 00:11:07.311
Why, when the question
of what the good life is

00:11:07.335 --> 00:11:09.674
informs everything that we design,

00:11:09.698 --> 00:11:12.492
should we stop at design
and not ask ourselves:

00:11:12.516 --> 00:11:14.506
How does it apply to our own life?

00:11:14.881 --> 00:11:17.593
"Why should the lamp
or the house be an art object,

00:11:17.617 --> 00:11:18.793
but not our life?"

00:11:18.817 --> 00:11:20.300
as Michel Foucault puts it.

00:11:20.696 --> 00:11:24.307
Just to give you a practical
example of Buster Benson.

00:11:24.331 --> 00:11:26.589
This is Buster setting up
a pull-up machine

00:11:26.613 --> 00:11:29.225
at the office of his new
start-up, Habit Labs,

00:11:29.249 --> 00:11:32.464
where they're trying to build
other applications like "Health Month"

00:11:32.488 --> 00:11:33.646
for people.

00:11:33.670 --> 00:11:35.632
And why is he building a thing like this?

00:11:35.656 --> 00:11:37.689
Well, here is the set of axioms

00:11:37.713 --> 00:11:41.111
that Habit Labs, Buster's start-up,
put up for themselves

00:11:41.135 --> 00:11:43.840
on how they wanted to work
together as a team

00:11:43.864 --> 00:11:45.893
when they're building
these applications --

00:11:45.917 --> 00:11:48.106
a set of moral principles
they set themselves

00:11:48.130 --> 00:11:49.491
for working together --

00:11:49.515 --> 00:11:50.753
one of them being,

00:11:50.777 --> 00:11:53.864
"We take care of our own health
and manage our own burnout."

00:11:54.221 --> 00:11:57.721
Because ultimately,
how can you ask yourselves

00:11:57.745 --> 00:12:01.675
and how can you find an answer
on what vision of the good life

00:12:01.699 --> 00:12:04.868
you want to convey and create
with your designs

00:12:04.892 --> 00:12:06.622
without asking the question:

00:12:06.646 --> 00:12:10.478
What vision of the good life
do you yourself want to live?

00:12:11.018 --> 00:12:12.192
And with that,

00:12:12.945 --> 00:12:14.357
I thank you.

00:12:14.381 --> 00:12:18.537
(Applause)

