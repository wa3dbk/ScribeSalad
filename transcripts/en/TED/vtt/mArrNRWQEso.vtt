WEBVTT
Kind: captions
Language: en

00:00:13.381 --> 00:00:17.007
Charlie Rose: So Larry sent me an email

00:00:17.007 --> 00:00:18.994
and he basically said,

00:00:18.994 --> 00:00:22.723
we've got to make sure that 
we don't seem like we're

00:00:22.723 --> 00:00:27.214
a couple of middle-aged boring men.

00:00:27.214 --> 00:00:30.256
I said, I'm flattered by that --

00:00:30.256 --> 00:00:32.628
(Laughter) —

00:00:32.628 --> 00:00:36.143
because I'm a bit older,

00:00:36.143 --> 00:00:40.294
and he has a bit more net worth than I do.

00:00:40.294 --> 00:00:42.893
Larry Page: Well, thank you.

00:00:42.893 --> 00:00:45.873
CR: So we'll have a conversation about

00:00:45.873 --> 00:00:48.571
the Internet, and we'll have a conversation Google,

00:00:48.571 --> 00:00:50.005
and we'll have a conversation about search

00:00:50.005 --> 00:00:51.372
and privacy,

00:00:51.372 --> 00:00:52.927
and also about your philosophy

00:00:52.927 --> 00:00:55.383
and a sense of how you've connected the dots

00:00:55.383 --> 00:00:57.474
and how this journey that began

00:00:57.474 --> 00:00:58.758
some time ago

00:00:58.758 --> 00:01:00.653
has such interesting prospects.

00:01:00.653 --> 00:01:03.249
Mainly we want to talk about the future.

00:01:03.249 --> 00:01:04.838
So my first question: Where is Google

00:01:04.838 --> 00:01:06.884
and where is it going?

00:01:06.884 --> 00:01:08.343
LP: Well, this is something we think about a lot,

00:01:08.343 --> 00:01:11.918
and our mission we defined a long time ago

00:01:11.918 --> 00:01:14.181
is to organize the world's information

00:01:14.181 --> 00:01:17.619
and make it universally accessible and useful.

00:01:17.619 --> 00:01:19.661
And people always say,

00:01:19.661 --> 00:01:21.876
is that really what you guys are still doing?

00:01:21.876 --> 00:01:23.994
And I always kind of think about that myself,

00:01:23.994 --> 00:01:26.190
and I'm not quite sure.

00:01:26.190 --> 00:01:30.197
But actually, when I think about search,

00:01:30.197 --> 00:01:32.813
it's such a deep thing for all of us,

00:01:32.813 --> 00:01:35.056
to really understand what you want,

00:01:35.056 --> 00:01:37.424
to understand the world's information,

00:01:37.424 --> 00:01:40.956
and we're still very much in the early stages of that,

00:01:40.956 --> 00:01:42.769
which is totally crazy.

00:01:42.769 --> 00:01:45.287
We've been at it for 15 years already,

00:01:45.287 --> 00:01:48.862
but it's not at all done.

00:01:48.862 --> 00:01:51.538
CR: When it's done, how will it be?

00:01:51.538 --> 00:01:54.255
LP: Well, I guess,

00:01:54.255 --> 00:01:56.655
in thinking about where we're going --

00:01:56.655 --> 00:01:58.942
you know, why is it not done? --

00:01:58.942 --> 00:02:01.378
a lot of it is just computing's kind of a mess.

00:02:01.378 --> 00:02:03.181
You know, your computer
doesn't know where you are,

00:02:03.181 --> 00:02:05.216
it doesn't know what you're doing,

00:02:05.216 --> 00:02:06.898
it doesn't know what you know,

00:02:06.898 --> 00:02:09.474
and a lot we've been trying to do recently

00:02:09.474 --> 00:02:12.769
is just make your devices work,

00:02:12.769 --> 00:02:15.110
make them understand your context.

00:02:15.110 --> 00:02:17.113
Google Now, you know, knows where you are,

00:02:17.113 --> 00:02:19.295
knows what you may need.

00:02:19.295 --> 00:02:23.403
So really having computing 
work and understand you

00:02:23.403 --> 00:02:25.459
and understand that information,

00:02:25.459 --> 00:02:27.769
we really haven't done that yet.

00:02:27.769 --> 00:02:29.318
It's still very, very clunky.

00:02:29.318 --> 00:02:31.684
CR: Tell me, when you look at what Google is doing,

00:02:31.684 --> 00:02:34.653
where does Deep Mind fit?

00:02:34.653 --> 00:02:36.237
LP: Yeah, so Deep Mind is a company

00:02:36.237 --> 00:02:38.768
we just acquired recently.

00:02:38.768 --> 00:02:41.850
It's in the U.K.

00:02:41.850 --> 00:02:44.504
First, let me tell you the way we got there,

00:02:44.504 --> 00:02:46.732
which was looking at search

00:02:46.732 --> 00:02:48.355
and really understanding,

00:02:48.355 --> 00:02:50.588
trying to understand everything,

00:02:50.588 --> 00:02:52.193
and also make the computers not clunky

00:02:52.193 --> 00:02:54.394
and really understand you --

00:02:54.394 --> 00:02:56.506
like, voice was really important.

00:02:56.506 --> 00:02:59.367
So what's the state of the art 
on speech recognition?

00:02:59.367 --> 00:03:01.027
It's not very good.

00:03:01.027 --> 00:03:03.093
It doesn't really understand you.

00:03:03.093 --> 00:03:05.096
So we started doing machine learning research

00:03:05.096 --> 00:03:06.633
to improve that.

00:03:06.633 --> 00:03:08.336
That helped a lot.

00:03:08.336 --> 00:03:10.703
And we started just looking at things like YouTube.

00:03:10.703 --> 00:03:12.671
Can we understand YouTube?

00:03:12.671 --> 00:03:15.357
But we actually ran machine learning on YouTube

00:03:15.357 --> 00:03:19.442
and it discovered cats, just by itself.

00:03:19.442 --> 00:03:21.533
Now, that's an important concept.

00:03:21.533 --> 00:03:24.524
And we realized there's really something here.

00:03:24.524 --> 00:03:26.641
If we can learn what cats are,

00:03:26.641 --> 00:03:28.716
that must be really important.

00:03:28.716 --> 00:03:31.345
So I think Deep Mind,

00:03:31.345 --> 00:03:33.709
what's really amazing about Deep Mind

00:03:33.709 --> 00:03:35.713
is that it can actually --

00:03:35.713 --> 00:03:39.270
they're learning things in this unsupervised way.

00:03:39.270 --> 00:03:41.837
They started with video games,

00:03:41.837 --> 00:03:44.330
and really just, maybe I can show the video,

00:03:44.330 --> 00:03:46.534
just playing video games,

00:03:46.534 --> 00:03:48.549
and learning how to do that automatically.

00:03:48.549 --> 00:03:50.401
CR: Take a look at the video games

00:03:50.401 --> 00:03:52.811
and how machines are coming to be able

00:03:52.811 --> 00:03:55.267
to do some remarkable things.

00:03:55.267 --> 00:03:56.596
LP: The amazing thing about this

00:03:56.596 --> 00:03:58.276
is this is, I mean, obviously,

00:03:58.276 --> 00:03:59.750
these are old games,

00:03:59.750 --> 00:04:04.548
but the system just sees what you see, the pixels,

00:04:04.548 --> 00:04:06.979
and it has the controls and it has the score,

00:04:06.979 --> 00:04:09.190
and it's learned to play all of these games,

00:04:09.190 --> 00:04:10.769
same program.

00:04:10.769 --> 00:04:12.806
It's learned to play all of these games

00:04:12.806 --> 00:04:14.592
with superhuman performance.

00:04:14.592 --> 00:04:16.447
We've not been able to do things like this

00:04:16.447 --> 00:04:17.965
with computers before.

00:04:17.965 --> 00:04:20.260
And maybe I'll just narrate this one quickly.

00:04:20.260 --> 00:04:23.065
This is boxing, and it figures out it can

00:04:23.065 --> 00:04:25.699
sort of pin the opponent down.

00:04:25.699 --> 00:04:27.438
The computer's on the left,

00:04:27.438 --> 00:04:30.523
and it's just racking up points.

00:04:30.523 --> 00:04:32.609
So imagine if this kind

00:04:32.609 --> 00:04:34.736
of intelligence were thrown at your schedule,

00:04:34.736 --> 00:04:39.373
or your information needs, or things like that.

00:04:39.373 --> 00:04:41.991
We're really just at the beginning of that,

00:04:41.991 --> 00:04:44.356
and that's what I'm really excited about.

00:04:44.356 --> 00:04:46.826
CR: When you look at all that's taken place

00:04:46.826 --> 00:04:49.410
with Deep Mind and the boxing,

00:04:49.410 --> 00:04:51.750
also a part of where we're going

00:04:51.750 --> 00:04:54.639
is artificial intelligence.

00:04:54.639 --> 00:04:57.438
Where are we, when you look at that?

00:04:57.438 --> 00:04:59.223
LP: Well, I think for me,

00:04:59.223 --> 00:05:00.726
this is kind of one of the most exciting things

00:05:00.726 --> 00:05:02.638
I've seen in a long time.

00:05:02.638 --> 00:05:05.051
The guy who started this company, Demis,

00:05:05.051 --> 00:05:07.829
has a neuroscience and a
computer science background.

00:05:07.829 --> 00:05:09.459
He went back to school

00:05:09.459 --> 00:05:12.585
to get his Ph.D. to study the brain.

00:05:12.585 --> 00:05:15.205
And so I think we're seeing a lot of exciting work

00:05:15.205 --> 00:05:18.286
going on that sort of crosses computer science

00:05:18.286 --> 00:05:20.036
and neuroscience

00:05:20.036 --> 00:05:22.361
in terms of really understanding

00:05:22.361 --> 00:05:24.815
what it takes to make something smart

00:05:24.815 --> 00:05:26.530
and do really interesting things.

00:05:26.530 --> 00:05:28.668
CR: But where's the level of it now?

00:05:28.668 --> 00:05:31.374
And how fast do you think we are moving?

00:05:31.374 --> 00:05:34.643
LP: Well, this is the state of the art right now,

00:05:34.643 --> 00:05:36.774
understanding cats on YouTube

00:05:36.774 --> 00:05:38.057
and things like that,

00:05:38.057 --> 00:05:40.204
improving voice recognition.

00:05:40.204 --> 00:05:42.622
We used a lot of machine learning

00:05:42.622 --> 00:05:45.101
to improve things incrementally,

00:05:45.101 --> 00:05:48.495
but I think for me, this example's really exciting,

00:05:48.495 --> 00:05:50.738
because it's one program

00:05:50.738 --> 00:05:52.782
that can do a lot of different things.

00:05:52.782 --> 00:05:53.920
CR: I don't know if we can do this,

00:05:53.920 --> 00:05:55.105
but we've got the image of the cat.

00:05:55.105 --> 00:05:56.859
It would be wonderful to see this.

00:05:56.859 --> 00:05:59.368
This is how machines looked at cats

00:05:59.368 --> 00:06:00.483
and what they came up with.

00:06:00.483 --> 00:06:01.538
Can we see that image?

00:06:01.538 --> 00:06:03.940
LP: Yeah.
CR: There it is. Can you see the cat?

00:06:03.940 --> 00:06:05.967
Designed by machines, seen by machines.

00:06:05.967 --> 00:06:07.077
LP: That's right.

00:06:07.077 --> 00:06:09.684
So this is learned from just watching YouTube.

00:06:09.684 --> 00:06:11.551
And there's no training,

00:06:11.551 --> 00:06:12.935
no notion of a cat,

00:06:12.935 --> 00:06:15.496
but this concept of a cat

00:06:15.496 --> 00:06:18.304
is something important that you would understand,

00:06:18.304 --> 00:06:20.827
and now that the machines can kind of understand.

00:06:20.827 --> 00:06:21.999
Maybe just finishing

00:06:21.999 --> 00:06:24.221
also on the search part,

00:06:24.221 --> 00:06:27.007
it started with search, really understanding

00:06:27.007 --> 00:06:29.571
people's context and their information.

00:06:29.571 --> 00:06:31.431
I did have a video

00:06:31.431 --> 00:06:33.441
I wanted to show quickly on that

00:06:33.441 --> 00:06:35.088
that we actually found.

00:06:35.088 --> 00:06:40.200
(Video) ["Soy, Kenya"]

00:06:40.580 --> 00:06:42.452
Zack Matere: Not long ago,

00:06:42.452 --> 00:06:45.038
I planted a crop of potatoes.

00:06:45.038 --> 00:06:48.438
Then suddenly they started
dying one after the other.

00:06:48.438 --> 00:06:51.188
I checked out the books and 
they didn't tell me much.

00:06:51.188 --> 00:06:53.134
So, I went and I did a search.

00:06:53.134 --> 00:06:56.253
["Zack Matere, Farmer"]

00:06:57.609 --> 00:07:00.756
Potato diseases.

00:07:00.756 --> 00:07:02.484
One of the websites told me

00:07:02.484 --> 00:07:04.386
that ants could be the problem.

00:07:04.386 --> 00:07:06.657
It said, sprinkle wood ash over the plants.

00:07:06.657 --> 00:07:08.941
Then after a few days the ants disappeared.

00:07:08.941 --> 00:07:11.535
I got excited about the Internet.

00:07:11.535 --> 00:07:13.200
I have this friend

00:07:13.200 --> 00:07:16.818
who really would like to expand his business.

00:07:16.818 --> 00:07:20.013
So I went with him to the cyber cafe

00:07:20.013 --> 00:07:22.554
and we checked out several sites.

00:07:22.554 --> 00:07:25.095
When I met him next, he was going to put a windmill

00:07:25.095 --> 00:07:27.789
at the local school.

00:07:27.789 --> 00:07:29.393
I felt proud because

00:07:29.393 --> 00:07:31.421
something that wasn't there before

00:07:31.421 --> 00:07:33.308
was suddenly there.

00:07:33.308 --> 00:07:35.998
I realized that not everybody

00:07:35.998 --> 00:07:37.532
can be able to access

00:07:37.532 --> 00:07:39.018
what I was able to access.

00:07:39.018 --> 00:07:40.856
I thought that I need to have an Internet

00:07:40.856 --> 00:07:42.657
that my grandmother can use.

00:07:42.657 --> 00:07:45.114
So I thought about a notice board.

00:07:45.114 --> 00:07:47.030
A simple wooden notice board.

00:07:47.030 --> 00:07:49.345
When I get information on my phone,

00:07:49.345 --> 00:07:51.582
I'm able to post the information

00:07:51.582 --> 00:07:53.304
on the notice board.

00:07:53.304 --> 00:07:56.162
So it's basically like a computer.

00:07:56.162 --> 00:08:00.051
I use the Internet to help people.

00:08:00.051 --> 00:08:03.461
I think I am searching for

00:08:03.461 --> 00:08:05.002
a better life

00:08:05.002 --> 00:08:09.116
for me and my neighbors.

00:08:09.116 --> 00:08:13.100
So many people have access to information,

00:08:13.100 --> 00:08:15.681
but there's no follow-up to that.

00:08:15.681 --> 00:08:18.189
I think the follow-up to that is our knowledge.

00:08:18.189 --> 00:08:19.795
When people have the knowledge,

00:08:19.795 --> 00:08:21.425
they can find solutions

00:08:21.425 --> 00:08:23.409
without having to helped out.

00:08:23.440 --> 00:08:25.561
Information is powerful,

00:08:25.561 --> 00:08:30.163
but it is how we use it that will define us.

00:08:30.163 --> 00:08:34.544
(Applause)

00:08:34.544 --> 00:08:37.090
LP: Now, the amazing thing about that video,

00:08:37.090 --> 00:08:38.556
actually, was we just read about it in the news,

00:08:38.556 --> 00:08:41.061
and we found this gentlemen,

00:08:41.061 --> 00:08:43.376
and made that little clip.

00:08:43.376 --> 00:08:44.767
CR: When I talk to people about you,

00:08:44.767 --> 00:08:47.372
they say to me, people who know you well, say,

00:08:47.372 --> 00:08:49.263
Larry wants to change the world,

00:08:49.263 --> 00:08:53.375
and he believes technology can show the way.

00:08:53.375 --> 00:08:55.233
And that means access to the Internet.

00:08:55.233 --> 00:08:56.964
It has to do with languages.

00:08:56.964 --> 00:08:59.793
It also means how people can get access

00:08:59.793 --> 00:09:02.499
and do things that will affect their community,

00:09:02.499 --> 00:09:04.992
and this is an example.

00:09:04.992 --> 00:09:08.568
LP: Yeah, that's right, and I think for me,

00:09:08.568 --> 00:09:10.950
I have been focusing on access more,

00:09:10.950 --> 00:09:13.148
if we're talking about the future.

00:09:13.148 --> 00:09:15.822
We recently released this Loon Project

00:09:15.822 --> 00:09:18.122
which is using balloons to do it.

00:09:18.122 --> 00:09:19.782
It sounds totally crazy.

00:09:19.782 --> 00:09:22.321
We can show the video here.

00:09:22.321 --> 00:09:23.801
Actually, two out of three people in the world

00:09:23.801 --> 00:09:26.187
don't have good Internet access now.

00:09:26.187 --> 00:09:29.093
We actually think this can really help people

00:09:29.093 --> 00:09:31.150
sort of cost-efficiently.

00:09:31.150 --> 00:09:34.521
CR: It's a balloon.
LP: Yeah, get access to the Internet.

00:09:34.521 --> 00:09:36.664
CR: And why does this balloon give you access

00:09:36.664 --> 00:09:37.877
to the Internet?

00:09:37.877 --> 00:09:39.092
Because there was some interesting things

00:09:39.092 --> 00:09:40.926
you had to do to figure out how

00:09:40.926 --> 00:09:43.057
to make balloons possible,

00:09:43.057 --> 00:09:44.806
they didn't have to be tethered.

00:09:44.806 --> 00:09:46.887
LP: Yeah, and this is a good example of innovation.

00:09:46.887 --> 00:09:49.431
Like, we've been thinking about this idea

00:09:49.431 --> 00:09:51.203
for five years or more

00:09:51.203 --> 00:09:52.804
before we started working on it,

00:09:52.804 --> 00:09:54.123
but it was just really,

00:09:54.123 --> 00:09:57.643
how do we get access points up high, cheaply?

00:09:57.643 --> 00:09:59.435
You normally have to use satellites

00:09:59.435 --> 00:10:02.374
and it takes a long time to launch them.

00:10:02.374 --> 00:10:04.868
But you saw there how easy it is to launch a balloon

00:10:04.868 --> 00:10:06.387
and get it up,

00:10:06.387 --> 00:10:08.388
and actually again, it's the power of the Internet,

00:10:08.388 --> 00:10:10.168
I did a search on it,

00:10:10.168 --> 00:10:12.472
and I found, 30, 40 years ago,

00:10:12.472 --> 00:10:14.361
someone had put up a balloon

00:10:14.361 --> 00:10:17.166
and it had gone around the Earth multiple times.

00:10:17.166 --> 00:10:20.001
And I thought, why can't we do that today?

00:10:20.001 --> 00:10:22.368
And that's how this project got going.

00:10:22.368 --> 00:10:24.698
CR: But are you at the mercy of the wind?

00:10:24.698 --> 00:10:26.820
LP: Yeah, but it turns out,

00:10:26.820 --> 00:10:28.313
we did some weather simulations

00:10:28.313 --> 00:10:30.860
which probably hadn't really been done before,

00:10:30.860 --> 00:10:32.970
and if you control the altitude of the balloons,

00:10:32.970 --> 00:10:35.251
which you can do by pumping air into them

00:10:35.251 --> 00:10:37.073
and other ways,

00:10:37.073 --> 00:10:40.002
you can actually control roughly where they go,

00:10:40.002 --> 00:10:42.207
and so I think we can build a worldwide mesh

00:10:42.207 --> 00:10:45.546
of these balloons that can cover the whole planet.

00:10:45.546 --> 00:10:47.788
CR: Before I talk about the future and transportation,

00:10:47.788 --> 00:10:49.683
where you've been a nerd for a while,

00:10:49.683 --> 00:10:52.107
and this fascination you have with transportation

00:10:52.107 --> 00:10:54.170
and automated cars and bicycles,

00:10:54.170 --> 00:10:55.907
let me talk a bit about what's been the subject here

00:10:55.907 --> 00:10:58.350
earlier with Edward Snowden.

00:10:58.350 --> 00:11:01.456
It is security and privacy.

00:11:01.456 --> 00:11:03.796
You have to have been thinking about that.

00:11:03.796 --> 00:11:05.150
LP: Yeah, absolutely.

00:11:05.150 --> 00:11:07.993
I saw the picture of Sergey with
Edward Snowden yesterday.

00:11:07.993 --> 00:11:10.863
Some of you may have seen it.

00:11:10.863 --> 00:11:14.034
But I think, for me, I guess,

00:11:14.034 --> 00:11:17.696
privacy and security are a really important thing.

00:11:17.696 --> 00:11:19.941
We think about it in terms of both things,

00:11:19.941 --> 00:11:22.844
and I think you can't have privacy without security,

00:11:22.844 --> 00:11:25.215
so let me just talk about security first,

00:11:25.215 --> 00:11:27.811
because you asked about Snowden and all of that,

00:11:27.811 --> 00:11:30.252
and then I'll say a little bit about privacy.

00:11:30.252 --> 00:11:34.052
I think for me, it's tremendously disappointing

00:11:34.052 --> 00:11:35.491
that the government

00:11:35.491 --> 00:11:37.821
secretly did all this stuff and didn't tell us.

00:11:37.821 --> 00:11:41.124
I don't think we can have a democracy

00:11:41.124 --> 00:11:44.554
if we're having to protect you and our users

00:11:44.554 --> 00:11:46.250
from the government

00:11:46.250 --> 00:11:49.053
for stuff that we've never had a conversation about.

00:11:49.053 --> 00:11:50.949
And I don't mean we have to know

00:11:50.949 --> 00:11:52.644
what the particular terrorist attack is they're worried

00:11:52.644 --> 00:11:54.406
about protecting us from,

00:11:54.406 --> 00:11:56.204
but we do need to know

00:11:56.204 --> 00:11:58.614
what the parameters of it is,

00:11:58.614 --> 00:12:00.658
what kind of surveillance the government's

00:12:00.658 --> 00:12:02.826
going to do and how and why,

00:12:02.826 --> 00:12:05.103
and I think we haven't had that conversation.

00:12:05.103 --> 00:12:07.670
So I think the government's actually done

00:12:07.670 --> 00:12:09.838
itself a tremendous disservice

00:12:09.838 --> 00:12:11.999
by doing all that in secret.

00:12:11.999 --> 00:12:13.614
CR: Never coming to Google

00:12:13.614 --> 00:12:15.139
to ask for anything.

00:12:15.139 --> 00:12:17.169
LP: Not Google, but the public.

00:12:17.169 --> 00:12:20.942
I think we need to 
have a debate about that,

00:12:20.942 --> 00:12:23.441
or we can't have a functioning democracy.

00:12:23.441 --> 00:12:24.847
It's just not possible.

00:12:24.847 --> 00:12:27.091
So I'm sad that Google's

00:12:27.091 --> 00:12:29.707
in the position of protecting you and our users

00:12:29.707 --> 00:12:31.241
from the government

00:12:31.241 --> 00:12:33.485
doing secret thing that nobody knows about.

00:12:33.485 --> 00:12:35.232
It doesn't make any sense.

00:12:35.232 --> 00:12:38.222
CR: Yeah. And then there's a privacy side of it.

00:12:38.222 --> 00:12:40.649
LP: Yes. The privacy side,

00:12:40.649 --> 00:12:42.618
I think it's -- the world is changing.

00:12:42.618 --> 00:12:46.523
You carry a phone. It knows where you are.

00:12:46.523 --> 00:12:49.608
There's so much more information about you,

00:12:49.608 --> 00:12:52.454
and that's an important thing,

00:12:52.454 --> 00:12:54.726
and it makes sense why people are asking

00:12:54.726 --> 00:12:56.762
difficult questions.

00:12:56.762 --> 00:13:00.129
We spend a lot of time thinking about this

00:13:00.129 --> 00:13:02.840
and what the issues are.

00:13:02.840 --> 00:13:04.569
I'm a little bit --

00:13:04.569 --> 00:13:05.829
I think the main thing that we need to do

00:13:05.829 --> 00:13:08.191
is just provide people choice,

00:13:08.191 --> 00:13:10.703
show them what data's being collected --

00:13:10.703 --> 00:13:15.454
search history, location data.

00:13:15.454 --> 00:13:18.226
We're excited about incognito mode in Chrome,

00:13:18.226 --> 00:13:20.475
and doing that in more ways,

00:13:20.475 --> 00:13:21.871
just giving people more choice

00:13:21.871 --> 00:13:25.164
and more awareness of what's going on.

00:13:25.164 --> 00:13:27.557
I also think it's very easy.

00:13:27.557 --> 00:13:28.834
What I'm worried is that we throw out

00:13:28.834 --> 00:13:30.924
the baby with the bathwater.

00:13:30.924 --> 00:13:33.838
And I look at, on your show, actually,

00:13:33.838 --> 00:13:35.557
I kind of lost my voice,

00:13:35.557 --> 00:13:36.888
and I haven't gotten it back.

00:13:36.888 --> 00:13:38.532
I'm hoping that by talking to you

00:13:38.532 --> 00:13:40.185
I'm going to get it back.

00:13:40.185 --> 00:13:41.917
CR: If I could do anything, I would do that.

00:13:41.917 --> 00:13:44.097
LP: All right. So get out your voodoo doll

00:13:44.097 --> 00:13:46.516
and whatever you need to do.

00:13:46.516 --> 00:13:48.844
But I think, you know what, I look at that,

00:13:48.844 --> 00:13:50.674
I made that public,

00:13:50.674 --> 00:13:51.891
and I got all this information.

00:13:51.891 --> 00:13:54.620
We got a survey done on medical conditions

00:13:54.620 --> 00:13:57.991
with people who have similar issues,

00:13:57.991 --> 00:14:02.732
and I look at medical records, and I say,

00:14:02.732 --> 00:14:04.137
wouldn't it be amazing

00:14:04.137 --> 00:14:06.187
if everyone's medical records were available

00:14:06.187 --> 00:14:07.870
anonymously

00:14:07.870 --> 00:14:10.506
to research doctors?

00:14:10.506 --> 00:14:13.547
And when someone accesses your medical record,

00:14:13.547 --> 00:14:15.156
a research doctor,

00:14:15.156 --> 00:14:17.790
they could see, you could see which doctor

00:14:17.790 --> 00:14:19.650
accessed it and why,

00:14:19.650 --> 00:14:21.230
and you could maybe learn about

00:14:21.230 --> 00:14:22.860
what conditions you have.

00:14:22.860 --> 00:14:24.362
I think if we just did that,

00:14:24.362 --> 00:14:26.527
we'd save 100,000 lives this year.

00:14:26.527 --> 00:14:29.475
CR: Absolutely. Let me go — (Applause)

00:14:29.475 --> 00:14:32.237
LP: So I guess I'm just very worried that

00:14:32.237 --> 00:14:34.043
with Internet privacy,

00:14:34.043 --> 00:14:36.343
we're doing the same thing we're 
doing with medical records,

00:14:36.347 --> 00:14:38.876
is we're throwing out the baby with the bathwater,

00:14:38.876 --> 00:14:40.704
and we're not really thinking

00:14:40.704 --> 00:14:42.914
about the tremendous good that can come

00:14:42.914 --> 00:14:45.105
from people sharing information

00:14:45.105 --> 00:14:47.682
with the right people in the right ways.

00:14:47.682 --> 00:14:49.919
CR: And the necessary condition

00:14:49.919 --> 00:14:51.621
that people have to have confidence

00:14:51.621 --> 00:14:54.076
that their information will not be abused.

00:14:54.076 --> 00:14:55.853
LP: Yeah, and I had this problem with my voice stuff.

00:14:55.853 --> 00:14:57.361
I was scared to share it.

00:14:57.361 --> 00:14:59.251
Sergey encouraged me to do that,

00:14:59.251 --> 00:15:01.078
and it was a great thing to do.

00:15:01.078 --> 00:15:02.812
CR: And the response has been overwhelming.

00:15:02.812 --> 00:15:04.472
LP: Yeah, and people are super positive.

00:15:04.472 --> 00:15:07.305
We got thousands and thousands of people

00:15:07.305 --> 00:15:08.593
with similar conditions,

00:15:08.593 --> 00:15:11.621
which there's no data on today.

00:15:11.621 --> 00:15:12.977
So it was a really good thing.

00:15:12.977 --> 00:15:15.996
CR: So talking about the future, what is it about you

00:15:15.996 --> 00:15:19.754
and transportation systems?

00:15:19.754 --> 00:15:21.931
LP: Yeah. I guess I was just frustrated

00:15:21.931 --> 00:15:24.470
with this when I was at college in Michigan.

00:15:24.470 --> 00:15:25.920
I had to get on the bus and take it

00:15:25.920 --> 00:15:27.562
and wait for it.

00:15:27.562 --> 00:15:29.741
And it was cold and snowing.

00:15:29.741 --> 00:15:32.396
I did some research on how much it cost,

00:15:32.396 --> 00:15:38.821
and I just became a bit obsessed
with transportation systems.

00:15:38.821 --> 00:15:41.191
CR: And that began the idea of an automated car.

00:15:41.191 --> 00:15:42.885
LP: Yeah, about 18 years ago I learned about

00:15:42.885 --> 00:15:46.067
people working on automated cars,

00:15:46.067 --> 00:15:47.690
and I became fascinated by that,

00:15:47.690 --> 00:15:50.467
and it takes a while to 
get these projects going,

00:15:50.467 --> 00:15:55.564
but I'm super excited about the possibilities of that

00:15:55.564 --> 00:15:57.232
improving the world.

00:15:57.232 --> 00:16:01.758
There's 20 million people or more injured per year.

00:16:01.758 --> 00:16:03.744
It's the leading cause of death

00:16:03.744 --> 00:16:05.874
for people under 34 in the U.S.

00:16:05.874 --> 00:16:07.425
CR: So you're talking about saving lives.

00:16:07.425 --> 00:16:09.780
LP: Yeah, and also saving space

00:16:09.780 --> 00:16:13.695
and making life better.

00:16:13.695 --> 00:16:17.940
Los Angeles is half parking lots and roads,

00:16:17.940 --> 00:16:19.673
half of the area,

00:16:19.673 --> 00:16:22.500
and most cities are not far behind, actually.

00:16:22.500 --> 00:16:24.064
It's just crazy

00:16:24.064 --> 00:16:25.657
that that's what we use our space for.

00:16:25.657 --> 00:16:28.000
CR: And how soon will we be there?

00:16:28.000 --> 00:16:29.926
LP: I think we can be there very, very soon.

00:16:29.926 --> 00:16:33.427
We've driven well over 100,000 miles

00:16:33.427 --> 00:16:37.520
now totally automated.

00:16:37.520 --> 00:16:41.172
I'm super excited about getting that out quickly.

00:16:41.172 --> 00:16:43.577
CR: But it's not only you're
talking about automated cars.

00:16:43.577 --> 00:16:45.963
You also have this idea for bicycles.

00:16:45.963 --> 00:16:48.209
LP: Well at Google, we got this idea

00:16:48.209 --> 00:16:51.660
that we should just provide free bikes to everyone,

00:16:51.660 --> 00:16:54.428
and that's been amazing, most of the trips.

00:16:54.428 --> 00:16:56.014
You see bikes going everywhere,

00:16:56.014 --> 00:16:57.580
and the bikes wear out.

00:16:57.580 --> 00:16:59.034
They're getting used 24 hours a day.

00:16:59.034 --> 00:17:01.194
CR: But you want to put them above the street, too.

00:17:01.194 --> 00:17:02.769
LP: Well I said, how do we get people

00:17:02.769 --> 00:17:04.296
using bikes more?

00:17:04.296 --> 00:17:05.921
CR: We may have a video here.

00:17:05.921 --> 00:17:07.199
LP: Yeah, let's show the video.

00:17:07.199 --> 00:17:10.291
I just got excited about this.

00:17:10.291 --> 00:17:14.333
(Music)

00:17:16.213 --> 00:17:18.638
So this is actually how you might separate

00:17:18.638 --> 00:17:22.267
bikes from cars with minimal cost.

00:17:26.711 --> 00:17:28.466
Anyway, it looks totally crazy,

00:17:28.466 --> 00:17:30.793
but I was actually thinking about our campus,

00:17:30.793 --> 00:17:32.853
working with the Zippies and stuff,

00:17:32.853 --> 00:17:35.151
and just trying to get a lot more bike usage,

00:17:35.151 --> 00:17:36.699
and I was thinking about,

00:17:36.699 --> 00:17:39.530
how do you cost-effectively separate

00:17:39.530 --> 00:17:40.944
the bikes from traffic?

00:17:40.944 --> 00:17:42.094
And I went and searched,

00:17:42.094 --> 00:17:43.465
and this is what I found.

00:17:43.465 --> 00:17:45.310
And we're not actually working on this,

00:17:45.310 --> 00:17:46.602
that particular thing,

00:17:46.602 --> 00:17:48.656
but it gets your imagination going.

00:17:48.656 --> 00:17:50.420
CR: Let me close with this.

00:17:50.420 --> 00:17:52.765
Give me a sense of the philosophy 
of your own mind.

00:17:52.765 --> 00:17:55.253
You have this idea of [Google X].

00:17:55.253 --> 00:17:58.249
You don't simply want

00:17:58.249 --> 00:18:03.845
to go in some small, measurable arena of progress.

00:18:03.845 --> 00:18:05.558
LP: Yeah, I think

00:18:05.558 --> 00:18:07.689
many of the things we just 
talked about are like that,

00:18:07.689 --> 00:18:10.641
where they're really --

00:18:10.641 --> 00:18:14.271
I almost use the economic concept of additionality,

00:18:14.271 --> 00:18:16.461
which means that you're doing something

00:18:16.461 --> 00:18:19.409
that wouldn't happen unless 
you were actually doing it.

00:18:19.409 --> 00:18:22.549
And I think the more you can do things like that,

00:18:22.549 --> 00:18:24.620
the bigger impact you have,

00:18:24.620 --> 00:18:27.610
and that's about doing things

00:18:27.610 --> 00:18:31.217
that people might not think are possible.

00:18:31.217 --> 00:18:33.046
And I've been amazed,

00:18:33.046 --> 00:18:35.275
the more I learn about technology,

00:18:35.275 --> 00:18:37.471
the more I realize I don't know,

00:18:37.471 --> 00:18:40.808
and that's because this technological horizon,

00:18:40.808 --> 00:18:43.705
the thing that you can see to do next,

00:18:43.705 --> 00:18:45.545
the more you learn about technology,

00:18:45.545 --> 00:18:48.147
the more you learn what's possible.

00:18:48.147 --> 00:18:50.393
You learn that the balloons are possible

00:18:50.393 --> 00:18:52.730
because there's some material
that will work for them.

00:18:52.730 --> 00:18:55.109
CR: What's interesting about 
you too, though, for me,

00:18:55.109 --> 00:18:56.820
is that, we have lots of people

00:18:56.820 --> 00:18:58.962
who are thinking about the future,

00:18:58.962 --> 00:19:02.230
and they are going and looking
and they're coming back,

00:19:02.230 --> 00:19:04.357
but we never see the implementation.

00:19:04.357 --> 00:19:05.962
I think of somebody you knew

00:19:05.962 --> 00:19:08.869
and read about, Tesla.

00:19:08.869 --> 00:19:12.673
The principle of that for you is what?

00:19:12.673 --> 00:19:14.458
LP: Well, I think invention is not enough.

00:19:14.458 --> 00:19:15.679
If you invent something,

00:19:15.679 --> 00:19:18.874
Tesla invented electric power that we use,

00:19:18.874 --> 00:19:21.535
but he struggled to get it out to people.

00:19:21.535 --> 00:19:23.219
That had to be done by other people.

00:19:23.219 --> 00:19:24.845
It took a long time.

00:19:24.845 --> 00:19:28.712
And I think if we can actually combine both things,

00:19:28.712 --> 00:19:32.243
where we have an innovation and invention focus,

00:19:32.243 --> 00:19:35.215
plus the ability to really -- a company

00:19:35.215 --> 00:19:37.213
that can really commercialize things

00:19:37.213 --> 00:19:38.843
and get them to people

00:19:38.843 --> 00:19:40.918
in a way that's positive for the world

00:19:40.918 --> 00:19:42.974
and to give people hope.

00:19:42.974 --> 00:19:45.748
You know, I'm amazed with the Loon Project

00:19:45.748 --> 00:19:48.534
just how excited people were about that,

00:19:48.534 --> 00:19:50.348
because it gave them hope

00:19:50.348 --> 00:19:51.969
for the two thirds of the world

00:19:51.969 --> 00:19:54.695
that doesn't have Internet right now that's any good.

00:19:54.695 --> 00:19:56.817
CR: Which is a second thing about corporations.

00:19:56.817 --> 00:19:59.293
You are one of those people who believe

00:19:59.293 --> 00:20:01.610
that corporations are an agent of change

00:20:01.610 --> 00:20:03.081
if they are run well.

00:20:03.081 --> 00:20:04.902
LP: Yeah. I'm really dismayed

00:20:04.902 --> 00:20:08.196
most people think companies are basically evil.

00:20:08.196 --> 00:20:09.962
They get a bad rap.

00:20:09.962 --> 00:20:12.203
And I think that's somewhat correct.

00:20:12.203 --> 00:20:15.073
Companies are doing the same incremental thing

00:20:15.073 --> 00:20:16.836
that they did 50 years ago

00:20:16.836 --> 00:20:18.467
or 20 years ago.

00:20:18.467 --> 00:20:19.837
That's not really what we need.

00:20:19.837 --> 00:20:22.055
We need, especially in technology,

00:20:22.055 --> 00:20:24.172
we need revolutionary change,

00:20:24.172 --> 00:20:25.585
not incremental change.

00:20:25.585 --> 00:20:26.754
CR: You once said, actually,

00:20:26.754 --> 00:20:28.572
as I think I've got this about right,

00:20:28.572 --> 00:20:30.217
that you might consider,

00:20:30.217 --> 00:20:31.970
rather than giving your money,

00:20:31.970 --> 00:20:35.290
if you were leaving it to some cause,

00:20:35.290 --> 00:20:37.296
just simply giving it to Elon Musk,

00:20:37.296 --> 00:20:38.459
because you had confidence

00:20:38.459 --> 00:20:40.301
that he would change the future,

00:20:40.301 --> 00:20:42.078
and that you would therefore —

00:20:42.078 --> 00:20:43.662
LP: Yeah, if you want to go Mars,

00:20:43.662 --> 00:20:45.383
he wants to go to Mars,

00:20:45.383 --> 00:20:47.354
to back up humanity,

00:20:47.354 --> 00:20:49.026
that's a worthy goal, but it's a company,

00:20:49.026 --> 00:20:51.581
and it's philanthropical.

00:20:51.581 --> 00:20:54.533
So I think we aim to do kind of similar things.

00:20:54.533 --> 00:20:57.520
And I think, you ask, we have a lot of employees

00:20:57.520 --> 00:21:00.835
at Google who have become pretty wealthy.

00:21:00.835 --> 00:21:03.355
People make a lot of money in technology.

00:21:03.355 --> 00:21:05.511
A lot of people in the room are pretty wealthy.

00:21:05.511 --> 00:21:07.825
You're working because you
want to change the world.

00:21:07.825 --> 00:21:09.587
You want to make it better.

00:21:09.587 --> 00:21:13.032
Why isn't the company that you work for

00:21:13.032 --> 00:21:14.975
worthy not just of your time

00:21:14.975 --> 00:21:17.126
but your money as well?

00:21:17.126 --> 00:21:18.848
I mean, but we don't have a concept of that.

00:21:18.848 --> 00:21:21.152
That's not how we think about companies,

00:21:21.152 --> 00:21:22.619
and I think it's sad,

00:21:22.619 --> 00:21:26.386
because companies are most of our effort.

00:21:26.386 --> 00:21:28.901
They're where most of people's time is,

00:21:28.901 --> 00:21:30.755
where a lot of the money is,

00:21:30.755 --> 00:21:33.107
and so I think I'd like for us to help out

00:21:33.107 --> 00:21:34.233
more than we are.

00:21:34.233 --> 00:21:35.954
CR: When I close conversations with lots of people,

00:21:35.954 --> 00:21:37.733
I always ask this question:

00:21:37.733 --> 00:21:39.248
What state of mind,

00:21:39.248 --> 00:21:41.057
what quality of mind is it

00:21:41.057 --> 00:21:42.824
that has served you best?

00:21:42.824 --> 00:21:45.345
People like Rupert Murdoch have said curiosity,

00:21:45.345 --> 00:21:47.973
and other people in the media have said that.

00:21:47.973 --> 00:21:50.997
Bill Gates and Warren Buffett have said focus.

00:21:50.997 --> 00:21:52.424
What quality of mind,

00:21:52.424 --> 00:21:53.798
as I leave this audience,

00:21:53.798 --> 00:21:57.328
has enabled you to think about the future

00:21:57.328 --> 00:21:58.975
and at the same time

00:21:58.975 --> 00:22:01.180
change the present?

00:22:01.180 --> 00:22:02.850
LP: You know, I think the most important thing --

00:22:02.850 --> 00:22:04.462
I looked at lots of companies

00:22:04.462 --> 00:22:07.765
and why I thought they don't succeed over time.

00:22:07.765 --> 00:22:10.598
We've had a more rapid turnover of companies.

00:22:10.598 --> 00:22:13.367
And I said, what did they fundamentally do wrong?

00:22:13.367 --> 00:22:15.534
What did those companies all do wrong?

00:22:15.534 --> 00:22:18.806
And usually it's just that they missed the future.

00:22:18.806 --> 00:22:21.250
And so I think, for me,

00:22:21.250 --> 00:22:23.674
I just try to focus on that and say,

00:22:23.674 --> 00:22:25.858
what is that future really going to be

00:22:25.858 --> 00:22:27.645
and how do we create it,

00:22:27.645 --> 00:22:32.312
and how do we cause our organization,

00:22:32.312 --> 00:22:34.752
to really focus on that

00:22:34.752 --> 00:22:38.077
and drive that at a really high rate?

00:22:38.077 --> 00:22:39.437
And so that's been curiosity,

00:22:39.437 --> 00:22:41.170
it's been looking at things

00:22:41.170 --> 00:22:42.888
people might not think about,

00:22:42.888 --> 00:22:45.993
working on things that no one else is working on,

00:22:45.993 --> 00:22:49.299
because that's where the additionality really is,

00:22:49.299 --> 00:22:50.850
and be willing to do that,

00:22:50.850 --> 00:22:52.232
to take that risk.

00:22:52.232 --> 00:22:53.297
Look at Android.

00:22:53.297 --> 00:22:56.082
I felt guilty about working on Android

00:22:56.082 --> 00:22:57.398
when it was starting.

00:22:57.398 --> 00:22:59.356
It was a little startup we bought.

00:22:59.356 --> 00:23:02.026
It wasn't really what we were really working on.

00:23:02.026 --> 00:23:04.521
And I felt guilty about spending time on that.

00:23:04.521 --> 00:23:05.975
That was stupid.

00:23:05.975 --> 00:23:07.026
That was the future, right?

00:23:07.026 --> 00:23:09.311
That was a good thing to be working on.

00:23:09.311 --> 00:23:10.728
CR: It is great to see you here.

00:23:10.728 --> 00:23:12.188
It's great to hear from you,

00:23:12.188 --> 00:23:14.485
and a pleasure to sit at this table with you.

00:23:14.485 --> 00:23:15.413
Thanks, Larry.

00:23:15.413 --> 00:23:17.516
LP: Thank you.

00:23:17.516 --> 00:23:21.448
(Applause)

00:23:21.448 --> 00:23:24.759
CR: Larry Page.

