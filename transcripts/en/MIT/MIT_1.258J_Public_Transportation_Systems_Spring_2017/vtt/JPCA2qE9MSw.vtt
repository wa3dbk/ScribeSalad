WEBVTT
Kind: captions
Language: en

00:00:01.170 --> 00:00:03.510
The following content is
provided under a Creative

00:00:03.510 --> 00:00:04.930
Commons license.

00:00:04.930 --> 00:00:07.120
Your support will help
MIT OpenCourseWare

00:00:07.120 --> 00:00:11.230
continue to offer high-quality
educational resources for free.

00:00:11.230 --> 00:00:13.770
To make a donation or to
view additional materials

00:00:13.770 --> 00:00:17.730
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:17.730 --> 00:00:18.610
at ocw.mit.edu.

00:00:23.542 --> 00:00:25.750
GABRIEL SANCHEZ-MARTINEZ:
Any questions on Homework 1

00:00:25.750 --> 00:00:26.680
before we get started?

00:00:29.308 --> 00:00:30.190
AUDIENCE: Yeah.

00:00:30.190 --> 00:00:33.100
GABRIEL SANCHEZ-MARTINEZ:
OK, fire away.

00:00:33.100 --> 00:00:36.940
AUDIENCE: I guess,
first, do you think

00:00:36.940 --> 00:00:39.400
we have like this
minimum cycle time,

00:00:39.400 --> 00:00:42.360
like a theoretical minimum cycle
time and then what was actually

00:00:42.360 --> 00:00:45.630
[INAUDIBLE] cycle time?

00:00:45.630 --> 00:00:49.890
GABRIEL SANCHEZ-MARTINEZ: So
cycle time, just to review--

00:00:49.890 --> 00:00:54.540
it's the time that
it takes a bus to--

00:00:54.540 --> 00:00:57.620
from the time
[AUDIO OUT] for a trip.

00:00:57.620 --> 00:01:01.530
It goes all the way one way,
has to wait at the other end

00:01:01.530 --> 00:01:05.010
to recover the schedule,
comes back, waits to recover,

00:01:05.010 --> 00:01:07.290
and is ready to
begin the next round.

00:01:07.290 --> 00:01:09.890
So that's a cycle.

00:01:09.890 --> 00:01:14.040
AUDIENCE: Since you have
[INAUDIBLE] going on,

00:01:14.040 --> 00:01:17.579
if you had 4.1 buses,
then you use a cycle time.

00:01:17.579 --> 00:01:18.995
Then obviously,
you can't do that?

00:01:18.995 --> 00:01:19.930
[INTERPOSING VOICES]

00:01:19.930 --> 00:01:21.315
GABRIEL SANCHEZ-MARTINEZ: So
you would need five buses--

00:01:21.315 --> 00:01:21.610
AUDIENCE: Yeah.

00:01:21.610 --> 00:01:23.860
GABRIEL SANCHEZ-MARTINEZ:
--if that's what you've got.

00:01:23.860 --> 00:01:26.892
Or you would have to do a
trade-off with reliability

00:01:26.892 --> 00:01:27.850
if that were to happen.

00:01:31.650 --> 00:01:33.312
AUDIENCE: I think
most of my questions

00:01:33.312 --> 00:01:35.440
were on this very last
couple of questions.

00:01:35.440 --> 00:01:38.368
GABRIEL SANCHEZ-MARTINEZ: Yeah.

00:01:38.368 --> 00:01:41.680
AUDIENCE: We were aggregating
a bunch of data for--

00:01:41.680 --> 00:01:45.094
[INAUDIBLE] you did it
across both directions

00:01:45.094 --> 00:01:46.510
and then asked,
how does it change

00:01:46.510 --> 00:01:49.650
when you would like to evaluate
each direction separately

00:01:49.650 --> 00:01:51.062
in layover time?

00:01:51.062 --> 00:01:53.520
GABRIEL SANCHEZ-MARTINEZ: This
is the penultimate question,

00:01:53.520 --> 00:01:53.880
correct?

00:01:53.880 --> 00:01:54.120
AUDIENCE: Yeah.

00:01:54.120 --> 00:01:54.510
GABRIEL SANCHEZ-MARTINEZ:
So that's

00:01:54.510 --> 00:01:55.920
the hardest question
on the assignment.

00:01:55.920 --> 00:01:56.670
AUDIENCE: OK.

00:01:56.670 --> 00:01:58.836
GABRIEL SANCHEZ-MARTINEZ:
It is a challenge question

00:01:58.836 --> 00:02:02.430
because there are different
cases that you have to analyze.

00:02:02.430 --> 00:02:05.330
That's maybe the hint, right?

00:02:05.330 --> 00:02:07.330
There are some cases.

00:02:07.330 --> 00:02:09.537
And for each case,
there is a probability

00:02:09.537 --> 00:02:10.620
that that case will occur.

00:02:10.620 --> 00:02:11.830
AUDIENCE: Yeah.

00:02:11.830 --> 00:02:22.334
GABRIEL SANCHEZ-MARTINEZ: And--
let's see if this starts--

00:02:22.334 --> 00:02:23.750
there's a probability
that it will

00:02:23.750 --> 00:02:30.090
occur and then a consequence, or
something happens in that case.

00:02:30.090 --> 00:02:32.990
So you have to look at each case
and then aggregate the cases

00:02:32.990 --> 00:02:34.880
together, if that make sense.

00:02:34.880 --> 00:02:36.146
AUDIENCE: Yes.

00:02:36.146 --> 00:02:38.770
GABRIEL SANCHEZ-MARTINEZ: We're
taking questions for Assignment

00:02:38.770 --> 00:02:40.090
1, which is due on Thursday.

00:02:43.740 --> 00:02:44.880
Any other questions?

00:02:44.880 --> 00:02:47.565
AUDIENCE: That's it.

00:02:47.565 --> 00:02:48.440
AUDIENCE: [INAUDIBLE]

00:02:48.440 --> 00:02:51.200
GABRIEL SANCHEZ-MARTINEZ:
It is due at 4:00

00:02:51.200 --> 00:02:54.620
so at class time
essentially, yeah.

00:02:54.620 --> 00:02:56.410
I actually [AUDIO OUT]
if you 4:00.

00:02:56.410 --> 00:02:58.960
I said 4:05, so you
have five minutes.

00:03:01.876 --> 00:03:05.035
AUDIENCE: Can you [INAUDIBLE]
what assumptions there

00:03:05.035 --> 00:03:06.250
are [INAUDIBLE]?

00:03:10.485 --> 00:03:12.276
GABRIEL SANCHEZ-MARTINEZ:
In what question?

00:03:12.276 --> 00:03:14.463
AUDIENCE: When you
said it seems to be

00:03:14.463 --> 00:03:17.622
the reasoning or assumption
about the schedule [INAUDIBLE]??

00:03:17.622 --> 00:03:20.052
Which metric do you use?

00:03:20.052 --> 00:03:22.757
Based on the data,
which [INAUDIBLE]??

00:03:22.757 --> 00:03:25.340
GABRIEL SANCHEZ-MARTINEZ: Yeah,
so that's Question 3, correct?

00:03:25.340 --> 00:03:25.965
AUDIENCE: Yeah.

00:03:25.965 --> 00:03:28.887
GABRIEL SANCHEZ-MARTINEZ:
So I can't really explain.

00:03:28.887 --> 00:03:30.720
I can't give you the
answer to the question.

00:03:30.720 --> 00:03:34.250
So what I'm looking for
there is your intuition

00:03:34.250 --> 00:03:38.870
and your understanding of why
you would pick which statistics

00:03:38.870 --> 00:03:45.240
from Question 2, where it tells
you calculate all these things.

00:03:45.240 --> 00:03:48.500
Now I'm saying pick
from those statistics

00:03:48.500 --> 00:03:52.370
what you would use
for t and for r.

00:03:52.370 --> 00:03:54.770
And you may want to combine
different statistics

00:03:54.770 --> 00:03:57.450
for the computation of r.

00:03:57.450 --> 00:03:57.950
Yeah?

00:03:57.950 --> 00:04:02.132
AUDIENCE: [INAUDIBLE]
multiple valid responses but--

00:04:02.132 --> 00:04:04.590
GABRIEL SANCHEZ-MARTINEZ: Yes,
some more valid than others,

00:04:04.590 --> 00:04:06.510
but some that are
definitely invalid

00:04:06.510 --> 00:04:12.900
and some that are almost 100%
valid but not 100% valid.

00:04:12.900 --> 00:04:15.670
So there are several
correct answers,

00:04:15.670 --> 00:04:18.130
and some that are
very good answers

00:04:18.130 --> 00:04:21.220
because you can justify
the choice of the statistic

00:04:21.220 --> 00:04:23.310
conceptually.

00:04:23.310 --> 00:04:24.380
Yeah.

00:04:24.380 --> 00:04:26.920
Any other questions
on Homework 1?

00:04:26.920 --> 00:04:30.860
I can take some more questions
after class, if that's OK.

00:04:30.860 --> 00:04:36.260
So we had a snow day if you had
a good time, and/or at least,

00:04:36.260 --> 00:04:37.910
you could use it to catch up.

00:04:37.910 --> 00:04:40.430
So the schedule is a
little different now.

00:04:40.430 --> 00:04:43.260
I've posted an update about
that on Stellar (class site).

00:04:43.260 --> 00:04:44.930
There's a new syllabus.

00:04:44.930 --> 00:04:47.970
And we're going to do
some [AUDIO OUT] different

00:04:47.970 --> 00:04:49.890
[AUDIO OUT].

00:04:49.890 --> 00:04:53.370
You may remember that we have
three introductory classes

00:04:53.370 --> 00:04:56.370
on topics of [INAUDIBLE].

00:04:56.370 --> 00:04:59.140
And then, we had model
characteristics and roles.

00:04:59.140 --> 00:05:02.100
And then, [AUDIO OUT].

00:05:02.100 --> 00:05:03.788
We're going to
shuffle a little bit.

00:05:03.788 --> 00:05:08.770
[AUDIO OUT] Microphone working?

00:05:08.770 --> 00:05:13.360
So because the second assignment
is on data collection,

00:05:13.360 --> 00:05:14.770
we're going to cover that today.

00:05:14.770 --> 00:05:16.769
And we're going to give
you that homework today,

00:05:16.769 --> 00:05:19.810
so that you can get started
on the data collection side.

00:05:19.810 --> 00:05:23.080
Then, we're going to cover some
of the short-range [INAUDIBLE]

00:05:23.080 --> 00:05:24.670
of planning concepts.

00:05:24.670 --> 00:05:25.910
Nema is going to do that--

00:05:25.910 --> 00:05:26.480
Nema Nassir.

00:05:26.480 --> 00:05:29.540
You might recall him from
the previous lecture.

00:05:29.540 --> 00:05:33.370
And then, we'll finish
with [INAUDIBLE] and costs

00:05:33.370 --> 00:05:36.250
in March the 2nd, OK?

00:05:36.250 --> 00:05:39.860
So remember, there's no
class on Monday the 21st.

00:05:44.410 --> 00:05:46.400
AUDIENCE: You mean Tuesday?

00:05:46.400 --> 00:05:49.131
GABRIEL SANCHEZ-MARTINEZ:
Sorry, yes, Tuesday.

00:05:49.131 --> 00:05:50.630
I think, there's
no class on Monday.

00:05:50.630 --> 00:05:52.190
And then, Tuesday
there are classes.

00:05:52.190 --> 00:05:53.420
But it's Monday's schedule.

00:05:53.420 --> 00:05:55.250
So we don't have class.

00:05:55.250 --> 00:05:58.320
Thank you for bringing that up.

00:05:58.320 --> 00:05:59.630
OK.

00:05:59.630 --> 00:06:03.610
I'll leave Homework 2 for when
we finish with the lecture.

00:06:03.610 --> 00:06:06.370
But I'll distribute it later.

00:06:06.370 --> 00:06:09.240
So let's just get
started on that.

00:06:09.240 --> 00:06:11.430
So data collection techniques
and program design--

00:06:11.430 --> 00:06:13.999
that's the topic for today.

00:06:13.999 --> 00:06:14.790
Here's the outline.

00:06:14.790 --> 00:06:17.660
So we're going to cover a
summary of current practice

00:06:17.660 --> 00:06:18.747
quite quickly.

00:06:18.747 --> 00:06:21.330
Then, we're going to talk about
data collection program design

00:06:21.330 --> 00:06:25.050
process, the needs, the data
needs, the techniques for data

00:06:25.050 --> 00:06:26.301
collection, the sampling.

00:06:26.301 --> 00:06:28.050
We're going to get
into the details of how

00:06:28.050 --> 00:06:29.890
we get sample slices.

00:06:29.890 --> 00:06:32.730
And we're going to finish
with special considerations

00:06:32.730 --> 00:06:35.200
for surveys and
surveying techniques.

00:06:37.740 --> 00:06:38.610
so where are we?

00:06:38.610 --> 00:06:42.090
Where is the transit industry
in terms of data collection,

00:06:42.090 --> 00:06:44.370
and sampling, and these things?

00:06:44.370 --> 00:06:45.810
Largely, there's
been a transition

00:06:45.810 --> 00:06:48.047
from manual to automatic
data collection.

00:06:48.047 --> 00:06:50.130
As you might imagine, with
the internet of things,

00:06:50.130 --> 00:06:52.800
and sensors, and the
internet, and wireless,

00:06:52.800 --> 00:06:54.720
it used to be that
if you wanted to have

00:06:54.720 --> 00:06:56.100
statistics on your
running times,

00:06:56.100 --> 00:06:57.690
you had to send people out.

00:06:57.690 --> 00:06:59.880
We call those people checkers.

00:06:59.880 --> 00:07:03.330
And those checkers would
have notebooks and record

00:07:03.330 --> 00:07:05.400
running times, and number
of people boarding,

00:07:05.400 --> 00:07:06.660
and these things.

00:07:06.660 --> 00:07:09.950
Nowadays, with the modern
systems, especially

00:07:09.950 --> 00:07:13.920
the modern systems, we have
several sensors and types

00:07:13.920 --> 00:07:16.410
of sensors that collect
some of that data for us.

00:07:16.410 --> 00:07:20.085
So we're going to
cover both approaches.

00:07:20.085 --> 00:07:23.054
[INAUDIBLE] data
collection to supplement

00:07:23.054 --> 00:07:24.220
[INAUDIBLE] data collection.

00:07:24.220 --> 00:07:27.730
And if you happen to be
consulting for a developing

00:07:27.730 --> 00:07:32.560
country that is working with a
system that has not yet brought

00:07:32.560 --> 00:07:35.500
in automatic data
collection technologies,

00:07:35.500 --> 00:07:39.100
it's also useful to know
all about the manual design

00:07:39.100 --> 00:07:42.120
and manual data
collection process.

00:07:42.120 --> 00:07:44.710
[AUDIO OUT] took this
class and ended up

00:07:44.710 --> 00:07:47.980
working in large consulting
firms have gone off

00:07:47.980 --> 00:07:52.369
to help countries put
in new transit systems.

00:07:52.369 --> 00:07:54.160
And one of the first
things they have to do

00:07:54.160 --> 00:07:59.222
is back to these slides and see
what the plan is going to be,

00:07:59.222 --> 00:08:01.180
and how many people you
need, and how much it's

00:08:01.180 --> 00:08:01.930
going to cost.

00:08:01.930 --> 00:08:04.510
So very useful topic.

00:08:04.510 --> 00:08:07.519
So as I said, there's
automatic data collection.

00:08:07.519 --> 00:08:08.810
There's manual data collection.

00:08:08.810 --> 00:08:11.860
There's sometimes a mix of
data collection techniques.

00:08:11.860 --> 00:08:14.470
Often, what happens is
that we just send people

00:08:14.470 --> 00:08:15.970
out and collect data.

00:08:15.970 --> 00:08:19.420
Or we just extract a sample of
automatically collected data.

00:08:19.420 --> 00:08:21.970
And we don't really think about
sampling, and the confidence

00:08:21.970 --> 00:08:24.750
interval, and how sure
are we of that result

00:08:24.750 --> 00:08:27.490
that we're going to influence
policy or make decisions

00:08:27.490 --> 00:08:29.260
that will affect service.

00:08:29.260 --> 00:08:31.390
How sure are we of those?

00:08:31.390 --> 00:08:33.640
So statistical validity.

00:08:33.640 --> 00:08:37.179
Often, there's an
efficient use of data.

00:08:37.179 --> 00:08:41.919
And ADCS, which is Automatic
Data Collection Systems--

00:08:41.919 --> 00:08:44.260
we'll use that abbreviation
throughout the course-

00:08:44.260 --> 00:08:47.020
presents a major opportunity
for strengthening data

00:08:47.020 --> 00:08:48.260
to support decision making.

00:08:48.260 --> 00:08:49.790
We'll talk about
how that happens.

00:08:49.790 --> 00:08:52.520
Let's first compare manual
and automatic data collection.

00:08:52.520 --> 00:08:54.386
So what happens with
manual data collection?

00:08:54.386 --> 00:08:55.510
You hire people, as I said.

00:08:55.510 --> 00:08:56.950
You hired checkers.

00:08:56.950 --> 00:08:59.860
So initially, there's
no setup cost.

00:08:59.860 --> 00:09:01.950
There's a low
capital cost to that.

00:09:01.950 --> 00:09:04.210
But there's a high marginal
cost because if you

00:09:04.210 --> 00:09:06.680
want to collect more data,
you have to hire more people.

00:09:06.680 --> 00:09:08.134
Does that make sense?

00:09:08.134 --> 00:09:10.300
If you want to bring in an
automatic data collection

00:09:10.300 --> 00:09:12.341
system, you might have to
retrofit all your buses

00:09:12.341 --> 00:09:13.930
with AVL sensors.

00:09:13.930 --> 00:09:16.410
And that's going to
cost you initially.

00:09:16.410 --> 00:09:19.710
So that's a high
capital cost relatively.

00:09:19.710 --> 00:09:22.420
But low marginal cost-- once
you have those systems in place,

00:09:22.420 --> 00:09:24.160
they keep collecting
data for you.

00:09:24.160 --> 00:09:25.300
And it's almost free.

00:09:25.300 --> 00:09:27.760
You do need some maintenance
on these equipments.

00:09:27.760 --> 00:09:31.510
But comparing to
manual data collection,

00:09:31.510 --> 00:09:33.310
you have low marginal cost.

00:09:33.310 --> 00:09:35.770
Because of that marginal
cost difference,

00:09:35.770 --> 00:09:38.320
it tends to happen that when
you have manual data collection,

00:09:38.320 --> 00:09:41.920
you only pay checkers
for small sample sizes--

00:09:41.920 --> 00:09:43.300
just what you need.

00:09:43.300 --> 00:09:46.930
Whereas, once you put in
automatic data collection

00:09:46.930 --> 00:09:49.720
systems, they keep
collecting data.

00:09:49.720 --> 00:09:52.110
So you get much bigger data.

00:09:52.110 --> 00:09:53.950
Bless you.

00:09:53.950 --> 00:09:57.430
OK, in both cases, we can
collect data and analyze it

00:09:57.430 --> 00:09:59.860
for aggregate analysis
and disaggregate analysis.

00:09:59.860 --> 00:10:01.720
So you might want
passenger-specific data

00:10:01.720 --> 00:10:02.620
on things.

00:10:02.620 --> 00:10:06.400
Or you might want things
like just averages

00:10:06.400 --> 00:10:09.340
and aggregate things,
total number of passengers

00:10:09.340 --> 00:10:10.960
using the system.

00:10:10.960 --> 00:10:12.940
And when you're doing
manual data collection,

00:10:12.940 --> 00:10:14.890
you can look at
quantitative things, things

00:10:14.890 --> 00:10:16.440
you can measure and count.

00:10:16.440 --> 00:10:19.820
Or you can also observe
things qualitatively.

00:10:19.820 --> 00:10:22.090
One example that I
saw in a recent paper

00:10:22.090 --> 00:10:26.680
was considering the
[? therivation ?]

00:10:26.680 --> 00:10:28.719
by student in some country.

00:10:28.719 --> 00:10:30.760
And they didn't ask people
if they were students.

00:10:30.760 --> 00:10:32.582
They were looking at people's--

00:10:32.582 --> 00:10:33.790
more or less, are they young?

00:10:33.790 --> 00:10:35.410
Are they carrying a backpack?

00:10:35.410 --> 00:10:38.390
And that would be the
labeling for your student.

00:10:38.390 --> 00:10:42.010
So that's something that a
sensor might not do so well.

00:10:42.010 --> 00:10:44.270
Although now with machine
learning, who knows?

00:10:44.270 --> 00:10:45.890
But we haven't seen that so.

00:10:45.890 --> 00:10:48.580
So you can do
qualitative observations

00:10:48.580 --> 00:10:50.410
when you're doing
manual data collection.

00:10:50.410 --> 00:10:52.810
Manual data collection
tends to be unreliable,

00:10:52.810 --> 00:10:56.020
especially when people
aren't very well trained

00:10:56.020 --> 00:10:59.320
and when you have a group of
different people collecting

00:10:59.320 --> 00:10:59.830
data.

00:10:59.830 --> 00:11:01.621
So each person might
have different biases.

00:11:01.621 --> 00:11:05.020
It's hard to reproduce the
exact bias across persons.

00:11:05.020 --> 00:11:07.870
With automatic data
collection, you do the errors.

00:11:07.870 --> 00:11:10.450
And often, they
are not corrected.

00:11:10.450 --> 00:11:14.260
But if you do correct them,
and you estimate those biases

00:11:14.260 --> 00:11:18.550
just for them, you can end
up with a better result.

00:11:18.550 --> 00:11:21.280
Because of the small
sample sizes in manual data

00:11:21.280 --> 00:11:25.180
collection, you tend to
have to have limited spatial

00:11:25.180 --> 00:11:27.290
and temporal coverage of data.

00:11:27.290 --> 00:11:29.650
So for example, if you're
interested in ridership

00:11:29.650 --> 00:11:34.900
in the system, it's unlikely
that you will cover ridership

00:11:34.900 --> 00:11:38.650
in holidays for
[INAUDIBLE] system

00:11:38.650 --> 00:11:40.330
because there are
only a few holidays.

00:11:40.330 --> 00:11:44.350
And usually, you're not
mostly interested in holidays.

00:11:44.350 --> 00:11:48.160
So chances are, you won't have
data collection for holidays.

00:11:48.160 --> 00:11:50.320
Whereas once you install
automatic data collection

00:11:50.320 --> 00:11:51.880
systems, they keep
collecting data.

00:11:51.880 --> 00:11:56.500
So you get data at midnight
on President's Day.

00:11:56.500 --> 00:11:59.350
So they're always on.

00:11:59.350 --> 00:12:01.210
They're always collecting data.

00:12:01.210 --> 00:12:06.170
Manual data needs to be checked,
cleaned, analyzed, coded,

00:12:06.170 --> 00:12:08.670
and sometimes put into systems
before they can be analyzed.

00:12:08.670 --> 00:12:09.670
That could take a while.

00:12:09.670 --> 00:12:11.320
You need to hire
people to do that.

00:12:11.320 --> 00:12:15.490
Whereas automatic data
collection systems often

00:12:15.490 --> 00:12:17.969
send their data to databases
in real-time or very

00:12:17.969 --> 00:12:18.760
close to real-time.

00:12:18.760 --> 00:12:24.580
[INAUDIBLE] you can start
analyzing things the next day.

00:12:24.580 --> 00:12:28.750
So you arrive in the morning to
your desk at a transit agency,

00:12:28.750 --> 00:12:30.790
and you have performance
metrics for yesterday.

00:12:30.790 --> 00:12:33.520
So you wouldn't be able to do
that unless you have people

00:12:33.520 --> 00:12:36.250
working very hard if
you're using manual data

00:12:36.250 --> 00:12:37.870
collection system.

00:12:37.870 --> 00:12:41.050
When we talk about automatic
data collection systems,

00:12:41.050 --> 00:12:42.220
there are many.

00:12:42.220 --> 00:12:47.630
But there are three types that
we refer to very, very often.

00:12:47.630 --> 00:12:51.250
And so the first one in AFC,
Automatic Fare Collection

00:12:51.250 --> 00:12:52.180
Systems.

00:12:52.180 --> 00:12:54.710
This is your fare box or your
fare gates in your smart card,

00:12:54.710 --> 00:12:55.370
your Charlie Card.

00:12:55.370 --> 00:12:56.078
You're in Boston.

00:12:56.078 --> 00:12:57.210
You tap to enter the bus.

00:12:57.210 --> 00:13:00.040
And you tap to enter
the subway system.

00:13:00.040 --> 00:13:03.220
Increasingly, it's based
on contactless smart cards.

00:13:03.220 --> 00:13:04.660
And those contactless
smart cards

00:13:04.660 --> 00:13:06.760
have some sort of
RFID technology

00:13:06.760 --> 00:13:08.440
with a unique identifier.

00:13:08.440 --> 00:13:10.780
When you tap that
card to the sensor,

00:13:10.780 --> 00:13:13.240
the sensor will read
that identifier.

00:13:13.240 --> 00:13:16.240
And it'll do things like
fare calculation for you.

00:13:16.240 --> 00:13:18.760
But that record gets
sent to a database.

00:13:18.760 --> 00:13:23.680
And it's there for people
like us to analyze and make

00:13:23.680 --> 00:13:25.340
good use of it for planning.

00:13:25.340 --> 00:13:29.770
So it tends to provide entry
information almost always.

00:13:29.770 --> 00:13:34.810
In some systems, like the
Washington, DC metro or the TFL

00:13:34.810 --> 00:13:37.600
subway, you tap in
to enter and exit.

00:13:37.600 --> 00:13:41.320
So you have both origin
and destinations.

00:13:41.320 --> 00:13:43.690
And if you always
have the systems on,

00:13:43.690 --> 00:13:47.050
then you have full spatial
and temporal coverage

00:13:47.050 --> 00:13:51.100
of all of the use of the system
at an individual passenger

00:13:51.100 --> 00:13:51.600
level.

00:13:51.600 --> 00:13:55.040
So very disaggregate--
sorry about that.

00:13:55.040 --> 00:13:57.320
Traditionally, these
systems are not real-time.

00:13:57.320 --> 00:14:01.340
So it might take a while
for those transactions

00:14:01.340 --> 00:14:03.170
to make it to the
data warehouse, where

00:14:03.170 --> 00:14:05.810
they're available for
planners to analyze it.

00:14:05.810 --> 00:14:10.070
The calculation of how
much fare in some systems

00:14:10.070 --> 00:14:11.000
is in real-time.

00:14:11.000 --> 00:14:13.400
In other systems like
the Charlie Card,

00:14:13.400 --> 00:14:17.210
the stored value that you
have is stored on your card.

00:14:17.210 --> 00:14:21.020
So it may take a while if
you tap at a bus for that bus

00:14:21.020 --> 00:14:23.570
to go to a garage
and get probed--

00:14:23.570 --> 00:14:25.940
and for the data that has
been stored in that bus

00:14:25.940 --> 00:14:31.500
to be extracted from that
bus to the central server.

00:14:31.500 --> 00:14:33.171
There is a move--

00:14:33.171 --> 00:14:34.920
and we'll talk more
about this when we get

00:14:34.920 --> 00:14:37.020
to fare policy and technology--

00:14:37.020 --> 00:14:39.810
towards using mobile
phone payments

00:14:39.810 --> 00:14:42.820
and using contactless
bank card payment systems.

00:14:42.820 --> 00:14:45.840
And those systems often
do the full transaction

00:14:45.840 --> 00:14:47.040
over the air in real-time.

00:14:47.040 --> 00:14:49.770
So we're starting to
look at the possibility

00:14:49.770 --> 00:14:52.170
of having all this data
in real-time or almost

00:14:52.170 --> 00:14:53.130
in real-time.

00:14:53.130 --> 00:14:54.110
But it's not there yet.

00:14:54.110 --> 00:14:56.360
AUDIENCE: [INAUDIBLE] can I
ask a question about that?

00:14:56.360 --> 00:14:56.980
GABRIEL SANCHEZ-MARTINEZ:
Yeah, of course.

00:14:56.980 --> 00:14:59.305
AUDIENCE: In terms
of smart card,

00:14:59.305 --> 00:15:01.449
where this balance is
stored on the card--

00:15:01.449 --> 00:15:02.740
GABRIEL SANCHEZ-MARTINEZ: Yeah.

00:15:02.740 --> 00:15:06.134
AUDIENCE: --if one can figure
out how to hack that card--

00:15:06.134 --> 00:15:07.425
GABRIEL SANCHEZ-MARTINEZ: Yeah.

00:15:07.425 --> 00:15:08.966
AUDIENCE: --then
what can [INAUDIBLE]

00:15:08.966 --> 00:15:12.877
fares through an elaborate
technology that I couldn't do

00:15:12.877 --> 00:15:14.320
and most people couldn't do.

00:15:14.320 --> 00:15:15.290
But maybe some could.

00:15:15.290 --> 00:15:17.081
GABRIEL SANCHEZ-MARTINEZ:
Yeah, definitely.

00:15:17.081 --> 00:15:19.880
So the Charlie Card system
is an example about--

00:15:19.880 --> 00:15:23.480
actually, MIT students
were the first to hack it.

00:15:23.480 --> 00:15:24.980
AUDIENCE: I'm not surprised.

00:15:24.980 --> 00:15:28.310
GABRIEL SANCHEZ-MARTINEZ:
So it's older technology.

00:15:28.310 --> 00:15:30.530
It used a low-bit
encryption key.

00:15:30.530 --> 00:15:32.660
That's a symmetric
encryption key.

00:15:32.660 --> 00:15:35.731
And they just brute forced it.

00:15:35.731 --> 00:15:36.980
They figured what the key was.

00:15:36.980 --> 00:15:39.260
They happened to use the
same key for every card.

00:15:39.260 --> 00:15:43.250
So once you broke that key,
you could take any card.

00:15:43.250 --> 00:15:45.844
And with the right hardware,
you could add however much value

00:15:45.844 --> 00:15:46.760
you want to that card.

00:15:46.760 --> 00:15:47.260
And--

00:15:47.260 --> 00:15:48.140
AUDIENCE: [INAUDIBLE]

00:15:48.140 --> 00:15:50.390
GABRIEL SANCHEZ-MARTINEZ:
Yeah, yeah, exactly.

00:15:50.390 --> 00:15:52.700
We don't think it's
been a major problem.

00:15:52.700 --> 00:15:54.590
AUDIENCE: But it happens.

00:15:54.590 --> 00:15:56.798
GABRIEL SANCHEZ-MARTINEZ:
I haven't seen MIT students

00:15:56.798 --> 00:15:58.550
selling special MIT cards.

00:15:58.550 --> 00:16:02.690
But that would be
criminal, of course.

00:16:02.690 --> 00:16:06.450
Yeah, so newer systems have
much stronger encryption.

00:16:06.450 --> 00:16:10.410
And they have different
encryption keys for each card.

00:16:10.410 --> 00:16:13.970
And certainly, when we're moving
towards contactless bank cards,

00:16:13.970 --> 00:16:17.570
we're talking about a much
more secure encryption.

00:16:17.570 --> 00:16:20.270
It's your credit card
that you're using to tap

00:16:20.270 --> 00:16:21.539
or your Android or Apple Pay.

00:16:21.539 --> 00:16:23.080
AUDIENCE: Account
based [INAUDIBLE]..

00:16:23.080 --> 00:16:24.788
GABRIEL SANCHEZ-MARTINEZ:
Account based--

00:16:24.788 --> 00:16:27.860
and essentially, what you
have is a token with an ID.

00:16:27.860 --> 00:16:32.020
And then, the balance is not
even stored on your card.

00:16:32.020 --> 00:16:36.320
The account server is handling
the balance and those things.

00:16:36.320 --> 00:16:39.740
So much more difficult to break.

00:16:39.740 --> 00:16:42.380
Yup.

00:16:42.380 --> 00:16:45.950
OK, AVL systems, or Automatic
Vehicle Location systems--

00:16:45.950 --> 00:16:49.250
so these are systems that
track vehicle movement.

00:16:49.250 --> 00:16:51.490
So for bus, they tend
to be based on GPS.

00:16:51.490 --> 00:16:54.520
You have GPS on a bus, on the
top of the bus, a little hub.

00:16:54.520 --> 00:16:58.960
And it collects data every five
seconds or every 10 seconds.

00:16:58.960 --> 00:17:04.119
And these positions might
get sent either in real-time,

00:17:04.119 --> 00:17:07.089
or maybe they get stored
on the onboard computer

00:17:07.089 --> 00:17:10.920
and then are extracted when
the bus reaches the garage.

00:17:10.920 --> 00:17:17.160
So just GPS-- sophisticated
AVL systems for bus

00:17:17.160 --> 00:17:21.930
also have gyroscopes to do
inertial navigation and dead

00:17:21.930 --> 00:17:25.380
reckoning, especially when
the GPS precision drops.

00:17:25.380 --> 00:17:28.830
And that happens especially
with the urban canyon effect.

00:17:28.830 --> 00:17:31.540
If you have tall buildings,
GPS signal bounces around.

00:17:31.540 --> 00:17:36.950
The dilution of precision messes
up the position of the bus.

00:17:36.950 --> 00:17:38.790
Or maybe you're
entering a tunnel,

00:17:38.790 --> 00:17:42.210
and you want to
continue to get updates

00:17:42.210 --> 00:17:43.800
of positions inside the tunnel.

00:17:43.800 --> 00:17:45.390
So this is a
temporary system that

00:17:45.390 --> 00:17:49.500
kicks in and interpolates
positions and figures

00:17:49.500 --> 00:17:51.780
out how the bus is moving.

00:17:51.780 --> 00:17:54.119
For a train, it's usually
based on track circuits.

00:17:54.119 --> 00:17:56.160
So we're going to talk
more about track circuits.

00:17:56.160 --> 00:17:59.160
But essentially, a
track knows if a train

00:17:59.160 --> 00:18:02.640
is occupying that segment or
not occupying that segment.

00:18:02.640 --> 00:18:09.570
And there are often some sensors
that read with RFID technology

00:18:09.570 --> 00:18:11.670
the ID number of a car.

00:18:11.670 --> 00:18:14.190
And sometimes, you have a
sensor in the front of each car

00:18:14.190 --> 00:18:15.750
and [AUDIO OUT] each car.

00:18:15.750 --> 00:18:20.490
And so a computer will look
up the sequence of readings

00:18:20.490 --> 00:18:23.610
and follow track circuits
as they are being occupied

00:18:23.610 --> 00:18:25.560
and unoccupied--

00:18:25.560 --> 00:18:29.530
and in that manner, track
trains throughout the system.

00:18:29.530 --> 00:18:32.790
These systems were put in
place mostly for safety

00:18:32.790 --> 00:18:35.670
to prevent train crashes.

00:18:35.670 --> 00:18:39.330
And because of that, you
would need it to know buses

00:18:39.330 --> 00:18:41.310
or where a train was.

00:18:41.310 --> 00:18:42.900
They are available in real-time.

00:18:42.900 --> 00:18:44.460
They were designed
from the beginning

00:18:44.460 --> 00:18:46.000
to track vehicles in real-time.

00:18:46.000 --> 00:18:48.086
So that's what we have.

00:18:48.086 --> 00:18:49.710
I guess what's newer
is that now, we're

00:18:49.710 --> 00:18:52.650
collecting them and keeping
them in a data warehouse

00:18:52.650 --> 00:18:54.730
so that we can
analyze running times.

00:18:54.730 --> 00:18:56.895
AUDIENCE: [INAUDIBLE]
these systems have benefit

00:18:56.895 --> 00:18:58.320
to the consumer?

00:18:58.320 --> 00:18:58.680
GABRIEL SANCHEZ-MARTINEZ:
They do.

00:18:58.680 --> 00:19:00.638
And that's the newest
thing that has happened--

00:19:00.638 --> 00:19:02.460
that nobody thought
about consumers when

00:19:02.460 --> 00:19:04.080
they were put in place.

00:19:04.080 --> 00:19:07.110
So yeah, we are
talking about tracking,

00:19:07.110 --> 00:19:09.780
knowing how many minutes
I have to wait for my bus,

00:19:09.780 --> 00:19:10.725
for example.

00:19:10.725 --> 00:19:13.380
And those things are pushed
through a public API,

00:19:13.380 --> 00:19:16.200
so that if I'm a
smartphone app developer,

00:19:16.200 --> 00:19:19.950
I can go ahead and pull
data from this next bus app

00:19:19.950 --> 00:19:20.979
and make an app.

00:19:20.979 --> 00:19:23.520
And so people can download it,
and they know how many minutes

00:19:23.520 --> 00:19:24.380
they have to wait.

00:19:24.380 --> 00:19:27.800
Yeah, so definitely.

00:19:27.800 --> 00:19:31.170
So we have seen a lot of AVL
being pushed in that manner.

00:19:31.170 --> 00:19:35.850
We have not seen so much AFC
data or APC data being pushed.

00:19:35.850 --> 00:19:37.980
Obviously, you wouldn't
want all the details

00:19:37.980 --> 00:19:39.840
of AFC being pushed.

00:19:39.840 --> 00:19:42.540
But you might want to know
how crowded is my next bus,

00:19:42.540 --> 00:19:45.100
or how crowded is my next train.

00:19:45.100 --> 00:19:46.860
And you might actually
alter your decision

00:19:46.860 --> 00:19:48.780
whether to wait
for a crowded train

00:19:48.780 --> 00:19:52.640
or walk a longer time
based on that information.

00:19:52.640 --> 00:19:54.127
So that's coming.

00:19:54.127 --> 00:19:55.710
I think, in the next
few years, that's

00:19:55.710 --> 00:19:57.900
going to start happening.

00:19:57.900 --> 00:20:00.690
So passenger counting-- many
different technologies exist.

00:20:00.690 --> 00:20:05.700
For bus, we tend to have these
optical sensors in the back.

00:20:05.700 --> 00:20:08.640
You might see them if
you pay attention--

00:20:08.640 --> 00:20:09.740
broken beam sensors.

00:20:09.740 --> 00:20:12.210
They look like two little
eyes with two little mirrors

00:20:12.210 --> 00:20:13.320
on each door.

00:20:13.320 --> 00:20:16.260
And so when you cross
the beams, if you

00:20:16.260 --> 00:20:18.870
press one beam first
and then the other,

00:20:18.870 --> 00:20:20.280
that sensor will know--

00:20:20.280 --> 00:20:22.230
is a person coming into the bus?

00:20:22.230 --> 00:20:24.270
Or is a person exiting the bus?

00:20:24.270 --> 00:20:26.100
And you have that at each door.

00:20:26.100 --> 00:20:31.470
And it counts those beams
going in and going out.

00:20:31.470 --> 00:20:34.110
And often, this is
slightly inaccurate.

00:20:34.110 --> 00:20:36.780
So you might get more boardings
and lightings for a given trip.

00:20:36.780 --> 00:20:39.150
So at the end of
a trip, whatever

00:20:39.150 --> 00:20:41.950
remains in terms of imbalance
between boardings and lightings

00:20:41.950 --> 00:20:42.900
gets zeroed out.

00:20:42.900 --> 00:20:46.910
And the area is distributed
throughout that trip

00:20:46.910 --> 00:20:48.372
that was just run.

00:20:48.372 --> 00:20:50.580
And often, you still have
to do some error correction

00:20:50.580 --> 00:20:51.360
after that.

00:20:51.360 --> 00:20:54.420
But it's a way of counting
people getting on and off.

00:20:54.420 --> 00:20:57.060
And that's useful to get
how many people are riding

00:20:57.060 --> 00:21:00.330
the system and also
the passenger miles--

00:21:00.330 --> 00:21:02.720
the passengers multiplied
by distance, which is often

00:21:02.720 --> 00:21:07.380
a required reporting element
in things like the NTB,

00:21:07.380 --> 00:21:10.020
the National Transit Database.

00:21:10.020 --> 00:21:14.420
So for rail systems,
we have gates

00:21:14.420 --> 00:21:16.231
that count how many
times they open

00:21:16.231 --> 00:21:17.480
and how many times they close.

00:21:17.480 --> 00:21:21.530
So you might have that
kind of counting in rail.

00:21:21.530 --> 00:21:23.150
You also have
video-based counting--

00:21:23.150 --> 00:21:27.710
so camera feeds that
can be hooked up

00:21:27.710 --> 00:21:31.990
to a system that will
essentially track nodes moving

00:21:31.990 --> 00:21:33.270
inside that frame.

00:21:33.270 --> 00:21:36.260
And you can count things
that cross a certain line,

00:21:36.260 --> 00:21:37.370
for example.

00:21:37.370 --> 00:21:42.020
And you could do
that to count flows.

00:21:42.020 --> 00:21:45.200
And then for train, we also
have the weight systems.

00:21:45.200 --> 00:21:47.870
So this is only in trains.

00:21:47.870 --> 00:21:50.780
The braking systems in
trains apply braking force

00:21:50.780 --> 00:21:53.780
in proportion to the
load on each car.

00:21:53.780 --> 00:21:55.340
So if you have a
very heavy car, you

00:21:55.340 --> 00:21:58.490
need to apply stronger braking
force than in a car that

00:21:58.490 --> 00:22:00.050
is almost empty.

00:22:00.050 --> 00:22:04.400
If you don't do that, then
you apply a lot more force

00:22:04.400 --> 00:22:06.430
per weight on the lighter car.

00:22:06.430 --> 00:22:10.070
That car is going to be the
one pushing the other cars

00:22:10.070 --> 00:22:12.530
or pulling the other cars
through the coupling.

00:22:12.530 --> 00:22:14.480
And that will eventually
break the [INAUDIBLE]

00:22:14.480 --> 00:22:15.360
at a faster rate.

00:22:15.360 --> 00:22:18.560
So what you want is,
each car to slow down

00:22:18.560 --> 00:22:21.690
at the same rate by itself
as much as possible.

00:22:21.690 --> 00:22:24.620
And for that, you need to brake
in proportion to the weight.

00:22:24.620 --> 00:22:26.630
And therefore, you have
these weight systems.

00:22:26.630 --> 00:22:29.000
They used to just do that.

00:22:29.000 --> 00:22:30.680
And more recently,
we hooked them

00:22:30.680 --> 00:22:33.770
up to a little
storage device that

00:22:33.770 --> 00:22:36.830
keeps track of the
weight and maybe Wi-Fi,

00:22:36.830 --> 00:22:39.410
so that each time it reaches
a station or the terminal,

00:22:39.410 --> 00:22:40.930
it sends the data off.

00:22:40.930 --> 00:22:47.240
And we might have a rather
somewhat [? unprecise ?]

00:22:47.240 --> 00:22:50.600
idea of how many people
are in the car just based

00:22:50.600 --> 00:22:54.440
on an average
weight of a person.

00:22:54.440 --> 00:22:56.940
And these are traditionally not
available in real real-time.

00:22:56.940 --> 00:22:57.710
[INAUDIBLE] you have questions?

00:22:57.710 --> 00:22:58.090
Yeah?

00:22:58.090 --> 00:22:59.410
AUDIENCE: You could
also just reconcile it

00:22:59.410 --> 00:23:00.760
with the other system, right?

00:23:00.760 --> 00:23:01.370
GABRIEL SANCHEZ-MARTINEZ:
Of course, yeah.

00:23:01.370 --> 00:23:02.250
AUDIENCE: So if you have--

00:23:02.250 --> 00:23:02.460
[INTERPOSING VOICES]

00:23:02.460 --> 00:23:02.945
GABRIEL SANCHEZ-MARTINEZ: Yeah.

00:23:02.945 --> 00:23:05.370
AUDIENCE: --people early
can transport to get on to.

00:23:05.370 --> 00:23:05.520
GABRIEL SANCHEZ-MARTINEZ: Yeah.

00:23:05.520 --> 00:23:06.250
AUDIENCE: [INAUDIBLE]

00:23:06.250 --> 00:23:07.420
GABRIEL SANCHEZ-MARTINEZ:
Yeah, definitely.

00:23:07.420 --> 00:23:07.920
Yeah.

00:23:07.920 --> 00:23:11.900
And that's cutting edge research
that's happening right now.

00:23:11.900 --> 00:23:14.570
How do you do data fiction
and merge different systems?

00:23:14.570 --> 00:23:15.650
They all have errors.

00:23:15.650 --> 00:23:17.100
And how do you
detect when one is

00:23:17.100 --> 00:23:18.350
more erroneous than the other?

00:23:18.350 --> 00:23:20.420
And how do you mix
these data sources

00:23:20.420 --> 00:23:23.847
to get the most precise,
not just loads, but paths

00:23:23.847 --> 00:23:25.430
within a network and
things like that.

00:23:25.430 --> 00:23:26.460
Yeah.

00:23:26.460 --> 00:23:31.039
So any questions on these three
very important automatic data

00:23:31.039 --> 00:23:31.830
collection systems?

00:23:31.830 --> 00:23:32.640
AUDIENCE: [INAUDIBLE]

00:23:32.640 --> 00:23:33.889
GABRIEL SANCHEZ-MARTINEZ: Yup.

00:23:33.889 --> 00:23:41.426
AUDIENCE: So if
there [INAUDIBLE]

00:23:41.426 --> 00:23:45.782
AVL, what kind of reason
can be [INAUDIBLE]??

00:23:45.782 --> 00:23:47.490
GABRIEL SANCHEZ-MARTINEZ:
So the question

00:23:47.490 --> 00:23:52.780
is, why might some of these
technologies produce errors?

00:23:52.780 --> 00:23:55.150
And in particular,
you're asking about AVL.

00:23:55.150 --> 00:23:58.090
So each of these has
a different behavior.

00:23:58.090 --> 00:24:01.030
And within each of these
categories of technologies,

00:24:01.030 --> 00:24:04.870
each vendor's system might have
specific things that happen.

00:24:04.870 --> 00:24:06.730
With AVL, the most
common thing is

00:24:06.730 --> 00:24:10.900
end of root problems--
detecting when a trip actually

00:24:10.900 --> 00:24:12.460
begins and ends.

00:24:12.460 --> 00:24:17.020
So AVL systems,
you have this GPS

00:24:17.020 --> 00:24:18.450
coming in every five seconds.

00:24:18.450 --> 00:24:20.950
Depending on your chip set, you
might get it more frequently

00:24:20.950 --> 00:24:21.450
than that.

00:24:21.450 --> 00:24:25.230
But you also actually
sometimes hook it to the doors.

00:24:25.230 --> 00:24:28.420
So if the door is opening, you
say, well, I must be at a stop.

00:24:28.420 --> 00:24:30.880
And therefore, let me
find which one is closest.

00:24:30.880 --> 00:24:32.540
So there are ways to correct it.

00:24:32.540 --> 00:24:34.750
But when you get to
the end of the route,

00:24:34.750 --> 00:24:37.430
it's not clear always--
have you finished your trip?

00:24:37.430 --> 00:24:41.290
Or rather, are you
starting your trip already?

00:24:41.290 --> 00:24:45.970
So maybe if the terminal is at
the same place on the trip--

00:24:45.970 --> 00:24:47.710
the previous trip
ends at the same place

00:24:47.710 --> 00:24:49.960
that the next trip
begins, there might

00:24:49.960 --> 00:24:53.950
be a time where the doors
open and close various times.

00:24:53.950 --> 00:24:56.140
And the trip isn't
ready to leave yet.

00:24:56.140 --> 00:24:58.810
And so you really have to
wait to see the bus leaving

00:24:58.810 --> 00:25:00.370
that terminal and moving.

00:25:00.370 --> 00:25:01.900
Sometimes, there
are false starts.

00:25:01.900 --> 00:25:06.040
So maybe another bus comes
along, and it needs that space.

00:25:06.040 --> 00:25:10.270
So the driver moves the
bus a few meters forward.

00:25:10.270 --> 00:25:13.880
And the system thinks
my trip has started.

00:25:13.880 --> 00:25:16.130
And then, when you're
looking at aggregate data,

00:25:16.130 --> 00:25:19.120
you're looking at, say, running
times at the trip level.

00:25:19.120 --> 00:25:21.940
You see these outliers
with very long times.

00:25:21.940 --> 00:25:23.500
And if you were to
plot them by stop,

00:25:23.500 --> 00:25:25.510
you see that the link
between the first stop

00:25:25.510 --> 00:25:29.360
and the second step is
sometimes very high, 15 minutes.

00:25:29.360 --> 00:25:30.880
And so you can throw those out.

00:25:30.880 --> 00:25:33.850
Or you can do some interpolation
or imputation of data.

00:25:33.850 --> 00:25:36.880
Some systems that care
very much about that

00:25:36.880 --> 00:25:40.240
will purposely
place the terminal

00:25:40.240 --> 00:25:45.310
stops sufficiently far
apart to prevent that

00:25:45.310 --> 00:25:48.210
from happening because
it is a problem.

00:25:48.210 --> 00:25:52.050
And this data is crucial to
planning service and figuring

00:25:52.050 --> 00:25:54.610
out how much resource you're
going to put into each route.

00:25:54.610 --> 00:25:56.856
So yup.

00:25:56.856 --> 00:26:03.758
AUDIENCE: For tap cards,
[INAUDIBLE] and metros,

00:26:03.758 --> 00:26:07.702
some of them we have
to tap out to exit.

00:26:07.702 --> 00:26:09.903
It is because of
variable [INAUDIBLE]..

00:26:09.903 --> 00:26:11.153
GABRIEL SANCHEZ-MARTINEZ: Yes.

00:26:11.153 --> 00:26:14.604
AUDIENCE: But in some systems,
it's still a flat fare.

00:26:14.604 --> 00:26:16.083
You still have to tap out.

00:26:16.083 --> 00:26:18.548
Is the reason behind that
mostly data collection?

00:26:18.548 --> 00:26:20.766
Or is there anything
[INAUDIBLE] you're

00:26:20.766 --> 00:26:22.695
going to still have to
tap out [INAUDIBLE]??

00:26:22.695 --> 00:26:24.170
GABRIEL SANCHEZ-MARTINEZ:
So yeah, no examples of it

00:26:24.170 --> 00:26:24.999
come to mind.

00:26:24.999 --> 00:26:25.790
You might know one.

00:26:25.790 --> 00:26:27.360
AUDIENCE: MARTA?

00:26:27.360 --> 00:26:29.460
GABRIEL SANCHEZ-MARTINEZ:
OK, I haven't visited.

00:26:29.460 --> 00:26:31.890
So yeah, data collection
might be a reason to do that.

00:26:31.890 --> 00:26:35.640
But I'll have to get back to
you on why MARTA did that.

00:26:35.640 --> 00:26:41.090
But yeah, most systems that
have controls in and out

00:26:41.090 --> 00:26:43.680
are for fare policy
reasons and not

00:26:43.680 --> 00:26:46.560
for data collection reasons.

00:26:46.560 --> 00:26:49.980
We're starting to see more
interest in data collection

00:26:49.980 --> 00:26:53.797
and in investing on
these technologies just

00:26:53.797 --> 00:26:54.630
for data collection.

00:26:54.630 --> 00:26:58.220
So maybe-- but I'll have to
check and get back to you.

00:26:58.220 --> 00:27:01.177
AUDIENCE: You mentioned some
systems separate their depots

00:27:01.177 --> 00:27:03.260
to not confuse the end
[? from the start point. ?]

00:27:03.260 --> 00:27:03.515
[INTERPOSING VOICES]

00:27:03.515 --> 00:27:04.760
GABRIEL SANCHEZ-MARTINEZ:
Their terminal stops, yeah.

00:27:04.760 --> 00:27:06.720
AUDIENCE: What are
some examples of those?

00:27:06.720 --> 00:27:10.510
GABRIEL SANCHEZ-MARTINEZ: TFL
will do that in London, yeah.

00:27:10.510 --> 00:27:11.960
Yeah, so they'll monitor this.

00:27:11.960 --> 00:27:17.110
And if they see that
this is occurring often,

00:27:17.110 --> 00:27:20.319
they will separate
the stops a bit.

00:27:20.319 --> 00:27:22.110
And the reason they do
that is because they

00:27:22.110 --> 00:27:26.190
have people whose job
it is to impute data

00:27:26.190 --> 00:27:27.420
when it's incorrect.

00:27:27.420 --> 00:27:30.330
So if they don't do that, and
the system is consistently

00:27:30.330 --> 00:27:32.170
producing bad data,
then that means

00:27:32.170 --> 00:27:35.850
they're going to have to spend
human resources on correcting

00:27:35.850 --> 00:27:37.050
that data.

00:27:37.050 --> 00:27:38.520
So at some point,
it's just easier

00:27:38.520 --> 00:27:40.350
to move the stop a little bit.

00:27:40.350 --> 00:27:42.427
It doesn't have to
be a long distance.

00:27:42.427 --> 00:27:43.135
AUDIENCE: Got it.

00:27:43.135 --> 00:27:45.260
GABRIEL SANCHEZ-MARTINEZ:
It does not make the same

00:27:45.260 --> 00:27:48.030
and make it far enough apart
that the geo fences can

00:27:48.030 --> 00:27:51.180
be told apart from each other.

00:27:51.180 --> 00:27:51.680
Alright?

00:27:51.680 --> 00:27:54.382
AUDIENCE: Really small scale
data of the EZRide who I work

00:27:54.382 --> 00:27:57.922
for, actually you could
see real-time bus loads

00:27:57.922 --> 00:27:59.340
[INAUDIBLE]--

00:27:59.340 --> 00:28:02.349
GABRIEL SANCHEZ-MARTINEZ:
Oh, interesting.

00:28:02.349 --> 00:28:04.890
AUDIENCE: --which was actually
helpful if you're dispatching,

00:28:04.890 --> 00:28:07.950
and you know a bus is
getting through people on it.

00:28:07.950 --> 00:28:08.450
[INAUDIBLE]

00:28:08.450 --> 00:28:10.450
GABRIEL SANCHEZ-MARTINEZ:
Yeah, for real-time control.

00:28:10.450 --> 00:28:11.070
[INTERPOSING VOICES]

00:28:11.070 --> 00:28:12.778
AUDIENCE: But the
terminal at our station

00:28:12.778 --> 00:28:15.082
had a drop-off point
and a pick-up point.

00:28:15.082 --> 00:28:18.004
The drop-off point was
before layover [INAUDIBLE]

00:28:18.004 --> 00:28:21.570
was after for this exact
reason to make sure

00:28:21.570 --> 00:28:23.361
that it will go through
the drop-off point,

00:28:23.361 --> 00:28:25.009
reset, until people
get off of it.

00:28:25.009 --> 00:28:26.300
GABRIEL SANCHEZ-MARTINEZ: Yeah.

00:28:26.300 --> 00:28:27.192
Yeah, so it happens.

00:28:27.192 --> 00:28:28.025
[INTERPOSING VOICES]

00:28:28.025 --> 00:28:28.900
AUDIENCE: Definitely.

00:28:28.900 --> 00:28:31.179
[INAUDIBLE]

00:28:31.179 --> 00:28:33.262
GABRIEL SANCHEZ-MARTINEZ:
That sounds about right.

00:28:36.324 --> 00:28:37.740
OK, if there are
no more questions

00:28:37.740 --> 00:28:41.859
on the three very important
categories of automated data

00:28:41.859 --> 00:28:43.650
collection systems,
let's talk a little bit

00:28:43.650 --> 00:28:46.360
about the data collection
program design process.

00:28:46.360 --> 00:28:49.920
So this comes from before
automatic data collection.

00:28:49.920 --> 00:28:53.179
And nowadays, we think a
little bit less about this.

00:28:53.179 --> 00:28:54.220
But it's still important.

00:28:54.220 --> 00:28:59.010
So if you do need to
collect some data,

00:28:59.010 --> 00:29:01.500
there's a structure that you
can follow to do it properly

00:29:01.500 --> 00:29:03.660
and to make sure that you
collect data efficiently,

00:29:03.660 --> 00:29:06.624
so that you don't spend too much
resources on data collection

00:29:06.624 --> 00:29:08.790
and that you can answer
your policy or your planning

00:29:08.790 --> 00:29:09.840
questions.

00:29:09.840 --> 00:29:15.060
So based on your needs and
the properties of your agency,

00:29:15.060 --> 00:29:17.400
I say here, determine
property characteristics.

00:29:17.400 --> 00:29:18.630
That's a North American term.

00:29:18.630 --> 00:29:20.050
A property is an agency.

00:29:20.050 --> 00:29:23.259
So if you see that,
that's an agency.

00:29:23.259 --> 00:29:25.800
So based on the characteristics
of the service you're running

00:29:25.800 --> 00:29:28.811
and your data needs, you can
select some data collection

00:29:28.811 --> 00:29:29.310
technique.

00:29:29.310 --> 00:29:31.690
We'll get into what
some of these are.

00:29:31.690 --> 00:29:35.070
Then, you can develop
route-by-route sampling plans

00:29:35.070 --> 00:29:39.810
based on how variable
the data is in each case.

00:29:39.810 --> 00:29:41.900
And you can determine how
many checkers do I need.

00:29:41.900 --> 00:29:44.760
A checker is a person who
goes out and collects data.

00:29:44.760 --> 00:29:46.770
And then from that, the cost--

00:29:46.770 --> 00:29:47.790
so human resources.

00:29:47.790 --> 00:29:49.440
It's a planning exercise.

00:29:49.440 --> 00:29:52.740
And what we do usually is that
we conduct a baseline phase.

00:29:52.740 --> 00:29:57.280
So that's the first time
you go out and collect data.

00:29:57.280 --> 00:30:00.150
You don't know much
about what you're

00:30:00.150 --> 00:30:01.970
wanting to collect data on.

00:30:01.970 --> 00:30:06.870
So it might be only
matrices, or loads,

00:30:06.870 --> 00:30:09.600
the people getting on and off.

00:30:09.600 --> 00:30:13.350
So you have to go out
and do a bigger effort.

00:30:13.350 --> 00:30:15.810
And that's called the
baseline phase effort.

00:30:15.810 --> 00:30:19.020
Once you've done that and you've
established some tendencies,

00:30:19.020 --> 00:30:22.080
you might want to monitor
that to see if it changes.

00:30:22.080 --> 00:30:25.530
So then, you do a lighter weight
data collection effort, where

00:30:25.530 --> 00:30:29.220
you go out and less frequently,
using fewer resources,

00:30:29.220 --> 00:30:31.980
you collect sometimes
the same thing.

00:30:31.980 --> 00:30:37.890
Or sometimes, you observe
something else that is related

00:30:37.890 --> 00:30:41.100
or can be correlated with
what you really want.

00:30:41.100 --> 00:30:44.340
And then based on a
relationship between the two,

00:30:44.340 --> 00:30:46.560
you can estimate
what you really want.

00:30:46.560 --> 00:30:50.090
So you can monitor
what you collected.

00:30:50.090 --> 00:30:51.870
And then, if you
detect that there's

00:30:51.870 --> 00:30:54.360
been a trend or a change, and
you need to investigate it

00:30:54.360 --> 00:30:57.420
further, you might go ahead
and repeat the baseline phase

00:30:57.420 --> 00:30:59.530
to increase your accuracy.

00:30:59.530 --> 00:31:04.080
So one of the catches of
this is that to determine

00:31:04.080 --> 00:31:06.600
sampling plans, to
determine required sample

00:31:06.600 --> 00:31:09.700
sizes to achieve some
confidence interval,

00:31:09.700 --> 00:31:12.120
you need to know how
variable your data is.

00:31:12.120 --> 00:31:15.030
And if you haven't collected
it yet, you don't know.

00:31:15.030 --> 00:31:18.350
So you might have some default
values that you resort to.

00:31:18.350 --> 00:31:20.800
And we'll get to that
later in this lecture.

00:31:20.800 --> 00:31:22.770
But you might also
do a pre-test, where

00:31:22.770 --> 00:31:24.270
you send some
people out, and you

00:31:24.270 --> 00:31:27.150
collect some data
to really start

00:31:27.150 --> 00:31:30.030
to get a sense of
how variable is it,

00:31:30.030 --> 00:31:35.090
and how big will my
sample requirements be,

00:31:35.090 --> 00:31:37.560
and how much will it
cost for me to do this.

00:31:37.560 --> 00:31:40.810
So this is the process
that you might follow.

00:31:40.810 --> 00:31:44.622
And there are different
data needs by the question

00:31:44.622 --> 00:31:45.830
that you're trying to answer.

00:31:45.830 --> 00:31:48.430
So one way of looking
at that is, are you

00:31:48.430 --> 00:31:51.130
collecting things that
are for specific routes,

00:31:51.130 --> 00:31:54.070
or for specific route
segments, or at the stop level?

00:31:54.070 --> 00:31:57.950
Or are you using more aggregate
system level data collection?

00:31:57.950 --> 00:32:00.100
Are your questions
more system level?

00:32:00.100 --> 00:32:02.920
So system-level things
are more about reporting,

00:32:02.920 --> 00:32:06.730
and they might be tied to
things like federal funding.

00:32:06.730 --> 00:32:09.610
Whereas route-level things
and stop-level things

00:32:09.610 --> 00:32:12.020
are more important for planning.

00:32:12.020 --> 00:32:14.860
So when we talk about route
and route segment level,

00:32:14.860 --> 00:32:17.350
we're looking at things like
loads at the peak load points

00:32:17.350 --> 00:32:18.580
or at some other key points.

00:32:18.580 --> 00:32:20.900
How many people are in the bus?

00:32:20.900 --> 00:32:23.980
The running time
is by the segment

00:32:23.980 --> 00:32:26.260
to do schedule that
has time points

00:32:26.260 --> 00:32:30.010
or maybe end-to-end to
your operations plan.

00:32:30.010 --> 00:32:32.470
Schedule adherence-- are
these buses running on time?

00:32:32.470 --> 00:32:34.870
Or are my schedules
not realistic?

00:32:34.870 --> 00:32:37.120
Total boardings or
revenue, two things

00:32:37.120 --> 00:32:41.590
that are highly correlated--
so number of passenger trips.

00:32:41.590 --> 00:32:44.014
Boardings by fare
category-- so you might say,

00:32:44.014 --> 00:32:45.430
well, I want
boardings, but I want

00:32:45.430 --> 00:32:47.170
to know how many
seniors are using this,

00:32:47.170 --> 00:32:50.500
and how many students are using
this, and how many people are

00:32:50.500 --> 00:32:52.540
using monthly passes,
and how many people are

00:32:52.540 --> 00:32:55.750
using pay-per-ride.

00:32:55.750 --> 00:32:58.600
So you have different
fare categories.

00:32:58.600 --> 00:33:03.430
And you might want to
segregate the data by that.

00:33:03.430 --> 00:33:05.920
You might want passenger
boarding and lighting by stop.

00:33:05.920 --> 00:33:07.840
So that's what
APC would give you

00:33:07.840 --> 00:33:10.900
if you have an automated system.

00:33:10.900 --> 00:33:13.540
But you might also use a write
checker, who sits on the bus

00:33:13.540 --> 00:33:16.660
and counts people
boarding in a lighting.

00:33:16.660 --> 00:33:19.690
Transfer rates between routes--
to see you maybe you're

00:33:19.690 --> 00:33:23.460
looking at changing
service so that people

00:33:23.460 --> 00:33:25.920
don't have to transfer.

00:33:25.920 --> 00:33:28.440
Passenger characteristics
and attitudes-- this usually

00:33:28.440 --> 00:33:31.020
requires some degree
of survey, where

00:33:31.020 --> 00:33:35.622
you ask people things,
passenger travel patterns.

00:33:35.622 --> 00:33:37.080
At the system level,
we have things

00:33:37.080 --> 00:33:39.840
like unlinked passenger
trips, passenger miles, linked

00:33:39.840 --> 00:33:40.817
passenger trips.

00:33:40.817 --> 00:33:42.150
This had the whole system level.

00:33:42.150 --> 00:33:45.990
So sometimes, you do route
level or route segment level

00:33:45.990 --> 00:33:47.400
analysis, and
then, you aggregate

00:33:47.400 --> 00:33:48.750
to get the system-level things.

00:33:48.750 --> 00:33:50.970
That's usually how you proceed.

00:33:50.970 --> 00:33:54.120
But the requirements in
terms of how many of these

00:33:54.120 --> 00:33:56.204
you have to sample
might be different.

00:33:56.204 --> 00:33:58.620
So if you want to achieve a
certain accuracy at the system

00:33:58.620 --> 00:34:01.260
level, you don't need
to achieve the accuracy

00:34:01.260 --> 00:34:04.830
for each of the routes
that are in that system

00:34:04.830 --> 00:34:07.740
because you might have--

00:34:07.740 --> 00:34:11.400
so if you want to
say 90% confidence

00:34:11.400 --> 00:34:15.810
in some system-level
data element,

00:34:15.810 --> 00:34:19.239
you might only need 80% or
70% of the element level.

00:34:19.239 --> 00:34:21.000
And once you bring
those altogether,

00:34:21.000 --> 00:34:23.159
you achieve the
90% that you need.

00:34:23.159 --> 00:34:27.840
So data inference, I talked
about how sometimes we

00:34:27.840 --> 00:34:33.280
can infer items if we don't
observe them directly.

00:34:33.280 --> 00:34:36.540
So from AFC with AFC is a
low-fare collection system,

00:34:36.540 --> 00:34:39.449
we have boardings because
people are tapping into the bus

00:34:39.449 --> 00:34:41.560
or tapping into
the subway system.

00:34:41.560 --> 00:34:44.909
And if we have APC, we
count people getting on.

00:34:44.909 --> 00:34:49.360
So we can look at total
number of boardings that way,

00:34:49.360 --> 00:34:50.670
if that makes sense.

00:34:50.670 --> 00:34:51.690
That's pretty direct.

00:34:51.690 --> 00:34:54.300
Sometimes, you want to correct
for errors in the APC system,

00:34:54.300 --> 00:34:57.271
or you might have things
like variation affecting

00:34:57.271 --> 00:34:59.520
that number-- like it goes
from AFC to how many people

00:34:59.520 --> 00:35:00.720
were actually in that bus.

00:35:00.720 --> 00:35:02.100
How many people
actually boarded?

00:35:02.100 --> 00:35:05.160
So you might do a little
bit of manual surveys

00:35:05.160 --> 00:35:09.450
to check what that relationship
is and apply some correction.

00:35:09.450 --> 00:35:11.340
For passenger miles,
we need to know

00:35:11.340 --> 00:35:15.330
how many people are at the
bus between each stop here.

00:35:15.330 --> 00:35:18.930
So AFC gives you boardings
and only boardings.

00:35:18.930 --> 00:35:20.820
APC gives you ons and offs.

00:35:20.820 --> 00:35:23.700
If every bus had APC, then you
could calculate passenger miles

00:35:23.700 --> 00:35:24.630
directly.

00:35:24.630 --> 00:35:28.710
But often, you have systems
where only a portion

00:35:28.710 --> 00:35:29.970
of the fleet has APC.

00:35:29.970 --> 00:35:33.240
So maybe 15% of your fleet
is equipped with APC.

00:35:33.240 --> 00:35:38.220
And from that, you get
the sample OD matrix.

00:35:38.220 --> 00:35:40.080
And you can use that
OD matrix to convert

00:35:40.080 --> 00:35:43.560
from boardings only to the
distribution and the ons

00:35:43.560 --> 00:35:45.810
and offs at all bus routes.

00:35:45.810 --> 00:35:47.760
And from that, you can
get passenger miles.

00:35:47.760 --> 00:35:50.280
Or you might just
use your buses that

00:35:50.280 --> 00:35:54.720
have APC, if that suffices
for your data collection unit.

00:35:54.720 --> 00:35:59.070
Same thing with peak
point load-- similar idea.

00:35:59.070 --> 00:36:01.200
The AFC only measures boardings.

00:36:01.200 --> 00:36:03.940
So it doesn't give you the
peak point load automatically.

00:36:03.940 --> 00:36:05.670
But from APC, you could get it.

00:36:05.670 --> 00:36:09.390
And it you can establish a
relationship between boardings

00:36:09.390 --> 00:36:11.460
and the peak load
point, then you

00:36:11.460 --> 00:36:14.730
can use that model to
infer the peak load

00:36:14.730 --> 00:36:16.200
point from just boardings.

00:36:16.200 --> 00:36:19.620
So this is a key thing to
be efficient about data

00:36:19.620 --> 00:36:20.580
collection.

00:36:20.580 --> 00:36:24.194
Any questions on this idea?

00:36:24.194 --> 00:36:25.176
Yup.

00:36:25.176 --> 00:36:27.140
AUDIENCE: So to get
passenger miles,

00:36:27.140 --> 00:36:29.104
you're also going
to have a GPS system

00:36:29.104 --> 00:36:31.068
as well to know the distance?

00:36:31.068 --> 00:36:33.277
Or are we just basically
[INAUDIBLE] this

00:36:33.277 --> 00:36:34.699
is the routing [INAUDIBLE]?

00:36:34.699 --> 00:36:35.990
GABRIEL SANCHEZ-MARTINEZ: Both.

00:36:35.990 --> 00:36:36.790
AUDIENCE: [INAUDIBLE]

00:36:36.790 --> 00:36:37.730
GABRIEL SANCHEZ-MARTINEZ:
Yeah, both.

00:36:37.730 --> 00:36:39.190
AUDIENCE: [INAUDIBLE]

00:36:39.190 --> 00:36:41.106
GABRIEL SANCHEZ-MARTINEZ:
What tends to happen

00:36:41.106 --> 00:36:44.770
is that the APC, it'll come in.

00:36:44.770 --> 00:36:47.720
And it'll say, at this stop,
this many people boarded.

00:36:47.720 --> 00:36:48.940
This many people are lighted.

00:36:48.940 --> 00:36:52.740
So you have other
layers in your database

00:36:52.740 --> 00:36:55.780
that say where the buses
and what the distance

00:36:55.780 --> 00:37:00.450
is between stops and
the stop pair level.

00:37:00.450 --> 00:37:03.267
So you then essentially
know how many people

00:37:03.267 --> 00:37:05.350
are riding on each link
and how long that link is,

00:37:05.350 --> 00:37:06.391
and you multiply the two.

00:37:06.391 --> 00:37:09.000
So yeah, passenger miles.

00:37:09.000 --> 00:37:10.640
Yeah, more questions.

00:37:10.640 --> 00:37:13.420
AUDIENCE: Yeah, for these
checks that are going on

00:37:13.420 --> 00:37:14.649
like the more manual checks--

00:37:14.649 --> 00:37:15.940
GABRIEL SANCHEZ-MARTINEZ: Yeah.

00:37:15.940 --> 00:37:17.100
AUDIENCE: --I know
often, there's

00:37:17.100 --> 00:37:18.900
derivation checkers who
are coming into a check.

00:37:18.900 --> 00:37:20.775
GABRIEL SANCHEZ-MARTINEZ:
That's right, yeah.

00:37:20.775 --> 00:37:23.480
AUDIENCE: Do they also use
that data to cross-reference

00:37:23.480 --> 00:37:25.370
the passenger counts?

00:37:25.370 --> 00:37:26.790
As in, [? this ?]
person gets on,

00:37:26.790 --> 00:37:28.939
and they check everyone's
voice to [INAUDIBLE] DFL.

00:37:28.939 --> 00:37:30.230
GABRIEL SANCHEZ-MARTINEZ: Yeah.

00:37:30.230 --> 00:37:32.970
AUDIENCE: They then know
exactly how they go on the bus.

00:37:32.970 --> 00:37:34.220
GABRIEL SANCHEZ-MARTINEZ: Yes.

00:37:34.220 --> 00:37:34.615
Yeah.

00:37:34.615 --> 00:37:35.800
AUDIENCE: Do they use that data?

00:37:35.800 --> 00:37:36.740
GABRIEL SANCHEZ-MARTINEZ:
Yeah, they can.

00:37:36.740 --> 00:37:39.350
In the APC, sometimes
there's reliability problems,

00:37:39.350 --> 00:37:41.200
especially when
vehicles are very

00:37:41.200 --> 00:37:43.090
full because
sometimes, people will

00:37:43.090 --> 00:37:44.530
block the sensor by the door.

00:37:47.230 --> 00:37:49.030
Actually, people like
to stand by the door

00:37:49.030 --> 00:37:50.821
all the time, even when
the bus isn't full.

00:37:50.821 --> 00:37:53.235
And that kind of affects APC.

00:37:53.235 --> 00:37:54.610
You might notice
this on the one.

00:37:54.610 --> 00:37:55.600
If you take the one--

00:37:55.600 --> 00:38:00.970
so yeah, you sometimes have a
little bit of a manual effort

00:38:00.970 --> 00:38:01.840
to figure out.

00:38:01.840 --> 00:38:03.730
Just learn about
your APC system,

00:38:03.730 --> 00:38:06.190
and what are the errors,
and when do you see them.

00:38:06.190 --> 00:38:09.430
It often happens that you
have more variation when

00:38:09.430 --> 00:38:10.540
you have very high loads.

00:38:10.540 --> 00:38:12.400
And that's when APC
is least accurate.

00:38:12.400 --> 00:38:15.880
So it all comes together.

00:38:15.880 --> 00:38:17.294
Yeah.

00:38:17.294 --> 00:38:18.210
Questions on the back?

00:38:18.210 --> 00:38:19.330
I think I saw a question.

00:38:19.330 --> 00:38:19.829
No?

00:38:19.829 --> 00:38:22.864
AUDIENCE: Yeah, I
noticed that in Chicago,

00:38:22.864 --> 00:38:26.720
when the bus would be crowded,
then people get off the bus.

00:38:26.720 --> 00:38:28.180
They let people off--

00:38:28.180 --> 00:38:28.660
GABRIEL SANCHEZ-MARTINEZ:
That's right.

00:38:28.660 --> 00:38:28.990
AUDIENCE: --and then back on.

00:38:28.990 --> 00:38:29.510
GABRIEL SANCHEZ-MARTINEZ: Yeah.

00:38:29.510 --> 00:38:30.010
Yeah.

00:38:30.010 --> 00:38:31.210
These double things.

00:38:31.210 --> 00:38:33.296
But somebody might be by
the door just blocking

00:38:33.296 --> 00:38:34.295
the two little sensors--

00:38:34.295 --> 00:38:34.990
[INTERPOSING VOICES]

00:38:34.990 --> 00:38:36.990
GABRIEL SANCHEZ-MARTINEZ:
--the two little eyes.

00:38:36.990 --> 00:38:40.710
And that's it, no records
of people getting on or off.

00:38:44.369 --> 00:38:46.660
So if you're doing a little
data collection, as I said,

00:38:46.660 --> 00:38:48.010
we use checkers.

00:38:48.010 --> 00:38:50.260
And actually, your
second assignment, you

00:38:50.260 --> 00:38:52.630
will be checkers of some kind.

00:38:52.630 --> 00:38:55.550
The typical checkers which you
won't be in this assignment

00:38:55.550 --> 00:38:57.940
are ride checkers
and point checkers.

00:38:57.940 --> 00:39:02.050
So a ride checker sits
in the vehicle and rides

00:39:02.050 --> 00:39:03.370
with the vehicle.

00:39:03.370 --> 00:39:07.540
And the typical thing that these
ride checkers are looking at

00:39:07.540 --> 00:39:10.380
is, how long did it take
to cover some distance?

00:39:10.380 --> 00:39:12.479
So what was the running
time for that trip?

00:39:12.479 --> 00:39:14.020
And also, people
getting on and off--

00:39:14.020 --> 00:39:16.090
so they act as APC essentially.

00:39:16.090 --> 00:39:18.140
And they act as AVL.

00:39:18.140 --> 00:39:20.770
So AVL and APC
together might replace

00:39:20.770 --> 00:39:23.170
most of the functionality
of a ride checker.

00:39:23.170 --> 00:39:26.980
Although a ride checker often
can conduct an onboard survey,

00:39:26.980 --> 00:39:30.250
asking passengers about
where are they going,

00:39:30.250 --> 00:39:33.590
or their trip purpose, or things
related to social demographics,

00:39:33.590 --> 00:39:38.530
which are qualitative and cannot
be collected with the sensors.

00:39:38.530 --> 00:39:40.900
Point checkers stand
outside of the vehicle.

00:39:40.900 --> 00:39:43.720
They stay at a specific
place, and they

00:39:43.720 --> 00:39:46.360
can look at headways
between buses--

00:39:46.360 --> 00:39:49.570
so how long did it take
between each bus to come by,

00:39:49.570 --> 00:39:52.120
and how loaded were these buses?

00:39:52.120 --> 00:39:55.540
So if you're interested
in the peak load point,

00:39:55.540 --> 00:39:57.400
and you know where the
peak load point is,

00:39:57.400 --> 00:40:01.612
and you just want
to observe, measure

00:40:01.612 --> 00:40:03.070
what are the loads
of the peak load

00:40:03.070 --> 00:40:05.530
point, then you can
just station a point

00:40:05.530 --> 00:40:06.880
checker at the peak load point.

00:40:06.880 --> 00:40:09.310
And if that person
is strained, we'll

00:40:09.310 --> 00:40:13.270
be able to more or less say how
many people are in the vehicle

00:40:13.270 --> 00:40:16.680
from looking at the vehicle.

00:40:16.680 --> 00:40:19.212
With automated data
collection systems--

00:40:19.212 --> 00:40:21.420
yeah, with a fair system,
we have passenger accounts.

00:40:21.420 --> 00:40:23.410
We have transaction
data, which is very rich.

00:40:23.410 --> 00:40:25.440
It will tell you not
only that somebody

00:40:25.440 --> 00:40:27.930
is entering or exiting,
but also how much they're

00:40:27.930 --> 00:40:32.430
paying, sometimes information
about the fare product

00:40:32.430 --> 00:40:36.510
type, which might help you
infer if this person is

00:40:36.510 --> 00:40:39.630
a senior, or a student, or a
frequent user, an infrequent

00:40:39.630 --> 00:40:40.290
user--

00:40:40.290 --> 00:40:43.490
so many things that are
very useful for planning.

00:40:43.490 --> 00:40:46.060
And we'll get to play with some
of these later in the course.

00:40:46.060 --> 00:40:49.750
And then, there's Automatic
Passenger Counters, APC.

00:40:49.750 --> 00:40:54.880
So as more and motor systems
switch to automatic data

00:40:54.880 --> 00:40:57.940
collection, we still use
some manual data collection,

00:40:57.940 --> 00:41:01.000
but not in the
traditional sense.

00:41:01.000 --> 00:41:02.920
Now, we reserve those
resources for things

00:41:02.920 --> 00:41:07.180
like surveys about social
demographics and other things.

00:41:07.180 --> 00:41:10.640
And we also carry out
web-based surveys,

00:41:10.640 --> 00:41:12.640
which would have some biases.

00:41:12.640 --> 00:41:16.260
But if people
registered their cards,

00:41:16.260 --> 00:41:18.010
and you have email
accounts, you can maybe

00:41:18.010 --> 00:41:21.730
send a mass email to everyone
and carry out surveys.

00:41:21.730 --> 00:41:23.110
The MBTA does that.

00:41:23.110 --> 00:41:25.090
Maybe some of you
are in the panel

00:41:25.090 --> 00:41:27.670
of people who are e-mailed
every now and then.

00:41:27.670 --> 00:41:29.370
Is anybody in that panel?

00:41:29.370 --> 00:41:30.350
No hands.

00:41:30.350 --> 00:41:31.410
I'm in that panel.

00:41:31.410 --> 00:41:35.006
But I know somebody must be.

00:41:35.006 --> 00:41:37.630
So yeah, they send an email, and
they ask about your last ride.

00:41:37.630 --> 00:41:39.370
And they say, where
did you start from?

00:41:39.370 --> 00:41:41.350
What were you doing
this trip for?

00:41:41.350 --> 00:41:43.900
How long did you have to walk?

00:41:43.900 --> 00:41:45.450
Are you happy with the system?

00:41:45.450 --> 00:41:47.130
Was your bus on time?

00:41:47.130 --> 00:41:48.130
Yeah, things like that--

00:41:48.130 --> 00:41:51.000
how satisfied are you?

00:41:51.000 --> 00:41:53.200
It's a survey with
qualitative questions

00:41:53.200 --> 00:41:55.450
that you couldn't
collect automatically.

00:41:55.450 --> 00:41:57.850
It's [INAUDIBLE] seeing
things about your experience

00:41:57.850 --> 00:42:03.370
outside of the bus, which
there are no sensors for.

00:42:03.370 --> 00:42:05.170
All right, sampling
strategies-- a bunch

00:42:05.170 --> 00:42:08.200
of different ones
and the simplest one

00:42:08.200 --> 00:42:12.200
is called simple random
sampling-- very, very simple.

00:42:12.200 --> 00:42:14.310
So when you have
sample random sampling,

00:42:14.310 --> 00:42:16.060
what happens is that
every trip, if you're

00:42:16.060 --> 00:42:18.850
looking at surveying trips,
for things like how many people

00:42:18.850 --> 00:42:19.930
boarded this trip--

00:42:19.930 --> 00:42:22.960
let's take that as an example.

00:42:22.960 --> 00:42:24.920
Then, if you're using
simple random sampling,

00:42:24.920 --> 00:42:27.490
every trip has equal likelihood
of being picked and being

00:42:27.490 --> 00:42:28.330
surveyed.

00:42:28.330 --> 00:42:33.610
So if you go through
your process,

00:42:33.610 --> 00:42:35.560
and you determine that
you need to observe 100

00:42:35.560 --> 00:42:38.550
trips to get an
average reliably.

00:42:38.550 --> 00:42:42.380
And you're going to use
that to plan something,

00:42:42.380 --> 00:42:44.450
then you need to
look at 100 trips.

00:42:44.450 --> 00:42:46.270
So if you use simple
random sampling,

00:42:46.270 --> 00:42:50.020
you take your schedule, and
you randomly pick 100 trips.

00:42:50.020 --> 00:42:51.190
And that's your sample.

00:42:51.190 --> 00:42:53.860
Those are the ones that you
send people out to collect data.

00:42:53.860 --> 00:42:56.450
Now, there's a little bit
of a problem with that.

00:42:56.450 --> 00:42:57.880
It's not the most
efficient method

00:42:57.880 --> 00:42:59.713
because if you're going
to send someone out,

00:42:59.713 --> 00:43:03.340
and that person is going to be
active, and require some time

00:43:03.340 --> 00:43:06.520
to get to the site and
some time to return, then

00:43:06.520 --> 00:43:08.260
once they're out
there, you want them

00:43:08.260 --> 00:43:10.240
to collect as much as they can.

00:43:10.240 --> 00:43:12.100
So that's not simple
random sampling.

00:43:12.100 --> 00:43:14.600
That's cluster sampling.

00:43:14.600 --> 00:43:16.460
Before we get to that
systematic sampling--

00:43:16.460 --> 00:43:21.350
so typically, instead of
picking randomly, we say,

00:43:21.350 --> 00:43:26.000
OK, we need to get
10% of the trips.

00:43:26.000 --> 00:43:30.290
So let's just make it
such that we count.

00:43:30.290 --> 00:43:33.680
And maybe it's every five
trips, we have to survey it.

00:43:33.680 --> 00:43:35.780
So now, it's evenly spaced.

00:43:35.780 --> 00:43:38.850
And this is useful
for some things.

00:43:38.850 --> 00:43:41.180
One example is weekday,
picking the weekday

00:43:41.180 --> 00:43:43.610
that you're going to survey on.

00:43:43.610 --> 00:43:47.340
So the technique that is often
used is sample every six days.

00:43:47.340 --> 00:43:49.581
Why would that be?

00:43:49.581 --> 00:43:50.080
Yeah.

00:43:50.080 --> 00:43:53.000
So if you do it every seven,
then you always have a Monday.

00:43:53.000 --> 00:43:54.655
And that's going
to get some bias

00:43:54.655 --> 00:43:57.120
if Mondays happen to
be low ridership days

00:43:57.120 --> 00:43:58.420
or high ridership days.

00:43:58.420 --> 00:44:01.630
So if do every sixth
day over a year,

00:44:01.630 --> 00:44:04.390
you have a good sample
of every week day.

00:44:04.390 --> 00:44:07.510
So that's an example
of systematic sampling.

00:44:07.510 --> 00:44:11.830
But you still have
that issue of it

00:44:11.830 --> 00:44:13.540
might not be the most efficient.

00:44:13.540 --> 00:44:17.740
Cluster sampling, sometimes
it's more efficient

00:44:17.740 --> 00:44:20.110
once you send out
a person to collect

00:44:20.110 --> 00:44:22.690
data to do as much as possible.

00:44:22.690 --> 00:44:24.760
And you survey a cluster.

00:44:24.760 --> 00:44:28.510
So one example is, if
you're distributing surveys

00:44:28.510 --> 00:44:31.180
to passengers, and you need
to distribute 100 surveys.

00:44:31.180 --> 00:44:35.071
If you do 100 simple
random sample,

00:44:35.071 --> 00:44:37.570
then those people might be in
different parts of the system.

00:44:37.570 --> 00:44:40.570
And one might be
the first person

00:44:40.570 --> 00:44:43.000
you see getting off
at South Station.

00:44:43.000 --> 00:44:44.920
And then another
one by me might be

00:44:44.920 --> 00:44:48.700
the first person you see getting
off at the Kendall station.

00:44:48.700 --> 00:44:50.270
So that's very inefficient.

00:44:50.270 --> 00:44:53.070
So a cluster might be
everybody on board a bus,

00:44:53.070 --> 00:44:55.690
and that will get a
bunch of people together.

00:44:55.690 --> 00:44:59.470
However, it's not as efficient
statistically to do that.

00:44:59.470 --> 00:45:01.930
So you can't just add
up to 100, and you're

00:45:01.930 --> 00:45:07.360
done because there might be some
correlation within the people

00:45:07.360 --> 00:45:09.670
riding that vehicle
that they will tend

00:45:09.670 --> 00:45:12.310
to answer in a similar way.

00:45:12.310 --> 00:45:14.410
So you might need to
increase your sample size

00:45:14.410 --> 00:45:15.576
when you use this technique.

00:45:15.576 --> 00:45:19.830
But still, you might have a
more efficient sampling plan.

00:45:19.830 --> 00:45:21.290
Then, there is the
ratio estimation

00:45:21.290 --> 00:45:22.520
and conversion factors.

00:45:22.520 --> 00:45:24.560
We gave examples
of this already.

00:45:24.560 --> 00:45:26.820
This is in the context
of baseline phase

00:45:26.820 --> 00:45:28.770
and then monitoring phase.

00:45:28.770 --> 00:45:31.930
So you start out with
a baseline phase.

00:45:31.930 --> 00:45:33.790
And in the baseline
phase, you collect

00:45:33.790 --> 00:45:36.640
the thing you really
want and something

00:45:36.640 --> 00:45:40.480
that is very easily collected
with lower resources.

00:45:40.480 --> 00:45:42.850
And you make a model
of the thing you really

00:45:42.850 --> 00:45:45.910
want as a function
of the thing that

00:45:45.910 --> 00:45:47.920
is cheap and easy to collect.

00:45:47.920 --> 00:45:49.420
And then, on the
monitoring phase,

00:45:49.420 --> 00:45:54.310
you only measure the thing that
is cheap, and easy, and quick.

00:45:54.310 --> 00:45:57.890
And you then use the model to
estimate what you really want.

00:45:57.890 --> 00:46:00.790
So converting AFC boarding
to passenger miles,

00:46:00.790 --> 00:46:02.320
we give an example of that.

00:46:02.320 --> 00:46:04.090
We're converting
loads at checkpoints

00:46:04.090 --> 00:46:05.840
to load somewhere else.

00:46:05.840 --> 00:46:07.840
So maybe only measure
loads with a point

00:46:07.840 --> 00:46:09.640
checker at the peak load point.

00:46:09.640 --> 00:46:12.910
And you have some relationship
to convert those loads

00:46:12.910 --> 00:46:18.702
to loads at other key transfer
stations as an example.

00:46:18.702 --> 00:46:20.160
And then, the
stratified sampling--

00:46:20.160 --> 00:46:23.970
so one of the things that
determines how big of a sample

00:46:23.970 --> 00:46:25.830
you need is the
variability in the data

00:46:25.830 --> 00:46:26.910
that you're collecting.

00:46:26.910 --> 00:46:30.900
So correlation,
when you're looking

00:46:30.900 --> 00:46:35.650
at a whole system with multiple
routes or multiple segments--

00:46:35.650 --> 00:46:37.690
maybe when you
look at one route,

00:46:37.690 --> 00:46:42.550
there's some variability
of running times.

00:46:42.550 --> 00:46:44.770
But they have a central
tendency as well.

00:46:44.770 --> 00:46:46.420
And when you've
got a second route,

00:46:46.420 --> 00:46:48.392
you have also some
variability and

00:46:48.392 --> 00:46:49.600
a different central tendency.

00:46:49.600 --> 00:46:51.624
So you bunch all
the data together,

00:46:51.624 --> 00:46:54.040
some of the variability across
data points in our data set

00:46:54.040 --> 00:46:56.980
are going to be the inherent
variability of each route.

00:46:56.980 --> 00:46:59.920
And some of it will be
systematic-- the differences

00:46:59.920 --> 00:47:01.390
between both routes.

00:47:01.390 --> 00:47:03.340
So if you do a
simple random sample,

00:47:03.340 --> 00:47:05.800
and you don't separate
the systematic variability

00:47:05.800 --> 00:47:08.560
from the inherent
variability, then you're

00:47:08.560 --> 00:47:10.650
going to get a
wider variability.

00:47:10.650 --> 00:47:13.270
And you will require
a bigger sample size.

00:47:13.270 --> 00:47:14.950
Stratified sampling
is an approach

00:47:14.950 --> 00:47:18.790
where you determine sample sizes
for each of these separately.

00:47:18.790 --> 00:47:21.790
And it's more efficient
if you do it well

00:47:21.790 --> 00:47:25.270
because you eliminate
the need, or you at least

00:47:25.270 --> 00:47:28.600
reduce the need, to
collect data for the sake

00:47:28.600 --> 00:47:32.380
of the systematic differences
between different parts

00:47:32.380 --> 00:47:35.090
of the system.

00:47:35.090 --> 00:47:36.450
Any questions on these methods?

00:47:39.614 --> 00:47:41.066
Yes.

00:47:41.066 --> 00:47:42.518
AUDIENCE: [INAUDIBLE]

00:47:45.034 --> 00:47:46.450
GABRIEL SANCHEZ-MARTINEZ:
Yeah, so

00:47:46.450 --> 00:47:47.860
let's maybe pick
another example.

00:47:55.330 --> 00:48:01.130
Let's say that you're looking
at the proportion of passengers

00:48:01.130 --> 00:48:04.070
in a bus who are students.

00:48:04.070 --> 00:48:05.660
And you're
distributing a survey.

00:48:05.660 --> 00:48:11.800
And they tell you whether
they're students or not.

00:48:11.800 --> 00:48:13.820
And you want this
for the whole system

00:48:13.820 --> 00:48:16.830
or for at least a
group of routes.

00:48:16.830 --> 00:48:19.900
And it tends to be that some
routes don't serve universities

00:48:19.900 --> 00:48:20.900
and don't serve schools.

00:48:20.900 --> 00:48:24.020
So they have a lower
proportion of people.

00:48:24.020 --> 00:48:26.690
And then, some routes that
do go through universities,

00:48:26.690 --> 00:48:28.860
and they have a higher
proportion of students.

00:48:28.860 --> 00:48:33.290
So if you just want the
system-wide proportion

00:48:33.290 --> 00:48:36.890
of people who are students, and
you join all these data points

00:48:36.890 --> 00:48:39.320
together, there's going
to be a lot of variability

00:48:39.320 --> 00:48:41.630
in what proportion that
is across every trip

00:48:41.630 --> 00:48:44.930
that you survey, correct?

00:48:44.930 --> 00:48:49.610
So in some sense,
it will indicate

00:48:49.610 --> 00:48:51.290
that because of
that variability,

00:48:51.290 --> 00:48:55.260
you're going to need a
higher sampling size.

00:48:55.260 --> 00:48:57.830
You're going to have
to survey more trips

00:48:57.830 --> 00:49:02.810
to get at your desired
accuracy level and tolerance.

00:49:02.810 --> 00:49:06.080
But now, if you say no, I'm
going to split routes in two,

00:49:06.080 --> 00:49:07.100
into two stratas.

00:49:07.100 --> 00:49:11.060
One is the routes that
serve the universities.

00:49:11.060 --> 00:49:16.700
And these tend to have
around 50% proportion.

00:49:16.700 --> 00:49:19.610
And then, there's the routes
that don't serve universities.

00:49:19.610 --> 00:49:23.180
And these tend to have
proportions near 0.

00:49:23.180 --> 00:49:27.260
So if you're in your 0, you
might require a lower sample

00:49:27.260 --> 00:49:28.700
size to cover those.

00:49:28.700 --> 00:49:30.410
And you can just
very efficiently

00:49:30.410 --> 00:49:32.480
cover most of your
bus routes that way.

00:49:32.480 --> 00:49:35.030
And then, focus your
efforts on just the ones

00:49:35.030 --> 00:49:37.160
that have higher proportion.

00:49:37.160 --> 00:49:39.980
And you achieved your
system-level tolerance

00:49:39.980 --> 00:49:44.990
requirements with much fewer,
with by far fewer resources

00:49:44.990 --> 00:49:47.069
required to collect the data.

00:49:47.069 --> 00:49:48.360
Does that answer your question?

00:49:48.360 --> 00:49:48.942
Yeah.

00:49:48.942 --> 00:49:50.298
AUDIENCE: [INAUDIBLE]

00:49:52.260 --> 00:49:54.510
GABRIEL SANCHEZ-MARTINEZ:
So what he meant by inherent

00:49:54.510 --> 00:49:57.600
is that within each bus
route or within each strata,

00:49:57.600 --> 00:49:59.130
there will be some variability.

00:49:59.130 --> 00:50:02.130
Even within the trips that
are serving universities,

00:50:02.130 --> 00:50:04.530
every trip might have
a different proportion.

00:50:04.530 --> 00:50:07.120
So there's going to be a little
bit of variability in that.

00:50:07.120 --> 00:50:10.600
But if you mix that with trips
that are not serving students,

00:50:10.600 --> 00:50:12.992
then you pull all
that data together.

00:50:12.992 --> 00:50:15.450
Then, it's going to look like
the variance of that data set

00:50:15.450 --> 00:50:16.170
is much higher.

00:50:20.950 --> 00:50:23.200
All right, so we've
tossed these terms

00:50:23.200 --> 00:50:25.430
around-- tolerance,
confidence, level accuracy.

00:50:25.430 --> 00:50:27.996
So let's define
them more precisely.

00:50:27.996 --> 00:50:29.620
Accuracy-- when we
talk about accuracy,

00:50:29.620 --> 00:50:31.960
that has two dimensions.

00:50:31.960 --> 00:50:36.070
So somebody might say, the
average boardings per trip

00:50:36.070 --> 00:50:38.032
is 33.1.

00:50:38.032 --> 00:50:39.490
And then, the
question that follows

00:50:39.490 --> 00:50:42.070
is, do you mean exactly 33.1?

00:50:42.070 --> 00:50:43.570
How certain are you of that?

00:50:43.570 --> 00:50:45.100
And how accurate is that?

00:50:45.100 --> 00:50:48.970
So when we talk about tolerance,
there's relative tolerance,

00:50:48.970 --> 00:50:50.860
and there's absolute tolerance.

00:50:50.860 --> 00:50:52.750
Relative tolerance
is expressed in terms

00:50:52.750 --> 00:50:57.760
of a percent of the amount you
were collecting or a fraction.

00:50:57.760 --> 00:51:01.660
So you might say mean
boardings per trip is 33.1,

00:51:01.660 --> 00:51:03.170
plus or minus 10%.

00:51:03.170 --> 00:51:05.710
And that's the 10% of 33.1.

00:51:05.710 --> 00:51:07.876
That's why it's
relative tolerance.

00:51:07.876 --> 00:51:09.250
Then, there's
absolute tolerance.

00:51:09.250 --> 00:51:14.240
So mean boarding per trip
is 33.1, plus or minus 3.3.

00:51:14.240 --> 00:51:17.630
Now, in this case, these
two are equivalent.

00:51:17.630 --> 00:51:20.810
3.3 in absolute
terms is 10% of 33.1.

00:51:20.810 --> 00:51:23.600
But this was expressed
in absolute terms,

00:51:23.600 --> 00:51:25.820
and the previous one was
expressed in relative terms.

00:51:28.766 --> 00:51:32.130
So don't always assume
that if you see a percent,

00:51:32.130 --> 00:51:35.190
it's relative because if what
you're measuring is in itself

00:51:35.190 --> 00:51:38.850
a percent, unless you're
using a percent of a percent,

00:51:38.850 --> 00:51:39.930
then it's absolute.

00:51:39.930 --> 00:51:41.940
So here's an example.

00:51:41.940 --> 00:51:46.740
Mean percentage of students
is 23%, plus or minus 5%.

00:51:46.740 --> 00:51:49.785
That's absolute because
it's 5%, not 5% of 23%.

00:51:54.660 --> 00:51:57.480
First, we talked about,
is that exactly 33.1?

00:51:57.480 --> 00:52:00.010
Or is it something
different from 33.1?

00:52:00.010 --> 00:52:02.460
Then, the second question
is, how sure are you,

00:52:02.460 --> 00:52:06.310
how confident are you
that the number you give,

00:52:06.310 --> 00:52:12.320
plus or minus the tolerance
you give, is the right answer?

00:52:12.320 --> 00:52:15.400
So now, you say
I'm 95% confident

00:52:15.400 --> 00:52:18.355
that the mean boardings per
trip is 33.1, plus or minus 10%.

00:52:18.355 --> 00:52:20.347
So now, you combine
the tolerance

00:52:20.347 --> 00:52:21.430
with the confidence level.

00:52:21.430 --> 00:52:24.170
And that's the full
expression of your accuracy.

00:52:24.170 --> 00:52:27.740
And that's what you need when
we look at the data collection.

00:52:27.740 --> 00:52:30.800
So you have two different
things that you could play with.

00:52:30.800 --> 00:52:33.860
And what happens typically
is that you choose

00:52:33.860 --> 00:52:35.210
a high confidence level--

00:52:35.210 --> 00:52:38.150
90%, 95 percent are typical.

00:52:38.150 --> 00:52:39.830
And then, you hold that fixed.

00:52:39.830 --> 00:52:42.830
And you calculate what
level of accuracy you need.

00:52:42.830 --> 00:52:45.020
Or rather, you decide
what level of accuracy

00:52:45.020 --> 00:52:48.110
you need, depending on the
question you want to answer,

00:52:48.110 --> 00:52:51.560
and the impact it could
have on the system.

00:52:51.560 --> 00:52:54.350
So if you're looking to
[INAUDIBLE] something

00:52:54.350 --> 00:53:01.850
that will have very significant
effects on the service plan

00:53:01.850 --> 00:53:04.070
or maybe on investment
in the system,

00:53:04.070 --> 00:53:07.430
then you might need
a higher accuracy.

00:53:07.430 --> 00:53:10.597
But if you're collecting
data just for reporting,

00:53:10.597 --> 00:53:11.930
maybe it doesn't matter as much.

00:53:11.930 --> 00:53:15.830
And you don't need to spend as
much money on data collection.

00:53:15.830 --> 00:53:20.540
So as an example here, the
National Transit Database--

00:53:20.540 --> 00:53:23.150
NTD, we call it NTD--

00:53:23.150 --> 00:53:26.150
for annual boardings and
passenger miles, it says,

00:53:26.150 --> 00:53:27.740
you should collect
data to achieve

00:53:27.740 --> 00:53:31.890
an accuracy of 10%, relative
tolerance at 95% confidence

00:53:31.890 --> 00:53:33.250
level.

00:53:33.250 --> 00:53:36.090
You need both.

00:53:36.090 --> 00:53:38.340
So take home message about this.

00:53:38.340 --> 00:53:40.630
The other thing,
the t distribution--

00:53:40.630 --> 00:53:43.920
so this is a probability
distribution that

00:53:43.920 --> 00:53:44.960
is bell-shaped.

00:53:44.960 --> 00:53:47.490
It kind of looks like
the normal distribution.

00:53:47.490 --> 00:53:49.440
And it approaches the
normal distribution

00:53:49.440 --> 00:53:52.330
as the sample size
gets very large.

00:53:52.330 --> 00:53:54.960
This is the distribution
that arises naturally

00:53:54.960 --> 00:53:58.110
when you're estimating the
mean of a population that

00:53:58.110 --> 00:54:01.950
is normally distributed with
unknown mean and variance

00:54:01.950 --> 00:54:04.380
and some known sample size.

00:54:04.380 --> 00:54:08.870
So to the right here,
we have your equations

00:54:08.870 --> 00:54:11.990
that I'm sure you've seen
before for sample mean, sample

00:54:11.990 --> 00:54:13.880
variance.

00:54:13.880 --> 00:54:15.740
And I guess, what's
important to think

00:54:15.740 --> 00:54:18.470
about is that the
distribution of what

00:54:18.470 --> 00:54:20.220
you're collecting--
for example, you

00:54:20.220 --> 00:54:23.630
might be collecting data on a
number of people boarding route

00:54:23.630 --> 00:54:25.100
1.

00:54:25.100 --> 00:54:29.390
So that might have
some distribution.

00:54:29.390 --> 00:54:31.440
As you collect
more and more data,

00:54:31.440 --> 00:54:36.350
so as you survey
more and more trips,

00:54:36.350 --> 00:54:40.700
the distribution of how
many people board each trip

00:54:40.700 --> 00:54:43.400
does not necessarily
have to be normal.

00:54:43.400 --> 00:54:45.980
But it turns out from
the Central Limit Theorem

00:54:45.980 --> 00:54:52.990
and other laws and properties
of statistics and probability

00:54:52.990 --> 00:54:54.920
that the distribution
of the estimator--

00:54:54.920 --> 00:54:58.570
so the distribution of the
mean that you calculate based

00:54:58.570 --> 00:55:00.040
on that sample that
you collected--

00:55:00.040 --> 00:55:03.380
is normally distributed as
the sample size increases.

00:55:03.380 --> 00:55:06.402
So if you have a
lower sample size,

00:55:06.402 --> 00:55:08.110
instead of using the
normal distribution,

00:55:08.110 --> 00:55:10.650
use t distribution.

00:55:10.650 --> 00:55:12.730
Sometimes, we call that
a student, the t student

00:55:12.730 --> 00:55:13.780
distribution.

00:55:13.780 --> 00:55:20.440
And this distribution gets wider
as the variability increases

00:55:20.440 --> 00:55:23.310
and as the sample
size gets smaller.

00:55:23.310 --> 00:55:26.090
It has a property called
degrees of freedom,

00:55:26.090 --> 00:55:28.360
which is sample size minus 1.

00:55:28.360 --> 00:55:31.294
And you can see from this
chart right here when

00:55:31.294 --> 00:55:32.710
you have degrees
of freedom equals

00:55:32.710 --> 00:55:35.540
1, which means you
collected two data points,

00:55:35.540 --> 00:55:38.870
it's wider than when
V approaches infinity.

00:55:38.870 --> 00:55:42.610
And what you have in black here,
the thinnest and least variable

00:55:42.610 --> 00:55:46.520
of these, is essentially
a normal distribution.

00:55:46.520 --> 00:55:48.990
And this is the distribution
not of what you collected.

00:55:48.990 --> 00:55:52.540
It's not the distribution
of the number

00:55:52.540 --> 00:55:54.250
of people who boarded route 1.

00:55:54.250 --> 00:55:58.690
It's the distribution of
the mean that you estimate.

00:55:58.690 --> 00:55:59.860
AUDIENCE: [INAUDIBLE]

00:55:59.860 --> 00:56:00.550
GABRIEL SANCHEZ-MARTINEZ:
Exactly, it's

00:56:00.550 --> 00:56:02.420
a sampling distribution
of the mean.

00:56:02.420 --> 00:56:05.980
And if you were to repeat that
experiment with the same number

00:56:05.980 --> 00:56:08.680
of trips but different
number of trips,

00:56:08.680 --> 00:56:11.320
you might get a
slightly different mean.

00:56:11.320 --> 00:56:14.110
So if you were to repeat
that many, many times,

00:56:14.110 --> 00:56:19.145
the distribution of those means
would be shaped in this manner.

00:56:19.145 --> 00:56:20.020
AUDIENCE: [INAUDIBLE]

00:56:20.020 --> 00:56:22.519
GABRIEL SANCHEZ-MARTINEZ: Yeah,
well, student t distributed.

00:56:22.519 --> 00:56:26.700
And as sample size increases to
infinity, normally distributed.

00:56:26.700 --> 00:56:27.200
Harry.

00:56:27.200 --> 00:56:32.009
AUDIENCE: So just for V equals
5, I think you [INAUDIBLE]..

00:56:32.009 --> 00:56:33.175
GABRIEL SANCHEZ-MARTINEZ: 4.

00:56:33.175 --> 00:56:33.620
AUDIENCE: 4.

00:56:33.620 --> 00:56:34.460
GABRIEL SANCHEZ-MARTINEZ:
Sorry, 6.

00:56:34.460 --> 00:56:35.308
6.

00:56:35.308 --> 00:56:36.955
AUDIENCE: Approximately
5 [INAUDIBLE]..

00:56:36.955 --> 00:56:38.330
GABRIEL
SANCHEZ-MARTINEZ: Yes, 6.

00:56:38.330 --> 00:56:39.280
Yeah.

00:56:39.280 --> 00:56:41.950
I mispoke.

00:56:41.950 --> 00:56:43.940
[INAUDIBLE]

00:56:43.940 --> 00:56:47.340
AUDIENCE: When there's a sample
variance, sigma x squared

00:56:47.340 --> 00:56:48.320
equals roughly.

00:56:48.320 --> 00:56:50.250
Is that not supposed
to be an equals?

00:56:50.250 --> 00:56:52.890
Is that not the way the
sample variances define?

00:56:52.890 --> 00:56:56.104
Because I thought it's the--

00:56:56.104 --> 00:56:57.645
GABRIEL SANCHEZ-MARTINEZ:
So-- --it's

00:56:57.645 --> 00:56:59.103
below the variance
of distribution.

00:56:59.103 --> 00:57:02.110
But that's roughly [INAUDIBLE].

00:57:02.110 --> 00:57:05.380
AUDIENCE: Yeah, I guess
the issue is that you

00:57:05.380 --> 00:57:10.060
don't know the true mean.

00:57:10.060 --> 00:57:14.530
So you're using an estimate to
calculate the sample variance.

00:57:14.530 --> 00:57:17.517
And therefore, it's almost,
almost the sample variance.

00:57:17.517 --> 00:57:18.850
GABRIEL SANCHEZ-MARTINEZ: Right.

00:57:18.850 --> 00:57:19.782
But I thought--

00:57:19.782 --> 00:57:21.240
AUDIENCE: You're
using an estimator

00:57:21.240 --> 00:57:23.340
to do the-- that's
what you have to do.

00:57:23.340 --> 00:57:24.700
[INTERPOSING VOICES]

00:57:24.700 --> 00:57:26.390
AUDIENCE: He's
incorporating the fact

00:57:26.390 --> 00:57:29.350
we're dividing by n minus 1
rather dividing by [INAUDIBLE]..

00:57:29.350 --> 00:57:31.225
GABRIEL SANCHEZ-MARTINEZ:
No, so n minus 1,

00:57:31.225 --> 00:57:34.450
that has to do with the
degrees of freedom issue.

00:57:34.450 --> 00:57:38.750
And that's to go from population
variance to sample variance.

00:57:38.750 --> 00:57:40.630
But the other thing
that happens is

00:57:40.630 --> 00:57:43.760
that if you're doing
the population,

00:57:43.760 --> 00:57:46.200
then you know exactly
what your mean is.

00:57:46.200 --> 00:57:47.295
It's exact, right?

00:57:47.295 --> 00:57:47.920
AUDIENCE: Yeah.

00:57:47.920 --> 00:57:49.920
GABRIEL SANCHEZ-MARTINEZ:
And then in that case,

00:57:49.920 --> 00:57:52.500
you would know what the
exact variances is as well.

00:57:52.500 --> 00:57:53.080
Yeah.

00:57:53.080 --> 00:57:55.900
So the n minus 1
is just to remove

00:57:55.900 --> 00:57:59.700
a bias that would arise from
collecting only a sample.

00:57:59.700 --> 00:58:01.460
AUDIENCE: But here
for example, you

00:58:01.460 --> 00:58:03.960
can say this is
equals to [INAUDIBLE]..

00:58:03.960 --> 00:58:04.960
GABRIEL SANCHEZ-MARTINEZ:
Yeah, yeah, yeah, yeah.

00:58:04.960 --> 00:58:05.792
AUDIENCE: You're
working with the sample

00:58:05.792 --> 00:58:07.890
to know it would be an
approximate [INAUDIBLE]..

00:58:07.890 --> 00:58:09.310
GABRIEL SANCHEZ-MARTINEZ:
Yeah, in practice equal 2.

00:58:09.310 --> 00:58:11.270
AUDIENCE: As your
sample distribution

00:58:11.270 --> 00:58:13.377
increases, then obviously,
your sample increases--

00:58:13.377 --> 00:58:14.210
[INTERPOSING VOICES]

00:58:14.210 --> 00:58:14.920
GABRIEL SANCHEZ-MARTINEZ:
And therefore, this

00:58:14.920 --> 00:58:16.030
becomes more and more accurate.

00:58:16.030 --> 00:58:16.660
AUDIENCE: [INAUDIBLE]

00:58:16.660 --> 00:58:17.080
GABRIEL SANCHEZ-MARTINEZ:
Exactly.

00:58:17.080 --> 00:58:18.640
AUDIENCE: It should be
approaching more [INAUDIBLE]..

00:58:18.640 --> 00:58:19.180
GABRIEL SANCHEZ-MARTINEZ:
Yeah, so I

00:58:19.180 --> 00:58:20.620
guess what's
important to realize

00:58:20.620 --> 00:58:27.430
is that this is an estimate of
the population variance, which

00:58:27.430 --> 00:58:30.260
in itself uses another estimate.

00:58:30.260 --> 00:58:32.200
And I guess, that's
why that's there.

00:58:32.200 --> 00:58:33.530
But it's a very small detail.

00:58:33.530 --> 00:58:37.496
I didn't mean to distract you.

00:58:37.496 --> 00:58:42.046
AUDIENCE: So for the n, is it
the sum of all the different

00:58:42.046 --> 00:58:43.730
samples of [INAUDIBLE]
or is it just--

00:58:43.730 --> 00:58:44.070
[INTERPOSING VOICES]

00:58:44.070 --> 00:58:45.630
GABRIEL SANCHEZ-MARTINEZ:
So you don't ever

00:58:45.630 --> 00:58:47.160
repeat the experiment like this.

00:58:47.160 --> 00:58:49.800
This is more of a
theoretical explanation

00:58:49.800 --> 00:58:52.420
to why there is a
distribution to the mean,

00:58:52.420 --> 00:58:53.850
even though you only have one.

00:58:53.850 --> 00:58:55.380
You only have one mean, right?

00:58:55.380 --> 00:58:57.340
Because you're going
to collect data.

00:58:57.340 --> 00:58:59.100
And once you finish
collecting data,

00:58:59.100 --> 00:59:01.680
you're going to calculate
the mean of all that data.

00:59:01.680 --> 00:59:04.020
So you only have one mean.

00:59:04.020 --> 00:59:08.160
If you were hypothetically
to repeat that experiment,

00:59:08.160 --> 00:59:10.656
and you calculated separate
means for each one,

00:59:10.656 --> 00:59:12.030
then you would
get a distribution

00:59:12.030 --> 00:59:14.220
that would look like this.

00:59:14.220 --> 00:59:17.100
In practice, you would just
increase your sample size

00:59:17.100 --> 00:59:21.554
and still compute one mean,
which would be more accurate.

00:59:21.554 --> 00:59:22.054
Yeah.

00:59:24.910 --> 00:59:27.010
OK, let's move on.

00:59:27.010 --> 00:59:28.629
So tolerance and
confidence level--

00:59:28.629 --> 00:59:29.920
so we have these distributions.

00:59:29.920 --> 00:59:33.760
These are the distributions
of the statistics,

00:59:33.760 --> 00:59:35.310
of the mean in this case.

00:59:35.310 --> 00:59:36.640
They are bell-shaped.

00:59:36.640 --> 00:59:41.977
As your sample size increases,
the degrees of freedom goes up.

00:59:41.977 --> 00:59:43.060
And your accuracy goes up.

00:59:43.060 --> 00:59:45.790
And the variance of that
statistic distribution

00:59:45.790 --> 00:59:46.370
decreases.

00:59:46.370 --> 00:59:47.770
So it gets thinner.

00:59:47.770 --> 00:59:52.240
So here in red, you have a
distribution with a smaller

00:59:52.240 --> 00:59:55.570
sample, and therefore, less
accuracy or less confidence

00:59:55.570 --> 00:59:56.590
would look like.

00:59:56.590 --> 00:59:59.260
And then as you increase
your sample size,

00:59:59.260 --> 01:00:04.120
you see that it
becomes more peaky.

01:00:04.120 --> 01:00:09.130
So when we talk about
tolerance, and let's

01:00:09.130 --> 01:00:11.170
come back to the concept
of absolute tolerance

01:00:11.170 --> 01:00:13.330
in particular, we're
talking about the distance

01:00:13.330 --> 01:00:16.000
between the center of
that distribution, which

01:00:16.000 --> 01:00:20.020
is a symmetrical
distribution, and some limit.

01:00:20.020 --> 01:00:24.460
So we're saying, if you have
a tolerance of plus/minus 10.

01:00:24.460 --> 01:00:28.390
Then, you're going to
measure 10, say 10 boardings,

01:00:28.390 --> 01:00:32.270
from the center to the right
and from the center to the left.

01:00:32.270 --> 01:00:35.590
And that's your
absolute tolerance.

01:00:35.590 --> 01:00:38.410
So when you calculate
absolute tolerance,

01:00:38.410 --> 01:00:40.750
you can express that
tolerance as a function

01:00:40.750 --> 01:00:46.210
of the variance and/or
the standard deviation,

01:00:46.210 --> 01:00:48.790
rather of your mean.

01:00:48.790 --> 01:00:52.750
So instead of saying 10,
you could say 2 times

01:00:52.750 --> 01:00:57.010
the standard deviation of that
distribution using the equation

01:00:57.010 --> 01:00:58.496
that we just calculated.

01:00:58.496 --> 01:00:59.620
And that's very convenient.

01:00:59.620 --> 01:01:02.100
Why would we do that?

01:01:02.100 --> 01:01:04.170
Why would I want to
complicate things that way?

01:01:07.068 --> 01:01:09.075
AUDIENCE: [? Outside ?]
[? of ?] a cumulative

01:01:09.075 --> 01:01:10.950
GABRIEL SANCHEZ-MARTINEZ:
No, I mean, there's

01:01:10.950 --> 01:01:12.690
a mathematical convenience here.

01:01:12.690 --> 01:01:15.420
What is this a function of?

01:01:15.420 --> 01:01:18.510
It's a function of
the standard deviation

01:01:18.510 --> 01:01:22.490
of the thing you were collecting
and your sample size, right?

01:01:22.490 --> 01:01:23.670
And what do we want to do?

01:01:23.670 --> 01:01:25.470
We want to determine
how many things we

01:01:25.470 --> 01:01:26.670
need to collect, right?

01:01:26.670 --> 01:01:27.570
So here we go--

01:01:27.570 --> 01:01:28.650
we have n.

01:01:28.650 --> 01:01:32.280
And now we can solve for
n, we have the sample size

01:01:32.280 --> 01:01:34.380
that we require for
a given tolerance.

01:01:34.380 --> 01:01:37.560
So we're going to decide
what the tolerance is

01:01:37.560 --> 01:01:41.100
and calculate sample size, a
minimum required sample size.

01:01:41.100 --> 01:01:44.030
You can always
collect more data.

01:01:44.030 --> 01:01:44.810
All right.

01:01:44.810 --> 01:01:46.790
So again, to review,
this is the same equation

01:01:46.790 --> 01:01:48.200
I had in the last slide.

01:01:48.200 --> 01:01:51.020
You have absolutely tolerance.

01:01:51.020 --> 01:01:54.740
You can express
that as a multiplier

01:01:54.740 --> 01:01:59.270
times the standard
deviation of the mean.

01:01:59.270 --> 01:02:02.330
And then you solve for n,
and you get this equation

01:02:02.330 --> 01:02:03.260
right here.

01:02:03.260 --> 01:02:06.170
t is your tolerance
and you can--

01:02:06.170 --> 01:02:09.980
oh, sorry. t is the number
of standard deviations

01:02:09.980 --> 01:02:11.690
from the mean.

01:02:11.690 --> 01:02:14.600
d is your tolerance,
which you choose.

01:02:14.600 --> 01:02:17.090
And this is something
that you know, or collect,

01:02:17.090 --> 01:02:18.410
or approximate.

01:02:18.410 --> 01:02:20.210
So these are all given.

01:02:20.210 --> 01:02:21.510
Where does t come from?

01:02:21.510 --> 01:02:24.050
Well, we said that
we're going to use the t

01:02:24.050 --> 01:02:24.890
distribution, right?

01:02:24.890 --> 01:02:28.220
So the t distribution
has a table--

01:02:28.220 --> 01:02:30.230
or it has a certain
shape, rather.

01:02:30.230 --> 01:02:32.870
And using Excel or
looking up at some table,

01:02:32.870 --> 01:02:38.030
you can figure out
what t is for two times

01:02:38.030 --> 01:02:40.890
the standard deviation
from the center.

01:02:40.890 --> 01:02:43.820
So you can just plug it
in from Excel or from--

01:02:43.820 --> 01:02:46.040
it's a property of the
distribution, essentially.

01:02:46.040 --> 01:02:48.890
Once you pick a confidence
interval, you know t.

01:02:48.890 --> 01:02:51.470
If you want to go to 95,
it's a certain value.

01:02:51.470 --> 01:02:54.320
If you want to go to 90,
it's a different value.

01:02:54.320 --> 01:02:55.460
OK.

01:02:55.460 --> 01:02:57.050
When we look at
relative tolerance,

01:02:57.050 --> 01:03:00.740
relative tolerance is
just absolute tolerance

01:03:00.740 --> 01:03:03.890
divided by the mean that
you are collecting, correct?

01:03:03.890 --> 01:03:06.890
Because instead of saying
plus or minus 10 boardings,

01:03:06.890 --> 01:03:09.380
we're saying plus or
minus 5% of the mean.

01:03:09.380 --> 01:03:13.730
So we just take absolute
tolerance and divide by x bar,

01:03:13.730 --> 01:03:17.240
the sampling mean,
the sample mean.

01:03:17.240 --> 01:03:19.040
And we solve for n again.

01:03:19.040 --> 01:03:23.690
So what we have now, it looks
very similar as to the question

01:03:23.690 --> 01:03:24.570
right here.

01:03:24.570 --> 01:03:27.660
But now we have the mean
and the denominator.

01:03:27.660 --> 01:03:30.860
OK, this quantity,
standard deviation

01:03:30.860 --> 01:03:34.040
divided by mean, sample
standard deviation divided

01:03:34.040 --> 01:03:38.200
by sampling mean, is called
the coefficient of variation.

01:03:38.200 --> 01:03:40.930
And there's a
convenience to this.

01:03:40.930 --> 01:03:44.192
And there's actually
a reason why

01:03:44.192 --> 01:03:45.900
sometimes relative
tolerance is preferred

01:03:45.900 --> 01:03:46.820
to absolute tolerance.

01:03:46.820 --> 01:03:48.361
It's because of
this, because there's

01:03:48.361 --> 01:03:52.620
a mathematically convenient
characteristic of property

01:03:52.620 --> 01:03:53.760
coming out of this--

01:03:53.760 --> 01:03:57.270
that you don't need to know
the standard deviation of what

01:03:57.270 --> 01:04:00.300
you're collecting to figure
out your sample size.

01:04:00.300 --> 01:04:02.310
We're kind of running
in circles here, right?

01:04:02.310 --> 01:04:04.101
We're saying that to
determine sample size,

01:04:04.101 --> 01:04:05.829
you need to know the
standard deviation.

01:04:05.829 --> 01:04:07.120
Well, I haven't collected data.

01:04:07.120 --> 01:04:09.009
So I don't know how
variable the data is.

01:04:09.009 --> 01:04:09.800
So that's an issue.

01:04:09.800 --> 01:04:11.820
Now I have to
estimate what that is.

01:04:11.820 --> 01:04:15.510
It tends to happen that the
coefficient of variation

01:04:15.510 --> 01:04:19.230
is a more stable property
than the variation in itself,

01:04:19.230 --> 01:04:22.410
than the variance or the
standard deviation itself.

01:04:22.410 --> 01:04:26.670
So you're more
likely to get away

01:04:26.670 --> 01:04:29.640
with using default values for
the coefficient of variation

01:04:29.640 --> 01:04:34.260
than you are with assuming a
specific standard deviation.

01:04:34.260 --> 01:04:37.480
AUDIENCE: It should be noted
that it's unitless, coefficient

01:04:37.480 --> 01:04:38.410
of variation.

01:04:38.410 --> 01:04:40.326
GABRIEL SANCHEZ-MARTINEZ:
Yes, it is unitless.

01:04:40.326 --> 01:04:41.980
Thank you.

01:04:41.980 --> 01:04:42.480
OK.

01:04:42.480 --> 01:04:45.210
So what happens is that relative
tolerances are typically

01:04:45.210 --> 01:04:46.080
used for averages.

01:04:46.080 --> 01:04:47.310
So here's an example--

01:04:47.310 --> 01:04:51.760
you measured 5720
boardings plus minus 5%.

01:04:51.760 --> 01:04:54.494
So if you were to get
the absolute equivalent

01:04:54.494 --> 01:04:55.910
of the absolute
tolerance of that.

01:04:55.910 --> 01:04:58.890
That would be 5% of 5720.

01:04:58.890 --> 01:05:01.180
That would be 286 passengers.

01:05:01.180 --> 01:05:03.600
That's a weird thing to report.

01:05:03.600 --> 01:05:06.000
5% is more
understandable, right?

01:05:06.000 --> 01:05:07.630
And it kind of makes more sense.

01:05:07.630 --> 01:05:11.700
So that's what we want
naturally, anyway.

01:05:11.700 --> 01:05:14.360
So as I said, the
coefficient variation

01:05:14.360 --> 01:05:17.310
is typically easier to guess
than the mean and the variance

01:05:17.310 --> 01:05:18.690
separately.

01:05:18.690 --> 01:05:20.820
So we use that.

01:05:20.820 --> 01:05:23.070
Here's an example using
the t distribution,

01:05:23.070 --> 01:05:26.070
where the sample
is not large enough

01:05:26.070 --> 01:05:30.280
to assume a normal distribution.

01:05:30.280 --> 01:05:33.550
So we say, let's have a relative
tolerance of plus minus 5%,

01:05:33.550 --> 01:05:36.120
a confidence level of
95%, and a coefficient

01:05:36.120 --> 01:05:37.650
of variation of 0.3.

01:05:37.650 --> 01:05:39.660
So we start out
assuming large sample,

01:05:39.660 --> 01:05:42.210
and therefore degrees
of freedom is infinity.

01:05:42.210 --> 01:05:44.140
We can use the
normal distribution.

01:05:44.140 --> 01:05:46.860
If we look at the
normal distribution,

01:05:46.860 --> 01:05:52.920
with plus minus 5%, confidence
level 95%, the t is 1.96.

01:05:52.920 --> 01:05:57.030
So we look that up on a table,
or we use Excel norm dist,

01:05:57.030 --> 01:05:58.440
or-- yeah.

01:05:58.440 --> 01:06:02.110
t dist for t and
norm dist for normal.

01:06:02.110 --> 01:06:04.860
We got 1.96.

01:06:04.860 --> 01:06:06.870
We plug in the
relative tolerance,

01:06:06.870 --> 01:06:08.366
the 0.3-- we get 140.

01:06:08.366 --> 01:06:11.460
140 is not quite
infinity, right?

01:06:11.460 --> 01:06:14.190
So if we look at 140
as a sample size,

01:06:14.190 --> 01:06:16.980
that would imply that all the
degrees of freedom is 139.

01:06:16.980 --> 01:06:19.410
Now we go back and
look at the t dist,

01:06:19.410 --> 01:06:23.730
and we change 1.96 to the
value from the t distribution

01:06:23.730 --> 01:06:26.680
for that degree of freedoms.

01:06:26.680 --> 01:06:28.710
And we get 140.73.

01:06:28.710 --> 01:06:32.010
So you're sort of seeing
that you were almost right.

01:06:32.010 --> 01:06:35.160
140 is very large.

01:06:35.160 --> 01:06:37.380
In practice, you would
just round up a little bit

01:06:37.380 --> 01:06:40.800
and get a nice round number, and
you would even play with this

01:06:40.800 --> 01:06:43.860
once you're looking at planning
who you're going to send out

01:06:43.860 --> 01:06:45.780
and how many hours
you're going to collect.

01:06:45.780 --> 01:06:48.974
You want to get at
least 141, but if you're

01:06:48.974 --> 01:06:51.390
going to have people in units
of eight hours, for example,

01:06:51.390 --> 01:06:54.560
or units of four hours, then you
might as well finish the batch

01:06:54.560 --> 01:06:56.250
for four hours, the last one.

01:06:56.250 --> 01:07:00.500
Maybe you'll get
150, 160 from that.

01:07:00.500 --> 01:07:02.740
Here's an example
of that equation

01:07:02.740 --> 01:07:08.260
with different assumptions
of confidence and tolerance.

01:07:08.260 --> 01:07:11.320
And so we're using
90% confidence,

01:07:11.320 --> 01:07:15.410
and we're assuming a
certain sample size here.

01:07:15.410 --> 01:07:19.000
So you can see that, as the
tolerance decreases, which

01:07:19.000 --> 01:07:22.150
means that you require
a greater accuracy

01:07:22.150 --> 01:07:25.060
for different
coefficients of variation,

01:07:25.060 --> 01:07:26.670
the sample size can
get really large.

01:07:26.670 --> 01:07:29.200
So if your data is
not very variable,

01:07:29.200 --> 01:07:31.160
then you can sample
just a few trips.

01:07:31.160 --> 01:07:33.490
And you know because
they don't vary

01:07:33.490 --> 01:07:35.440
that much what the mean is.

01:07:35.440 --> 01:07:37.540
But if there's a lot of
variability across strips,

01:07:37.540 --> 01:07:38.440
then you need more.

01:07:38.440 --> 01:07:43.630
So that's what you see as you
go down the rows on this table.

01:07:43.630 --> 01:07:44.860
Here we have tolerance.

01:07:44.860 --> 01:07:51.850
If you only have to be 50%
accurate, plus minus 50%,

01:07:51.850 --> 01:07:54.160
then you don't have to
collect that much data.

01:07:54.160 --> 01:07:56.410
If you want to be
more precise, and you

01:07:56.410 --> 01:08:00.860
want to say plus minus 5%, then
you need a bigger sample size,

01:08:00.860 --> 01:08:01.870
right?

01:08:01.870 --> 01:08:03.720
OK.

01:08:03.720 --> 01:08:05.940
Proportions-- and the
homework, actually,

01:08:05.940 --> 01:08:08.871
is based on proportions,
so this is important.

01:08:08.871 --> 01:08:10.620
Consider something, a
group of passengers,

01:08:10.620 --> 01:08:13.740
to estimate the proportion of
passengers who are students.

01:08:13.740 --> 01:08:16.109
So from probability,
when you are

01:08:16.109 --> 01:08:17.880
looking at an event
that can either

01:08:17.880 --> 01:08:20.830
be 0 or 1, or black or white--

01:08:20.830 --> 01:08:24.540
in this case, students
or non-students--

01:08:24.540 --> 01:08:27.240
there's a certain probability
that that person is a student,

01:08:27.240 --> 01:08:27.739
right?

01:08:27.739 --> 01:08:29.850
And what you want to
estimate is that probability

01:08:29.850 --> 01:08:31.920
or, in other words, what
percent of the things

01:08:31.920 --> 01:08:34.290
you observe are students.

01:08:37.020 --> 01:08:40.229
So from the properties of
the Bernoulli distribution,

01:08:40.229 --> 01:08:43.200
the variance is p
times 1 minus p.

01:08:43.200 --> 01:08:47.160
So if everybody is a student,
or nobody is a student,

01:08:47.160 --> 01:08:49.800
either way there's no
variability, right?

01:08:49.800 --> 01:08:55.319
So you would have 1 times 1
minus 1, 1 times 0, 0-- no

01:08:55.319 --> 01:08:56.430
variability.

01:08:56.430 --> 01:08:59.609
Though at the peak variability,
the highest variance

01:08:59.609 --> 01:09:02.910
of this distribution, is
when 50% of your people

01:09:02.910 --> 01:09:08.340
are students, so 0.5
times 1 minus 0.5, 0.25.

01:09:08.340 --> 01:09:10.859
That's the highest variance, OK?

01:09:10.859 --> 01:09:12.792
So the tolerance is
typically specified

01:09:12.792 --> 01:09:15.000
in absolute terms when you're
estimating proportions,

01:09:15.000 --> 01:09:18.420
because the proportion
is in itself a percent.

01:09:18.420 --> 01:09:22.470
So you use absolute tolerance.

01:09:22.470 --> 01:09:28.859
And you just substitute,
essentially, this variance.

01:09:28.859 --> 01:09:31.710
You put in the variance of
the Bernoulli distribution,

01:09:31.710 --> 01:09:33.300
which is p times 1 minus p.

01:09:33.300 --> 01:09:36.205
And that's how you get the
sampling equation, sample size

01:09:36.205 --> 01:09:37.080
requirement equation.

01:09:41.950 --> 01:09:43.180
Here's a problem.

01:09:43.180 --> 01:09:47.899
We don't know in advance what
the proportion will be, right?

01:09:47.899 --> 01:09:50.415
And we need that to know how
many people we need to survey

01:09:50.415 --> 01:09:52.540
to figure out-- or how many
trips we need to survey

01:09:52.540 --> 01:09:53.649
to figure out--

01:09:53.649 --> 01:09:55.066
sorry, how many
students we need--

01:09:55.066 --> 01:09:56.440
how many riders
we need to survey

01:09:56.440 --> 01:09:58.760
to figure out what the average
number of students are.

01:09:58.760 --> 01:09:59.963
OK, so--

01:09:59.963 --> 01:10:03.414
AUDIENCE: And it's also
a [INAUDIBLE] p times 1

01:10:03.414 --> 01:10:05.248
minus p [INAUDIBLE] is
a constrained number.

01:10:05.248 --> 01:10:07.455
GABRIEL SANCHEZ-MARTINEZ:
It is a constrained number,

01:10:07.455 --> 01:10:09.417
and that's exactly
where we're going.

01:10:09.417 --> 01:10:11.750
So we use something called
absolute equivalent tolerance

01:10:11.750 --> 01:10:13.340
instead of absolute tolerance.

01:10:13.340 --> 01:10:15.950
We assume that p is 0.5--

01:10:15.950 --> 01:10:18.090
that's the maximum it could be.

01:10:18.090 --> 01:10:20.750
So let's go ahead with
a worst case scenario.

01:10:20.750 --> 01:10:22.830
And then what happens
with p itself?

01:10:22.830 --> 01:10:27.260
Well, if your percent
is high, then you

01:10:27.260 --> 01:10:29.960
can tolerate a
bigger number, right?

01:10:29.960 --> 01:10:35.600
So if it's 32%, you're
probably OK with plus minus 5%.

01:10:35.600 --> 01:10:39.320
If your average were
1.2, plus minus 5%

01:10:39.320 --> 01:10:40.970
is not that good, right?

01:10:40.970 --> 01:10:42.170
You need a higher--

01:10:42.170 --> 01:10:46.220
you need a much stricter,
tighter confidence

01:10:46.220 --> 01:10:47.700
interval for that.

01:10:47.700 --> 01:10:51.259
So probably not good to do
plus minus 5% in that case.

01:10:51.259 --> 01:10:53.550
AUDIENCE: [? Well, do ?]
[? you mean ?] you have a plus

01:10:53.550 --> 01:10:55.730
minus 5% absolutely percentage?

01:10:55.730 --> 01:10:56.040
GABRIEL SANCHEZ-MARTINEZ:
Absolute, yeah.

01:10:56.040 --> 01:10:57.530
AUDIENCE: And you'd be
going negative [INAUDIBLE]

01:10:57.530 --> 01:10:57.800
GABRIEL SANCHEZ-MARTINEZ:
Negative,

01:10:57.800 --> 01:11:00.590
which is possible but
difficult to interpret.

01:11:00.590 --> 01:11:04.320
AUDIENCE: Sorry, so this isn't
actually 32% plus or minus 5%

01:11:04.320 --> 01:11:06.020
of 32 [INAUDIBLE]

01:11:06.020 --> 01:11:06.610
GABRIEL SANCHEZ-MARTINEZ:
It is not-- yeah,

01:11:06.610 --> 01:11:09.110
it's absolute tolerance, not
relative tolerance, right.

01:11:09.110 --> 01:11:12.500
So what's convenient about this
is that these two factors work

01:11:12.500 --> 01:11:13.490
in opposite directions.

01:11:13.490 --> 01:11:19.490
So as you get bigger, as the
proportion gets closer to 50%,

01:11:19.490 --> 01:11:20.690
the variance increases.

01:11:20.690 --> 01:11:23.150
So oh, well, we need
a bigger sample.

01:11:23.150 --> 01:11:26.630
But your tolerance
increases as well,

01:11:26.630 --> 01:11:28.670
so you don't need
as big of a sample.

01:11:28.670 --> 01:11:30.050
And so it's convenient.

01:11:30.050 --> 01:11:33.500
And the practical solution
is assume p is 0.5

01:11:33.500 --> 01:11:37.070
and work in terms of absolute
equivalent tolerance.

01:11:37.070 --> 01:11:40.160
So you pick a tolerance
under the assumption

01:11:40.160 --> 01:11:43.670
that our proportion is 50%.

01:11:43.670 --> 01:11:46.170
And here's what happens.

01:11:46.170 --> 01:11:48.800
Yeah, if the expected
proportion is 50%,

01:11:48.800 --> 01:11:51.890
and you say plus minus 5
percent, what you would get

01:11:51.890 --> 01:11:56.520
is this 5%, if it
turns out that p is 5%.

01:11:56.520 --> 01:12:01.400
But if it worked more to the
extremes, like 5% or 95%,

01:12:01.400 --> 01:12:04.970
what you would actually achieve
from having planned the survey,

01:12:04.970 --> 01:12:07.580
assuming 50%, is 2.2--

01:12:07.580 --> 01:12:11.690
so much better,
much more acceptable

01:12:11.690 --> 01:12:14.840
to say 5% plus
minus 2.2%, right?

01:12:14.840 --> 01:12:16.370
So it works out.

01:12:16.370 --> 01:12:20.030
And there's a
convenient equation

01:12:20.030 --> 01:12:22.640
if you assume a very large
sample, or large enough sample,

01:12:22.640 --> 01:12:26.570
and you pick 95%, 0.25,
which is the variance

01:12:26.570 --> 01:12:30.320
times the normal
distribution t squared

01:12:30.320 --> 01:12:32.280
is 0.96, which is almost 1.

01:12:32.280 --> 01:12:33.530
So then you get this equation.

01:12:33.530 --> 01:12:35.654
You take 1, you divide
it by the tolerance

01:12:35.654 --> 01:12:37.820
that you want, your equivalent
tolerance, and that's

01:12:37.820 --> 01:12:38.940
your sample size.

01:12:38.940 --> 01:12:42.950
So it doesn't depend on anything
about the data in itself.

01:12:42.950 --> 01:12:46.490
You just say if I want, on
whatever I'm collecting,

01:12:46.490 --> 01:12:48.270
whatever proportion
I'm collecting,

01:12:48.270 --> 01:12:51.620
a 5% absolute
equivalent tolerance,

01:12:51.620 --> 01:12:57.190
then I need 400
surveys to be answered.

01:12:57.190 --> 01:12:58.296
Yeah?

01:12:58.296 --> 01:13:03.152
AUDIENCE: So this
assumes a random--

01:13:03.152 --> 01:13:05.110
GABRIEL SANCHEZ-MARTINEZ:
Simple random sample.

01:13:05.110 --> 01:13:05.750
AUDIENCE: [INAUDIBLE]

01:13:05.750 --> 01:13:07.190
GABRIEL SANCHEZ-MARTINEZ:
Yes, a simple random sample.

01:13:07.190 --> 01:13:08.648
So you would increase
these numbers

01:13:08.648 --> 01:13:11.050
if you are using
cluster sampling

01:13:11.050 --> 01:13:13.330
to account for correlation.

01:13:13.330 --> 01:13:16.830
You would have to increase
them if you're giving people

01:13:16.830 --> 01:13:19.330
a survey, and not all of them
answer the survey, because you

01:13:19.330 --> 01:13:22.240
need 400 surveys answered.

01:13:22.240 --> 01:13:24.610
So if only half of the
people answer the survey,

01:13:24.610 --> 01:13:27.010
then you need to
distribute 800 surveys.

01:13:27.010 --> 01:13:28.962
AUDIENCE: Do you
recommend calculating also

01:13:28.962 --> 01:13:32.070
that the standard error after
this so that [INAUDIBLE]

01:13:32.070 --> 01:13:32.570
make sure?

01:13:32.570 --> 01:13:33.530
GABRIEL SANCHEZ-MARTINEZ:
Absolutely, yeah.

01:13:33.530 --> 01:13:35.810
You want to go back and
check with the standard error

01:13:35.810 --> 01:13:38.330
and when your confidence
interval is and see

01:13:38.330 --> 01:13:39.830
if you meet it or
if you need to add

01:13:39.830 --> 01:13:41.570
a few days of data collection.

01:13:41.570 --> 01:13:42.360
AUDIENCE: Right.

01:13:42.360 --> 01:13:43.651
GABRIEL SANCHEZ-MARTINEZ: Yeah.

01:13:43.651 --> 01:13:48.740
OK, so with proportions, you
need a very large sample size

01:13:48.740 --> 01:13:51.590
to estimate a proportion
if you want accuracy.

01:13:51.590 --> 01:13:54.800
If you say absolutely
equivalent intolerance of 4%,

01:13:54.800 --> 01:13:56.900
then you need 600.

01:13:56.900 --> 01:14:00.020
That's a big number, so it
just gives you an idea of that.

01:14:00.020 --> 01:14:02.390
If you get greedy
with the tolerance,

01:14:02.390 --> 01:14:08.580
you have to pay for the
surveyors to go out.

01:14:08.580 --> 01:14:11.090
OK.

01:14:11.090 --> 01:14:14.510
So the process is you determine
the needed sample size

01:14:14.510 --> 01:14:18.140
just with the discussion of the
equations that we discussed.

01:14:18.140 --> 01:14:19.850
Then you multiply
the sample sizes.

01:14:23.675 --> 01:14:25.550
If you're using stratified
sampling or if you

01:14:25.550 --> 01:14:28.280
have questions that
have multiple variables,

01:14:28.280 --> 01:14:30.920
you need to then make sure
that you achieve that sample

01:14:30.920 --> 01:14:34.200
size for each combination of
things that you're measuring.

01:14:34.200 --> 01:14:36.830
So if you're, for example,
looking at not just

01:14:36.830 --> 01:14:42.880
boardings, but proportion of
passengers that are car-owning,

01:14:42.880 --> 01:14:43.810
who are pleased.

01:14:43.810 --> 01:14:46.990
So you could just independently
measure pleased, independently

01:14:46.990 --> 01:14:52.840
measure passengers
who own a car.

01:14:52.840 --> 01:14:55.960
And you might have the
tolerance you need on each one,

01:14:55.960 --> 01:14:57.910
but if you want the
combination of that,

01:14:57.910 --> 01:14:59.650
now you need a higher
sample, because you

01:14:59.650 --> 01:15:03.610
need that number for the
combination of those things.

01:15:03.610 --> 01:15:05.230
Then there's a
clustering effect,

01:15:05.230 --> 01:15:06.862
so a typical thing
if you're doing

01:15:06.862 --> 01:15:08.820
the clustering of a whole
vehicle of passengers

01:15:08.820 --> 01:15:12.190
is to multiply by 4.

01:15:12.190 --> 01:15:15.010
And then for things like OD
matrices, the rule of thumb

01:15:15.010 --> 01:15:17.927
is 20 times the number of cells.

01:15:17.927 --> 01:15:18.760
What does that mean?

01:15:18.760 --> 01:15:20.554
That if your OD matrix
is quite aggregate,

01:15:20.554 --> 01:15:21.970
and it's at the
segment level-- so

01:15:21.970 --> 01:15:24.700
say you divide a root
into two segments,

01:15:24.700 --> 01:15:27.190
then your OD matrix
has four cells.

01:15:27.190 --> 01:15:30.310
Four cells times 20, that's how
many people you have to survey.

01:15:30.310 --> 01:15:33.269
If you do error
at the stop level,

01:15:33.269 --> 01:15:35.560
then you have many more stops
and, therefore, many more

01:15:35.560 --> 01:15:39.465
cells and, therefore, a
much higher sample size.

01:15:39.465 --> 01:15:41.090
If you have a response
rate that is not

01:15:41.090 --> 01:15:43.360
100%, which is always
the case, then you

01:15:43.360 --> 01:15:46.480
have to expand by 1 minus that
in the reciprocal-- sorry, 1

01:15:46.480 --> 01:15:48.080
over that in the reciprocal.

01:15:48.080 --> 01:15:49.760
And then you get a
very large number,

01:15:49.760 --> 01:15:51.860
and you say I don't have
the budget for that.

01:15:51.860 --> 01:15:57.460
And you have to make tradeoffs
and figure out what you can do.

01:15:57.460 --> 01:15:59.590
And maybe you have to--

01:15:59.590 --> 01:16:01.750
maybe you can't collect
this combination

01:16:01.750 --> 01:16:03.160
and know that accurately, right?

01:16:03.160 --> 01:16:07.500
So you revise your expectations.

01:16:07.500 --> 01:16:11.265
OK, with response
rates, you are concerned

01:16:11.265 --> 01:16:12.640
with getting the
correct answers.

01:16:12.640 --> 01:16:14.740
You also want to be getting
a high response rate.

01:16:14.740 --> 01:16:17.281
If you don't get a high response
rate, there might be a bias.

01:16:17.281 --> 01:16:19.730
So you have to worry about that.

01:16:19.730 --> 01:16:21.250
If you have low
response rates, that

01:16:21.250 --> 01:16:23.000
means you need to
distribute more surveys,

01:16:23.000 --> 01:16:24.190
and that costs money.

01:16:24.190 --> 01:16:26.240
And there's the bias
that I just mentioned,

01:16:26.240 --> 01:16:29.980
so people who don't respond may
not be responding for a reason.

01:16:29.980 --> 01:16:32.560
And then done that
might bias your results.

01:16:32.560 --> 01:16:34.990
And that might make you
decide something in planning

01:16:34.990 --> 01:16:38.570
that is not the right decision
based on what actually happens.

01:16:38.570 --> 01:16:41.410
So we call that the
non-response bias.

01:16:41.410 --> 01:16:43.099
OK, so what happens?

01:16:43.099 --> 01:16:44.890
People who don't respond
might be different

01:16:44.890 --> 01:16:47.015
or might have responded
differently to the question

01:16:47.015 --> 01:16:47.950
had they responded.

01:16:47.950 --> 01:16:50.120
So here's some examples.

01:16:50.120 --> 01:16:52.660
If you're surveying
people who are standing,

01:16:52.660 --> 01:16:54.220
they are less comfortable.

01:16:54.220 --> 01:16:57.280
And maybe it's a crowded bus--
they are less comfortable.

01:16:57.280 --> 01:17:00.100
Or maybe they're getting
off one of those stops that

01:17:00.100 --> 01:17:03.250
is coming up, so they are
less likely to have the time

01:17:03.250 --> 01:17:05.020
to respond to your survey.

01:17:05.020 --> 01:17:07.570
People with low
literacy, teenagers,

01:17:07.570 --> 01:17:10.420
people who don't
speak the language,

01:17:10.420 --> 01:17:11.870
are less likely to respond.

01:17:11.870 --> 01:17:14.720
And they might have
different travel patterns.

01:17:14.720 --> 01:17:16.710
So if you understand
those things,

01:17:16.710 --> 01:17:18.392
and you get lower
samples for them,

01:17:18.392 --> 01:17:20.350
you might be able to do
some sort of correction

01:17:20.350 --> 01:17:21.670
to those biases.

01:17:21.670 --> 01:17:23.740
But you have to pay attention.

01:17:23.740 --> 01:17:25.390
How do you improve
your response rate?

01:17:25.390 --> 01:17:28.150
Well you can make your
questions shorter.

01:17:28.150 --> 01:17:29.950
You can do a quick oral survey.

01:17:29.950 --> 01:17:32.890
That's what we're going
to do for this homework.

01:17:32.890 --> 01:17:36.550
You can try to get information
from automatic sources whenever

01:17:36.550 --> 01:17:37.100
possible.

01:17:37.100 --> 01:17:42.100
So if you have an AFC system,
let's not collect boardings,

01:17:42.100 --> 01:17:45.100
because we know that.

01:17:45.100 --> 01:17:47.650
And then of course some
training, and just being kind,

01:17:47.650 --> 01:17:51.610
and having supervision
helps a lot.

01:17:51.610 --> 01:17:53.650
OK, here's some
suggested tolerances

01:17:53.650 --> 01:17:55.340
for different things.

01:17:55.340 --> 01:17:58.420
So we're looking here at
boardings or the peak load.

01:17:58.420 --> 01:18:00.580
And you see here that
the suggested tolerance

01:18:00.580 --> 01:18:05.290
is 30%, plus minus 30%, when
you have a route with one

01:18:05.290 --> 01:18:05.980
to three buses.

01:18:05.980 --> 01:18:07.270
And then as you have
more and more buses,

01:18:07.270 --> 01:18:08.380
the tolerance decreases.

01:18:08.380 --> 01:18:11.920
That means you require
a larger sample.

01:18:11.920 --> 01:18:14.670
Why is that?

01:18:14.670 --> 01:18:16.530
Why do you need a
bigger sample if you

01:18:16.530 --> 01:18:20.238
have a route with more buses?

01:18:20.238 --> 01:18:23.560
AUDIENCE: You're less likely
to sample a different bus.

01:18:23.560 --> 01:18:26.830
GABRIEL SANCHEZ-MARTINEZ: Yes,
and when you have higher--

01:18:26.830 --> 01:18:30.112
when you have more buses, you
tend to have higher frequency.

01:18:30.112 --> 01:18:30.820
There's bunching.

01:18:30.820 --> 01:18:35.260
OK, so if you then survey
loads, for example,

01:18:35.260 --> 01:18:38.590
and you only get a few
because of the bunching effect

01:18:38.590 --> 01:18:40.380
and because there
are more buses,

01:18:40.380 --> 01:18:42.910
and you're observing a
smaller percentage of them

01:18:42.910 --> 01:18:45.490
for a given time
period, say, you're

01:18:45.490 --> 01:18:48.760
less likely to have observed
the bus that was really crowded,

01:18:48.760 --> 01:18:49.330
right?

01:18:49.330 --> 01:18:52.390
So that means that you need
to decrease your tolerance.

01:18:52.390 --> 01:18:55.490
And therefore, it's more
expensive to survey that.

01:18:55.490 --> 01:18:56.350
OK, good.

01:18:56.350 --> 01:19:00.220
Trip time-- 10% for routes
with less than 20 minutes,

01:19:00.220 --> 01:19:03.490
5% with routes of
greater than 20 minutes.

01:19:03.490 --> 01:19:06.100
Similar concept if you have
greater than 20 minutes--

01:19:09.540 --> 01:19:11.170
there can be just
more variability,

01:19:11.170 --> 01:19:14.860
and you really want
to get that right.

01:19:14.860 --> 01:19:16.900
When you have less
than 20 minutes,

01:19:16.900 --> 01:19:20.080
your decision on
cycle times and things

01:19:20.080 --> 01:19:22.960
like this are not going to have
as much impact on the fleet

01:19:22.960 --> 01:19:24.550
size that you require.

01:19:24.550 --> 01:19:31.720
As you get bigger running
times, a small percentage change

01:19:31.720 --> 01:19:34.600
in the mean could
influence how many buses

01:19:34.600 --> 01:19:37.750
you need to dedicate to
that and the cost of running

01:19:37.750 --> 01:19:39.990
that service.

01:19:39.990 --> 01:19:43.610
On-time performance-- 10%
absolute equivalent tolerance.

01:19:43.610 --> 01:19:47.260
These are typical values-- don't
take them as gospel, please.

01:19:47.260 --> 01:19:49.530
And these are for reporting,
not for anything that's

01:19:49.530 --> 01:19:51.750
very critical for operations.

01:19:51.750 --> 01:19:53.560
Some of them are.

01:19:53.560 --> 01:19:56.820
Yeah, 30% at least, I would
say, is for reporting.

01:19:56.820 --> 01:20:00.840
I wouldn't make any
critical decisions with 30%.

01:20:00.840 --> 01:20:04.410
On-time performance-- we're
talking here about whether

01:20:04.410 --> 01:20:07.060
a trip is on time
or not on time--

01:20:07.060 --> 01:20:08.970
so Bernoulli trials, right?

01:20:08.970 --> 01:20:10.650
And there's a
proportion of trips

01:20:10.650 --> 01:20:15.120
that are on time, and what
we do is that, we essentially

01:20:15.120 --> 01:20:19.710
say plus-- if we say plus
minus 10%, then we're saying

01:20:19.710 --> 01:20:22.980
that the sample size
should be 1 over 0.1.

01:20:22.980 --> 01:20:23.480
Yeah.

01:20:26.330 --> 01:20:28.160
All right, default
coefficient-- these

01:20:28.160 --> 01:20:29.576
are default values
for coefficient

01:20:29.576 --> 01:20:30.950
of variation of key data items.

01:20:30.950 --> 01:20:33.170
Ideally, you have your
own data that you look at,

01:20:33.170 --> 01:20:34.790
and you don't resort to this.

01:20:34.790 --> 01:20:37.910
But if you ever find
yourself in a situation

01:20:37.910 --> 01:20:40.470
where you need to start
out with something.

01:20:40.470 --> 01:20:45.440
Here are some based on studies
that previous [AUDIO OUT] They

01:20:45.440 --> 01:20:48.590
took different routes
and looked at loads

01:20:48.590 --> 01:20:51.440
and running times for
different time periods

01:20:51.440 --> 01:20:53.570
and found what the coefficients
of variations were.

01:20:53.570 --> 01:20:56.420
And here they are on a
table for you to use.

01:21:00.947 --> 01:21:03.530
In the interest of time, since
I want to discuss the homework,

01:21:03.530 --> 01:21:05.750
I'm going to stop
here with slide 25.

01:21:05.750 --> 01:21:11.480
And I'm going to not cover
the whole process, which

01:21:11.480 --> 01:21:14.880
includes the monitoring phase.

01:21:14.880 --> 01:21:17.790
And in this slide
here, we have how you

01:21:17.790 --> 01:21:20.010
establish conversion factor.

01:21:20.010 --> 01:21:23.870
The conversion factor in
itself has a variance.

01:21:23.870 --> 01:21:26.130
So there's some uncertainty
about the relationship

01:21:26.130 --> 01:21:31.380
that you estimate between
your baseline data item

01:21:31.380 --> 01:21:33.550
and your auxiliary data item.

01:21:33.550 --> 01:21:37.210
So you need to consider
that in your sample size.

01:21:37.210 --> 01:21:39.720
And here are some tables
with some examples of what

01:21:39.720 --> 01:21:44.130
happens when you require
different-- well, when you're

01:21:44.130 --> 01:21:47.940
variability of or
your coefficient

01:21:47.940 --> 01:21:52.650
of variation of your
relationship increases

01:21:52.650 --> 01:21:54.390
or decreases.

01:21:54.390 --> 01:21:56.430
OK, let's look at the homework.

01:21:56.430 --> 01:21:59.893
I really want to use these
last five minutes for that.

01:21:59.893 --> 01:22:07.560
So please take one and pass.

01:22:07.560 --> 01:22:12.300
OK, so the MBTA, there's
a proposal here in Boston

01:22:12.300 --> 01:22:14.850
of taking Route 70 and 70A--

01:22:14.850 --> 01:22:17.370
they run through
Waltham, and they

01:22:17.370 --> 01:22:20.130
go into around Central Square.

01:22:20.130 --> 01:22:23.690
And some people are saying those
two routes should be extended

01:22:23.690 --> 01:22:28.430
to Kendall Square,
because a lot of people

01:22:28.430 --> 01:22:31.700
are actually going to MIT, or
Kendall Square, or the Kendall

01:22:31.700 --> 01:22:33.890
Square area--

01:22:33.890 --> 01:22:37.280
not just Kendall Square Station,
but the whole area around.

01:22:37.280 --> 01:22:39.350
So if it's true, A
lot of people could

01:22:39.350 --> 01:22:40.670
benefit from that extension.

01:22:40.670 --> 01:22:41.670
And we don't know.

01:22:41.670 --> 01:22:43.140
So what are you going to do?

01:22:43.140 --> 01:22:45.620
You're going to go
to a specific stop

01:22:45.620 --> 01:22:48.620
where it is very likely that
the people who would be going

01:22:48.620 --> 01:22:52.430
to MIT or those areas of Kendall
Square that would benefit

01:22:52.430 --> 01:22:55.040
from this extension
would alight,

01:22:55.040 --> 01:22:57.140
and you're going to
ask people, would you

01:22:57.140 --> 01:23:01.250
have stayed on your bus
if this bus had continued

01:23:01.250 --> 01:23:02.960
to MIT and Kendall Square?

01:23:02.960 --> 01:23:06.635
It's a simple oral survey, yes
or no question, one question.

01:23:06.635 --> 01:23:08.510
You're going to work in
teams of four people.

01:23:13.130 --> 01:23:16.670
The stop that you're going
to station yourself in

01:23:16.670 --> 01:23:18.296
is shown in figure 3.

01:23:21.230 --> 01:23:23.360
And you're going to collect
data for the AM peak,

01:23:23.360 --> 01:23:25.760
from 7:30 to 9:30.

01:23:25.760 --> 01:23:27.320
You pick the day.

01:23:27.320 --> 01:23:29.090
The teams are
assigned on Stellar,

01:23:29.090 --> 01:23:32.150
so please log into Stellar
and see what your team is

01:23:32.150 --> 01:23:34.910
and coordinate with
them to pick a day.

01:23:34.910 --> 01:23:37.580
And tell me what that
day is, because--

01:23:37.580 --> 01:23:39.410
actually, right after
class, I'm going

01:23:39.410 --> 01:23:43.370
to set up a shared spreadsheet
that you can all access.

01:23:43.370 --> 01:23:46.519
And just go into that
spreadsheet and pick a day.

01:23:46.519 --> 01:23:48.560
I'm going to put all the
days that are available,

01:23:48.560 --> 01:23:51.170
and you can say team
1, team 2, et cetera.

01:23:51.170 --> 01:23:54.410
Make sure that two teams
don't go on the same day.

01:23:54.410 --> 01:23:56.400
We want data from
different days.

01:23:56.400 --> 01:23:58.400
And you're going to all
bring that data together

01:23:58.400 --> 01:24:00.650
in that same
spreadsheet, and there

01:24:00.650 --> 01:24:03.650
are some questions
for you to analyze

01:24:03.650 --> 01:24:06.230
the data that you collected,
all of the class collected

01:24:06.230 --> 01:24:08.540
together.

01:24:08.540 --> 01:24:12.980
You're measuring the
percent of people who would

01:24:12.980 --> 01:24:14.450
have stayed on the bus, right?

01:24:14.450 --> 01:24:18.730
So it's a proportion.

01:24:18.730 --> 01:24:22.960
And one submission per team
in PDF format to Stellar.

01:24:22.960 --> 01:24:26.410
This is due March
7, but in order

01:24:26.410 --> 01:24:28.830
to leave you enough
time to do the analysis,

01:24:28.830 --> 01:24:31.590
the data collection efforts
should be done by February 28.

01:24:31.590 --> 01:24:37.150
So please submit your data by
the end of Tuesday, February 28

01:24:37.150 --> 01:24:41.230
at midnight, say, or sometime
before the beginning of March

01:24:41.230 --> 01:24:43.300
in the morning,
where a person would

01:24:43.300 --> 01:24:45.100
be trying to analyze your data.

01:24:48.510 --> 01:24:51.280
OK, if you have
questions, let me know.

01:24:51.280 --> 01:24:56.250
And if not, have fun.

01:24:56.250 --> 01:24:58.910
Remember that assignment
1 is due Thursday.

01:25:01.531 --> 01:25:02.030
Eric?

01:25:02.030 --> 01:25:03.822
AUDIENCE: Just the one question:
[? is that ?] [? this is ?]

01:25:03.822 --> 01:25:06.140
going to miss anyone who is
transferred to the Red Line

01:25:06.140 --> 01:25:07.746
to then go to Kendall Square.

01:25:07.746 --> 01:25:09.620
GABRIEL SANCHEZ-MARTINEZ:
And going back to--

01:25:09.620 --> 01:25:10.120
let's see.

01:25:14.430 --> 01:25:17.660
I forget where I had it.

01:25:17.660 --> 01:25:20.630
Well, I guess what I-- there
was a point I made earlier

01:25:20.630 --> 01:25:23.730
where we can measure that from
automatically collected data,

01:25:23.730 --> 01:25:24.230
right?

01:25:24.230 --> 01:25:24.950
AUDIENCE: OK.

01:25:24.950 --> 01:25:25.610
GABRIEL SANCHEZ-MARTINEZ:
Does that make sense?

01:25:25.610 --> 01:25:27.860
AUDIENCE: Yeah, people who
[? car up ?] come from 70.

01:25:27.860 --> 01:25:29.235
GABRIEL
SANCHEZ-MARTINEZ: So if I

01:25:29.235 --> 01:25:32.410
see you tapping of
the 70 or the 70A,

01:25:32.410 --> 01:25:35.480
and then I see you
tapping at Central Square,

01:25:35.480 --> 01:25:37.790
I can infer that you
were using the service

01:25:37.790 --> 01:25:40.790
to transfer to Central Square.

01:25:40.790 --> 01:25:42.950
And then we'll
cover ODX, which is

01:25:42.950 --> 01:25:44.480
an inference model
for destinations

01:25:44.480 --> 01:25:46.210
later in this course.

01:25:46.210 --> 01:25:51.170
But looking at the sequence
of taps, I can infer--

01:25:51.170 --> 01:25:53.420
we can infer-- what the
destination of that bus trip

01:25:53.420 --> 01:25:53.919
was.

01:25:53.919 --> 01:25:55.720
We can infer that
it was the stop that

01:25:55.720 --> 01:25:57.440
was closest to Central.

01:25:57.440 --> 01:26:00.710
And later that day,
presumably the person

01:26:00.710 --> 01:26:04.310
who might be going to Kendall
Square Station after work taps

01:26:04.310 --> 01:26:05.199
to Kendall Square.

01:26:05.199 --> 01:26:07.490
So I might think, oh, he took
the Red Line from Central

01:26:07.490 --> 01:26:09.500
to Kendall.

01:26:09.500 --> 01:26:12.320
So I don't need to ask those
people where they're going.

01:26:12.320 --> 01:26:14.880
And anyway, they might not
care about this extension.

01:26:14.880 --> 01:26:17.570
So we're going to stand
on the bus stop that

01:26:17.570 --> 01:26:21.590
is after Central Square and see
where those people are going

01:26:21.590 --> 01:26:25.350
and whether they would
have stayed on that bus.

01:26:25.350 --> 01:26:28.119
AUDIENCE: Is this an
actual [INAUDIBLE]

01:26:28.119 --> 01:26:30.410
GABRIEL SANCHEZ-MARTINEZ:
Some people are proposing it.

01:26:30.410 --> 01:26:33.060
It is a real proposal.

01:26:33.060 --> 01:26:35.230
The MBTA is a big organization.

01:26:35.230 --> 01:26:41.490
So I can't say that the
MBTA wants to do this

01:26:41.490 --> 01:26:43.210
or doesn't want to do this.

01:26:43.210 --> 01:26:45.090
But some people are interested.

01:26:45.090 --> 01:26:48.630
And it will get looked into.

01:26:48.630 --> 01:26:50.770
So it's useful.

01:26:50.770 --> 01:26:53.195
AUDIENCE: [? Can ?] [? we ?]
[? share ?] [INAUDIBLE]

01:26:53.195 --> 01:26:56.105
GABRIEL SANCHEZ-MARTINEZ:
Yeah, why not?

01:26:56.105 --> 01:26:58.045
AUDIENCE: [INAUDIBLE]

01:26:58.045 --> 01:27:00.470
GABRIEL SANCHEZ-MARTINEZ: Yeah.

01:27:00.470 --> 01:27:03.320
And I guess one other
thing that I-- yeah,

01:27:03.320 --> 01:27:06.250
so we're going to
probably make of this

01:27:06.250 --> 01:27:08.594
like a theme of assignments.

01:27:08.594 --> 01:27:10.760
So there's going to be
another assignment on surface

01:27:10.760 --> 01:27:12.510
planning, operations planning.

01:27:12.510 --> 01:27:15.160
So we're going to start looking
at this combination of Route 70

01:27:15.160 --> 01:27:19.760
and 70A, and we're going
to essentially make

01:27:19.760 --> 01:27:22.520
a thread of this and do
some serious planning

01:27:22.520 --> 01:27:26.300
on some scenarios where the 70
and the 70A could be merged.

01:27:26.300 --> 01:27:29.860
And they could maybe be
terminated a little--

01:27:29.860 --> 01:27:32.810
yeah, we'll make some
changes to the service plan

01:27:32.810 --> 01:27:34.440
under some
hypothetical scenarios.

01:27:34.440 --> 01:27:38.840
And you'll get a chance to do
an operations plan on these.

01:27:38.840 --> 01:27:41.550
And then the last homework
will be on policy,

01:27:41.550 --> 01:27:44.170
so there might be
some policy questions

01:27:44.170 --> 01:27:47.930
that I have in mind about
what we could do about

01:27:47.930 --> 01:27:52.640
service outside, on the outer
parts of the 70 and 70A.

01:27:57.440 --> 01:27:59.290
All right?

