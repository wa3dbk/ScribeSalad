WEBVTT
Kind: captions
Language: en

00:00:00.499 --> 00:00:02.766
The following content is
provided under a Creative

00:00:02.766 --> 00:00:03.620
Commons license.

00:00:03.620 --> 00:00:06.730
Your support will help
MIT OpenCourseWare

00:00:06.730 --> 00:00:10.050
continue to offer high quality
educational resources for free.

00:00:10.050 --> 00:00:13.450
To make a donation, or to
view additional materials

00:00:13.450 --> 00:00:16.150
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:16.150 --> 00:00:19.330
at ocw.mit.edu.

00:00:19.330 --> 00:00:26.300
PROFESSOR STRANG:
Shall we start?

00:00:26.300 --> 00:00:31.390
The main job of today is
eigenvalues and eigenvectors.

00:00:31.390 --> 00:00:34.330
The next section in the
book and a very big topic

00:00:34.330 --> 00:00:37.170
and things to say about it.

00:00:37.170 --> 00:00:41.170
I do want to begin with a
recap of what I didn't quite

00:00:41.170 --> 00:00:45.130
finish last time.

00:00:45.130 --> 00:00:50.360
So what we did was solve this
very straightforward equation.

00:00:50.360 --> 00:00:53.330
Straightforward except
that it has a point source,

00:00:53.330 --> 00:00:54.910
a delta function.

00:00:54.910 --> 00:00:58.350
And we solved it, both
the fixed-fixed case

00:00:58.350 --> 00:01:02.720
when a straight line
went up and back down

00:01:02.720 --> 00:01:05.520
and in the free-fixed
case when it

00:01:05.520 --> 00:01:11.790
was a horizontal line and then
down with slope minus one.

00:01:11.790 --> 00:01:15.060
And there are different
ways to get to this answer.

00:01:15.060 --> 00:01:18.570
But once you have it,
you can look at it

00:01:18.570 --> 00:01:20.230
and say, well is it right?

00:01:20.230 --> 00:01:22.830
Certainly the boundary
conditions are correct.

00:01:22.830 --> 00:01:26.060
Zero slope, went through
zero, that's good.

00:01:26.060 --> 00:01:28.470
And then the only
thing you really

00:01:28.470 --> 00:01:33.230
have to check is does
the slope drop by one

00:01:33.230 --> 00:01:36.780
at the point of the impulse?

00:01:36.780 --> 00:01:40.580
Because that's what this
is forcing us to do.

00:01:40.580 --> 00:01:43.180
It's saying the slope
should drop by one.

00:01:43.180 --> 00:01:46.550
And here the slope
is 1-a going up.

00:01:46.550 --> 00:01:51.330
And if I take the derivative,
it's -a going down.

00:01:51.330 --> 00:01:54.740
1-a dropped to -a, good.

00:01:54.740 --> 00:01:56.640
Here the slope was zero.

00:01:56.640 --> 00:02:00.100
Here the slope was
minus one, good.

00:02:00.100 --> 00:02:01.850
So those are the right answers.

00:02:01.850 --> 00:02:11.120
And this is simple, but
really a great example.

00:02:11.120 --> 00:02:14.330
And then, what I
wanted to do was

00:02:14.330 --> 00:02:17.500
catch the same thing
for the matrices.

00:02:17.500 --> 00:02:24.640
So those matrices, we all
know what K is and what T is.

00:02:24.640 --> 00:02:27.380
So I'm solving,
I'm really solving

00:02:27.380 --> 00:02:31.890
K K inverse equal identity.

00:02:31.890 --> 00:02:33.520
That's the equation I'm solving.

00:02:33.520 --> 00:02:37.340
So I'm looking for
K inverse and trying

00:02:37.340 --> 00:02:40.090
to get the columns
of the identity.

00:02:40.090 --> 00:02:42.930
And you realize the
columns of the identity

00:02:42.930 --> 00:02:45.660
are just like delta vectors.

00:02:45.660 --> 00:02:48.000
They've got a one
in one spot, they're

00:02:48.000 --> 00:02:52.620
a point load just
like this thing.

00:02:52.620 --> 00:02:56.610
So can I just say how
I remember K inverse?

00:02:56.610 --> 00:02:58.640
I finally, you
know-- again there

00:02:58.640 --> 00:03:01.790
are different ways to get to it.

00:03:01.790 --> 00:03:03.900
One way is MATLAB, just do it.

00:03:03.900 --> 00:03:08.620
But I guess maybe
the whole point

00:03:08.620 --> 00:03:13.100
is, the whole point of these
and the eigenvalues that

00:03:13.100 --> 00:03:16.370
are coming too, is this.

00:03:16.370 --> 00:03:25.230
That we have here the chance
to see important special cases

00:03:25.230 --> 00:03:26.580
that work out.

00:03:26.580 --> 00:03:28.710
Normally we don't
find the inverse,

00:03:28.710 --> 00:03:30.640
print out the
inverse of a matrix.

00:03:30.640 --> 00:03:32.370
It's not nice.

00:03:32.370 --> 00:03:36.870
Normally we just let eig
find the eigenvalues.

00:03:36.870 --> 00:03:39.590
Because that's an even
worse calculation,

00:03:39.590 --> 00:03:42.130
to find eigenvalues, in general.

00:03:42.130 --> 00:03:47.240
I'm talking here about our
matrices of all sizes n by n.

00:03:47.240 --> 00:03:51.680
Nobody finds the eigenvalues
by hand of n by n matrices.

00:03:51.680 --> 00:03:55.880
But these have
terrific eigenvalues

00:03:55.880 --> 00:03:58.380
and especially eigenvectors.

00:03:58.380 --> 00:04:04.010
So in a way this is a little
bit like, typical of math.

00:04:04.010 --> 00:04:07.700
That you ask about
general stuff or you

00:04:07.700 --> 00:04:14.690
write the equation
with a matrix A.

00:04:14.690 --> 00:04:17.540
So that's the
general information.

00:04:17.540 --> 00:04:21.110
And then there's the
specific, special guys

00:04:21.110 --> 00:04:22.980
with special functions.

00:04:22.980 --> 00:04:27.170
And here there'll be sines
and cosines and exponentials.

00:04:27.170 --> 00:04:29.240
Other places in
applied math, there

00:04:29.240 --> 00:04:31.710
are Bessel functions
and Legendre functions.

00:04:31.710 --> 00:04:33.210
Special guys.

00:04:33.210 --> 00:04:37.080
So here, these are special.

00:04:37.080 --> 00:04:40.880
And how do I complete K inverse?

00:04:40.880 --> 00:04:44.810
So this four, three, two, one.

00:04:44.810 --> 00:04:46.180
Let me complete T inverse.

00:04:46.180 --> 00:04:48.460
You probably know
T inverse already.

00:04:48.460 --> 00:04:52.090
So T, this is, four,
three, two, one,

00:04:52.090 --> 00:04:57.090
is when the load is way
over at the far left end

00:04:57.090 --> 00:04:59.250
and it's just descending.

00:04:59.250 --> 00:05:05.770
And now I'm going to-- Let me
show you how I write it in.

00:05:05.770 --> 00:05:07.890
Pay attention here
to the diagonal.

00:05:07.890 --> 00:05:15.810
So this will be three,
three, two, one.

00:05:15.810 --> 00:05:24.110
Do you see that's the solution
that's sort of like this one?

00:05:24.110 --> 00:05:28.310
That's the second column of
the inverse so it's solving,

00:05:28.310 --> 00:05:31.820
I'm solving, T T
inverse equals I here.

00:05:31.820 --> 00:05:34.700
It's the-- The second
column is the guy

00:05:34.700 --> 00:05:39.030
with a one in the second place.

00:05:39.030 --> 00:05:42.400
So that's where the load
is, in position number two.

00:05:42.400 --> 00:05:46.000
So I'm level, three,
three, up to that load.

00:05:46.000 --> 00:05:51.620
And then I'm dropping
after the load.

00:05:51.620 --> 00:05:56.720
What's the third
column of T inverse?

00:05:56.720 --> 00:05:59.230
I started with that
first column and I

00:05:59.230 --> 00:06:01.700
knew that the answer
would be symmetric

00:06:01.700 --> 00:06:03.710
because T is symmetric,
so that allowed

00:06:03.710 --> 00:06:05.890
me to write the first row.

00:06:05.890 --> 00:06:08.760
And now we can fill in the rest.

00:06:08.760 --> 00:06:12.450
So what do you think, if
the point load is-- Now,

00:06:12.450 --> 00:06:16.250
I'm looking at the third column,
third column of the identity,

00:06:16.250 --> 00:06:19.350
the load has moved down
to position number three.

00:06:19.350 --> 00:06:22.080
So what do I have
there and there?

00:06:22.080 --> 00:06:23.760
Two and two.

00:06:23.760 --> 00:06:26.241
And what do I have last?

00:06:26.241 --> 00:06:26.740
One.

00:06:26.740 --> 00:06:28.290
It's dropping to zero.

00:06:28.290 --> 00:06:31.730
You could put zero in
green here if you wanted.

00:06:31.730 --> 00:06:38.810
Zero is the unseen
last boundary,

00:06:38.810 --> 00:06:42.370
you know, row at this end.

00:06:42.370 --> 00:06:45.990
And finally, what's
happening here?

00:06:45.990 --> 00:06:50.080
What do I get from that?

00:06:50.080 --> 00:06:54.420
All one, one, one
to the diagonal.

00:06:54.420 --> 00:06:57.890
And then sure enough
it drops to zero.

00:06:57.890 --> 00:07:01.010
So this would be a case
where the load is there.

00:07:01.010 --> 00:07:06.010
It would be one, one,
one, one and then boom.

00:07:06.010 --> 00:07:07.112
No, it wouldn't be.

00:07:07.112 --> 00:07:08.070
It'd be more like this.

00:07:08.070 --> 00:07:14.780
One, one, one, one
and then down to--

00:07:14.780 --> 00:07:15.280
Okay.

00:07:15.280 --> 00:07:18.380
That's a pretty clean inverse.

00:07:18.380 --> 00:07:22.240
That's a very beautiful matrix.

00:07:22.240 --> 00:07:24.110
Don't you admire that matrix?

00:07:24.110 --> 00:07:27.100
I mean, if they were
all like that, gee,

00:07:27.100 --> 00:07:29.630
this would be a great world.

00:07:29.630 --> 00:07:40.760
But of course it's not sparse.

00:07:40.760 --> 00:07:43.510
That's why we don't
often use the inverse.

00:07:43.510 --> 00:07:46.090
Because we had a
sparse matrix T that

00:07:46.090 --> 00:07:48.380
was really fast to compute with.

00:07:48.380 --> 00:07:50.830
And here, if you
tell me the inverse,

00:07:50.830 --> 00:07:52.630
you've actually slowed me down.

00:07:52.630 --> 00:07:58.720
Because you've given me now a
dense matrix, no zeroes even

00:07:58.720 --> 00:08:04.830
and multiplying T inverse
times the right side

00:08:04.830 --> 00:08:08.800
would be slower than
just doing elimination.

00:08:08.800 --> 00:08:11.400
Now this is the kind of
more interesting one.

00:08:11.400 --> 00:08:16.000
Because this is the one that
has to go up to the diagonal

00:08:16.000 --> 00:08:18.490
and then down.

00:08:18.490 --> 00:08:22.680
So let me-- can I fill in what
I think-- way this one goes?

00:08:22.680 --> 00:08:26.370
I'm going upwards
to the diagonal

00:08:26.370 --> 00:08:28.170
and then I'm coming
down to zero.

00:08:28.170 --> 00:08:31.600
Remember that I'm coming
down to zero on this K.

00:08:31.600 --> 00:08:37.590
So Zero, zero, zero, zero
is kind of the row number.

00:08:37.590 --> 00:08:41.540
If that's row number zero,
here's one, two, three, four,

00:08:41.540 --> 00:08:42.700
the real thing.

00:08:42.700 --> 00:08:48.400
And then row five is
getting back to zero again.

00:08:48.400 --> 00:08:52.660
So what do you think, finish
the rest of that column.

00:08:52.660 --> 00:08:56.550
So you're telling me now
the response to the load

00:08:56.550 --> 00:08:57.850
in position two.

00:08:57.850 --> 00:08:59.910
So it's going to look like this.

00:08:59.910 --> 00:09:03.010
In fact, it's going to
look very like this.

00:09:03.010 --> 00:09:06.010
There's the three and then
this is in position two.

00:09:06.010 --> 00:09:08.750
And then I'm going to have
something here and something

00:09:08.750 --> 00:09:12.510
here and it'll drop to zero.

00:09:12.510 --> 00:09:14.050
What do I get?

00:09:14.050 --> 00:09:15.630
Four, two.

00:09:15.630 --> 00:09:17.830
Six, four, two, zero.

00:09:17.830 --> 00:09:19.490
It's dropping to zero.

00:09:19.490 --> 00:09:21.580
I'm going to finish
this in but then I'm

00:09:21.580 --> 00:09:25.660
going to look back and see
have I really got it right.

00:09:25.660 --> 00:09:28.880
How does this go now?

00:09:28.880 --> 00:09:31.480
Two, let's see.

00:09:31.480 --> 00:09:36.800
Now it's going up from
zero to two to four to six.

00:09:36.800 --> 00:09:38.330
That's on the diagonal.

00:09:38.330 --> 00:09:39.620
Now it starts down.

00:09:39.620 --> 00:09:43.300
It's got to get to zero,
so that'll be a three.

00:09:43.300 --> 00:09:48.320
Here is a one going up
to two to three to four.

00:09:48.320 --> 00:09:49.360
Is that right?

00:09:49.360 --> 00:09:52.120
And then dropped fast to zero.

00:09:52.120 --> 00:09:55.600
Is that correct?

00:09:55.600 --> 00:09:57.410
Think so, yep.

00:09:57.410 --> 00:10:01.260
Except, wait a minute now.

00:10:01.260 --> 00:10:03.740
We've got the right
overall picture.

00:10:03.740 --> 00:10:06.170
Climbing up, dropping down.

00:10:06.170 --> 00:10:07.970
Climbing up, dropping down.

00:10:07.970 --> 00:10:09.550
Climbing up, dropping down.

00:10:09.550 --> 00:10:10.420
All good.

00:10:10.420 --> 00:10:17.190
But we haven't yet got,
we haven't checked yet

00:10:17.190 --> 00:10:23.130
that the change in the
slope is supposed to be one.

00:10:23.130 --> 00:10:24.680
And it's not.

00:10:24.680 --> 00:10:29.130
Here the slope is like,
three, It's going up by threes

00:10:29.130 --> 00:10:33.840
and then it's
going down by twos.

00:10:33.840 --> 00:10:38.250
So we've gone from going
up at a slope of three

00:10:38.250 --> 00:10:41.010
to down to a slope of two.

00:10:41.010 --> 00:10:44.140
Up three, down just like this.

00:10:44.140 --> 00:10:47.520
But that would be a
change in slope of five.

00:10:47.520 --> 00:10:51.490
Therefore there's a 1/5.

00:10:51.490 --> 00:10:54.330
So this is going up with
a slope of four and down

00:10:54.330 --> 00:10:55.760
with a slope of one.

00:10:55.760 --> 00:11:00.050
Four dropping to one when I
divide by the five, that's

00:11:00.050 --> 00:11:01.070
what I like.

00:11:01.070 --> 00:11:04.060
Here is up by twos,
down by threes, again

00:11:04.060 --> 00:11:07.090
it's a change of five
so I need the five.

00:11:07.090 --> 00:11:09.720
Up by ones, down by four.

00:11:09.720 --> 00:11:12.740
Sudden, that's a
fast drop of four.

00:11:12.740 --> 00:11:16.190
Again, the slope changed
by five, dividing by five,

00:11:16.190 --> 00:11:17.610
that's got it.

00:11:17.610 --> 00:11:18.690
So that's my picture.

00:11:18.690 --> 00:11:22.420
You could now create K
inverse for any size.

00:11:22.420 --> 00:11:30.160
And more than that, sort
of see into K inverse

00:11:30.160 --> 00:11:32.250
what those numbers are.

00:11:32.250 --> 00:11:35.350
Because if I wrote the
five by five or six

00:11:35.350 --> 00:11:39.470
by six, doing it a
column at a time,

00:11:39.470 --> 00:11:42.290
it would look like
a bunch of numbers.

00:11:42.290 --> 00:11:44.050
But you see it now.

00:11:44.050 --> 00:11:46.880
Do you see the pattern?

00:11:46.880 --> 00:11:51.560
Right.

00:11:51.560 --> 00:11:54.260
This is one way to
get to those inverses,

00:11:54.260 --> 00:11:57.540
and homework problems
are offering other ways.

00:11:57.540 --> 00:12:04.240
T, in particular, is
quite easy to invert.

00:12:04.240 --> 00:12:07.400
Do I have any other
comment on inverses

00:12:07.400 --> 00:12:12.510
before the lecture on
eigenvalues really starts?

00:12:12.510 --> 00:12:18.200
Maybe I do have one comment,
one important comment.

00:12:18.200 --> 00:12:20.910
It's this, and I won't
develop it in full,

00:12:20.910 --> 00:12:24.530
but let's just say it.

00:12:24.530 --> 00:12:28.730
What if the load is
not a delta function?

00:12:28.730 --> 00:12:31.860
What if I have other loads?

00:12:31.860 --> 00:12:35.980
Like the uniform load of
all ones or any other load?

00:12:35.980 --> 00:12:45.660
What if the discrete load
here is not a delta vector?

00:12:45.660 --> 00:12:50.350
I now know the responses to each
column of the identity, right?

00:12:50.350 --> 00:12:54.140
If I put a load in position
one, there's the response.

00:12:54.140 --> 00:12:58.480
If I put a load in position
two, there is the response.

00:12:58.480 --> 00:13:03.340
Now, what if I have other loads?

00:13:03.340 --> 00:13:05.140
Let me take a typical load.

00:13:05.140 --> 00:13:10.190
What if the load was, well,
the one we looked at before.

00:13:10.190 --> 00:13:13.490
If the load was [1, 1, 1, 1].

00:13:13.490 --> 00:13:20.760
So that I had, the bar was
hanging by its own weight,

00:13:20.760 --> 00:13:24.930
let's say.

00:13:24.930 --> 00:13:29.090
In other words, could
I solve all problems

00:13:29.090 --> 00:13:31.480
by knowing these answers?

00:13:31.480 --> 00:13:33.510
That's what I'm
trying to get to.

00:13:33.510 --> 00:13:36.920
If I know these
special delta loads,

00:13:36.920 --> 00:13:41.340
then can I get the
solution for every load?

00:13:41.340 --> 00:13:42.250
Yes, no?

00:13:42.250 --> 00:13:43.490
What do you think?

00:13:43.490 --> 00:13:45.730
Yes, right.

00:13:45.730 --> 00:13:47.890
Now with this
matrix it's kind of

00:13:47.890 --> 00:13:51.040
easy to see because if you
know the inverse matrix, well

00:13:51.040 --> 00:13:53.020
you're obviously in business.

00:13:53.020 --> 00:13:59.390
If I had another load, say
another load f for load,

00:13:59.390 --> 00:14:03.450
I would just multiply by
K inverse, no problem.

00:14:03.450 --> 00:14:05.490
But I want to look
a little deeper.

00:14:05.490 --> 00:14:11.800
Because if I had other loads
here than a delta function,

00:14:11.800 --> 00:14:14.710
obviously if I had
two delta functions

00:14:14.710 --> 00:14:17.700
I could just combine
the two solutions.

00:14:17.700 --> 00:14:20.470
That's linearity that
we're using all the time.

00:14:20.470 --> 00:14:23.570
If I had ten delta functions
I could combine them.

00:14:23.570 --> 00:14:29.420
But then suppose I had
instead of a bunch of spikes,

00:14:29.420 --> 00:14:31.330
instead of a bunch
of point loads,

00:14:31.330 --> 00:14:33.710
I had a distributed load.

00:14:33.710 --> 00:14:38.110
Like all ones,
how could I do it?

00:14:38.110 --> 00:14:39.690
Main point is I could.

00:14:39.690 --> 00:14:40.410
Right?

00:14:40.410 --> 00:14:44.220
If I know these answers,
I know all answers.

00:14:44.220 --> 00:14:47.780
If I know the response
to a load at each point,

00:14:47.780 --> 00:14:50.850
then-- come back to
the discrete one.

00:14:50.850 --> 00:14:57.140
What would be the answer if
the load was [1, 1, 1, 1]?

00:14:57.140 --> 00:15:06.370
Suppose I now try to solve
the equation Ku=ones(4,1),

00:15:06.370 --> 00:15:08.509
so all ones.

00:15:08.509 --> 00:15:09.550
What would be the answer?

00:15:09.550 --> 00:15:12.960
How would I get it?

00:15:12.960 --> 00:15:15.510
I would just add the columns.

00:15:15.510 --> 00:15:20.990
Now why would I do that?

00:15:20.990 --> 00:15:21.590
Right.

00:15:21.590 --> 00:15:24.680
Because this, the
right-hand side,

00:15:24.680 --> 00:15:29.630
the input is the sum of
the four columns, the four

00:15:29.630 --> 00:15:31.330
special inputs.

00:15:31.330 --> 00:15:36.000
So the output is the sum
of the four outputs, right.

00:15:36.000 --> 00:15:39.140
In other words, as you saw,
we must know everything.

00:15:39.140 --> 00:15:41.950
And that's the way
we really know it.

00:15:41.950 --> 00:15:42.520
By linearity.

00:15:42.520 --> 00:15:46.580
If the input is a
combination of these,

00:15:46.580 --> 00:15:49.950
the output is the same
combination of those.

00:15:49.950 --> 00:15:50.770
Right.

00:15:50.770 --> 00:16:00.240
So, for example, in this T case,
if input was, if I did Tu=ones,

00:16:00.240 --> 00:16:06.760
I would just add those and the
output would be [10 9, 7, 4].

00:16:06.760 --> 00:16:10.380
That would be the output
from [1, 1, 1, 1].

00:16:10.380 --> 00:16:20.470
And now, oh boy.

00:16:20.470 --> 00:16:24.720
Actually, let me just
introduce a guy's name

00:16:24.720 --> 00:16:31.550
for these solutions
and not today show you.

00:16:31.550 --> 00:16:33.970
You have the idea, of course.

00:16:33.970 --> 00:16:37.930
Here we added because
everything was discrete.

00:16:37.930 --> 00:16:40.550
So you know what we're
going to do over here.

00:16:40.550 --> 00:16:44.290
We'll take integrals, right?

00:16:44.290 --> 00:16:51.430
A general load will be an
integral over point loads.

00:16:51.430 --> 00:16:53.090
That's the idea.

00:16:53.090 --> 00:16:54.220
A fundamental idea.

00:16:54.220 --> 00:17:00.960
That some other load, f(x),
is an integral of these guys.

00:17:00.960 --> 00:17:05.320
So the solution will be the
same integral of these guys.

00:17:05.320 --> 00:17:08.700
Let me not go there except
to tell you the name,

00:17:08.700 --> 00:17:11.020
because it's a very famous name.

00:17:11.020 --> 00:17:14.830
This solution u with
the delta function

00:17:14.830 --> 00:17:17.480
is called the Green's function.

00:17:17.480 --> 00:17:21.660
So I've now introduced the idea,
this is the Green's function.

00:17:21.660 --> 00:17:30.320
This guy is the Green's function
for the fixed-fixed problem.

00:17:30.320 --> 00:17:33.010
And this guy is the
Green's function

00:17:33.010 --> 00:17:36.280
for the free-fixed problem.

00:17:36.280 --> 00:17:38.820
And the whole point
is, maybe this

00:17:38.820 --> 00:17:44.700
is the one point I want you to
sort of see always by analogy.

00:17:44.700 --> 00:17:50.450
The Green's function is
just like the inverse.

00:17:50.450 --> 00:17:52.080
What is the Green's function?

00:17:52.080 --> 00:17:59.070
The Green's function is the
response at x, the u at x,

00:17:59.070 --> 00:18:03.010
when the input, when
the impulse is at a.

00:18:03.010 --> 00:18:04.800
So it sort of depends
on two things.

00:18:04.800 --> 00:18:09.940
It depends on the position a
of the input and it tells you

00:18:09.940 --> 00:18:14.990
the response at position x.

00:18:14.990 --> 00:18:19.260
And often we would use
the letter G for Green.

00:18:19.260 --> 00:18:23.680
So it depends on x and a.

00:18:23.680 --> 00:18:29.650
And maybe I'm happy if you
just sort of see in some way

00:18:29.650 --> 00:18:33.200
what we did there is just
like what we did here.

00:18:33.200 --> 00:18:35.220
And therefore the
Green's function

00:18:35.220 --> 00:18:40.820
must be just a differential,
continuous version

00:18:40.820 --> 00:18:46.330
of an inverse matrix.

00:18:46.330 --> 00:18:52.760
Let's move on to
eigenvalues with that point

00:18:52.760 --> 00:18:59.230
sort of made, but not driven
home by many, many examples.

00:18:59.230 --> 00:19:15.820
Question, I'll take
a question, shoot.

00:19:15.820 --> 00:19:21.220
Why did I increase zero, three,
six and then decrease six?

00:19:21.220 --> 00:19:29.350
Well intuitively it's
because this is copying this.

00:19:29.350 --> 00:19:32.660
What's wonderful is that
it's a perfect copy.

00:19:32.660 --> 00:19:37.460
I mean, intuitively the solution
to our difference equation

00:19:37.460 --> 00:19:40.710
should be like the solution
to our differential equation.

00:19:40.710 --> 00:19:44.530
That's why if we have
some computational,

00:19:44.530 --> 00:19:47.070
some differential equation
that we can't solve,

00:19:47.070 --> 00:19:49.930
which would be much more
typical than this one,

00:19:49.930 --> 00:19:53.220
that we couldn't solve it
exactly by pencil and paper,

00:19:53.220 --> 00:19:58.930
we would replace derivatives
by differences and go over here

00:19:58.930 --> 00:20:02.890
and we would hope that they
were like pretty close.

00:20:02.890 --> 00:20:07.820
Here they're right,
they're the same.

00:20:07.820 --> 00:20:08.880
Oh the other columns?

00:20:08.880 --> 00:20:09.630
Absolutely.

00:20:09.630 --> 00:20:11.610
These guys?

00:20:11.610 --> 00:20:14.880
Zero, two, four, six going up.

00:20:14.880 --> 00:20:18.180
Six, three, zero coming back.

00:20:18.180 --> 00:20:25.520
So that's a discrete
thing of one like that.

00:20:25.520 --> 00:20:27.670
And then the next
guy and the last guy

00:20:27.670 --> 00:20:30.310
would be going up
one, two, three, four

00:20:30.310 --> 00:20:34.360
and then sudden drop.

00:20:34.360 --> 00:20:35.940
Thanks for all questions.

00:20:35.940 --> 00:20:39.590
I mean, this sort of,
by adding these guys in,

00:20:39.590 --> 00:20:41.750
the first one actually
went up that way.

00:20:41.750 --> 00:20:45.500
You see the Green's functions.

00:20:45.500 --> 00:20:47.750
But of course this
has a Green's function

00:20:47.750 --> 00:20:53.300
for every a. x and a are running
all the way from zero to one.

00:20:53.300 --> 00:20:58.550
Here they're just
discrete positions.

00:20:58.550 --> 00:21:02.660
Thanks.

00:21:02.660 --> 00:21:06.140
So playing with
these delta functions

00:21:06.140 --> 00:21:09.120
and coming up with
this solution,

00:21:09.120 --> 00:21:12.910
well, as I say,
different ways to do it.

00:21:12.910 --> 00:21:16.710
I worked through one
way in class last time.

00:21:16.710 --> 00:21:18.470
It takes practice.

00:21:18.470 --> 00:21:21.610
So that's what the
homework's really for.

00:21:21.610 --> 00:21:24.820
You can see me come
up with this thing,

00:21:24.820 --> 00:21:28.810
then you can, with leisure,
you can follow the steps,

00:21:28.810 --> 00:21:32.740
but you've gotta do
it yourself to see.

00:21:32.740 --> 00:21:36.460
Eigenvalues and, of
course, eigenvectors.

00:21:36.460 --> 00:21:46.320
We have to give
them a fair shot.

00:21:46.320 --> 00:21:49.950
Square matrix.

00:21:49.950 --> 00:21:53.470
So I'm talking
about general, what

00:21:53.470 --> 00:21:57.100
eigenvectors and eigenvalues
are and why do we want them.

00:21:57.100 --> 00:22:01.400
I'm always trying to say
what's the purpose, you know,

00:22:01.400 --> 00:22:07.320
not doing this just for
abstract linear algebra.

00:22:07.320 --> 00:22:10.430
We do this, we look
for these things

00:22:10.430 --> 00:22:13.510
because they tremendously
simplify a problem

00:22:13.510 --> 00:22:16.260
if we can find it.

00:22:16.260 --> 00:22:19.970
So what's an eigenvector?

00:22:19.970 --> 00:22:23.510
The eigenvalue is
this number, lambda,

00:22:23.510 --> 00:22:26.840
and the eigenvector
is this vector y.

00:22:26.840 --> 00:22:33.120
And now, how do I
think about those?

00:22:33.120 --> 00:22:37.850
Suppose I take a vector
and I multiply by A.

00:22:37.850 --> 00:22:42.250
So the vector is headed
off in some direction.

00:22:42.250 --> 00:22:45.240
Here's a vector
v. If I multiply,

00:22:45.240 --> 00:22:47.070
and I'm given this
matrix, so I'm

00:22:47.070 --> 00:22:51.030
given the matrix,
whatever my matrix is.

00:22:51.030 --> 00:22:54.280
Could be one of those
matrices, any other matrix.

00:22:54.280 --> 00:23:00.130
If I multiply that by v,
I get some result, Av.

00:23:00.130 --> 00:23:01.410
What do I do?

00:23:01.410 --> 00:23:06.490
I look at that and I say that
v was not an eigenvector.

00:23:06.490 --> 00:23:10.290
Eigenvectors are the
special vectors which

00:23:10.290 --> 00:23:12.970
come out in the same direction.

00:23:12.970 --> 00:23:18.750
Av comes out parallel to v. So
this was not an eigenvector.

00:23:18.750 --> 00:23:21.360
Very few vectors
are eigenvectors,

00:23:21.360 --> 00:23:22.890
they're very special.

00:23:22.890 --> 00:23:25.960
Most vectors, that'll
be a typical picture.

00:23:25.960 --> 00:23:33.180
But there's a few of them
where I've a vector y

00:23:33.180 --> 00:23:36.840
and I multiply by A. And
then what's the point?

00:23:36.840 --> 00:23:42.530
Ay is in the same direction.

00:23:42.530 --> 00:23:45.090
It's on that same line as y.

00:23:45.090 --> 00:23:48.890
It could be, it might
be twice as far out.

00:23:48.890 --> 00:23:51.880
That would be Ay=2y.

00:23:51.880 --> 00:23:53.710
It might go backwards.

00:23:53.710 --> 00:23:56.070
This would be a
possibility, Ay=-y.

00:23:58.830 --> 00:24:02.200
It could be just halfway.

00:24:02.200 --> 00:24:05.020
It could be, not move at all.

00:24:05.020 --> 00:24:06.400
That's even a possibility.

00:24:06.400 --> 00:24:07.960
Ay=0y.

00:24:07.960 --> 00:24:10.910
Count that.

00:24:10.910 --> 00:24:16.870
Those y's are eigenvectors
and the eigenvalue is just,

00:24:16.870 --> 00:24:19.910
from this point of view, the
eigenvalue has come in second

00:24:19.910 --> 00:24:25.390
because it's-- So y was a
special vector that kept its

00:24:25.390 --> 00:24:26.290
direction.

00:24:26.290 --> 00:24:32.430
And then lambda is just the
number, the two, the zero,

00:24:32.430 --> 00:24:39.050
the minus one, the 1/2
that tells you stretching,

00:24:39.050 --> 00:24:41.260
shrinking, reversing, whatever.

00:24:41.260 --> 00:24:42.760
That's the number.

00:24:42.760 --> 00:24:45.830
But y is the vector.

00:24:45.830 --> 00:24:53.230
And notice that
if I knew y and I

00:24:53.230 --> 00:24:56.440
knew it was an eigenvector, then
of course if I multiply by A,

00:24:56.440 --> 00:24:59.360
I'll learn the eigenvalue.

00:24:59.360 --> 00:25:01.370
And if I knew an
eigenvalue, you'll

00:25:01.370 --> 00:25:03.790
see how I could find
the eigenvector.

00:25:03.790 --> 00:25:06.070
Problem is you have
to find them both.

00:25:06.070 --> 00:25:07.810
And they multiply each other.

00:25:07.810 --> 00:25:11.050
So we're not talking about
linear equations anymore.

00:25:11.050 --> 00:25:13.540
Because one unknown is
multiplying another.

00:25:13.540 --> 00:25:19.780
But we'll find a way to look
to discover eigenvectors

00:25:19.780 --> 00:25:23.790
and eigenvalues.

00:25:23.790 --> 00:25:27.750
I said I would try to make
clear what's the purpose.

00:25:27.750 --> 00:25:36.460
The purpose is that in this
direction on this y line, line

00:25:36.460 --> 00:25:43.080
of multiples of y, A is
just acting like a number.

00:25:43.080 --> 00:25:48.050
A is some big n by n,
1,000 by 1,000 matrix.

00:25:48.050 --> 00:25:50.050
So a million numbers.

00:25:50.050 --> 00:25:58.110
But on this line, if we find
it, if we find an eigenline,

00:25:58.110 --> 00:26:03.010
you could say, an eigendirection
in that direction,

00:26:03.010 --> 00:26:06.070
all the complications
of A are gone.

00:26:06.070 --> 00:26:08.200
It's just acting like a number.

00:26:08.200 --> 00:26:14.410
So in particular we could solve
1,000 differential equations

00:26:14.410 --> 00:26:23.680
with 1,000 unknown u's with
this 1,000 by 1,000 matrix.

00:26:23.680 --> 00:26:26.620
We can find a
solution and this is

00:26:26.620 --> 00:26:29.550
where the eigenvector
and eigenvalue

00:26:29.550 --> 00:26:34.250
are going to pay off.

00:26:34.250 --> 00:26:35.250
You recognize this.

00:26:35.250 --> 00:26:38.100
Matrix A is of size 1,000.

00:26:38.100 --> 00:26:41.940
And u is a vector
of 1,000 unknowns.

00:26:41.940 --> 00:26:44.330
So that's a system
of 1,000 equations.

00:26:44.330 --> 00:26:50.870
But if we have found an
eigenvector and its eigenvalue

00:26:50.870 --> 00:26:56.600
then the equation will, if
it starts in that direction

00:26:56.600 --> 00:26:59.770
it'll stay in that direction
and the matrix will just

00:26:59.770 --> 00:27:01.200
be acting like a number.

00:27:01.200 --> 00:27:03.660
And we know how to
solve u'=lambda*u.

00:27:06.850 --> 00:27:10.550
That one by one scalar
problem we know how to solve.

00:27:10.550 --> 00:27:13.770
The solution to that
is e to the lambda*t.

00:27:17.430 --> 00:27:21.270
And of course it could
have a constant in it.

00:27:21.270 --> 00:27:25.950
Don't forget that these
equations are linear.

00:27:25.950 --> 00:27:29.450
If I multiply it, if
I take 2e^(lambda*t),

00:27:29.450 --> 00:27:32.180
I have a two here and a two
here and it's just as good.

00:27:32.180 --> 00:27:37.660
So I better allow that as well.

00:27:37.660 --> 00:27:41.600
A constant times
e^(lambda*t) times y.

00:27:41.600 --> 00:27:43.240
Notice this is a vector.

00:27:43.240 --> 00:27:47.490
It's a number times
a number, the growth.

00:27:47.490 --> 00:27:50.520
So the lambda is now, for
the differential equation,

00:27:50.520 --> 00:27:54.570
the lambda, this number
lambda is crucial.

00:27:54.570 --> 00:27:58.810
It's telling us whether the
solution grows, whether it

00:27:58.810 --> 00:28:01.330
decays, whether it oscillates.

00:28:01.330 --> 00:28:04.680
And we're just looking
at this one normal mode,

00:28:04.680 --> 00:28:09.560
you could say normal
mode, for eigenvector y.

00:28:09.560 --> 00:28:18.010
We certainly have not found
all possible solutions.

00:28:18.010 --> 00:28:25.070
If we have an eigenvector,
we found that one.

00:28:25.070 --> 00:28:30.340
And there's other uses
and then, let me think.

00:28:30.340 --> 00:28:31.510
Other uses, what?

00:28:31.510 --> 00:28:33.950
So let me write again
the fundamental equation,

00:28:33.950 --> 00:28:34.450
Ay=lambda*y.

00:28:37.330 --> 00:28:41.150
So that was a
differential equation.

00:28:41.150 --> 00:28:43.200
Going forward in time.

00:28:43.200 --> 00:28:49.090
Now if we go forward in
steps we might multiply by A

00:28:49.090 --> 00:28:55.460
at every step.

00:28:55.460 --> 00:28:59.140
Tell me an eigenvector
of A squared.

00:28:59.140 --> 00:29:01.960
I'm looking for a vector
that doesn't change direction

00:29:01.960 --> 00:29:06.810
when I multiply twice by
A. You're going to tell me

00:29:06.810 --> 00:29:10.550
it's y. y will work.

00:29:10.550 --> 00:29:15.320
If I multiply once by
A I get lambda times y.

00:29:15.320 --> 00:29:20.620
When I multiply again by A I
get lambda squared times y.

00:29:20.620 --> 00:29:29.980
You see eigenvalues are
great for powers of a matrix,

00:29:29.980 --> 00:29:33.840
for differential equations.

00:29:33.840 --> 00:29:37.440
The nth power will just take
the eigenvalue to the nth.

00:29:37.440 --> 00:29:42.800
The nth power of A will just
have lambda to the nth there.

00:29:42.800 --> 00:29:47.350
You know, the pivots
of a matrix are all

00:29:47.350 --> 00:29:49.360
messed up when I square it.

00:29:49.360 --> 00:29:52.480
I can't see what's
happening with the pivots.

00:29:52.480 --> 00:29:56.870
The eigenvalues are a different
way to look at a matrix.

00:29:56.870 --> 00:30:01.770
The pivots are critical numbers
for steady-state problems.

00:30:01.770 --> 00:30:04.930
The eigenvalues are
the critical numbers

00:30:04.930 --> 00:30:09.250
for moving problems,
dynamic problems,

00:30:09.250 --> 00:30:13.520
things are oscillating
or growing or decaying.

00:30:13.520 --> 00:30:19.370
And by the way, let's just
recognize since this is

00:30:19.370 --> 00:30:24.990
the only thing that's
changing in time,

00:30:24.990 --> 00:30:31.400
what would be the-- I'll just
go down here, e^(lambda*t).

00:30:31.400 --> 00:30:32.850
Let's just look and see.

00:30:32.850 --> 00:30:35.630
When would I have decay?

00:30:35.630 --> 00:30:38.160
Which you might want
to call stability.

00:30:38.160 --> 00:30:40.800
A stable problem.

00:30:40.800 --> 00:30:42.840
What would be the
condition on lambda

00:30:42.840 --> 00:30:46.980
to get-- for this to decay.

00:30:46.980 --> 00:30:49.000
Lambda less than zero.

00:30:49.000 --> 00:30:52.600
Now there's one little
bit of bad news.

00:30:52.600 --> 00:30:55.180
Lambda could be complex.

00:30:55.180 --> 00:30:58.000
Lambda could be 3+4i.

00:31:00.850 --> 00:31:03.860
It can be a complex
number, these eigenvalues,

00:31:03.860 --> 00:31:09.200
even if A is real.

00:31:09.200 --> 00:31:11.370
You'll say, how did
that happen, let me see?

00:31:11.370 --> 00:31:13.200
I didn't think.

00:31:13.200 --> 00:31:14.980
Well, let me finish
this thought.

00:31:14.980 --> 00:31:18.040
Suppose lambda was 3+4i.

00:31:22.090 --> 00:31:26.610
So I'm thinking about what would
e to the lambda*t do in that

00:31:26.610 --> 00:31:27.900
case?

00:31:27.900 --> 00:31:30.820
So this is small example.

00:31:30.820 --> 00:31:32.510
If I had lambda is (3+4i), t.

00:31:35.860 --> 00:31:40.520
What does that do as time grows?

00:31:40.520 --> 00:31:42.410
It's going to grow
and oscillate.

00:31:42.410 --> 00:31:45.160
And what decides the growth?

00:31:45.160 --> 00:31:46.680
The real part.

00:31:46.680 --> 00:31:49.130
So it's really the
decay or growth

00:31:49.130 --> 00:31:51.850
is decided by the real part.

00:31:51.850 --> 00:31:55.810
The three, e to the 3t,
that would be a growth.

00:31:55.810 --> 00:31:58.430
Let me put growth.

00:31:58.430 --> 00:32:01.190
And that would be,
of course, unstable.

00:32:01.190 --> 00:32:05.000
And that's a problem
when I have a real part

00:32:05.000 --> 00:32:07.910
of lambda bigger than zero.

00:32:07.910 --> 00:32:12.340
And then if lambda
has a zero real part,

00:32:12.340 --> 00:32:17.640
so it's pure oscillation, let
me just take a case like that.

00:32:17.640 --> 00:32:18.250
So e^(4it).

00:32:20.990 --> 00:32:24.580
So that would be,
oscillating, right?

00:32:24.580 --> 00:32:31.570
It's cos(4t) + i*sin(4t),
it's just oscillating.

00:32:31.570 --> 00:32:39.430
So in this discussion we've
seen growth and decay.

00:32:39.430 --> 00:32:41.490
Tell me the parallels
because I'm always

00:32:41.490 --> 00:32:43.150
shooting for the parallels.

00:32:43.150 --> 00:32:45.930
What about the growth of A?

00:32:45.930 --> 00:32:51.300
What matrices, how
can I recognize

00:32:51.300 --> 00:32:56.500
a matrix whose powers grow?

00:32:56.500 --> 00:33:02.950
How can I recognize a matrix
whose powers go to zero?

00:33:02.950 --> 00:33:05.630
I'm asking you for
powers here, over there

00:33:05.630 --> 00:33:08.940
for exponentials somehow.

00:33:08.940 --> 00:33:15.400
So here would be A to
higher and higher powers

00:33:15.400 --> 00:33:18.670
goes to zero, the zero matrix.

00:33:18.670 --> 00:33:20.740
In other words, when
I multiply, multiply,

00:33:20.740 --> 00:33:24.440
multiply by that matrix I get
smaller and smaller and smaller

00:33:24.440 --> 00:33:26.760
matrices, zero in the limit.

00:33:26.760 --> 00:33:33.730
What do you think's the
test on the lambda now?

00:33:33.730 --> 00:33:37.500
So what are the
eigenvalues of A to the k?

00:33:37.500 --> 00:33:38.000
Let's see.

00:33:38.000 --> 00:33:40.980
If A had eigenvalues
lambda, A squared

00:33:40.980 --> 00:33:43.000
will have eigenvalues
lambda squared,

00:33:43.000 --> 00:33:45.510
A cubed will have
eigenvalues lambda cubed,

00:33:45.510 --> 00:33:48.165
A to the thousandth will
have eigenvalues lambda

00:33:48.165 --> 00:33:49.780
to the thousandth.

00:33:49.780 --> 00:33:54.820
And what's the test for
that to be getting small?

00:33:54.820 --> 00:33:58.640
Lambda less than one.

00:33:58.640 --> 00:34:03.880
So the test for stability will
be-- In the discrete case,

00:34:03.880 --> 00:34:07.530
it won't be the
real part of lambda,

00:34:07.530 --> 00:34:10.880
it'll be the size of
lambda less than one.

00:34:10.880 --> 00:34:16.430
And growth would be the size
of lambda greater than one.

00:34:16.430 --> 00:34:19.400
And again, there'd be
this borderline case

00:34:19.400 --> 00:34:24.310
when the eigenvalue has
magnitude exactly one.

00:34:24.310 --> 00:34:30.000
So you're seeing here
and also here the idea

00:34:30.000 --> 00:34:34.850
that we may have to deal
with complex numbers here.

00:34:34.850 --> 00:34:37.190
We don't have to deal
with the whole world

00:34:37.190 --> 00:34:40.620
of complex functions
and everything

00:34:40.620 --> 00:34:45.710
but it's possible for
complex numbers to come in.

00:34:45.710 --> 00:34:49.720
Well while I'm saying that,
why don't I give an example

00:34:49.720 --> 00:34:58.550
where it would come in.

00:34:58.550 --> 00:35:03.130
This is going to
be a real matrix

00:35:03.130 --> 00:35:07.360
with complex eigenvalues.

00:35:07.360 --> 00:35:11.030
Complex lambdas.

00:35:11.030 --> 00:35:19.770
It'll be an example.

00:35:19.770 --> 00:35:22.530
So I guess I'm
looking for a matrix

00:35:22.530 --> 00:35:29.320
where y and Ay never come
out in the same direction.

00:35:29.320 --> 00:35:34.240
For real y's I know, okay,
here's a good matrix.

00:35:34.240 --> 00:35:41.690
Take the matrix that rotates
every vector by 90 degrees.

00:35:41.690 --> 00:35:43.570
Or by theta.

00:35:43.570 --> 00:35:48.450
But let's say here's a matrix
that rotates every vector

00:35:48.450 --> 00:35:55.500
by 90 degrees.

00:35:55.500 --> 00:35:57.350
I'm going to raise
this board and hide it

00:35:57.350 --> 00:35:58.970
behind there in a minute.

00:35:58.970 --> 00:36:05.290
I just wanted to-- just to open
up this thought that we will

00:36:05.290 --> 00:36:09.960
have to face complex numbers.

00:36:09.960 --> 00:36:15.610
If you know how to multiply two
complex numbers and add them,

00:36:15.610 --> 00:36:16.800
you're okay.

00:36:16.800 --> 00:36:20.480
This isn't going to
turn into a big deal.

00:36:20.480 --> 00:36:25.020
But let's just realize
that-- Suppose that matrix,

00:36:25.020 --> 00:36:30.040
if I put in a vector y and
I multiply by that matrix,

00:36:30.040 --> 00:36:33.580
it'll turn it
through 90 degrees.

00:36:33.580 --> 00:36:35.420
So y couldn't be an eigenvector.

00:36:35.420 --> 00:36:37.070
That's the point
I'm trying to make.

00:36:37.070 --> 00:36:41.860
No real vector could
be the eigenvector

00:36:41.860 --> 00:36:46.720
of a rotation matrix because
every vector gets turned.

00:36:46.720 --> 00:36:53.230
So that's an example where you'd
have to go to complex vectors.

00:36:53.230 --> 00:36:58.960
and I think if I tried
the vector [1, i],

00:36:58.960 --> 00:37:02.730
so I'm letting the square
root of minus one into here,

00:37:02.730 --> 00:37:05.710
then I think it would come out.

00:37:05.710 --> 00:37:09.040
If I do that multiplication
I get minus i.

00:37:09.040 --> 00:37:10.670
And I get one.

00:37:10.670 --> 00:37:15.710
And I think that
this is, what is it?

00:37:15.710 --> 00:37:17.930
This is probably
minus i times that.

00:37:17.930 --> 00:37:32.230
So this is minus
i times the input.

00:37:32.230 --> 00:37:34.120
No big deal.

00:37:34.120 --> 00:37:36.940
That was like, you
can forget that.

00:37:36.940 --> 00:37:43.310
It's just complex
numbers can come in.

00:37:43.310 --> 00:37:52.650
Now let me come back to the
main point about eigenvectors.

00:37:52.650 --> 00:37:57.710
Things can be complex.

00:37:57.710 --> 00:38:02.400
So the main point is
how do we use them?

00:38:02.400 --> 00:38:08.690
And how many are there?

00:38:08.690 --> 00:38:10.610
Here's the key.

00:38:10.610 --> 00:38:13.520
A typical, good
matrix, which includes

00:38:13.520 --> 00:38:15.810
every symmetric
matrix, so it includes

00:38:15.810 --> 00:38:20.870
all of our examples and
more, if it's of size 1,000,

00:38:20.870 --> 00:38:24.810
it will have 1,000
different eigenvectors.

00:38:24.810 --> 00:38:29.770
And let me just say for
our symmetric matrices

00:38:29.770 --> 00:38:33.250
those eigenvectors
will all be real.

00:38:33.250 --> 00:38:37.170
They're great, the eigenvectors
of symmetric matrices.

00:38:37.170 --> 00:38:40.980
Oh, let me find them for one
particular symmetric matrix.

00:38:40.980 --> 00:38:47.040
Say this guy.

00:38:47.040 --> 00:38:49.950
So that's a matrix, two by two.

00:38:49.950 --> 00:38:53.850
How many eigenvectors
am I now looking for?

00:38:53.850 --> 00:38:55.960
Two.

00:38:55.960 --> 00:38:59.980
You could say, how
do I find them?

00:38:59.980 --> 00:39:07.740
Maybe with a two by two,
I can even just wing it.

00:39:07.740 --> 00:39:13.350
We can come up with a vector
that is an eigenvector.

00:39:13.350 --> 00:39:15.840
Actually that's what
we're going to do

00:39:15.840 --> 00:39:20.070
here is we're going to
guess the eigenvectors

00:39:20.070 --> 00:39:22.330
and then we're going to
show that they really

00:39:22.330 --> 00:39:24.990
are eigenvectors and then
we'll know the eigenvalues

00:39:24.990 --> 00:39:27.010
and it's fantastic.

00:39:27.010 --> 00:39:31.140
So like let's start here
with the two by two case.

00:39:31.140 --> 00:39:33.050
Anybody spot an eigenvector?

00:39:33.050 --> 00:39:35.360
Is [1, 0] an eigenvector?

00:39:35.360 --> 00:39:36.310
Try [1, 0].

00:39:36.310 --> 00:39:39.530
What comes out of [1, 0]?

00:39:39.530 --> 00:39:43.530
Well that picks the
first column, right?

00:39:43.530 --> 00:39:45.860
That's how I see,
multiplying by [1, 0],

00:39:45.860 --> 00:39:48.460
that says take one
of the first column.

00:39:48.460 --> 00:39:52.450
And is it an eigenvector?

00:39:52.450 --> 00:39:53.960
Yes, no?

00:39:53.960 --> 00:39:55.760
No.

00:39:55.760 --> 00:39:59.300
This vector is not in the
same direction as that one.

00:39:59.300 --> 00:40:00.870
No good.

00:40:00.870 --> 00:40:09.360
Now can you tell me one that is?

00:40:09.360 --> 00:40:12.200
You're going to
guess it. [1,  1].

00:40:12.200 --> 00:40:15.000
Try [1, 1].

00:40:15.000 --> 00:40:21.080
Do the multiplication
and what do you get?

00:40:21.080 --> 00:40:23.780
Right?

00:40:23.780 --> 00:40:29.000
If I input this vector
y, what do I get out?

00:40:29.000 --> 00:40:33.390
Actually I get y itself.

00:40:33.390 --> 00:40:36.510
Right?

00:40:36.510 --> 00:40:38.620
The point is it didn't
change direction,

00:40:38.620 --> 00:40:40.780
and it didn't even
change length.

00:40:40.780 --> 00:40:42.840
So what's the
eigenvalue for that?

00:40:42.840 --> 00:40:47.840
So I've got one eigenvalue
now, one eigenvector. [1, 1].

00:40:47.840 --> 00:40:51.120
And I've got the eigenvalue.

00:40:51.120 --> 00:40:53.980
So here are the
vectors, the y's.

00:40:53.980 --> 00:40:55.690
And here are the lambdas.

00:40:55.690 --> 00:41:01.440
And I've got one of them
and it's one, right?

00:41:01.440 --> 00:41:03.390
Would you like to
guess the other one?

00:41:03.390 --> 00:41:06.560
I'm only looking for two because
it's a two by two matrix.

00:41:06.560 --> 00:41:10.020
So let me erase here,
hope that you'll

00:41:10.020 --> 00:41:17.350
come up with another one. [1,
 -1] is certainly worth a try.

00:41:17.350 --> 00:41:19.220
Let's test it.

00:41:19.220 --> 00:41:21.430
If it's an eigenvector,
then it should come out

00:41:21.430 --> 00:41:22.430
in the same direction.

00:41:22.430 --> 00:41:26.290
What do I get when I do that?

00:41:26.290 --> 00:41:28.600
So I do that multiplication.

00:41:28.600 --> 00:41:32.740
Three and I get three
and minus three,

00:41:32.740 --> 00:41:35.790
so have we got an eigenvector?

00:41:35.790 --> 00:41:37.390
Yep.

00:41:37.390 --> 00:41:42.390
And what's, so if this was
y, what is this vector?

00:41:42.390 --> 00:41:44.220
3y.

00:41:44.220 --> 00:41:47.660
So there's the other
eigenvector, is [1, -1],

00:41:47.660 --> 00:41:56.150
and the other
eigenvalue is three.

00:41:56.150 --> 00:42:01.370
So we did it by
spotting it here.

00:42:01.370 --> 00:42:03.420
MATLAB can't do it that way.

00:42:03.420 --> 00:42:06.310
It's got to figure it out.

00:42:06.310 --> 00:42:12.120
But we're ahead of
MATLAB this time.

00:42:12.120 --> 00:42:15.650
So what do I notice?

00:42:15.650 --> 00:42:17.550
What do I notice
about this matrix?

00:42:17.550 --> 00:42:20.690
It was symmetric.

00:42:20.690 --> 00:42:25.150
And what do I notice
about the eigenvectors?

00:42:25.150 --> 00:42:29.390
If I show you those two
vectors, [1, 1] and [1, -1],

00:42:29.390 --> 00:42:32.710
what do you see there?

00:42:32.710 --> 00:42:38.270
They're orthogonal. [1, 1]
is orthogonal to [1, -1],

00:42:38.270 --> 00:42:40.910
perpendicular is the
same as orthogonal.

00:42:40.910 --> 00:42:49.890
These are orthogonal,
perpendicular.

00:42:49.890 --> 00:42:53.090
I can draw them, of course,
and see that. [1, 1]

00:42:53.090 --> 00:42:58.260
will go, if this is
one, it'll go here.

00:42:58.260 --> 00:43:00.510
So that's [1, 1].

00:43:00.510 --> 00:43:03.420
And [1, -1] will go
there, it'll go down,

00:43:03.420 --> 00:43:06.030
this would be the
other one. [1,  -1].

00:43:06.030 --> 00:43:07.820
So there's y_1.

00:43:07.820 --> 00:43:08.780
There's y_2.

00:43:08.780 --> 00:43:11.260
And they are perpendicular.

00:43:11.260 --> 00:43:17.300
But of course I don't draw
pictures all the time.

00:43:17.300 --> 00:43:21.920
What's the test for two
vectors being orthogonal?

00:43:21.920 --> 00:43:23.440
The dot product.

00:43:23.440 --> 00:43:24.530
The dot product.

00:43:24.530 --> 00:43:31.540
The inner product. y
transpose-- y_1 transpose * y_2.

00:43:31.540 --> 00:43:35.510
Do you prefer to write it
as y_1 with a dot, y_2?

00:43:38.550 --> 00:43:42.660
This is maybe better because
it's matrix notation.

00:43:42.660 --> 00:43:51.420
And the point is orthogonal,
the dot product is zero.

00:43:51.420 --> 00:43:53.160
So that's good.

00:43:53.160 --> 00:43:56.240
Very good, in fact.

00:43:56.240 --> 00:43:59.180
So here's a very important fact.

00:43:59.180 --> 00:44:06.730
Symmetric matrices have
orthogonal eigenvectors.

00:44:06.730 --> 00:44:09.470
What I'm trying to say is
eigenvectors and eigenvalues

00:44:09.470 --> 00:44:13.390
are like a new way
to look at a matrix.

00:44:13.390 --> 00:44:16.820
A new way to see into it.

00:44:16.820 --> 00:44:21.270
And when the matrix is
symmetric, what we see

00:44:21.270 --> 00:44:25.040
is perpendicular eigenvectors.

00:44:25.040 --> 00:44:28.080
And what comment do you
have about the eigenvalues

00:44:28.080 --> 00:44:32.260
of this symmetric matrix?

00:44:32.260 --> 00:44:36.290
Remembering what
was on the board

00:44:36.290 --> 00:44:40.330
for this anti-symmetric matrix.

00:44:40.330 --> 00:44:44.290
What was the point about
that anti-symmetric matrix?

00:44:44.290 --> 00:44:51.330
Its eigenvalues were imaginary
actually, an i there.

00:44:51.330 --> 00:44:53.240
Here it's the opposite.

00:44:53.240 --> 00:44:56.620
What's the property
of the eigenvalues

00:44:56.620 --> 00:45:00.940
for a symmetric matrix
that you would just guess?

00:45:00.940 --> 00:45:02.080
They're real.

00:45:02.080 --> 00:45:03.670
They're real.

00:45:03.670 --> 00:45:06.280
Symmetric matrices
are great because they

00:45:06.280 --> 00:45:18.960
have real eigenvalues and they
have perpendicular eigenvectors

00:45:18.960 --> 00:45:22.380
and actually, probably if a
matrix has real eigenvalues

00:45:22.380 --> 00:45:27.090
and perpendicular eigenvectors,
it's going to be symmetric.

00:45:27.090 --> 00:45:32.230
So symmetry is a great property
and it shows up in a great way

00:45:32.230 --> 00:45:38.580
in this real eigenvalue, real
lambdas, and orthogonal y's.

00:45:38.580 --> 00:45:48.270
Shows up perfectly
in the eigenpicture.

00:45:48.270 --> 00:45:53.660
Here's a handy little
check on the eigenvalues

00:45:53.660 --> 00:45:55.580
to see if we got it right.

00:45:55.580 --> 00:45:56.700
Course we did.

00:45:56.700 --> 00:45:59.460
That's one and three we can get.

00:45:59.460 --> 00:46:03.950
But let me just show you two
useful checks if you haven't

00:46:03.950 --> 00:46:06.230
seen eigenvalues before.

00:46:06.230 --> 00:46:10.520
If I add the eigenvalues,
what do I get?

00:46:10.520 --> 00:46:12.140
Four.

00:46:12.140 --> 00:46:15.060
And I compare that
with adding down

00:46:15.060 --> 00:46:17.340
the diagonal of the matrix.

00:46:17.340 --> 00:46:19.350
Two and two, four.

00:46:19.350 --> 00:46:21.800
And that check always works.

00:46:21.800 --> 00:46:25.160
The sum of the eigenvalues
matches the sum

00:46:25.160 --> 00:46:26.220
down the diagonal.

00:46:26.220 --> 00:46:30.810
So that's like, if you got all
the eigenvalues but one, that

00:46:30.810 --> 00:46:32.150
would tell you the last one.

00:46:32.150 --> 00:46:36.060
Because the sum
of the eigenvalues

00:46:36.060 --> 00:46:39.990
matches the sum
down the diagonal.

00:46:39.990 --> 00:46:45.130
You have no clue where that
comes from but it's true.

00:46:45.130 --> 00:46:48.060
And another useful fact.

00:46:48.060 --> 00:46:52.340
If I multiply the
eigenvalues what do I get?

00:46:52.340 --> 00:46:53.620
Three?

00:46:53.620 --> 00:46:58.390
And now, where do you
see a three over here?

00:46:58.390 --> 00:47:00.730
The determinant.

00:47:00.730 --> 00:47:03.370
4-1=3.

00:47:03.370 --> 00:47:07.860
Can I just write those two
facts with no idea of proof.

00:47:07.860 --> 00:47:12.290
The sum of the lambdas,
I could write "sum".

00:47:16.000 --> 00:47:21.680
This is for any matrix, the sum
of the lambdas is equal to the,

00:47:21.680 --> 00:47:25.170
it's called the
trace, of the matrix.

00:47:25.170 --> 00:47:29.190
The trace of the matrix is
the sum down the diagonal.

00:47:29.190 --> 00:47:36.360
And the product of the lambdas,
lambda_1 times lambda_2

00:47:36.360 --> 00:47:40.300
is the determinant
of the matrix.

00:47:40.300 --> 00:47:42.830
Or if I had ten eigenvalues,
I would multiply all ten

00:47:42.830 --> 00:47:47.220
and I'd get the determinant.

00:47:47.220 --> 00:47:51.500
So that's some facts
about eigenvalues.

00:47:51.500 --> 00:47:55.960
There's more, of
course, in section 1.5

00:47:55.960 --> 00:47:58.260
about how you would
find eigenvalues

00:47:58.260 --> 00:48:04.760
and how you would use them.

00:48:04.760 --> 00:48:09.770
That's of course the key point,
is how would we use them.

00:48:09.770 --> 00:48:15.770
Let me say something more about
that, how to use eigenvalues.

00:48:15.770 --> 00:48:22.480
Suppose I have this system of
1,000 differential equations.

00:48:22.480 --> 00:48:27.600
Linear, constant coefficients,
starts from some u(0).

00:48:34.220 --> 00:48:37.380
How do eigenvalues
and eigenvectors help?

00:48:37.380 --> 00:48:40.060
Well, first I have to
find them, that's the job.

00:48:40.060 --> 00:48:44.200
So suppose I find 1,000
eigenvalues and eigenvectors.

00:48:44.200 --> 00:48:50.680
A times eigenvector number
i is eigenvalue number i

00:48:50.680 --> 00:48:52.470
times eigenvector number i.

00:48:52.470 --> 00:49:00.230
So these, y_1 to y_1000, so y_1
to y_1000 are the eigenvectors.

00:49:00.230 --> 00:49:02.920
And each one has
its own eigenvalue,

00:49:02.920 --> 00:49:05.830
lambda_1 to lambda_1000.

00:49:05.830 --> 00:49:11.260
And now if I did that work,
sort of like, in advance,

00:49:11.260 --> 00:49:14.310
now I come to the
differential equation.

00:49:14.310 --> 00:49:21.250
How could I use this?

00:49:21.250 --> 00:49:26.770
This is now going to
be the most-- it's

00:49:26.770 --> 00:49:29.460
three steps to use
it, three steps

00:49:29.460 --> 00:49:33.600
to use these to get the answer.

00:49:33.600 --> 00:49:37.470
Ready for step one.

00:49:37.470 --> 00:49:44.280
Step one is break u
nought into eigenvectors.

00:49:44.280 --> 00:49:48.440
Split, separate,
write, express u(0)

00:49:48.440 --> 00:50:02.040
as a combination
of eigenvectors.

00:50:02.040 --> 00:50:05.360
Now step two.

00:50:05.360 --> 00:50:08.150
What happens to
each eigenvector?

00:50:08.150 --> 00:50:10.550
So this is where the
differential equation

00:50:10.550 --> 00:50:11.200
starts from.

00:50:11.200 --> 00:50:13.480
This is the initial condition.

00:50:13.480 --> 00:50:17.490
1,000 components of u
at the start and it's

00:50:17.490 --> 00:50:23.390
separated into 1,000
eigenvector pieces.

00:50:23.390 --> 00:50:28.580
Now step two is watch
each piece separately.

00:50:28.580 --> 00:50:41.620
So step two will be multiply
say c_1 by e^(lambda_1*t),

00:50:41.620 --> 00:50:44.150
by its growth.

00:50:44.150 --> 00:50:47.680
This is following
eigenvector number one.

00:50:47.680 --> 00:50:53.250
And in general, I would multiply
every one of the c's by e

00:50:53.250 --> 00:50:55.140
to those guys.

00:50:55.140 --> 00:50:59.550
So what would I have now?

00:50:59.550 --> 00:51:01.860
This is one piece of the start.

00:51:01.860 --> 00:51:05.300
And that gives me one
piece of the finish.

00:51:05.300 --> 00:51:14.220
So the finish is, the answer
is to add up the 1,000 pieces.

00:51:14.220 --> 00:51:18.900
And if you're with me, you see
what those 1,000 pieces are.

00:51:18.900 --> 00:51:23.480
Here's a piece, some multiple
of the first eigenvector.

00:51:23.480 --> 00:51:26.370
Now if we only were
working with that piece,

00:51:26.370 --> 00:51:29.470
we follow it in time
by multiplying it

00:51:29.470 --> 00:51:31.640
by e to the lambda_1
* t, and what do we

00:51:31.640 --> 00:51:36.034
have at a later time?

00:51:36.034 --> 00:51:36.950
c_1*e^(lambda_1*t)y_1.

00:51:41.990 --> 00:51:45.520
This piece has grown into that.

00:51:45.520 --> 00:51:48.460
And other pieces have
grown into other things.

00:51:48.460 --> 00:51:50.840
And what about the last piece?

00:51:50.840 --> 00:51:57.100
So what is it that
I have to add up?

00:51:57.100 --> 00:51:59.690
Tell me what to write here.

00:51:59.690 --> 00:52:05.190
c_1000, however much
of eigenvector 1,000

00:52:05.190 --> 00:52:10.700
was in there, and
then finally, never

00:52:10.700 --> 00:52:20.090
written left-handed
before, e to the who?

00:52:20.090 --> 00:52:23.310
Lambda number 1,000,
not 1,000 itself,

00:52:23.310 --> 00:52:31.500
but its eigenvalue, 1,000, t.

00:52:31.500 --> 00:52:36.900
This is just splitting, this
is constantly, constantly

00:52:36.900 --> 00:52:41.970
the method, the way to use
eigenvalues and eigenvectors.

00:52:41.970 --> 00:52:45.490
Split the problem
into the pieces that

00:52:45.490 --> 00:52:48.380
go-- that are eigenvectors.

00:52:48.380 --> 00:52:53.790
Watch each piece,
add up the pieces.

00:52:53.790 --> 00:52:56.560
That's why eigenvectors
are so important.

00:52:56.560 --> 00:52:59.800
Yeah?

00:52:59.800 --> 00:53:02.600
Yes, right.

00:53:02.600 --> 00:53:08.760
Well, now, very good question.

00:53:08.760 --> 00:53:09.979
Let's see.

00:53:09.979 --> 00:53:11.520
Well, the first
thing we have to know

00:53:11.520 --> 00:53:14.760
is that we do find
1,000 eigenvectors.

00:53:14.760 --> 00:53:19.940
And so my answer is going to
be for symmetric matrices,

00:53:19.940 --> 00:53:21.850
everything always works.

00:53:21.850 --> 00:53:25.060
For symmetric matrices,
if size is 1,000,

00:53:25.060 --> 00:53:28.360
they have 1,000 eigenvectors,
and next time we'll

00:53:28.360 --> 00:53:30.330
have a shot at some of these.

00:53:30.330 --> 00:53:33.920
What some of them are for
these special matrices.

00:53:33.920 --> 00:53:36.890
So this method
always works if I've

00:53:36.890 --> 00:53:42.660
got a full family of
independent eigenvectors.

00:53:42.660 --> 00:53:47.780
If it's of size 1,000, I need,
you're right, exactly right.

00:53:47.780 --> 00:53:52.690
To see that this was
the questionable step.

00:53:52.690 --> 00:53:55.270
If I haven't got
1,000 eigenvectors,

00:53:55.270 --> 00:53:57.270
I'm not going to be
able to take that step.

00:53:57.270 --> 00:53:59.890
And it happens.

00:53:59.890 --> 00:54:05.340
I am sad to report that
some matrices haven't

00:54:05.340 --> 00:54:07.650
got enough eigenvectors.

00:54:07.650 --> 00:54:11.800
Some matrices, they collapse.

00:54:11.800 --> 00:54:15.300
This always happens
in math, somehow.

00:54:15.300 --> 00:54:19.020
Two eigenvectors collapse
into one and the matrix

00:54:19.020 --> 00:54:23.950
is defective, like it's a loser.

00:54:23.950 --> 00:54:28.890
So now you have to, of
course, the equation

00:54:28.890 --> 00:54:31.720
still has a solution.

00:54:31.720 --> 00:54:34.320
So there has to be
something there,

00:54:34.320 --> 00:54:37.890
but the pure eigenvector
method is not

00:54:37.890 --> 00:54:40.890
going to make it on
those special matrices.

00:54:40.890 --> 00:54:43.530
I could write down
one but why should we

00:54:43.530 --> 00:54:46.760
give space to a loser?

00:54:46.760 --> 00:54:51.460
But what happens in that case?

00:54:51.460 --> 00:54:54.310
You might remember from
differential equations

00:54:54.310 --> 00:54:58.260
when two of these roots,
these are like roots,

00:54:58.260 --> 00:55:00.720
these lambdas are
like roots that you

00:55:00.720 --> 00:55:04.910
found in solving a
differential equation.

00:55:04.910 --> 00:55:09.290
When two of them come together,
that's when the danger is.

00:55:09.290 --> 00:55:11.680
When I have a double
eigenvalue, then there's

00:55:11.680 --> 00:55:15.090
a high risk that I've
only got one eigenvector.

00:55:15.090 --> 00:55:20.730
And I'll just put in this
little thing what the other,

00:55:20.730 --> 00:55:23.910
so the e^(lambda_1*t) is fine.

00:55:23.910 --> 00:55:29.130
But if that y_1 is like, if
the lambda_1's in there twice,

00:55:29.130 --> 00:55:30.570
I need something new.

00:55:30.570 --> 00:55:34.760
And the new thing turns
out to be t*e^(lambda* t).

00:55:38.220 --> 00:55:40.320
I don't know if
anybody remembers.

00:55:40.320 --> 00:55:44.570
This was probably hammered back
in differential equations that

00:55:44.570 --> 00:55:49.660
if you had repeated
something or other then this,

00:55:49.660 --> 00:55:53.180
you didn't get pure
e^(lambda*t)'s, you got also

00:55:53.180 --> 00:55:54.650
a t*e^(lambda*t).

00:55:54.650 --> 00:55:56.660
Anyway that's the answer.

00:55:56.660 --> 00:55:58.870
That if we're
short eigenvectors,

00:55:58.870 --> 00:56:02.380
and it can happen, but it
won't for our good matrices.

00:56:02.380 --> 00:56:07.580
Okay, so Monday
I've got lots to do.

00:56:07.580 --> 00:56:11.403
Special eigenvalues and vectors
and then positive definite.

