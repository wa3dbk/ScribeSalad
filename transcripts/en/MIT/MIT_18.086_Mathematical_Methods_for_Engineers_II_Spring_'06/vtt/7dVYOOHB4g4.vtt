WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.950
The following
content is provided

00:00:01.950 --> 00:00:06.090
by MIT OpenCourseWare under
a Creative Commons license.

00:00:06.090 --> 00:00:08.230
Additional information
about our license

00:00:08.230 --> 00:00:10.490
and MIT OpenCourseWare
in general,

00:00:10.490 --> 00:00:11.930
is available at ocw.mit.edu.

00:00:17.400 --> 00:00:20.440
PROFESSOR: For me, this is
the third and last major topic

00:00:20.440 --> 00:00:21.970
of the course.

00:00:21.970 --> 00:00:28.730
The first one was initial
value problems -- stability,

00:00:28.730 --> 00:00:31.020
accuracy.

00:00:31.020 --> 00:00:36.510
Topic two was solving
large linear systems

00:00:36.510 --> 00:00:42.850
by iterative methods and
also by direct methods

00:00:42.850 --> 00:00:45.740
like re-ordering the equations.

00:00:45.740 --> 00:00:50.070
Now, topic three is a whole
world of optimization.

00:00:55.260 --> 00:00:59.680
In reality it means you're
minimizing or possibly

00:00:59.680 --> 00:01:03.600
maximizing some expression.

00:01:03.600 --> 00:01:07.370
That expression could be a
function of several variables.

00:01:07.370 --> 00:01:11.390
We could be in the discrete
case, so we've got --

00:01:11.390 --> 00:01:15.790
maybe I just emphasize that
we have discrete optimization.

00:01:20.610 --> 00:01:29.440
So that's in R^n,
discrete in n dimensions,

00:01:29.440 --> 00:01:39.270
and that will include some
famous areas as single,

00:01:39.270 --> 00:01:43.400
as small subsets, really,
of the big picture.

00:01:43.400 --> 00:01:46.810
For example, one subset
would be linear programming.

00:01:52.050 --> 00:01:58.060
So that's a very special but
important case of problems

00:01:58.060 --> 00:02:01.070
where the cost is
linear, the constraints

00:02:01.070 --> 00:02:06.420
are linear, and has its
own special methods.

00:02:06.420 --> 00:02:11.940
So I think that's worth
considering on its own

00:02:11.940 --> 00:02:15.640
at a later point in a lecture.

00:02:15.640 --> 00:02:17.780
Another bigger picture
-- for us, actually,

00:02:17.780 --> 00:02:24.450
bigger will be quadratic
programming where the quantity

00:02:24.450 --> 00:02:28.490
that's being minimized
is a quadratic function.

00:02:28.490 --> 00:02:31.060
Now what's good about
a quadratic function?

00:02:31.060 --> 00:02:33.010
Its derivatives are linear.

00:02:33.010 --> 00:02:36.010
So that leads us to
linear equations,

00:02:36.010 --> 00:02:39.380
but always with constraints.

00:02:49.960 --> 00:02:53.570
We don't have a free choice
of any vector in R^n.

00:02:53.570 --> 00:02:58.980
We have constraints on the
vectors, they have to --

00:02:58.980 --> 00:03:05.690
maybe they solve a linear
system of their own.

00:03:05.690 --> 00:03:09.260
We might be in 100
dimensions and we

00:03:09.260 --> 00:03:13.390
might have 10 linear equations
as the unknowns have to solve.

00:03:13.390 --> 00:03:19.640
So in some way we're really in
90 dimensions, but it might --

00:03:19.640 --> 00:03:22.990
you know, how should we
treat those constraints?

00:03:22.990 --> 00:03:27.060
Well, you know that Lagrange
multipliers play a role.

00:03:27.060 --> 00:03:33.760
So there's a big area, very big
area, of discrete optimization.

00:03:33.760 --> 00:03:39.900
Then, also, there is
the continuous problems

00:03:39.900 --> 00:03:49.120
where the unknown is a function,
is a function u of x I'll say,

00:03:49.120 --> 00:03:52.020
or u of x and y.

00:03:52.020 --> 00:03:54.880
It's a function.

00:03:54.880 --> 00:03:58.430
That's why I refer to that area
as continuous optimization.

00:04:03.470 --> 00:04:07.780
Well, first, you
always want to get

00:04:07.780 --> 00:04:12.120
an equation, which is
in some way going to be

00:04:12.120 --> 00:04:15.000
derivative equals zero, right.

00:04:15.000 --> 00:04:18.680
When we learn about minimization
in elementary calculus,

00:04:18.680 --> 00:04:20.610
somewhere along
the line is going

00:04:20.610 --> 00:04:23.570
to be an equation
that has something

00:04:23.570 --> 00:04:26.620
like derivative equals zero.

00:04:26.620 --> 00:04:31.060
But, of course, we have to
account for the constraints.

00:04:31.060 --> 00:04:36.380
We have to ask, what is --
the derivative of what when

00:04:36.380 --> 00:04:38.670
our unknown is a function.

00:04:38.670 --> 00:04:43.400
I'm just going to write down
a topic within mathematics

00:04:43.400 --> 00:04:49.050
that this is often expressed as.

00:04:49.050 --> 00:04:52.700
Calculus -- that
would be derivative.

00:04:52.700 --> 00:04:57.214
But in the case
for functions it's

00:04:57.214 --> 00:04:58.880
often called the
calculus of variations.

00:05:02.150 --> 00:05:04.240
So that's just so
you see that word.

00:05:04.240 --> 00:05:06.190
There are books with that title.

00:05:09.220 --> 00:05:14.300
The idea of what is that
derivative when our unknown is

00:05:14.300 --> 00:05:19.540
a function and the objective
that we're trying to minimize

00:05:19.540 --> 00:05:23.070
is the integral of the
function and its derivatives --

00:05:23.070 --> 00:05:28.200
all sorts of
possibilities there.

00:05:28.200 --> 00:05:34.490
So that that's a very
quick overview of a field

00:05:34.490 --> 00:05:37.350
that we'll soon
know a lot about.

00:05:37.350 --> 00:05:41.120
I was trying to
think where to start.

00:05:41.120 --> 00:05:44.600
I think maybe it
better be discrete.

00:05:47.440 --> 00:05:53.140
I want to get to the
system of equations

00:05:53.140 --> 00:05:56.460
that you constantly see.

00:05:56.460 --> 00:06:01.330
So let me use, as an example
the, most basic problem which

00:06:01.330 --> 00:06:07.460
comes for -- maybe
I'll start over here --

00:06:07.460 --> 00:06:15.150
the problem of least squares,
which I'll express this way.

00:06:15.150 --> 00:06:18.620
I'm given a matrix A,
and a right-hand side b,

00:06:18.620 --> 00:06:26.890
and I want to minimize the
length squared of A*u minus b.

00:06:26.890 --> 00:06:30.630
So that would be a
first problem to which

00:06:30.630 --> 00:06:33.830
we could apply calculus, because
it's a straight minimization

00:06:33.830 --> 00:06:36.060
and I haven't got any
constraints in there yet.

00:06:40.090 --> 00:06:41.940
We could also apply
linear algebra,

00:06:41.940 --> 00:06:44.590
and actually linear
algebra's going

00:06:44.590 --> 00:06:48.280
to throw a little extra light.

00:06:48.280 --> 00:06:51.020
So, just what am I
thinking of here?

00:06:51.020 --> 00:06:58.120
I'm thinking of A as being m
by n, with m larger than n.

00:07:02.230 --> 00:07:06.400
If A is a square matrix,
then this problem is the same

00:07:06.400 --> 00:07:08.340
as solving A*u equal b.

00:07:11.080 --> 00:07:15.180
And, of course, we'll
always reduce to that case

00:07:15.180 --> 00:07:17.320
if m equals n.

00:07:17.320 --> 00:07:22.420
But to focus on the problems
that I'm really thinking about,

00:07:22.420 --> 00:07:25.780
I'm thinking about the
case where this is the --

00:07:25.780 --> 00:07:27.450
n is the number of unknowns.

00:07:30.910 --> 00:07:32.210
It's the size of u.

00:07:36.210 --> 00:07:39.990
m, the larger number, is
the number of measurements,

00:07:39.990 --> 00:07:46.330
the number of the data, so
it's the number of equations,

00:07:46.330 --> 00:07:50.070
and it's the size of b.

00:07:50.070 --> 00:07:54.020
So we have more
equations than unknowns.

00:07:54.020 --> 00:07:56.040
You've met least squares before.

00:07:56.040 --> 00:08:02.300
I hope that maybe even in these
few minutes, a little new light

00:08:02.300 --> 00:08:06.160
will be shed on least squares.

00:08:06.160 --> 00:08:12.760
So here's our problem,
and calculus could lead us

00:08:12.760 --> 00:08:15.980
to the equation for the best u.

00:08:15.980 --> 00:08:20.750
So, u stands for
u_1, u_2, up to u_n.

00:08:20.750 --> 00:08:26.670
There are n components
in that vector, u.

00:08:26.670 --> 00:08:29.673
Maybe you know the equation
-- I guess I hope you know

00:08:29.673 --> 00:08:38.870
the equation, because it's such
a key to so many applications.

00:08:38.870 --> 00:08:43.270
If I just write it, it will
sound as if problem over.

00:08:43.270 --> 00:08:44.920
Let me write it though.

00:08:44.920 --> 00:08:49.600
So the key equation -- and then
this comes up in statistics,

00:08:49.600 --> 00:08:52.790
for example.

00:08:52.790 --> 00:08:55.850
Well, that's one
of 100 examples.

00:08:55.850 --> 00:09:03.820
But in statistics, this is
the topic of linear regression

00:09:03.820 --> 00:09:05.010
in statistics.

00:09:05.010 --> 00:09:11.890
Let me write down -- they
gave the name normal equation

00:09:11.890 --> 00:09:17.740
to the equation that
gives u directly.

00:09:17.740 --> 00:09:21.010
Do you remember what it is?

00:09:21.010 --> 00:09:22.120
The normal equation?

00:09:22.120 --> 00:09:24.140
The equation for the
minimizing u, which

00:09:24.140 --> 00:09:25.940
we could find by calculus?

00:09:25.940 --> 00:09:33.610
It involves the key matrix A
transpose A. Let me call u hat

00:09:33.610 --> 00:09:40.020
the minimizer, the winner
in this competition.

00:09:40.020 --> 00:09:44.420
The right-hand side of the
equation is A transpose b.

00:09:44.420 --> 00:09:50.370
So I won't directly
go back to derive it,

00:09:50.370 --> 00:09:52.370
though probably I'm going
to end up deriving it,

00:09:52.370 --> 00:09:58.220
because you can't help
approaching that equation

00:09:58.220 --> 00:10:01.190
from one side or another.

00:10:01.190 --> 00:10:03.100
As I say, one way to
approach it would just

00:10:03.100 --> 00:10:08.480
be to write out what that sum of
squares is, take its derivative

00:10:08.480 --> 00:10:11.280
and you would get
linear equation.

00:10:11.280 --> 00:10:15.520
So again, u hat stands for
the u that gives the minimum.

00:10:19.350 --> 00:10:23.670
This A transpose A, of course --
so I'm putting in a little bit

00:10:23.670 --> 00:10:25.280
of linear algebra.

00:10:25.280 --> 00:10:29.940
This matrix A transpose
A is obviously symmetric.

00:10:36.040 --> 00:10:39.330
Its important property,
beyond the symmetry,

00:10:39.330 --> 00:10:43.490
is that it's positive definite.

00:10:43.490 --> 00:10:49.490
Well, I have to say
positive definite --

00:10:49.490 --> 00:10:51.230
there's always a
proviso, of course.

00:10:51.230 --> 00:10:55.500
I haven't eliminated
the degenerate case yet.

00:10:55.500 --> 00:11:05.160
A has m, many, many rows, a
smaller number of columns,

00:11:05.160 --> 00:11:09.200
and let's assume
that those columns

00:11:09.200 --> 00:11:15.250
are linearly independent so that
we really do have n unknowns.

00:11:15.250 --> 00:11:20.300
If those columns were, say if
all the columns were the same,

00:11:20.300 --> 00:11:26.890
then A*u would just be
multiplying that same column

00:11:26.890 --> 00:11:29.650
and there would really
be only one unknown.

00:11:29.650 --> 00:11:37.330
So I'm going to say that
A has rank n, by which I

00:11:37.330 --> 00:11:41.530
mean n independent columns.

00:11:41.530 --> 00:11:43.670
In that case, that's
what guarantees

00:11:43.670 --> 00:11:46.450
that this is positive definite.

00:11:46.450 --> 00:11:52.150
Let me try to draw
an arrow there --

00:11:52.150 --> 00:11:54.440
this is the same statement.

00:11:54.440 --> 00:11:58.040
If I say about A that the
columns are independent,

00:11:58.040 --> 00:12:00.180
then I'm saying
about A transpose A

00:12:00.180 --> 00:12:04.550
that it is positive definite.

00:12:04.550 --> 00:12:07.140
That means all its
eigenvalues are positive;

00:12:07.140 --> 00:12:11.310
it's invertible, certainly;
all its pivots are positive.

00:12:11.310 --> 00:12:13.940
It's the great
class of matrices.

00:12:16.720 --> 00:12:23.190
But I don't really want to
start with that equation.

00:12:23.190 --> 00:12:25.230
Here's my point.

00:12:25.230 --> 00:12:32.910
Optimization -- a key word
that I better get on the board,

00:12:32.910 --> 00:12:36.260
maybe up here, to show
that it's really important,

00:12:36.260 --> 00:12:39.240
is plus the idea of duality.

00:12:45.020 --> 00:12:51.080
The effect of duality, if
I just give a first mention

00:12:51.080 --> 00:12:56.890
to that word, is that very
often optimization problems,

00:12:56.890 --> 00:12:59.130
there are really two problems.

00:12:59.130 --> 00:13:02.180
Two problems that
don't look identical,

00:13:02.180 --> 00:13:06.500
but in some important
way they both,

00:13:06.500 --> 00:13:16.330
each problem is a statement
of the task ahead of us.

00:13:16.330 --> 00:13:20.560
What are the two problems,
the two dual problems

00:13:20.560 --> 00:13:25.870
in this basic example
of least squares.

00:13:25.870 --> 00:13:29.140
All right, here's
a good picture.

00:13:29.140 --> 00:13:30.430
Here's a good picture.

00:13:30.430 --> 00:13:34.160
Let me put it on this
board so I can recover it.

00:13:34.160 --> 00:13:37.700
So, minimize A*u minus b.

00:13:37.700 --> 00:13:44.160
So I think of the
vector b as being --

00:13:44.160 --> 00:13:45.620
where it's in m dimensions.

00:13:45.620 --> 00:13:49.960
So it's a picture -- I'm
in m dimensions here.

00:13:49.960 --> 00:13:52.620
Now, what about A*u?

00:13:52.620 --> 00:13:59.070
A*u -- where will A*u
go in this picture?

00:13:59.070 --> 00:14:03.100
So, A*u is -- all
the candidates A*u,

00:14:03.100 --> 00:14:10.660
multiply A by any vector u, so
that means A*u is a combination

00:14:10.660 --> 00:14:16.660
of the columns of A, the
possible vectors A*u lie

00:14:16.660 --> 00:14:18.640
in a subspace.

00:14:18.640 --> 00:14:23.280
So this is the subspace of
all possible vectors A*u.

00:14:28.110 --> 00:14:30.510
And it's only n-dimensional.

00:14:30.510 --> 00:14:41.250
This is an n-dimensional
subspace because I have only n

00:14:41.250 --> 00:14:44.840
parameters in u,
only n columns in A.

00:14:44.840 --> 00:14:49.360
So the set of all A*u's
I think of as a --

00:14:49.360 --> 00:14:54.420
you could say a plane, an
n-dimensional plane within

00:14:54.420 --> 00:14:55.960
the bigger space R^m.

00:15:00.840 --> 00:15:09.210
Another name for that
subspace, that plane, is the --

00:15:09.210 --> 00:15:15.640
in 18.06 I would call it
the column space of A,

00:15:15.640 --> 00:15:19.870
or the range of A is another
expression that you--.

00:15:19.870 --> 00:15:24.200
All the possible
A*u's and here's b,

00:15:24.200 --> 00:15:27.030
which isn't one of
the possible A*u's.

00:15:27.030 --> 00:15:29.930
So where is u hat?

00:15:29.930 --> 00:15:35.380
Where is the best A*u
-- the best A*u now?

00:15:35.380 --> 00:15:39.790
The one that's
closest to b is --

00:15:39.790 --> 00:15:44.190
now comes another central
word in this subject.

00:15:44.190 --> 00:15:48.960
If I draw it, I'm
going to draw it here.

00:15:48.960 --> 00:15:54.340
That will be my best A*u,
which I'm calling A u hat.

00:15:54.340 --> 00:16:00.250
That's the -- if the picture
seems reasonable to your eye,

00:16:00.250 --> 00:16:05.430
this is the vector that's
in the plane closest to b.

00:16:08.840 --> 00:16:11.782
What's the geometry here?

00:16:11.782 --> 00:16:13.240
See, that's what
I wanted to see --

00:16:13.240 --> 00:16:17.300
a little geometry and a little
algebra, not just calculus.

00:16:17.300 --> 00:16:24.740
So the geometry is
that this vector b,

00:16:24.740 --> 00:16:28.210
what's the connection
between b and that vector --

00:16:28.210 --> 00:16:30.580
that's the closest
vector, right?

00:16:30.580 --> 00:16:32.260
We're minimizing the distance.

00:16:32.260 --> 00:16:41.800
This distance here, I might
call that the error vector e.

00:16:41.800 --> 00:16:44.450
This is as small as possible.

00:16:44.450 --> 00:16:46.400
That's being minimized.

00:16:46.400 --> 00:16:53.360
That's the difference between
-- this is Pythagoras here.

00:16:53.360 --> 00:16:55.950
Of course, when I
say it's Pythagoras,

00:16:55.950 --> 00:16:58.770
I'm already saying the
most important point,

00:16:58.770 --> 00:17:04.885
that this a right angle here.

00:17:04.885 --> 00:17:05.760
That's a right angle.

00:17:08.430 --> 00:17:17.530
The closest A*u, which is A
u hat, which is this vector,

00:17:17.530 --> 00:17:21.460
the way geometrically we know
it's closest is that the line

00:17:21.460 --> 00:17:27.830
from b to the plane, that's
where the line from b,

00:17:27.830 --> 00:17:29.030
perpendicular to the plane.

00:17:29.030 --> 00:17:36.480
This line, this error vector e
is perpendicular to the plane.

00:17:42.300 --> 00:17:46.620
There's a good word that
everybody uses for this vector.

00:17:46.620 --> 00:17:49.200
Take a vector b that's
not on a plane, what's

00:17:49.200 --> 00:17:54.820
the word to look for the
nearest vector in the plane?

00:17:54.820 --> 00:17:56.260
AUDIENCE: Projection.

00:17:56.260 --> 00:17:58.187
PROFESSOR: Projection.

00:17:58.187 --> 00:17:59.270
So this is the projection.

00:18:05.380 --> 00:18:07.300
Orthogonal projection,
if I wanted

00:18:07.300 --> 00:18:11.310
to really emphasize the fact
that that's a right angle.

00:18:15.750 --> 00:18:22.530
So that would give
me a geometric way

00:18:22.530 --> 00:18:25.100
to see the least
squares problem.

00:18:25.100 --> 00:18:30.780
Now comes the point to
see the dual problem.

00:18:30.780 --> 00:18:37.631
The dual problem will be, here,
if I draw the perpendicular

00:18:37.631 --> 00:18:38.130
subspace.

00:18:44.590 --> 00:18:48.250
So that's a subspace
of what dimension?

00:18:48.250 --> 00:18:53.390
This contains all the vectors
perpendicular to the plane.

00:18:53.390 --> 00:18:59.740
So I have it as -- if m is 3,
so we're in three dimensions,

00:18:59.740 --> 00:19:03.190
and our plane is an ordinary
two-dimensional plane,

00:19:03.190 --> 00:19:08.150
then the dimension is one --
that's the perpendicular line.

00:19:08.150 --> 00:19:15.990
But thinking bigger, if we're in
m dimensions and this plane is

00:19:15.990 --> 00:19:18.990
n-dimensional, than
this is going to have --

00:19:18.990 --> 00:19:23.630
the true dimension
of this is m minus n,

00:19:23.630 --> 00:19:26.880
which could be
pretty substantial.

00:19:26.880 --> 00:19:32.020
But anyway, that's the
perpendicular subspace.

00:19:32.020 --> 00:19:34.910
If this is the
column space of A,

00:19:34.910 --> 00:19:39.150
I can figure out
what vectors are

00:19:39.150 --> 00:19:46.880
perpendicular to the columns of
A. That's really what I mean.

00:19:46.880 --> 00:19:49.940
This contains -- I've
drawn it as a line,

00:19:49.940 --> 00:19:54.310
but I've written up there its
dimension so that you see --

00:19:54.310 --> 00:20:02.490
I just don't know how to
draw, like, a bigger subspace.

00:20:02.490 --> 00:20:05.930
Yet you would have to see
that all the vectors in it

00:20:05.930 --> 00:20:09.480
were perpendicular to
all of these vectors.

00:20:09.480 --> 00:20:13.070
Do you see what I'm saying?

00:20:13.070 --> 00:20:17.620
If we were stuck in thinking
in three dimensions,

00:20:17.620 --> 00:20:21.060
if I make this a plane I
can't make that a plane.

00:20:21.060 --> 00:20:25.160
If I make m equal 3, and
I make n equal to two,

00:20:25.160 --> 00:20:28.680
I'm only got a line left
to be perpendicular.

00:20:28.680 --> 00:20:34.520
But in higher dimensions there
are lots of dimensions left.

00:20:34.520 --> 00:20:37.990
So what's my dual problem?

00:20:37.990 --> 00:20:46.480
My dual problem is find
the vector e in this plane

00:20:46.480 --> 00:20:47.410
closest to b.

00:20:50.950 --> 00:20:54.050
In other words, by
the same reasoning,

00:20:54.050 --> 00:20:56.840
what I'm saying is
take the vector b,

00:20:56.840 --> 00:21:04.750
project it over to this plane,
project it orthogonally --

00:21:04.750 --> 00:21:08.430
that same right angle
is going to be there.

00:21:08.430 --> 00:21:13.760
This plane -- I haven't
said what's in this --

00:21:13.760 --> 00:21:16.660
I've said what's in this plane
but I haven't written it yet.

00:21:16.660 --> 00:21:18.710
But you could tell me already.

00:21:18.710 --> 00:21:21.500
What is this?

00:21:21.500 --> 00:21:22.390
What's that vector?

00:21:25.100 --> 00:21:27.610
One answer would be,
it's the projection

00:21:27.610 --> 00:21:30.240
of b onto this perpendicular.

00:21:30.240 --> 00:21:33.670
So you see we're really
taking the vector b

00:21:33.670 --> 00:21:36.890
and we're separating
it into two components.

00:21:36.890 --> 00:21:40.927
One in the column space,
the other perpendicular

00:21:40.927 --> 00:21:41.760
to the column space.

00:21:41.760 --> 00:21:45.480
So just tell me
what that vector is.

00:21:45.480 --> 00:21:47.800
It is e.

00:21:47.800 --> 00:21:49.250
Same guy.

00:21:49.250 --> 00:21:53.470
In other words, e is the
solution to the dual problem --

00:21:53.470 --> 00:22:00.820
maybe I call this projection
p for the best vector

00:22:00.820 --> 00:22:06.520
in the plane. e is the best
vector in this subspace,

00:22:06.520 --> 00:22:08.450
and they add up to--.

00:22:08.450 --> 00:22:11.720
So, we're really
taking the vector b,

00:22:11.720 --> 00:22:13.480
and we're splitting
it into a part

00:22:13.480 --> 00:22:20.230
p in this space, and a part
e in the perpendicular space.

00:22:20.230 --> 00:22:22.830
If I just write down
the equations for that,

00:22:22.830 --> 00:22:25.480
I'll see what's cooking.

00:22:28.590 --> 00:22:33.600
Well, I guess what I have
to do is remember what

00:22:33.600 --> 00:22:37.930
are the equations to
be in this subspace,

00:22:37.930 --> 00:22:39.690
to be perpendicular
to the column.

00:22:39.690 --> 00:22:43.840
So I can't go further
without remembering

00:22:43.840 --> 00:22:47.030
what's in that subspace.

00:22:47.030 --> 00:22:49.520
So everything in
that subspace is

00:22:49.520 --> 00:22:55.030
perpendicular to
the columns of A.

00:22:55.030 --> 00:22:57.650
Let me just write
down what that means.

00:22:57.650 --> 00:23:01.460
Let me use the letter
maybe y for the vectors

00:23:01.460 --> 00:23:08.920
in that subspace, and e for the
winning vector, the projection.

00:23:08.920 --> 00:23:11.730
So y will be the vectors
in that subspace.

00:23:11.730 --> 00:23:14.260
So those vectors
are perpendicular --

00:23:14.260 --> 00:23:21.700
so this is the subspace
of y, all the y's in here.

00:23:21.700 --> 00:23:24.570
Now, what's the condition?

00:23:24.570 --> 00:23:32.710
So y -- that y in this
perpendicular subspace.

00:23:32.710 --> 00:23:33.990
What do I mean?

00:23:33.990 --> 00:23:44.990
I mean that y is perpendicular
to the columns of A.

00:23:44.990 --> 00:23:48.140
How shall I write that?

00:23:48.140 --> 00:23:51.390
Perpendicular means
inner product zero.

00:23:51.390 --> 00:23:59.060
So I want to change
the columns into rows,

00:23:59.060 --> 00:24:03.030
and take the inner product
with y, and get zeros.

00:24:03.030 --> 00:24:05.460
Zero, zero, zero.

00:24:05.460 --> 00:24:13.770
So, this is column 1
transposed, to be a row.

00:24:16.530 --> 00:24:21.000
I'm trying to express
this requirement

00:24:21.000 --> 00:24:22.730
in terms of the matrix.

00:24:26.030 --> 00:24:28.010
So to be perpendicular
to the first column,

00:24:28.010 --> 00:24:31.330
I know that means that the inner
product of the first column

00:24:31.330 --> 00:24:35.170
with y should be zero.

00:24:35.170 --> 00:24:38.720
The inner product with
the second column --

00:24:38.720 --> 00:24:42.900
the second column
with y should be zero.

00:24:42.900 --> 00:24:51.180
The n-th column, its inner
product with y should be zero.

00:24:51.180 --> 00:24:52.840
So what matrix have I got here?

00:24:56.830 --> 00:25:01.640
What's the condition on
y's, simple and beautiful?

00:25:01.640 --> 00:25:03.930
What matrix is that?

00:25:03.930 --> 00:25:06.520
It's A transpose.

00:25:06.520 --> 00:25:14.070
So that perpendicular thing --
this is completely expressed

00:25:14.070 --> 00:25:17.770
by the equation A
transpose y equals zero.

00:25:27.100 --> 00:25:31.230
That tells me the
y's, and, of course,

00:25:31.230 --> 00:25:34.410
e is going to be one of the y's.

00:25:34.410 --> 00:25:37.150
It's going to be,
I could say y hat,

00:25:37.150 --> 00:25:40.550
but I've already named it e.

00:25:40.550 --> 00:25:46.390
It's the particular one
that's closest to b --

00:25:46.390 --> 00:25:50.200
the y's are everybody
all along here --

00:25:50.200 --> 00:25:53.740
this is the null
space of A transpose.

00:25:53.740 --> 00:25:57.980
So in words, I would call it
that perpendicular thing is

00:25:57.980 --> 00:26:00.720
the null space of A transpose.

00:26:04.330 --> 00:26:08.470
So when you did linear
algebra, you'll remember that.

00:26:08.470 --> 00:26:11.760
That the null space of A
transpose -- let me write it --

00:26:11.760 --> 00:26:18.820
is perpendicular to
the column space of A.

00:26:18.820 --> 00:26:21.860
The fundamentals theorem of
linear algebra right there.

00:26:21.860 --> 00:26:26.190
Now we're just using
it again to see what

00:26:26.190 --> 00:26:28.700
are the two dual problems here.

00:26:28.700 --> 00:26:33.630
So the primal problem, the
one that we stated first,

00:26:33.630 --> 00:26:35.580
was this one.

00:26:35.580 --> 00:26:38.660
So I'll call this the
primal -- P for primal.

00:26:41.350 --> 00:26:43.750
What is the dual problem?

00:26:43.750 --> 00:26:54.480
The dual problem is the
problem about the y's.

00:26:54.480 --> 00:26:56.690
Not about the u's at all.

00:26:56.690 --> 00:26:59.420
That's the beauty
of this duality.

00:26:59.420 --> 00:27:02.080
One problem is
about u's, and it's

00:27:02.080 --> 00:27:06.410
a problem that ends up
projecting on the column space.

00:27:06.410 --> 00:27:09.890
The second problem
is about y's, it's

00:27:09.890 --> 00:27:12.010
the problem that
ends up projecting

00:27:12.010 --> 00:27:16.230
onto this perpendicular space,
and it was a projection.

00:27:16.230 --> 00:27:24.660
So the dual problem is just
minimize the distance from b

00:27:24.660 --> 00:27:32.310
to y, but with the
constraint, with --

00:27:32.310 --> 00:27:34.390
and now I get to use
that word constraint --

00:27:34.390 --> 00:27:37.470
with A transpose y equals zero.

00:27:37.470 --> 00:27:40.370
So there is the other problem.

00:27:46.600 --> 00:27:53.370
So I hope your eye can
travel between the -- well,

00:27:53.370 --> 00:27:55.220
let me write underneath
it the primal again.

00:27:59.720 --> 00:28:06.260
Minimize A*u minus b square.

00:28:13.160 --> 00:28:17.500
This is the one
whose solution is e,

00:28:17.500 --> 00:28:22.870
and this is the one whose
solution is, well, u,

00:28:22.870 --> 00:28:27.830
and the projection
-- u hat, sorry,

00:28:27.830 --> 00:28:34.860
and the projection p is A u
hat, and I guess what I'm trying

00:28:34.860 --> 00:28:39.070
to say is that somehow there's
a very important connection

00:28:39.070 --> 00:28:40.220
between the two problems.

00:28:44.090 --> 00:28:47.070
First of all, the two
problems use the same data.

00:28:47.070 --> 00:28:53.110
They use the same vector b, they
use the same matrix A. Notice

00:28:53.110 --> 00:28:55.610
that in one problem it's
A, and in the other problem

00:28:55.610 --> 00:28:57.260
it's the transpose appears.

00:28:57.260 --> 00:29:00.050
That's very common --
we'll see that always.

00:29:02.374 --> 00:29:04.040
But there's something
a little different

00:29:04.040 --> 00:29:05.870
about the two problems.

00:29:05.870 --> 00:29:11.330
This problem was unconstrained,
any u was allowed.

00:29:11.330 --> 00:29:18.490
This problem was constrained,
only a subset of y's, only

00:29:18.490 --> 00:29:21.400
that subspace of
y's was allowed.

00:29:21.400 --> 00:29:25.130
This is a problem
with n unknowns.

00:29:25.130 --> 00:29:29.470
This is a problem with
m minus n unknowns.

00:29:29.470 --> 00:29:37.330
m minus n unknown
variables, once we've

00:29:37.330 --> 00:29:38.850
accounted for the constraints.

00:29:44.690 --> 00:29:48.700
This is one thing
I'm thinking about.

00:29:48.700 --> 00:29:53.830
Often, the problem will
come with a constraint.

00:29:53.830 --> 00:29:58.120
Maybe I'll do a physical
example right away.

00:29:58.120 --> 00:30:01.630
The problem comes to
us with a constraint.

00:30:01.630 --> 00:30:04.940
In other words, suppose you
were given this problem.

00:30:04.940 --> 00:30:09.520
How would you deal with it?

00:30:09.520 --> 00:30:13.220
That's like the first
question in optimization,

00:30:13.220 --> 00:30:15.200
or one of the central questions.

00:30:15.200 --> 00:30:18.510
How do you deal
with a constraint?

00:30:18.510 --> 00:30:21.140
If we minimize this,
of course, the minimum

00:30:21.140 --> 00:30:24.720
would be when y equaled b.

00:30:24.720 --> 00:30:29.430
But that's failing to take into
account the constraint on y.

00:30:29.430 --> 00:30:32.370
So how do you take
constraints into account

00:30:32.370 --> 00:30:35.920
and end up with an equation?

00:30:35.920 --> 00:30:40.180
We can see, in this picture,
that somehow or other we

00:30:40.180 --> 00:30:42.420
ended up with this
normal equation,

00:30:42.420 --> 00:30:52.580
but actually I would rather end
up with a primal dual equation.

00:30:52.580 --> 00:30:55.250
I'd like to end up with
an equation for the best

00:30:55.250 --> 00:30:58.980
u and the best y.

00:30:58.980 --> 00:31:00.420
So what will that be?

00:31:00.420 --> 00:31:04.720
So I need now two equations
that will connect the best

00:31:04.720 --> 00:31:08.740
u and the best y, and probably
this is going to be the key.

00:31:08.740 --> 00:31:13.220
This b is A u hat, right.

00:31:17.220 --> 00:31:19.620
So this will be one
of my equations,

00:31:19.620 --> 00:31:20.840
and this will be the other.

00:31:23.620 --> 00:31:25.530
Let me see if I -- well, OK.

00:31:29.600 --> 00:31:34.290
I don't know what to do now.

00:31:34.290 --> 00:31:36.140
Here I've called it y.

00:31:36.140 --> 00:31:37.760
Over here it's e.

00:31:37.760 --> 00:31:40.550
I've got myself in a corner.

00:31:43.150 --> 00:31:47.200
Maybe I should call e y
hat, would you like that?

00:31:51.010 --> 00:31:56.370
We have in mind that it's e,
the error in the primal problem.

00:31:56.370 --> 00:32:04.310
But just to make the
notation for the two

00:32:04.310 --> 00:32:10.340
problems consistent, let me
call the winner here y hat,

00:32:10.340 --> 00:32:12.480
the winner here u hat.

00:32:12.480 --> 00:32:13.400
What's the relation?

00:32:13.400 --> 00:32:16.000
So let me just -- here I'll
write down the relation between

00:32:16.000 --> 00:32:17.380
the two.

00:32:17.380 --> 00:32:22.050
Well, it's over there.

00:32:22.050 --> 00:32:23.290
Let's see, is that right?

00:32:23.290 --> 00:32:24.950
Yes?

00:32:24.950 --> 00:32:38.590
y hat plus A u hat is b, and
A transpose y hat is zero.

00:32:38.590 --> 00:32:41.220
That's it.

00:32:41.220 --> 00:32:44.240
That's it.

00:32:44.240 --> 00:32:54.570
Here we have -- that's the
pair of equations that solves,

00:32:54.570 --> 00:32:59.700
that connects the primal and
the dual, solves them both,

00:32:59.700 --> 00:33:05.240
solves each one, and is
really, it's a system --

00:33:05.240 --> 00:33:09.110
you could say it's
a block equation.

00:33:09.110 --> 00:33:21.330
The block matrix being
identity A, A transpose, zero;

00:33:21.330 --> 00:33:27.340
the unknown being
the y and the u.

00:33:27.340 --> 00:33:30.530
The right-hand side being
the data, which in this case

00:33:30.530 --> 00:33:31.650
was the b.

00:33:38.850 --> 00:33:41.430
I guess what I want
to do is emphasize,

00:33:41.430 --> 00:33:45.740
in what's coming for
the month of April,

00:33:45.740 --> 00:33:50.060
the importance of this
class of problems.

00:33:54.040 --> 00:33:58.740
It's dealing with two --
it's dealing with the primal

00:33:58.740 --> 00:34:02.250
and the dual at the same time.

00:34:02.250 --> 00:34:07.770
It's important for so many
reasons I can't say them

00:34:07.770 --> 00:34:09.550
all on the first day.

00:34:09.550 --> 00:34:13.370
That would be a mistake,
to try to say everything

00:34:13.370 --> 00:34:13.960
the first day.

00:34:13.960 --> 00:34:18.960
But let me just say something
-- that linear programming,

00:34:18.960 --> 00:34:22.780
which is just one example, and
it doesn't fit this because it

00:34:22.780 --> 00:34:25.160
has inequality constraints.

00:34:25.160 --> 00:34:30.050
But you maybe know
that the number one

00:34:30.050 --> 00:34:37.490
method to solve linear program
is called the simplex method.

00:34:37.490 --> 00:34:43.500
Well, it was the number
one method for many years.

00:34:43.500 --> 00:34:46.740
For many problems it's still
the right way to do it.

00:34:46.740 --> 00:34:53.600
But a new method called
the primal-dual --

00:34:53.600 --> 00:34:56.250
at least that's part of
its name, primal-dual.

00:34:56.250 --> 00:35:02.070
It is essentially solving the
primal and the dual problems

00:35:02.070 --> 00:35:05.990
at once, and there are
inequality constraints,

00:35:05.990 --> 00:35:06.560
of course.

00:35:06.560 --> 00:35:09.250
I'm going to stop there
with linear programming

00:35:09.250 --> 00:35:13.450
and give it its turn later.

00:35:13.450 --> 00:35:21.610
In this perfect example
here, we have only equations.

00:35:21.610 --> 00:35:23.220
How many do we have?

00:35:23.220 --> 00:35:28.750
We have m plus n equations,
because y is m unknowns,

00:35:28.750 --> 00:35:30.440
u is n unknowns.

00:35:30.440 --> 00:35:35.600
I have altogether m
plus n equations --

00:35:35.600 --> 00:35:42.440
m y's, and n u's, and
they come together.

00:35:42.440 --> 00:35:48.320
Now, could you,
just to connect back

00:35:48.320 --> 00:35:51.680
with what we absolutely know,
that it's a normal equation,

00:35:51.680 --> 00:35:54.890
where is this normal
equation coming from?

00:35:54.890 --> 00:35:58.130
So here's the normal equation.

00:35:58.130 --> 00:36:02.920
We know that that's gotta
come, right, out of the thing.

00:36:02.920 --> 00:36:04.670
How does it come?

00:36:04.670 --> 00:36:08.910
Suppose I have a block
system, two by two.

00:36:08.910 --> 00:36:11.100
How do I solve it?

00:36:11.100 --> 00:36:15.780
Well actually, that's, in
a way, the big question.

00:36:15.780 --> 00:36:19.410
But one way to solve it,
the natural way to solve it,

00:36:19.410 --> 00:36:23.250
would be elimination.

00:36:23.250 --> 00:36:28.720
Multiply this first row
by a suitable matrix.

00:36:28.720 --> 00:36:32.270
Subtract from the second
row to produce a zero there.

00:36:32.270 --> 00:36:39.130
In other words, eliminate y
and get an equation for u hat.

00:36:39.130 --> 00:36:40.610
So what do I do?

00:36:40.610 --> 00:36:42.150
How do I do it?

00:36:42.150 --> 00:36:49.800
I multiply -- would you rather
look at equations or matrices?

00:36:49.800 --> 00:36:53.060
I've tried to keep the
two absolutely together.

00:36:53.060 --> 00:36:54.500
Let me look at the equation.

00:36:54.500 --> 00:36:58.620
What shall I multiply that
equation by and subtract from

00:36:58.620 --> 00:37:01.370
this -- I just
want to eliminate.

00:37:01.370 --> 00:37:05.520
I want to get y hat out of
there and leave just an equation

00:37:05.520 --> 00:37:09.040
for u hat that we will
totally recognize.

00:37:09.040 --> 00:37:10.350
So what do I do?

00:37:10.350 --> 00:37:14.250
I multiplying that
first equation by?

00:37:14.250 --> 00:37:17.000
A transpose, thanks.

00:37:17.000 --> 00:37:20.760
So I multiply this first
equation by A transpose.

00:37:20.760 --> 00:37:22.040
Let me just do it this way.

00:37:25.020 --> 00:37:27.610
Now what?

00:37:27.610 --> 00:37:30.120
A transpose y is zero.

00:37:30.120 --> 00:37:32.620
Now I use the second -- well,
this is one way to do it.

00:37:32.620 --> 00:37:34.310
A transpose y is zero.

00:37:34.310 --> 00:37:36.450
What am I left with?

00:37:36.450 --> 00:37:38.550
The normal equation.

00:37:38.550 --> 00:37:40.040
Well, it shouldn't
be a surprise.

00:37:40.040 --> 00:37:42.120
We had to end up with
the normal equation.

00:37:42.120 --> 00:37:44.590
Maybe you would rather
-- and actually,

00:37:44.590 --> 00:37:49.240
what I intended was to make
it sound more like Gaussian

00:37:49.240 --> 00:37:50.440
elimination.

00:37:50.440 --> 00:37:53.270
Multiply this row
by A transpose,

00:37:53.270 --> 00:37:55.240
subtract from this row.

00:37:55.240 --> 00:38:01.490
I still have identity A up here
-- when I do that subtraction,

00:38:01.490 --> 00:38:04.180
I get the zero,
that was the point.

00:38:04.180 --> 00:38:07.350
Here I get A transpose
A subtracted from zero,

00:38:07.350 --> 00:38:14.170
it's minus A transpose
A, y hat, u hat.

00:38:14.170 --> 00:38:17.960
Of course, I had to do the same
thing to the right-hand side,

00:38:17.960 --> 00:38:22.360
and when I subtracted this
the b was still there,

00:38:22.360 --> 00:38:26.580
but it was minus A transpose b.

00:38:26.580 --> 00:38:32.040
So, now I've got in
the second equation --

00:38:32.040 --> 00:38:36.550
the second equation only
involves u hat, and, of course,

00:38:36.550 --> 00:38:40.780
when I changed the
signs, it's our friend --

00:38:40.780 --> 00:38:43.720
A transpose A u hat
equal A transpose b.

00:38:43.720 --> 00:38:52.030
So this is -- maybe you would
say the natural way to solve

00:38:52.030 --> 00:38:59.660
this type of system, but I want
to emphasize -- throw it away.

00:38:59.660 --> 00:39:06.700
I really want to emphasize
the importance of these --

00:39:06.700 --> 00:39:13.010
let me clean it back up
again to what it was --

00:39:13.010 --> 00:39:14.120
of these block systems.

00:39:17.710 --> 00:39:20.330
Now, they need a name.

00:39:20.330 --> 00:39:27.430
We have to give some name to
this type of two-field problem.

00:39:27.430 --> 00:39:29.740
I guess then, in
the next month, I'm

00:39:29.740 --> 00:39:32.800
going to find examples
of it everywhere.

00:39:32.800 --> 00:39:35.040
So here I've found the
first example of it

00:39:35.040 --> 00:39:39.030
in ordinary old-fashioned
least square.

00:39:39.030 --> 00:39:41.600
So what am I going to call this?

00:39:41.600 --> 00:39:46.560
I'll call it -- I'll give
it a couple of names.

00:39:46.560 --> 00:39:50.020
Saddle point equation,
saddle point system maybe

00:39:50.020 --> 00:39:50.710
I should say.

00:39:53.530 --> 00:39:57.810
I have to explain, why do I
call it saddle point system.

00:39:57.810 --> 00:40:05.740
In optimization, I could call
it the optimality equation --

00:40:05.740 --> 00:40:08.130
just meaning it's the
equations for the winners.

00:40:11.190 --> 00:40:16.300
In the world of optimization,
the names of Kuhn and Tucker

00:40:16.300 --> 00:40:20.490
are associated with
these equations --

00:40:20.490 --> 00:40:29.010
the Kuhn-Tucker equations,
and there are other names

00:40:29.010 --> 00:40:30.420
we'll see.

00:40:30.420 --> 00:40:35.370
But let me just say for a
moment why saddle point.

00:40:35.370 --> 00:40:40.230
Why do I think of this as
a saddle point problem?

00:40:45.520 --> 00:40:49.050
See, the point
about A transpose A

00:40:49.050 --> 00:40:52.120
was that it was
positive definite.

00:40:52.120 --> 00:40:56.670
This is A transpose A.

00:40:56.670 --> 00:41:01.810
Now what's the corresponding
issue for this matrix?

00:41:01.810 --> 00:41:05.320
So this is my matrix that
I'm constantly gonna look at.

00:41:08.960 --> 00:41:12.770
Matrices of that form are
going to show up all the time.

00:41:12.770 --> 00:41:18.920
I've said probably in
18.085 where these appear

00:41:18.920 --> 00:41:20.940
but then we don't
do much with them.

00:41:20.940 --> 00:41:22.570
Now we're ready to do something.

00:41:26.580 --> 00:41:28.920
I didn't appreciate
their importance

00:41:28.920 --> 00:41:32.320
until I realized,
in going to lectures

00:41:32.320 --> 00:41:36.300
on applied mathematics,
that if I waited a little

00:41:36.300 --> 00:41:38.900
while that matrix would appear.

00:41:38.900 --> 00:41:40.010
That block matrix.

00:41:40.010 --> 00:41:42.570
It just shows up in
all these applications.

00:41:47.750 --> 00:41:53.930
One of our issues will
be how to solve it.

00:41:53.930 --> 00:41:59.420
Another issue that
comes first is what's

00:41:59.420 --> 00:42:01.320
the general form of this?

00:42:01.320 --> 00:42:03.450
Can I jump to that issue?

00:42:03.450 --> 00:42:09.020
Just so we see something more
than this single problem here.

00:42:09.020 --> 00:42:20.820
Let me put in the matrix as
it comes in applications.

00:42:20.820 --> 00:42:24.790
Some matrix A,
rectangular, right?

00:42:24.790 --> 00:42:27.550
Its transpose.

00:42:27.550 --> 00:42:28.370
A zero.

00:42:28.370 --> 00:42:30.440
Often a zero.

00:42:30.440 --> 00:42:34.440
But what's up here is
not always the identity.

00:42:34.440 --> 00:42:37.730
I want to allow
something more general.

00:42:37.730 --> 00:42:41.010
I want to allow, for example,
weighted least squares.

00:42:41.010 --> 00:42:46.680
So weighted least squares --
if you've met least squares,

00:42:46.680 --> 00:42:55.060
it's very important to meet
its extension to weighted least

00:42:55.060 --> 00:42:55.970
squares.

00:42:55.970 --> 00:43:04.700
When the equations A*u equal b
are not given the same weight,

00:43:04.700 --> 00:43:08.440
there's a weighting matrix,
often it's a covariance matrix.

00:43:08.440 --> 00:43:12.680
I'm going to call the matrix
that goes in here C inverse.

00:43:16.610 --> 00:43:25.690
So this will be then an
important class of application.

00:43:25.690 --> 00:43:29.740
This is pretty important already
when the identity is there,

00:43:29.740 --> 00:43:34.350
but many, many applications
produce some other matrix that

00:43:34.350 --> 00:43:39.000
is usually -- it very, very
often is symmetric positive

00:43:39.000 --> 00:43:44.690
definite in that corner,
like the identity is.

00:43:44.690 --> 00:43:48.230
But key point, which
I have to make today.

00:43:48.230 --> 00:43:52.600
Is the whole matrix --
either this one or this one.

00:43:52.600 --> 00:43:54.710
It is symmetric, right?

00:43:54.710 --> 00:43:56.570
That matrix is symmetric.

00:43:56.570 --> 00:43:59.530
Is it or isn't it
positive definite?

00:43:59.530 --> 00:44:04.060
If I do elimination do I
get all positive pivots?

00:44:04.060 --> 00:44:07.940
It's a matrix of size m plus n.

00:44:07.940 --> 00:44:11.500
So I'm asking, are all
its eigenvalues positive,

00:44:11.500 --> 00:44:15.130
but I don't want to really
compute eigenvalues.

00:44:15.130 --> 00:44:17.740
Also, in a lot of cases I would.

00:44:17.740 --> 00:44:19.930
Finding the eigenvalues
of this matrix

00:44:19.930 --> 00:44:24.410
would lead me to the
singular value decomposition,

00:44:24.410 --> 00:44:29.120
absolutely crucial topic in
linear algebra that we'll see.

00:44:29.120 --> 00:44:32.850
But let me just take
it as a linear system.

00:44:32.850 --> 00:44:40.610
If I do elimination, what
are the first m pivots?

00:44:40.610 --> 00:44:43.490
Let me not be abstract here.

00:44:43.490 --> 00:44:45.530
Let me be quite concrete.

00:44:45.530 --> 00:44:47.700
Let me put the identity here.

00:44:47.700 --> 00:44:53.310
Let me put some matrix -- oh,
I want the matrix here to be --

00:44:53.310 --> 00:44:58.630
I better put a bigger identity
just so we see the picture.

00:44:58.630 --> 00:45:03.530
Here I'm going to put to an A
transpose, which might be 2, 3,

00:45:03.530 --> 00:45:07.650
4; 5, 6, 7 -- when I
write numbers like that

00:45:07.650 --> 00:45:11.360
you'll realize that I've just
pick them out of the hat.

00:45:11.360 --> 00:45:15.920
Here is the transpose,
2, 3, 4; 5, 6, 7.

00:45:15.920 --> 00:45:18.120
Here's the zero block.

00:45:20.970 --> 00:45:23.575
I'd like to know
about that matrix.

00:45:23.575 --> 00:45:24.200
It's symmetric.

00:45:29.040 --> 00:45:32.100
And it's full rank.

00:45:32.100 --> 00:45:34.060
It's invertible.

00:45:34.060 --> 00:45:35.490
How do I know that?

00:45:35.490 --> 00:45:37.330
It's the invertibility
-- of course,

00:45:37.330 --> 00:45:40.170
the identity part is great.

00:45:40.170 --> 00:45:45.870
I guess I see that this is
invertible because I've ended

00:45:45.870 --> 00:45:52.820
up with A transpose A, and
here my A has rank two --

00:45:52.820 --> 00:45:56.450
those two columns
are independent.

00:45:56.450 --> 00:45:58.370
They're not in the same
direction -- [2, 3,

00:45:58.370 --> 00:46:00.820
4] is not a multiple
of [5, 6,  7].

00:46:00.820 --> 00:46:05.930
That's an invertible matrix, and
this process finds the inverse.

00:46:05.930 --> 00:46:07.880
Elimination finds the inverse.

00:46:07.880 --> 00:46:10.510
It's the pivots I
want to ask you about.

00:46:10.510 --> 00:46:15.480
What are the pivots
in this matrix?

00:46:15.480 --> 00:46:17.500
So what do I do?

00:46:17.500 --> 00:46:22.170
The first pivot is a 1 -- I use
it to clean out that column.

00:46:22.170 --> 00:46:25.420
The second pivot is a 1 -- I
use it to clean out that column.

00:46:25.420 --> 00:46:28.340
The third pivot is a 1 -- I use
it to clean out that column.

00:46:31.660 --> 00:46:32.740
What's the next pivot?

00:46:32.740 --> 00:46:38.340
What do I have -- of course, now
some stuff has filled in here.

00:46:38.340 --> 00:46:40.230
What is actually
filled in there?

00:46:40.230 --> 00:46:43.770
So this is the identity,
if I can write it fast.

00:46:43.770 --> 00:46:46.450
This guy is now the zero.

00:46:46.450 --> 00:46:50.010
This guy didn't move.

00:46:50.010 --> 00:46:54.060
What matrix filled in here?

00:46:54.060 --> 00:46:56.100
Well, just what I
was doing there.

00:46:56.100 --> 00:46:59.300
Elimination is exactly what
I'm repeating with numbers,

00:46:59.300 --> 00:47:00.740
what I did there with letters.

00:47:00.740 --> 00:47:05.540
What's in here is
minus A transpose A.

00:47:05.540 --> 00:47:08.970
I could figure out what
that -- I could do --

00:47:08.970 --> 00:47:15.070
if I was fast enough, I could do
2, 3, 4; 5, 6, 7 times 2, 3, 4;

00:47:15.070 --> 00:47:21.840
5, 6, 7 and I'd get this little
two by two matrix that sits

00:47:21.840 --> 00:47:22.340
there.

00:47:25.150 --> 00:47:28.850
With a minus sign,
and that's the point.

00:47:28.850 --> 00:47:31.900
That the pivots -- of course,
what's this first number going

00:47:31.900 --> 00:47:32.400
to be?

00:47:32.400 --> 00:47:34.610
4 plus 9 plus 16.

00:47:34.610 --> 00:47:39.060
29 is that number.

00:47:39.060 --> 00:47:44.430
So a minus 29 sits right there.

00:47:44.430 --> 00:47:46.560
That's the next pivot.

00:47:46.560 --> 00:47:50.280
The next pivot is a
negative number, minus 29,

00:47:50.280 --> 00:47:52.370
and the fifth pivot is negative.

00:47:52.370 --> 00:47:55.860
So what I'm seeing
is a matrix --

00:47:55.860 --> 00:48:05.140
this matrix has three
positive pivots,

00:48:05.140 --> 00:48:07.240
and two negative pivots.

00:48:11.340 --> 00:48:13.500
I sort of say that
was a saddle point.

00:48:13.500 --> 00:48:20.440
Positive pivots describe for me
a surface that's going upwards.

00:48:20.440 --> 00:48:22.640
This surface is going upward.

00:48:22.640 --> 00:48:25.660
I'm a surface in
five dimensions here.

00:48:25.660 --> 00:48:28.950
It's going upwards
in three directions,

00:48:28.950 --> 00:48:32.560
but it's going downwards in two.

00:48:32.560 --> 00:48:37.150
The point at the heart
of it, the saddle point,

00:48:37.150 --> 00:48:41.930
is the solution to our
system, is the y hat, u hat.

00:48:46.430 --> 00:48:54.020
Well, one conclusion
is that I wouldn't

00:48:54.020 --> 00:48:56.020
be able to use conjugate
gradient methods,

00:48:56.020 --> 00:48:59.230
for example, which we've just
learned how powerful they

00:48:59.230 --> 00:49:03.830
are, on the big matrix because
it's not positive definite.

00:49:03.830 --> 00:49:04.650
It's symmetric.

00:49:04.650 --> 00:49:07.010
I could use some other
available methods.

00:49:07.010 --> 00:49:09.020
I couldn't use
conjugate gradient.

00:49:09.020 --> 00:49:11.460
So if I wanted to use
conjugate gradient,

00:49:11.460 --> 00:49:23.480
I better do this reduction
to the definite system.

00:49:26.480 --> 00:49:34.000
That's longer than I intended
to spend on the simple example.

00:49:34.000 --> 00:49:38.240
But if you see that
example, then we'll

00:49:38.240 --> 00:49:44.320
be ready to move it to the
wide variety of applications.

00:49:44.320 --> 00:49:52.890
So let me just note that one
section, already up on the web,

00:49:52.890 --> 00:49:58.000
called saddle point systems,
solves differential equations

00:49:58.000 --> 00:49:59.640
that are of this kind.

00:49:59.640 --> 00:50:04.670
So we'll come to that, and we'll
come to matrix problems too.

00:50:04.670 --> 00:50:08.170
It's a very, very
central question,

00:50:08.170 --> 00:50:13.580
how to solve linear systems
with matrices of that form.

00:50:13.580 --> 00:50:16.830
In fact, I guess
I could say it's

00:50:16.830 --> 00:50:21.220
almost the fundamental problem
of numerical linear algebra,

00:50:21.220 --> 00:50:27.620
is to solve systems that
fall into that saddle point

00:50:27.620 --> 00:50:29.240
description.

00:50:29.240 --> 00:50:34.730
I'll try to justify
that by the importance

00:50:34.730 --> 00:50:38.660
I'm assigning to this
problem in the next weeks.

00:50:38.660 --> 00:50:39.270
OK.

00:50:39.270 --> 00:50:46.150
Thanks for today and
I'll turn off volume.

