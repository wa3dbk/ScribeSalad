WEBVTT
Kind: captions
Language: en

00:00:01.550 --> 00:00:03.920
The following content is
provided under a Creative

00:00:03.920 --> 00:00:05.310
Commons license.

00:00:05.310 --> 00:00:07.520
Your support will help
MIT OpenCourseWare

00:00:07.520 --> 00:00:11.610
continue to offer high quality
educational resources for free.

00:00:11.610 --> 00:00:14.180
To make a donation, or to
view additional materials

00:00:14.180 --> 00:00:18.140
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:18.140 --> 00:00:19.026
at ocw.mit.edu.

00:00:23.178 --> 00:00:23.970
GILBERT STRANG: OK.

00:00:23.970 --> 00:00:27.690
Now, clustering for graphs.

00:00:27.690 --> 00:00:30.360
So this is a topic--

00:00:30.360 --> 00:00:32.040
this is one of the
important things

00:00:32.040 --> 00:00:34.890
you can try to do with a graph.

00:00:34.890 --> 00:00:36.225
So you have a large graph.

00:00:44.230 --> 00:00:47.430
Let me kind of divide
it into two clusters.

00:00:55.020 --> 00:00:56.760
So you've got a giant graph.

00:00:56.760 --> 00:01:00.030
And then the job is to
make some sense out of it.

00:01:00.030 --> 00:01:04.560
And one possible step is
to be able to subdivide it,

00:01:04.560 --> 00:01:13.560
if, as I see here, there's
a cut between two reasonably

00:01:13.560 --> 00:01:16.080
equal parts of the graph--

00:01:16.080 --> 00:01:19.320
reasonable--
reasonably same size.

00:01:19.320 --> 00:01:24.810
And therefore, that graph
could be studied in two pieces.

00:01:24.810 --> 00:01:30.940
So the question is, how do you
find such a cut by a algorithm?

00:01:30.940 --> 00:01:33.260
What's an algorithm that
would find that cut?

00:01:33.260 --> 00:01:36.120
So that's a problem.

00:01:36.120 --> 00:01:41.775
Let's say we're looking
for two clusters.

00:01:45.940 --> 00:01:48.460
We could look for more
clusters, but let's say we

00:01:48.460 --> 00:01:50.470
want to look for two clusters.

00:01:50.470 --> 00:01:52.250
So what are we trying to do?

00:01:52.250 --> 00:01:55.580
We're trying to minimize.

00:01:55.580 --> 00:01:56.830
So this is the problem, then.

00:02:02.380 --> 00:02:04.720
So we look for--

00:02:04.720 --> 00:02:10.509
find positions x
and y, let's say.

00:02:10.509 --> 00:02:15.370
Two which will be the
centers, so to speak, of the--

00:02:15.370 --> 00:02:21.940
and really, it's just
these points that--

00:02:21.940 --> 00:02:25.350
so the data is the
points and the edges,

00:02:25.350 --> 00:02:27.810
as always-- the
nodes and the edges.

00:02:27.810 --> 00:02:31.090
So the problem is to
find x and y so that--

00:02:31.090 --> 00:02:32.200
to minimize.

00:02:36.860 --> 00:02:45.100
So it's a distance
of points ai from x--

00:02:45.100 --> 00:02:49.690
maybe should emphasize
we're in high dimensions--

00:02:49.690 --> 00:02:54.230
plus the distance
of other points.

00:02:54.230 --> 00:02:58.060
So the ai will be these points--

00:02:58.060 --> 00:03:00.220
these nodes.

00:03:00.220 --> 00:03:05.080
And the bi will be these
nodes, plus the sum

00:03:05.080 --> 00:03:09.670
of bi minus y squared.

00:03:09.670 --> 00:03:13.750
And you understand
the rule here--

00:03:13.750 --> 00:03:23.250
that together the a's union
the b's give me all nodes.

00:03:25.900 --> 00:03:36.765
And I guess to be complete, the
a's intersect the b's is empty.

00:03:39.340 --> 00:03:41.130
Just what you expect.

00:03:41.130 --> 00:03:45.110
I'm dividing the a's and
the b's into two groups.

00:03:45.110 --> 00:03:48.350
And I'm picking
an x and a y sort

00:03:48.350 --> 00:03:55.860
of at the center of those
groups, so that is a minimum.

00:03:55.860 --> 00:03:57.050
So I want to minimize.

00:03:59.690 --> 00:04:03.790
And also, I probably want to
impose some condition that

00:04:03.790 --> 00:04:08.060
the number of a's is reasonably
close to the number of b's.

00:04:08.060 --> 00:04:13.880
In other words, I don't want
just that to be the a, and all

00:04:13.880 --> 00:04:15.740
the rest to be the b's.

00:04:15.740 --> 00:04:21.140
That would be not a
satisfactory clustering.

00:04:21.140 --> 00:04:26.400
I'm looking for clusters
that are good sized clusters.

00:04:26.400 --> 00:04:27.990
So minimize that.

00:04:27.990 --> 00:04:28.980
OK.

00:04:28.980 --> 00:04:31.980
So there are a lot of
different algorithms to do it.

00:04:34.710 --> 00:04:41.010
Some are more directly
attacking this problem.

00:04:41.010 --> 00:04:46.470
Others use matrices that we
associate with the graph.

00:04:46.470 --> 00:04:49.390
So let me tell you about two
or three of those algorithms.

00:04:49.390 --> 00:04:51.660
And if you've seen--

00:04:51.660 --> 00:04:54.480
studied-- had a course
in graph theory, this--

00:04:54.480 --> 00:04:56.710
you may already have
seen this problem.

00:04:56.710 --> 00:05:02.910
First question would be,
suppose I decide these are

00:05:02.910 --> 00:05:06.210
the a's, and those are the
b's-- or some other decision.

00:05:06.210 --> 00:05:08.060
Yeah, probably some
other decision.

00:05:08.060 --> 00:05:11.940
I don't want to solve the
problem before I even start.

00:05:11.940 --> 00:05:14.640
So some a's and some b's.

00:05:14.640 --> 00:05:17.970
What would be the best choice
of the x once you've decided

00:05:17.970 --> 00:05:19.110
on the a's?

00:05:19.110 --> 00:05:21.750
And what would be the
best choice of the y once

00:05:21.750 --> 00:05:23.820
you've decided on the b's?

00:05:23.820 --> 00:05:33.290
So we can answer that question
if we knew the two groups.

00:05:33.290 --> 00:05:37.000
We could see where they
should be centered,

00:05:37.000 --> 00:05:41.360
with the first group centered
at x, the second group centered

00:05:41.360 --> 00:05:43.850
at y, and what does
centering mean?

00:05:43.850 --> 00:05:44.930
So let's just say--

00:05:48.325 --> 00:05:51.210
so I think what I'm
saying here is--

00:05:55.030 --> 00:05:57.800
let me bring that down a little.

00:05:57.800 --> 00:06:01.250
So given the a's--

00:06:01.250 --> 00:06:07.310
the a's-- this is
a1 up to, say, ak.

00:06:07.310 --> 00:06:19.190
What is the best x just
to make that part right?

00:06:19.190 --> 00:06:22.160
And the answer is, to do
you know, geometrically,

00:06:22.160 --> 00:06:24.230
what x should be here?

00:06:24.230 --> 00:06:28.430
X is the-- so if I
have a bunch of points,

00:06:28.430 --> 00:06:32.660
and I'm looking for the
middle of those points--

00:06:32.660 --> 00:06:36.870
the point x-- a good point x
to say, OK, that's the middle.

00:06:36.870 --> 00:06:41.190
It'll make the sum of the
distances, I think, squared--

00:06:41.190 --> 00:06:43.740
I hope I'm right about that--

00:06:43.740 --> 00:06:45.530
a minimum.

00:06:45.530 --> 00:06:48.350
What is x?

00:06:48.350 --> 00:06:50.242
It is the--

00:06:50.242 --> 00:06:51.878
AUDIENCE: [INAUDIBLE].

00:06:51.878 --> 00:06:52.920
GILBERT STRANG: Centroid.

00:06:52.920 --> 00:06:54.150
Centroid is the word.

00:06:54.150 --> 00:07:02.700
X is the centroid of the a's.

00:07:02.700 --> 00:07:05.490
And what is the centroid?

00:07:05.490 --> 00:07:06.600
Let's see.

00:07:06.600 --> 00:07:09.120
Oh, maybe I don't know if
x and y were a good choice,

00:07:09.120 --> 00:07:11.730
but let me see what--

00:07:15.140 --> 00:07:17.210
I guess, it's the average a.

00:07:17.210 --> 00:07:21.098
It's the sum of the a's--

00:07:21.098 --> 00:07:22.820
of these a's.

00:07:22.820 --> 00:07:28.220
Those are vectors, of course,
divided by the number of a's.

00:07:32.710 --> 00:07:33.340
I think.

00:07:33.340 --> 00:07:36.670
Actually, I was just quickly
reviewing this morning,

00:07:36.670 --> 00:07:42.350
so I'm not totally on
top of this centroid.

00:07:42.350 --> 00:07:44.000
What I'm going to talk--

00:07:44.000 --> 00:07:47.200
the algorithm that I'm going
to talk about is the k--

00:07:47.200 --> 00:07:51.970
well, the k-means,
it's always called.

00:07:51.970 --> 00:07:55.450
And here it will be
the-- k will be 2.

00:07:58.840 --> 00:08:01.120
I just have two--

00:08:01.120 --> 00:08:05.080
partitioning into two sets,
a's and b's, so I just-- k

00:08:05.080 --> 00:08:06.140
is just 2.

00:08:06.140 --> 00:08:06.640
OK.

00:08:06.640 --> 00:08:10.050
What's the algorithm?

00:08:10.050 --> 00:08:15.420
Well, if I've
chosen a partition--

00:08:15.420 --> 00:08:17.880
the a's and b's have
separated them--

00:08:17.880 --> 00:08:22.800
then that tells me what
the x and the y should be.

00:08:22.800 --> 00:08:26.140
But, now what do I do next?

00:08:26.140 --> 00:08:29.640
So is this going to be a sort
of an alternating partition?

00:08:29.640 --> 00:08:32.039
Now I take those two centroids.

00:08:32.039 --> 00:08:43.090
So step one is for
given a's and b's, find

00:08:43.090 --> 00:08:49.770
the centroids x and y.

00:08:49.770 --> 00:08:52.440
And that's elementary.

00:08:52.440 --> 00:09:03.510
Then the second step is,
given the centroids, x and y--

00:09:03.510 --> 00:09:06.890
given those positions--
given x and y--

00:09:06.890 --> 00:09:10.000
they won't be centroids
when you see what happened.

00:09:10.000 --> 00:09:13.310
Given x and y, redo--

00:09:18.750 --> 00:09:23.200
form the best partition--

00:09:23.200 --> 00:09:23.805
best clusters.

00:09:29.840 --> 00:09:36.230
So step one, we had a guess at
what the best clusters were.

00:09:36.230 --> 00:09:37.820
And we found they're centroids.

00:09:37.820 --> 00:09:40.460
Now, we start with
the centroids,

00:09:40.460 --> 00:09:43.250
and we form new clusters again.

00:09:43.250 --> 00:09:46.370
And if these clusters
are the same as the ones

00:09:46.370 --> 00:09:50.240
we started with, then the
algorithm is converged.

00:09:50.240 --> 00:09:52.070
But probably they won't be--

00:09:52.070 --> 00:09:53.070
these clusters.

00:09:53.070 --> 00:09:57.005
So you'll have to tell me what
I mean by the best clusters.

00:09:57.005 --> 00:10:02.390
If I've got the two points,
x and y, I want the points--

00:10:02.390 --> 00:10:03.980
I want to separate
all the points

00:10:03.980 --> 00:10:08.270
that cluster around x to the
ones that cluster around y.

00:10:08.270 --> 00:10:11.030
And then, they're
probably different

00:10:11.030 --> 00:10:13.160
from my original start.

00:10:13.160 --> 00:10:14.990
So now I've got new--

00:10:14.990 --> 00:10:18.360
now I repeat step one.

00:10:18.360 --> 00:10:20.920
But let's just think, how
do I form the best clusters?

00:10:23.550 --> 00:10:28.830
Well, I take a point and I have
to decide, does it go with x,

00:10:28.830 --> 00:10:30.900
or does it go within
the x cluster,

00:10:30.900 --> 00:10:33.390
or does it go in the
cluster around y?

00:10:33.390 --> 00:10:36.870
So how do I decide that?

00:10:36.870 --> 00:10:39.540
Just whichever one
it's closer to.

00:10:39.540 --> 00:10:48.540
So each point goes
with each node.

00:10:48.540 --> 00:10:51.720
You should-- I
could say, each node

00:10:51.720 --> 00:11:01.950
goes with the closer of x and y.

00:11:05.250 --> 00:11:08.961
So points that
should have been--

00:11:08.961 --> 00:11:11.340
that are closer to x-- now
we're going to put them

00:11:11.340 --> 00:11:13.430
in the cluster around x.

00:11:13.430 --> 00:11:16.890
And does that solve the problem?

00:11:16.890 --> 00:11:20.040
No, because-- well, it
might, but it might not.

00:11:24.430 --> 00:11:27.880
We'd have to come
back to step one.

00:11:27.880 --> 00:11:29.800
We've now changed the clusters.

00:11:29.800 --> 00:11:32.620
They'll have
different centroids.

00:11:32.620 --> 00:11:35.410
So we repeat step one--
find the centroids

00:11:35.410 --> 00:11:37.150
for the two new clusters.

00:11:37.150 --> 00:11:38.980
Then we come to step two.

00:11:38.980 --> 00:11:43.210
Find the ones that should
go with the two centroids,

00:11:43.210 --> 00:11:44.680
and back and forth.

00:11:44.680 --> 00:11:46.120
I don't know.

00:11:46.120 --> 00:11:49.750
I don't think there's a
nice theory of convergence,

00:11:49.750 --> 00:11:52.160
or rate of convergence--
all the questions

00:11:52.160 --> 00:11:55.150
that this course
is always asking.

00:11:55.150 --> 00:12:01.960
But it's a very popular
algorithm, k-means.

00:12:01.960 --> 00:12:04.924
k would be to have k clusters.

00:12:04.924 --> 00:12:06.760
OK.

00:12:06.760 --> 00:12:08.170
So that's a--

00:12:08.170 --> 00:12:10.210
I'm not going to discuss the--

00:12:10.210 --> 00:12:12.910
I'd rather discuss some
other ways to do this,

00:12:12.910 --> 00:12:14.410
to solve this problem.

00:12:14.410 --> 00:12:20.830
But that's one sort of
hack that works quite well.

00:12:20.830 --> 00:12:21.330
OK.

00:12:21.330 --> 00:12:27.000
So second approach is
what is coming next.

00:12:27.000 --> 00:12:39.140
Second solution
method-- and it's

00:12:39.140 --> 00:12:45.476
called the spectral clustering.

00:12:49.850 --> 00:12:52.400
That's the name of the method.

00:12:52.400 --> 00:12:57.050
And before I write down what
you do, what does the word

00:12:57.050 --> 00:12:58.580
spectral mean?

00:12:58.580 --> 00:13:02.750
You see spectral graph
theory, spectral clustering.

00:13:02.750 --> 00:13:06.320
And in other parts of
mathematics, you see that--

00:13:06.320 --> 00:13:08.900
you see spectral theorem.

00:13:08.900 --> 00:13:10.430
I gave you the most--

00:13:10.430 --> 00:13:15.070
and I described it as the
most important-- perhaps--

00:13:15.070 --> 00:13:18.160
theorem in linear algebra--
at least one of the top three.

00:13:21.940 --> 00:13:25.030
So I'll write it over
here, because it's not--

00:13:25.030 --> 00:13:27.760
it doesn't-- this is--

00:13:27.760 --> 00:13:29.125
it's the same word, spectral.

00:13:34.530 --> 00:13:36.870
Well, let me ask
that question again?

00:13:36.870 --> 00:13:39.560
What's that word spectral about?

00:13:39.560 --> 00:13:40.620
What does that mean?

00:13:40.620 --> 00:13:42.560
That means that if
I have a matrix,

00:13:42.560 --> 00:13:47.450
and I want to talk
about its spectrum, what

00:13:47.450 --> 00:13:50.000
is the spectrum of the matrix?

00:13:50.000 --> 00:13:54.190
It is the eigenvalues.

00:13:54.190 --> 00:13:56.960
So spectral theory,
spectral clustering

00:13:56.960 --> 00:14:01.760
is using the eigenvalues
of some matrix.

00:14:01.760 --> 00:14:04.890
That's what that
spectral is telling me.

00:14:04.890 --> 00:14:05.390
Yeah.

00:14:05.390 --> 00:14:07.550
So the spectral
theorem, of course,

00:14:07.550 --> 00:14:16.580
is that for a symmetric matrix
S, the eigenvalues are real,

00:14:16.580 --> 00:14:21.710
and the eigenvectors
are orthogonal.

00:14:21.710 --> 00:14:30.210
And don't forget what the
real, full statement is here,

00:14:30.210 --> 00:14:34.730
because there could be
repeated real eigenvalues.

00:14:34.730 --> 00:14:37.400
And what does the
spectral theorem tell me

00:14:37.400 --> 00:14:42.440
for symmetric matrices,
if lambda equals

00:14:42.440 --> 00:14:45.770
5 is repeated four times--

00:14:45.770 --> 00:14:53.190
if it's a four times
solution of the equation that

00:14:53.190 --> 00:14:57.180
gives eigenvalues, then
what's the conclusion?

00:14:57.180 --> 00:15:01.740
Then there are four independent,
orthogonal eigenvectors

00:15:01.740 --> 00:15:04.210
to go with it.

00:15:04.210 --> 00:15:06.480
We can't say that
about matrices--

00:15:06.480 --> 00:15:07.920
about all matrices.

00:15:07.920 --> 00:15:12.150
But we can say it about
all symmetric matrices.

00:15:12.150 --> 00:15:15.380
And in fact, those
eigenvectors are orthogonal.

00:15:15.380 --> 00:15:17.340
So we're even saying more.

00:15:17.340 --> 00:15:20.340
We can find four
orthogonal eigenvectors

00:15:20.340 --> 00:15:25.280
that go with a multiplicity
for eigenvalues.

00:15:25.280 --> 00:15:25.780
OK.

00:15:25.780 --> 00:15:27.780
That's spectral theorem.

00:15:27.780 --> 00:15:42.720
Spectral clustering starts with
the graph Laplacian matrix.

00:15:46.140 --> 00:15:49.700
May I remember what
that matrix is?

00:15:49.700 --> 00:15:56.370
Because that's the key
connection of linear algebra

00:15:56.370 --> 00:16:00.240
to graph theory, is the
properties of this graph,

00:16:00.240 --> 00:16:02.210
Laplacian matrix.

00:16:02.210 --> 00:16:02.940
OK.

00:16:02.940 --> 00:16:05.420
So let me say L, for Laplacian.

00:16:08.270 --> 00:16:10.640
So that matrix-- one
way to describe it

00:16:10.640 --> 00:16:18.680
is as A transpose A,
where A is the incidence

00:16:18.680 --> 00:16:25.380
matrix of the graph.

00:16:25.380 --> 00:16:30.720
Or another way
we'll see is the D--

00:16:30.720 --> 00:16:32.080
the degree matrix.

00:16:35.690 --> 00:16:36.395
That's diagonal.

00:16:42.890 --> 00:16:45.230
And I'll do an example
just to remind you.

00:16:45.230 --> 00:16:49.505
Minus the-- well, I don't
know what I'd call this one.

00:16:52.390 --> 00:16:55.480
Shall I call it
B for the moment.

00:16:55.480 --> 00:16:58.060
And what matrix is B?

00:16:58.060 --> 00:17:00.910
That's the adjacency matrix.

00:17:07.030 --> 00:17:13.900
Really, you should know
these four matrices.

00:17:13.900 --> 00:17:18.180
They're the key four matrices
associated with any graph.

00:17:18.180 --> 00:17:20.760
The incidence matrix,
that's m by n--

00:17:24.960 --> 00:17:31.330
edges and nodes--
edges and nodes.

00:17:31.330 --> 00:17:35.970
So it's rectangular, but I'm
forming A transpose A here.

00:17:35.970 --> 00:17:41.280
So I'm forming a symmetric,
positive, semi-definite matrix.

00:17:41.280 --> 00:17:50.350
So this Laplacian is symmetric,
positive, semi-definite.

00:17:50.350 --> 00:17:50.850
Yeah.

00:17:50.850 --> 00:17:54.170
Let me let me just recall
what all these matrices are

00:17:54.170 --> 00:17:57.210
for a simple graph.

00:18:02.090 --> 00:18:02.590
OK.

00:18:02.590 --> 00:18:03.930
So I'll just draw a graph.

00:18:07.870 --> 00:18:09.340
All right.

00:18:09.340 --> 00:18:09.840
OK.

00:18:09.840 --> 00:18:11.460
So the incidence matrix--

00:18:14.570 --> 00:18:17.600
there are 1, 2, 3, 4, 5 edges--

00:18:17.600 --> 00:18:18.605
so five rows.

00:18:22.030 --> 00:18:24.100
There are four nodes--

00:18:24.100 --> 00:18:27.890
1, 2, 3, and 4.

00:18:27.890 --> 00:18:29.590
So four columns.

00:18:29.590 --> 00:18:36.460
And a typical row would be edge
1 going from node 1 to node 2,

00:18:36.460 --> 00:18:41.390
so it would have a
minus 1 and a 1 there.

00:18:41.390 --> 00:18:46.400
And let me take edge 2,
going from 1 to node 3,

00:18:46.400 --> 00:18:51.600
so it would have a minus 1
and a 1 there, and so on.

00:18:51.600 --> 00:18:57.390
So that's the
incidence matrix A. OK.

00:18:57.390 --> 00:18:58.950
What's the degree matrix?

00:18:58.950 --> 00:19:00.720
That's simple.

00:19:00.720 --> 00:19:09.410
The degree matrix-- well, A
transpose A. This is m by n.

00:19:09.410 --> 00:19:11.280
This is n by m.

00:19:11.280 --> 00:19:14.190
So it's n by n.

00:19:18.300 --> 00:19:19.430
OK.

00:19:19.430 --> 00:19:22.330
In this case, 4 by 4.

00:19:22.330 --> 00:19:26.200
So the degree matrix
will be 4 by 4, n by n.

00:19:26.200 --> 00:19:29.230
And it will tell us the
degree of that, which means--

00:19:29.230 --> 00:19:30.880
which we just count the edges.

00:19:30.880 --> 00:19:38.110
So three edges going in, node
2, three edges going in, node 3

00:19:38.110 --> 00:19:40.180
has just two edges.

00:19:40.180 --> 00:19:43.030
And node 4 has just two edges.

00:19:43.030 --> 00:19:45.610
So that's the degree matrix.

00:19:45.610 --> 00:19:47.860
And then the adjacency
matrix that I've

00:19:47.860 --> 00:19:52.600
called B is also 4 by 4.

00:19:52.600 --> 00:19:55.630
And what is it?

00:19:55.630 --> 00:19:59.990
It tells us which node is
connected to which node.

00:19:59.990 --> 00:20:04.810
So I don't allow nodes--

00:20:04.810 --> 00:20:10.180
edges that connect a node to
itself, so 0's on the diagonal.

00:20:10.180 --> 00:20:14.680
How many-- so which nodes
are connected to node 1?

00:20:14.680 --> 00:20:18.640
Well, all of 2 and 4 and
3 are connected to 1.

00:20:18.640 --> 00:20:20.140
So I have 1's there.

00:20:22.670 --> 00:20:26.780
Node 2-- all three nodes
are connected to node 2.

00:20:26.780 --> 00:20:31.040
So I'll have-- the second column
and row will have all three

00:20:31.040 --> 00:20:32.210
1's.

00:20:32.210 --> 00:20:34.350
How about node 3?

00:20:34.350 --> 00:20:34.870
OK.

00:20:34.870 --> 00:20:39.770
Only edges-- only two
edges are connected.

00:20:39.770 --> 00:20:46.820
Only two nodes are connected
to 3, 1 and 2, but not 4.

00:20:46.820 --> 00:20:49.970
So 1 and 2 I have, but not 4.

00:20:49.970 --> 00:20:51.950
OK.

00:20:51.950 --> 00:20:54.500
So that's the adjacency matrix.

00:20:54.500 --> 00:20:55.700
Is that right?

00:20:55.700 --> 00:20:58.350
Think so.

00:20:58.350 --> 00:21:00.270
This is the degree matrix.

00:21:00.270 --> 00:21:04.290
This is the incidence matrix.

00:21:04.290 --> 00:21:08.730
And that formula gives
me the Laplacian.

00:21:08.730 --> 00:21:09.240
OK.

00:21:09.240 --> 00:21:11.356
Let's just write
down the Laplacian.

00:21:15.460 --> 00:21:19.150
So if I use the degree minus B--

00:21:19.150 --> 00:21:20.290
that's easy.

00:21:20.290 --> 00:21:23.888
The degrees were 3, 3, 2, and 2.

00:21:23.888 --> 00:21:24.930
Now I have these minuses.

00:21:30.610 --> 00:21:33.660
And those were 0.

00:21:33.660 --> 00:21:34.160
OK.

00:21:37.290 --> 00:21:39.990
So that's a positive,
semi-definite matrix.

00:21:39.990 --> 00:21:44.060
Is it a positive
definite matrix?

00:21:44.060 --> 00:21:49.890
So let me ask, is it singular
or is it not singular?

00:21:49.890 --> 00:21:51.690
Is there a vector
in its null space,

00:21:51.690 --> 00:21:54.580
or is there not a vector
in its null space?

00:21:54.580 --> 00:21:59.345
Can you solve Dx equals all 0's?

00:22:03.410 --> 00:22:06.050
And of course, you can.

00:22:06.050 --> 00:22:11.180
Everybody sees that
vector of all 1's will

00:22:11.180 --> 00:22:17.220
be a solution to L--

00:22:17.220 --> 00:22:17.720
sorry.

00:22:17.720 --> 00:22:21.670
I should be saying L here.

00:22:21.670 --> 00:22:24.750
Lx equals 0.

00:22:24.750 --> 00:22:38.130
Lx equals 0 as for a whole line
of one dimensional null space

00:22:38.130 --> 00:22:45.120
of L has dimension 1.

00:22:45.120 --> 00:22:49.140
It's got 1 basis
vector, 1, 1, 1, 1.

00:22:49.140 --> 00:22:55.860
And that will always happen
with the graph set up

00:22:55.860 --> 00:22:57.020
that I've created.

00:22:57.020 --> 00:22:57.520
OK.

00:22:57.520 --> 00:23:02.400
So that's a first fact, that
this positive, semi-definite

00:23:02.400 --> 00:23:09.980
matrix, L, has
lambda 1 equals 0.

00:23:09.980 --> 00:23:15.170
And the eigenvector
is constant--

00:23:15.170 --> 00:23:19.580
C, C, C, C-- the one
dimensional eigenspace.

00:23:19.580 --> 00:23:22.830
Or 1, 1, 1, 1 is the
typical eigenvector.

00:23:22.830 --> 00:23:23.330
OK.

00:23:26.580 --> 00:23:32.130
Now back to graph clustering.

00:23:32.130 --> 00:23:35.820
The idea of graph
clustering is to look

00:23:35.820 --> 00:23:39.960
at the Fiedler eigenvector.

00:23:39.960 --> 00:23:41.225
This is called the x2--

00:23:44.450 --> 00:23:55.850
is the next eigenvector-- is
the eigenvector for the smallest

00:23:55.850 --> 00:24:01.790
positive eigenvalue for a
lambda min excluding 0--

00:24:01.790 --> 00:24:06.020
so the smallest
eigenvalue of L--

00:24:11.454 --> 00:24:15.420
the smallest eigenvalue
and its eigenvector-- this

00:24:15.420 --> 00:24:17.670
is called the
Fiedler vector, named

00:24:17.670 --> 00:24:20.940
after the Czech mathematician.

00:24:25.330 --> 00:24:31.020
A great man in linear algebra,
and he studied this factor--

00:24:31.020 --> 00:24:32.510
this situation.

00:24:32.510 --> 00:24:38.310
So everybody who knows
about the graph Laplacian

00:24:38.310 --> 00:24:43.050
is aware that its
first eigenvalue is 0,

00:24:43.050 --> 00:24:46.170
and that the next
eigenvalue is important.

00:24:46.170 --> 00:24:46.801
Yeah.

00:24:46.801 --> 00:24:48.968
AUDIENCE: Is the graph
Laplacian named the Laplacian

00:24:48.968 --> 00:24:52.850
because it has connections to--

00:24:52.850 --> 00:24:54.705
GILBERT STRANG: To
Laplace's equation, yes.

00:24:58.860 --> 00:25:00.250
Yeah, that's a good question.

00:25:00.250 --> 00:25:04.430
So why the word--

00:25:04.430 --> 00:25:06.672
the name, Laplacian?

00:25:10.050 --> 00:25:15.400
So yeah, that's a good question.

00:25:15.400 --> 00:25:22.170
So the familiar thing-- so it
connects to Laplace's finite

00:25:22.170 --> 00:25:24.990
difference equation, because
we're talking about matrices

00:25:24.990 --> 00:25:27.030
here, and not derivatives--

00:25:27.030 --> 00:25:28.980
not functions.

00:25:28.980 --> 00:25:30.600
So why the word Laplacian?

00:25:30.600 --> 00:25:32.880
Well, so if I have a regular--

00:25:32.880 --> 00:25:37.950
if my graph is composed of--

00:25:37.950 --> 00:25:46.630
so there is a graph with
25 nodes, and 4 times 5--

00:25:46.630 --> 00:25:48.190
20, about 40.

00:25:48.190 --> 00:25:55.460
This probably has about
40 edges and 25 nodes.

00:25:58.550 --> 00:26:01.910
And of course, I
can construct its--

00:26:01.910 --> 00:26:05.446
graph all those four
matrices for it--

00:26:05.446 --> 00:26:11.050
its incidence matrix,
its degree matrix.

00:26:11.050 --> 00:26:15.470
So the degree will be four
at all these inside points.

00:26:15.470 --> 00:26:19.220
The degree will be three
at these boundary points.

00:26:19.220 --> 00:26:22.120
The degree will be two
at these corner points.

00:26:22.120 --> 00:26:28.670
But the-- what will
the matrix L look like?

00:26:28.670 --> 00:26:30.800
So what is L?

00:26:34.690 --> 00:26:39.660
And that will tell you why
it has this name Laplacian.

00:26:39.660 --> 00:26:42.690
So the matrix L will have--

00:26:42.690 --> 00:26:45.550
the degree 4 right will
be on the diagonal.

00:26:45.550 --> 00:26:49.990
That's coming from
D. The other--

00:26:49.990 --> 00:26:55.750
the minus 1's that come from
B, the adjacency matrix,

00:26:55.750 --> 00:27:01.510
will be associated with those
nodes, and otherwise, all 0's.

00:27:01.510 --> 00:27:05.860
So this is a typical row
of L. This is typical row

00:27:05.860 --> 00:27:09.280
of L centered at that node.

00:27:09.280 --> 00:27:12.760
So maybe that's node
number 5, 10, 13.

00:27:12.760 --> 00:27:17.100
That's 13 out of 25 that
would show you this.

00:27:17.100 --> 00:27:18.310
And the-- sorry.

00:27:18.310 --> 00:27:20.990
Those are minus 1's.

00:27:20.990 --> 00:27:22.330
Minus 1's.

00:27:22.330 --> 00:27:27.370
So a 4 on the diagonal,
and four minus 1's.

00:27:27.370 --> 00:27:31.810
That's the model problem for
when the graph is a grid--

00:27:31.810 --> 00:27:33.280
square grid.

00:27:33.280 --> 00:27:36.940
And do you associate that
with Laplace's equation?

00:27:36.940 --> 00:27:41.760
So this is the
reason that Laplace--

00:27:41.760 --> 00:27:45.220
why Laplace gets in it.

00:27:45.220 --> 00:27:48.940
Because Laplace's equation--
the differential equation--

00:27:48.940 --> 00:27:52.510
is second derivative with
respect to x squared,

00:27:52.510 --> 00:27:57.460
and the second derivative with
respect to y squared is 0.

00:27:57.460 --> 00:28:02.800
And what we have
here is Lu equals 0.

00:28:02.800 --> 00:28:07.000
It's the discrete Laplacian,
the vector Laplacian,

00:28:07.000 --> 00:28:08.710
the graph Laplacian--

00:28:08.710 --> 00:28:15.340
where the second x derivative
is replaced by -1, 2, -1.

00:28:15.340 --> 00:28:20.290
And the second y derivative
is replaced by -1, 2, -1.

00:28:20.290 --> 00:28:24.490
Second differences in the
x and the y directions.

00:28:24.490 --> 00:28:26.620
So that's-- yeah.

00:28:26.620 --> 00:28:30.610
So that's the
explanation for Laplace.

00:28:30.610 --> 00:28:33.910
It's the discrete Laplace--

00:28:33.910 --> 00:28:37.870
discrete, or the finite
difference Laplace.

00:28:37.870 --> 00:28:39.380
OK.

00:28:39.380 --> 00:28:46.870
Now to just finish, I have
to tell you what the--

00:28:46.870 --> 00:28:50.890
what clusters-- how do you
decide the clusters from L?

00:28:50.890 --> 00:28:57.920
How does L propose two
clusters, the a's and b's?

00:28:57.920 --> 00:29:02.290
And here's the answer.

00:29:02.290 --> 00:29:06.930
They come from
this eigenvector--

00:29:06.930 --> 00:29:09.180
the Fiedler eigenvector.

00:29:09.180 --> 00:29:10.750
You look at that eigenvector.

00:29:13.280 --> 00:29:17.908
It's got some positive and
some negative components.

00:29:17.908 --> 00:29:23.000
The components with positive
numbers of this eigenvector--

00:29:23.000 --> 00:29:31.790
so the positive
components of x--

00:29:34.890 --> 00:29:39.797
of-- this eigenvector.

00:29:42.480 --> 00:29:45.698
And there are negative
components of this eigenvector.

00:29:45.698 --> 00:29:46.990
And those are the two clusters.

00:29:51.930 --> 00:29:56.730
So it's-- the cluster is--
the two clusters are decided

00:29:56.730 --> 00:29:58.620
by the eigenvector--

00:29:58.620 --> 00:30:02.910
by the signs-- plus or minus
signs of the components.

00:30:02.910 --> 00:30:06.810
The plus signs go in one and
the minus signs go in another.

00:30:06.810 --> 00:30:12.450
And you have to experiment to
see that that would succeed.

00:30:12.450 --> 00:30:16.680
I don't know what it would do on
this, actually, because that's

00:30:16.680 --> 00:30:19.980
hardly split up into two.

00:30:19.980 --> 00:30:22.860
I suppose maybe the
split is along a line

00:30:22.860 --> 00:30:25.080
like that or something, to get--

00:30:25.080 --> 00:30:26.880
I don't know what clustering.

00:30:26.880 --> 00:30:31.770
This is not a graph that
is naturally clustered,

00:30:31.770 --> 00:30:36.480
but you could still
do k-means on it.

00:30:36.480 --> 00:30:40.740
You could still do
spectral clustering.

00:30:40.740 --> 00:30:42.480
And you would find
this eigenvector.

00:30:42.480 --> 00:30:46.080
Now what's the point
about this eigenvector?

00:30:46.080 --> 00:30:48.220
I'll finish in one moment.

00:30:48.220 --> 00:30:51.360
What do we know about
that eigenvector as

00:30:51.360 --> 00:30:53.530
compared to that one?

00:30:53.530 --> 00:30:55.710
So here was an
eigenvector all 1's.

00:30:55.710 --> 00:31:00.150
Let me just make it
all 1's, 1, 1, 1, 1.

00:31:00.150 --> 00:31:03.890
In that picture, it's 25 1's.

00:31:03.890 --> 00:31:07.320
Here's the next eigenvector up.

00:31:07.320 --> 00:31:12.320
And what's the relation between
those two eigenvectors of L?

00:31:12.320 --> 00:31:13.964
They are--

00:31:13.964 --> 00:31:14.845
AUDIENCE: Orthogonal.

00:31:14.845 --> 00:31:15.970
GILBERT STRANG: Orthogonal.

00:31:15.970 --> 00:31:19.460
These are eigenvectors
of a symmetric matrix.

00:31:19.460 --> 00:31:20.920
So they're orthogonal.

00:31:20.920 --> 00:31:25.840
So that means-- to be
orthogonal to this guy means

00:31:25.840 --> 00:31:28.195
that your components
add to 0, right?

00:31:28.195 --> 00:31:29.020
A Vector.

00:31:29.020 --> 00:31:31.510
Is orthogonal to all 1's.

00:31:31.510 --> 00:31:34.750
That dot product is just,
add up the components.

00:31:34.750 --> 00:31:36.760
So we have a bunch of
positive components

00:31:36.760 --> 00:31:38.740
and a bunch of
negative components.

00:31:38.740 --> 00:31:44.620
They have the same sum, because
the dot product with that is 0.

00:31:44.620 --> 00:31:48.610
And those two components--
those two sets of components are

00:31:48.610 --> 00:31:49.540
your--

00:31:49.540 --> 00:31:54.250
to tell you the two clusters
in spectral clustering.

00:31:54.250 --> 00:31:58.810
So it's a pretty
nifty algorithm.

00:31:58.810 --> 00:32:02.920
It does ask you to
compute an eigenvector.

00:32:02.920 --> 00:32:06.350
And that, of course, takes time.

00:32:06.350 --> 00:32:10.400
And then there's a third,
more direct algorithm

00:32:10.400 --> 00:32:14.140
to do this optimization problem.

00:32:14.140 --> 00:32:15.970
Well, actually, there are many.

00:32:15.970 --> 00:32:17.680
This is an important
problem, so there

00:32:17.680 --> 00:32:19.510
are many proposed algorithms.

00:32:19.510 --> 00:32:20.080
Good.

00:32:20.080 --> 00:32:20.580
OK.

00:32:20.580 --> 00:32:22.360
I'm closing up.

00:32:22.360 --> 00:32:23.160
Final question.

00:32:23.160 --> 00:32:23.660
Yeah?

00:32:23.660 --> 00:32:26.110
AUDIENCE: Is it possible to
do more than two clusters?

00:32:26.110 --> 00:32:28.480
GILBERT STRANG: Well,
certainly for k-means.

00:32:28.480 --> 00:32:31.870
Now, if I had to do three
clusters with Fiedler,

00:32:31.870 --> 00:32:34.740
I would look at the
first three eigenvectors.

00:32:34.740 --> 00:32:37.780
And, well, the first
one would be nothing.

00:32:37.780 --> 00:32:39.790
And I would look
at the next two.

00:32:39.790 --> 00:32:42.790
And that would be
pretty successful.

00:32:42.790 --> 00:32:45.130
If I wanted six
clusters, it probably

00:32:45.130 --> 00:32:49.700
would fall off in the
quality of the clustering.

00:32:49.700 --> 00:32:50.200
Yeah.

00:32:50.200 --> 00:32:53.380
But that certainly-- I
would look at the lowest six

00:32:53.380 --> 00:32:56.920
eigenvectors, and get somewhere.

00:32:56.920 --> 00:32:57.880
Yeah.

00:32:57.880 --> 00:32:58.420
Right.

00:32:58.420 --> 00:33:00.040
So OK.

00:33:00.040 --> 00:33:02.050
So that's a topic--

00:33:02.050 --> 00:33:08.320
an important topic-- a sort of
standard topic in applied graph

00:33:08.320 --> 00:33:09.820
theory.

00:33:09.820 --> 00:33:10.360
OK.

00:33:10.360 --> 00:33:12.550
So see you Wednesday.

00:33:12.550 --> 00:33:17.710
I'm hoping, on Wednesday--

00:33:17.710 --> 00:33:24.040
so Professor Edelman has
told me a new and optimal way

00:33:24.040 --> 00:33:29.995
to look at the problem
of backpropagation.

00:33:29.995 --> 00:33:32.680
Do you remember backpropagation?

00:33:32.680 --> 00:33:34.600
If you remember
the lecture on it--

00:33:34.600 --> 00:33:39.300
you don't want to remember
the lecture on it.

00:33:39.300 --> 00:33:43.990
It's a tricky, messy
thing to explain.

00:33:43.990 --> 00:33:50.110
But he says, if I explain it
using Julia in linear algebra,

00:33:50.110 --> 00:33:52.060
it's clear.

00:33:52.060 --> 00:33:54.580
So we'll give him a
chance on Wednesday

00:33:54.580 --> 00:34:02.110
to show that revolutionary
approach to the explanation

00:34:02.110 --> 00:34:03.640
of backpropagation.

00:34:03.640 --> 00:34:06.340
And I hope for--

00:34:06.340 --> 00:34:08.620
I told him he could
have half an hour,

00:34:08.620 --> 00:34:11.800
and projects would
take some time.

00:34:11.800 --> 00:34:15.730
I hope-- now we've had
two with wild applause.

00:34:15.730 --> 00:34:21.920
So I hope we get a couple
more in our last class.

00:34:21.920 --> 00:34:22.420
OK.

00:34:22.420 --> 00:34:23.440
See you Wednesday.

00:34:23.440 --> 00:34:25.360
And if you bring--

00:34:25.360 --> 00:34:30.460
well, if you have projects
ready, send them to me online,

00:34:30.460 --> 00:34:33.489
and maybe a print out as well.

00:34:33.489 --> 00:34:35.170
That would be terrific.

00:34:35.170 --> 00:34:41.080
If you don't have them ready
by the hour, they can go--

00:34:41.080 --> 00:34:43.699
the envelope outside my
office would receive them.

00:34:43.699 --> 00:34:44.199
Good.

00:34:44.199 --> 00:34:48.090
So I'll see you Wednesday
for the final class.

