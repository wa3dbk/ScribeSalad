WEBVTT
Kind: captions
Language: en

00:00:01.040 --> 00:00:03.460
The following content is
provided under a Creative

00:00:03.460 --> 00:00:04.870
Commons license.

00:00:04.870 --> 00:00:07.910
Your support will help MIT
OpenCourseWare continue to

00:00:07.910 --> 00:00:11.560
offer high-quality educational
resources for free.

00:00:11.560 --> 00:00:14.460
To make a donation or view
additional materials from

00:00:14.460 --> 00:00:20.290
hundreds of MIT courses, visit
MIT OpenCourseWare at

00:00:20.290 --> 00:00:21.540
ocw.mit.edu.

00:00:24.628 --> 00:00:27.830
PROFESSOR: He ended up last
Thursday's lectures talking

00:00:27.830 --> 00:00:30.570
about Gaussian distributions.

00:00:30.570 --> 00:00:32.710
As he said, one of the
interesting things about a

00:00:32.710 --> 00:00:36.650
Gaussian is it can be fully
characterized by its mean and

00:00:36.650 --> 00:00:39.070
its standard deviation.

00:00:39.070 --> 00:00:43.920
And this concept of being
able to take a curve and

00:00:43.920 --> 00:00:47.590
characterize it with a small
number of parameters is

00:00:47.590 --> 00:00:52.580
something we'll continue to see
as a very important way of

00:00:52.580 --> 00:00:56.200
looking at modeling
physical systems.

00:00:56.200 --> 00:00:58.570
And in fact, that is
the part of the

00:00:58.570 --> 00:01:00.290
term that we've entered.

00:01:00.290 --> 00:01:03.880
And it's a part of the term
we'll spend a lot of time on.

00:01:03.880 --> 00:01:08.270
And the whole issue is, how do
we construct computational

00:01:08.270 --> 00:01:14.665
models that will help us
understand the real world?

00:01:20.210 --> 00:01:26.370
When we can, we love to model
distributions as Gaussians, or

00:01:26.370 --> 00:01:30.120
normal, because they're so
nicely characterized.

00:01:30.120 --> 00:01:33.280
We have nice rules of thumb that
tell us how close things

00:01:33.280 --> 00:01:35.850
lie to the mean, et cetera.

00:01:35.850 --> 00:01:39.860
However, it's important to
understand that if something

00:01:39.860 --> 00:01:43.590
is not actually normally
distributed and we pretend it

00:01:43.590 --> 00:01:49.190
is, we can get very misleading
results out of our model.

00:01:49.190 --> 00:01:51.330
So let's think about the
fact that not all

00:01:51.330 --> 00:01:53.410
distributions are normal.

00:01:53.410 --> 00:01:57.130
So consider rolling
a single die.

00:01:57.130 --> 00:02:01.070
Each of the 6 outcomes
is equally probable.

00:02:01.070 --> 00:02:05.290
So we would not expect to see a
peak, say, at 3 or 4, and a

00:02:05.290 --> 00:02:07.166
trough at 1.

00:02:07.166 --> 00:02:10.385
A 3 or a 4 is the same
probability as 1.

00:02:13.470 --> 00:02:17.210
Similarly, if one thinks about
the Massachusetts state

00:02:17.210 --> 00:02:22.140
lottery, or any fair lottery,
the probability of each number

00:02:22.140 --> 00:02:26.250
coming up is the same.

00:02:26.250 --> 00:02:28.080
So it would be a flat line.

00:02:28.080 --> 00:02:32.280
If you had a million numbers,
the probability of each number

00:02:32.280 --> 00:02:33.990
is 1 over a million.

00:02:33.990 --> 00:02:36.480
And so if you plotted the
probability of each number,

00:02:36.480 --> 00:02:39.410
again, you'd get a flat line.

00:02:39.410 --> 00:02:42.200
Such distributions are
called uniform.

00:02:49.170 --> 00:02:52.800
Each result is equally
probable.

00:03:01.630 --> 00:03:06.100
We can fully characterize a
uniform distribution with a

00:03:06.100 --> 00:03:10.100
single parameter, its range.

00:03:10.100 --> 00:03:13.470
If I tell you it ranges over 1
to a million, that's all you

00:03:13.470 --> 00:03:17.120
need to know to know what the
distribution looks like.

00:03:17.120 --> 00:03:21.760
So they're even simpler than
normal distributions.

00:03:21.760 --> 00:03:27.030
Uniform distributions occur
quite often in games devised

00:03:27.030 --> 00:03:33.040
by humans, but almost
never in nature.

00:03:33.040 --> 00:03:36.770
And typically they're
not very useful for

00:03:36.770 --> 00:03:40.250
modeling complex systems.

00:03:40.250 --> 00:03:42.970
We have to work hard to invent
something that's normal.

00:03:42.970 --> 00:03:45.260
Most things are not naturally
that way.

00:03:49.310 --> 00:03:51.360
I'm sorry, to invent things
that are uniform.

00:03:51.360 --> 00:03:55.750
Normal, as we saw last time,
occurs all the time in nature.

00:03:55.750 --> 00:04:02.240
The other thing that occurs
quite frequently are

00:04:02.240 --> 00:04:03.516
exponential distributions.

00:04:15.150 --> 00:04:18.209
They're used in a lot
of different ways.

00:04:18.209 --> 00:04:21.640
For example, people who are
trying to plan things like

00:04:21.640 --> 00:04:26.730
highway systems use exponential
distributions to

00:04:26.730 --> 00:04:31.210
model inter-arrival times, how
much time there is between

00:04:31.210 --> 00:04:35.110
each car, say, entering
the Mass Turnpike.

00:04:35.110 --> 00:04:38.070
We'll see many other
examples of them.

00:04:38.070 --> 00:04:42.250
The key thing about them is
they have the property of

00:04:42.250 --> 00:04:43.500
being memoryless.

00:04:50.080 --> 00:04:54.800
They are in fact the only
continuous distributions that

00:04:54.800 --> 00:04:56.620
are memoryless.

00:04:56.620 --> 00:04:59.880
So let's look at an example
with which some of you are

00:04:59.880 --> 00:05:03.740
more familiar than you want to
be, the concentration of a

00:05:03.740 --> 00:05:06.440
drug in the human body.

00:05:06.440 --> 00:05:08.960
For those who are watching on
OpenCourseWare, it's not

00:05:08.960 --> 00:05:10.960
because all the students
are drug users.

00:05:10.960 --> 00:05:14.510
It's because they're working on
a problem set that involves

00:05:14.510 --> 00:05:16.150
modeling drugs in
the human body.

00:05:21.770 --> 00:05:25.010
I don't know how many of you
are drug users, all right?

00:05:25.010 --> 00:05:29.550
Assume that at each time step,
each molecule has a

00:05:29.550 --> 00:05:34.840
probability p of being
cleared by the body.

00:05:34.840 --> 00:05:39.930
The system is memoryless in the
sense that at each step,

00:05:39.930 --> 00:05:43.410
the probability of a particular
molecule being

00:05:43.410 --> 00:05:46.310
cleared is independent
of what happened at

00:05:46.310 --> 00:05:49.080
the previous steps.

00:05:49.080 --> 00:05:54.790
So the fact that a molecule
didn't get cleared at time t

00:05:54.790 --> 00:05:58.610
has no impact on whether
or not it will be

00:05:58.610 --> 00:06:00.810
cleared at time t1.

00:06:00.810 --> 00:06:06.230
The probability doesn't go up
as it doesn't get cleared.

00:06:06.230 --> 00:06:08.260
So it's independent of
the previous steps.

00:06:11.280 --> 00:06:19.580
So at time t equals 1, what's
the probability of the

00:06:19.580 --> 00:06:24.180
molecule still being
in the human body?

00:06:24.180 --> 00:06:28.150
If the probability of being
cleared at each step is p,

00:06:28.150 --> 00:06:32.110
it's 1 minus p, right?

00:06:32.110 --> 00:06:35.610
So if the probability of being
cleared was 0.5 at each time

00:06:35.610 --> 00:06:39.220
step, the time that it still
exists after the first time

00:06:39.220 --> 00:06:42.120
step is 1 minus 0.5--

00:06:42.120 --> 00:06:45.410
i.e., 0.5.

00:06:45.410 --> 00:06:48.270
So what's the probability of
it still being in the human

00:06:48.270 --> 00:06:50.900
body at time t equals 2?

00:06:53.850 --> 00:06:57.180
Well, it wasn't cleared
at time 1.

00:06:59.710 --> 00:07:03.320
Since it's memoryless, whether
or not it's cleared at time 2

00:07:03.320 --> 00:07:05.900
is also 1/p.

00:07:05.900 --> 00:07:10.770
And so it existing still after
two steps is going to be 1

00:07:10.770 --> 00:07:13.480
minus p squared.

00:07:13.480 --> 00:07:16.880
We saw that with independent
probabilities.

00:07:16.880 --> 00:07:19.400
And the nice thing about working
with exponential

00:07:19.400 --> 00:07:22.500
distributions is we know that
the probabilities are

00:07:22.500 --> 00:07:24.870
independent.

00:07:24.870 --> 00:07:29.920
More generally, its still being
in the body at time t is

00:07:29.920 --> 00:07:33.080
going to be 1 minus
p to the t.

00:07:35.870 --> 00:07:40.840
So we have a nice closed-form
solution that will give us the

00:07:40.840 --> 00:07:48.000
probability of each molecule
surviving until time t.

00:07:48.000 --> 00:07:49.740
All right?

00:07:49.740 --> 00:07:53.020
So now let's look at the
question of, suppose that at

00:07:53.020 --> 00:08:01.050
time t equals 0, there
are m0 molecules.

00:08:01.050 --> 00:08:04.060
Now we can ask, how many
molecules are there likely to

00:08:04.060 --> 00:08:07.420
be at any time t?

00:08:07.420 --> 00:08:10.180
Well, let's write a little
program to look at that.

00:08:19.730 --> 00:08:21.425
So that's this program, clear.

00:08:24.210 --> 00:08:28.350
We'll start with n, the number
of molecules, the probability

00:08:28.350 --> 00:08:32.169
of clearing it at each step,
and the number of steps.

00:08:32.169 --> 00:08:34.240
And we'll keep track of
the num remaining.

00:08:34.240 --> 00:08:39.140
So at the beginning, we have
n molecules remaining.

00:08:39.140 --> 00:08:45.890
And then for t in range steps,
we're just going to multiply

00:08:45.890 --> 00:08:49.540
n, the number we started with,
times the probability of each

00:08:49.540 --> 00:08:52.200
molecule still existing.

00:08:52.200 --> 00:08:54.890
And then we'll plot it.

00:08:54.890 --> 00:08:56.370
Does that make sense?

00:08:56.370 --> 00:08:59.980
So this is a tiny bit of code
that basically implements that

00:08:59.980 --> 00:09:03.880
formula over on the board.

00:09:03.880 --> 00:09:05.130
Let's run it.

00:09:10.540 --> 00:09:13.190
And we'll run it starting with
a 1,000 molecules, a

00:09:13.190 --> 00:09:17.190
probability of each being
cleared of 0.01, and we'll

00:09:17.190 --> 00:09:18.705
look at 500 time steps.

00:09:25.440 --> 00:09:26.450
All right.

00:09:26.450 --> 00:09:28.990
This is kind of interesting.

00:09:28.990 --> 00:09:31.700
We're getting a straight line.

00:09:31.700 --> 00:09:34.640
That doesn't look like an
exponential, does it?

00:09:34.640 --> 00:09:35.620
Or does it?

00:09:35.620 --> 00:09:39.870
Why do we have a straight
line here?

00:09:39.870 --> 00:09:42.300
Somebody?

00:09:42.300 --> 00:09:45.880
Because I used a semilog axis.

00:09:45.880 --> 00:09:48.535
So let's look at it
now without that.

00:09:53.650 --> 00:09:56.070
We now see something that
really does look like

00:09:56.070 --> 00:09:59.420
exponential decay.

00:09:59.420 --> 00:10:03.090
It drops very quickly in the
beginning, and then it

00:10:03.090 --> 00:10:05.210
asymptotes towards 0.

00:10:05.210 --> 00:10:08.720
But of course it never
quite gets there in

00:10:08.720 --> 00:10:10.640
a continuous model.

00:10:10.640 --> 00:10:14.560
If we had a discrete model, we
would eventually have to get

00:10:14.560 --> 00:10:16.960
to 0, because that last molecule
would either get

00:10:16.960 --> 00:10:18.370
cleared or not.

00:10:18.370 --> 00:10:20.510
But in a continuous world--

00:10:20.510 --> 00:10:23.910
which is in this case probably
not a good model, or not a

00:10:23.910 --> 00:10:27.240
perfect model I should say,
because it allows us to have a

00:10:27.240 --> 00:10:30.770
quarter of a molecule there,
which we kind of know is

00:10:30.770 --> 00:10:35.110
physiologically nonsense,
biochemically nonsense.

00:10:35.110 --> 00:10:39.460
But you can see we get this
exponential decay.

00:10:39.460 --> 00:10:45.012
But as we saw previously, if
we plot an exponential on a

00:10:45.012 --> 00:10:49.230
log axis, as the math
would tell us, we

00:10:49.230 --> 00:10:51.570
get a straight line.

00:10:51.570 --> 00:10:54.880
And that, in fact, is a very
simple and nice way to see

00:10:54.880 --> 00:10:57.790
whether you have an exponential
distribution.

00:10:57.790 --> 00:11:00.080
Put it on a log axis, see
if it's straight.

00:11:04.640 --> 00:11:08.530
It's a good trick, and
one we use a lot.

00:11:08.530 --> 00:11:09.780
OK.

00:11:11.650 --> 00:11:18.430
So there, I took the physical
model I described and derived,

00:11:18.430 --> 00:11:22.070
through a little bit of math,
what the result should be, and

00:11:22.070 --> 00:11:26.420
implemented some code
to give us a plot of

00:11:26.420 --> 00:11:28.230
what that told us.

00:11:28.230 --> 00:11:30.590
Let's look at a different
way of doing it.

00:11:39.730 --> 00:11:44.120
I could've instead written a
Monte Carlo simulation to do

00:11:44.120 --> 00:11:46.950
the same kind of thing.

00:11:46.950 --> 00:11:51.460
So here, instead of working out
the probabilities, I just

00:11:51.460 --> 00:11:56.540
tried to write some code that
exactly mimicked the physical

00:11:56.540 --> 00:12:00.370
process that I was
talking about.

00:12:00.370 --> 00:12:03.320
So instead of knowing that I
could just look at 1 minus p

00:12:03.320 --> 00:12:09.125
to the t, at each step, I
cleared some molecules.

00:12:15.830 --> 00:12:18.310
I just used random.random.

00:12:18.310 --> 00:12:20.290
If I came out with something
less than the clear

00:12:20.290 --> 00:12:23.930
probability, I got rid
of that molecule.

00:12:23.930 --> 00:12:26.730
And I did that for each
molecule, deciding whether or

00:12:26.730 --> 00:12:29.900
not it should be cleared.

00:12:29.900 --> 00:12:33.990
For molecule m in range, looking
at all the remaining

00:12:33.990 --> 00:12:38.610
molecules, I either clear
one or I don't.

00:12:38.610 --> 00:12:42.280
And then I can plot that.

00:12:42.280 --> 00:12:50.610
So let's look what happens if
I compare the two results.

00:12:50.610 --> 00:12:54.470
So I'm going to do the original
analytical model of

00:12:54.470 --> 00:12:59.780
clear, and then the simulation
model of clearing, and see

00:12:59.780 --> 00:13:01.030
what I get.

00:13:09.690 --> 00:13:14.170
Well, much to my relief, I get
kind of the same curve.

00:13:14.170 --> 00:13:16.310
Not exactly.

00:13:16.310 --> 00:13:19.210
You'll notice that the blue
curve, the analytical model,

00:13:19.210 --> 00:13:24.470
is a beautiful smooth curve,
whereas the red curve has got

00:13:24.470 --> 00:13:26.430
a little bit of jaggies.

00:13:26.430 --> 00:13:28.920
It's clearly very similar
to the blue

00:13:28.920 --> 00:13:30.170
curve, but not identical.

00:13:33.168 --> 00:13:34.680
It doesn't surprise me.

00:13:34.680 --> 00:13:36.245
There is some randomness
in there.

00:13:39.510 --> 00:13:41.850
And in fact, I could have gotten
unlucky and gotten

00:13:41.850 --> 00:13:44.390
something that didn't look
like the blue curve.

00:13:44.390 --> 00:13:48.640
But given the sample size, that
would have been quite

00:13:48.640 --> 00:13:49.890
surprising.

00:13:57.830 --> 00:14:02.450
Which of these two models
do you like better?

00:14:02.450 --> 00:14:03.630
So we've got two models.

00:14:03.630 --> 00:14:15.330
We've got one I'll call the
analytic model, and one I'll

00:14:15.330 --> 00:14:16.870
call the simulation model.

00:14:25.170 --> 00:14:28.005
Both show exponential decay.

00:14:38.000 --> 00:14:41.300
That is to say the number
of molecules declines

00:14:41.300 --> 00:14:44.820
exponentially, quite quickly.

00:14:44.820 --> 00:14:48.230
But they're not quite
identical.

00:14:48.230 --> 00:14:50.955
So which would we prefer?

00:14:50.955 --> 00:14:53.170
Or which would you prefer?

00:14:53.170 --> 00:14:57.050
There is no right
answer for this.

00:14:57.050 --> 00:14:59.100
Just for fun, I'll
ask for a poll.

00:14:59.100 --> 00:15:02.270
Who prefers the analytical
model?

00:15:02.270 --> 00:15:05.780
Who prefer the simulation?

00:15:05.780 --> 00:15:07.050
All right.

00:15:07.050 --> 00:15:09.240
Somebody who prefers the
analytical, tell me why.

00:15:12.000 --> 00:15:13.770
AUDIENCE: It looks
a lot nicer.

00:15:13.770 --> 00:15:15.265
PROFESSOR: Well, all right.

00:15:15.265 --> 00:15:16.800
It looks a lot nicer.

00:15:19.530 --> 00:15:23.240
That's kind of human
nature, to prefer

00:15:23.240 --> 00:15:25.170
something that looks prettier.

00:15:25.170 --> 00:15:29.290
On the other hand, what we're
really interested in is the

00:15:29.290 --> 00:15:37.520
question of not aesthetics,
but fidelity to the actual

00:15:37.520 --> 00:15:38.770
physical situation.

00:15:41.510 --> 00:15:43.630
A straight line might
look even nicer, but

00:15:43.630 --> 00:15:44.880
it wouldn't be accurate.

00:15:47.440 --> 00:15:50.840
So when we think about
evaluating a model, what we

00:15:50.840 --> 00:15:56.440
really should be asking, I
think, are two questions.

00:15:56.440 --> 00:15:57.690
One is fidelity.

00:16:03.190 --> 00:16:07.792
And another way to think about
that is credibility.

00:16:11.640 --> 00:16:15.460
Typically, we're creating a
model because we don't know

00:16:15.460 --> 00:16:17.460
the actual answer.

00:16:17.460 --> 00:16:19.890
And we're trying to see what
might actually happen if we,

00:16:19.890 --> 00:16:22.940
say, ran a physical
experiment.

00:16:22.940 --> 00:16:26.540
And so we have to ask the
question of, do we believe the

00:16:26.540 --> 00:16:28.310
results the model
are giving us.

00:16:30.830 --> 00:16:34.990
And so that sort of boils down
to not a question of

00:16:34.990 --> 00:16:38.500
mathematics, but a question
of reasoning.

00:16:38.500 --> 00:16:40.610
Can we look at the model
and convince

00:16:40.610 --> 00:16:42.045
ourselves that it is accurate?

00:16:45.850 --> 00:16:47.890
And the other question
is utility.

00:16:54.850 --> 00:17:05.210
And I can think about that as,
in some sense, what questions

00:17:05.210 --> 00:17:06.699
are answerable with the model?

00:17:13.329 --> 00:17:17.619
So the first one is pretty much
a question of personal

00:17:17.619 --> 00:17:19.970
preference.

00:17:19.970 --> 00:17:23.660
And for this particular
simulation, which is pretty

00:17:23.660 --> 00:17:28.200
simple, or this particular
model, it's hard to argue that

00:17:28.200 --> 00:17:32.300
one is more believable
than the other.

00:17:32.300 --> 00:17:35.770
I might argue the second is more
believable, because it's

00:17:35.770 --> 00:17:38.950
a direct implementation of
the physical system.

00:17:38.950 --> 00:17:42.360
I didn't rely on my
math being right.

00:17:42.360 --> 00:17:46.550
But the math is pretty
simple here.

00:17:46.550 --> 00:17:51.150
What's, I think, more apparent
is in this case there is some

00:17:51.150 --> 00:17:56.450
additional utility offered
by the simulation model.

00:17:56.450 --> 00:18:01.270
And it's often true of that,
simulation models, that we can

00:18:01.270 --> 00:18:07.550
ask what-if questions, because
we can easily change the model

00:18:07.550 --> 00:18:11.770
to be slightly different in ways
that is usually harder

00:18:11.770 --> 00:18:13.020
for an analytic model.

00:18:15.590 --> 00:18:21.820
For example, suppose these
drug molecules had this

00:18:21.820 --> 00:18:26.170
peculiar property that every
100 time steps, they could

00:18:26.170 --> 00:18:27.930
clone themselves.

00:18:27.930 --> 00:18:30.705
And so every molecule that was
there became two molecules.

00:18:33.640 --> 00:18:35.100
Unlikely for the drug.

00:18:35.100 --> 00:18:38.490
Not so unlikely for, say, a
bacterium or a virus, as

00:18:38.490 --> 00:18:40.540
you've seen.

00:18:40.540 --> 00:18:43.380
Well, a little hard to figure
out how to do the

00:18:43.380 --> 00:18:48.200
probabilities in the case that
that happens, because we'll no

00:18:48.200 --> 00:18:52.580
longer get this beautiful,
simple exponential decay.

00:18:52.580 --> 00:18:56.040
But quite easy to think about
how we would change the

00:18:56.040 --> 00:18:59.680
simulation model, which is
what I have done here.

00:19:04.600 --> 00:19:13.040
So I said here, if time is not
equal to 0 and time is evenly

00:19:13.040 --> 00:19:18.580
divisible by 100, then I'm
just going to double the

00:19:18.580 --> 00:19:19.830
number of molecules.

00:19:22.510 --> 00:19:25.460
Every living molecule
will clone itself.

00:19:25.460 --> 00:19:26.870
And now we'll see what we get.

00:19:34.600 --> 00:19:37.780
Well, we get this rather
peculiar-looking sawtooth

00:19:37.780 --> 00:19:40.250
distribution.

00:19:40.250 --> 00:19:46.200
We still have, overall,
an exponential decay.

00:19:46.200 --> 00:19:48.910
But we see every once in
while it jumps up, and

00:19:48.910 --> 00:19:50.970
then it comes down.

00:19:50.970 --> 00:19:54.520
It's not so easy to write a
simple closed-form formula

00:19:54.520 --> 00:19:59.590
that describes this, but very
easy to produce a simulation

00:19:59.590 --> 00:20:02.660
model that gives you
some insight to

00:20:02.660 --> 00:20:05.580
what's happening here.

00:20:05.580 --> 00:20:07.920
And that's, I think, one of
the great attractions of

00:20:07.920 --> 00:20:11.880
simulation modeling, is we get
to do this sort of thing.

00:20:17.730 --> 00:20:23.710
Many, many physical systems
exhibit exponential decay or

00:20:23.710 --> 00:20:25.840
exponential growth.

00:20:25.840 --> 00:20:30.370
For example, people in Japan
now are very interested in

00:20:30.370 --> 00:20:33.770
half-life of various radioactive
particles.

00:20:33.770 --> 00:20:36.740
And when we talk about
half-life, we mean that there

00:20:36.740 --> 00:20:40.050
is exponential decay
in radioactivity.

00:20:40.050 --> 00:20:41.830
That's what half-life is.

00:20:41.830 --> 00:20:44.685
So people are looking at what
is the half-life of iodine,

00:20:44.685 --> 00:20:49.370
say, versus other radioactive
particles.

00:20:49.370 --> 00:20:53.170
We also see exponential
growth a lot.

00:20:53.170 --> 00:20:56.560
I used to have a swimming pool
which I had to maintain, and I

00:20:56.560 --> 00:21:00.110
realized if I let the algae
get out of control in the

00:21:00.110 --> 00:21:04.250
pool, it went from having very
little algae to having a lot

00:21:04.250 --> 00:21:08.220
of algae very quickly,
because the algae

00:21:08.220 --> 00:21:10.790
doubles every period.

00:21:10.790 --> 00:21:14.640
And so all of a sudden,
it takes off.

00:21:14.640 --> 00:21:17.170
So exponential growth is--

00:21:17.170 --> 00:21:19.970
exponential decay are
important things.

00:21:19.970 --> 00:21:23.250
We see them all the time.

00:21:23.250 --> 00:21:27.090
People use the word very
carelessly when they mean

00:21:27.090 --> 00:21:27.730
quick growth.

00:21:27.730 --> 00:21:29.210
They say exponential.

00:21:29.210 --> 00:21:33.530
But of course, it has a
very specific meaning.

00:21:33.530 --> 00:21:34.450
OK.

00:21:34.450 --> 00:21:38.650
We've now, for the moment at
least, finished our short

00:21:38.650 --> 00:21:42.760
venture into probability
and distributions.

00:21:42.760 --> 00:21:47.230
We'll come back to it a little
bit when we talk about how to

00:21:47.230 --> 00:21:49.120
lie with statistics.

00:21:49.120 --> 00:21:55.130
But before we do that, before
we leave probability for a

00:21:55.130 --> 00:21:58.950
while, just for fun, I want to
pose to you one of these

00:21:58.950 --> 00:22:03.540
probability problems that
hurts people's heads.

00:22:03.540 --> 00:22:06.360
It's a very popular one.

00:22:06.360 --> 00:22:07.560
How many people here
have heard of

00:22:07.560 --> 00:22:10.080
the Monty Hall problem?

00:22:10.080 --> 00:22:11.470
OK, a lot of you.

00:22:11.470 --> 00:22:14.670
So as we play the game, those
of you who know the answer,

00:22:14.670 --> 00:22:20.230
I'll ask your forbearance
not to blurt it out.

00:22:20.230 --> 00:22:23.870
So it's a wonderful problem.

00:22:23.870 --> 00:22:27.425
It's so exciting that people
have written books about it.

00:22:30.590 --> 00:22:32.400
So here's how it works.

00:22:32.400 --> 00:22:36.300
This is from a game show called,
I think, Let's Make a

00:22:36.300 --> 00:22:40.280
Deal, with the host, Monty
Hall, who did it forever.

00:22:40.280 --> 00:22:44.000
So the way it works is you
start with three doors.

00:22:44.000 --> 00:22:47.340
Behind one of the doors
is a great prize--

00:22:47.340 --> 00:22:49.640
for example, an automobile.

00:22:49.640 --> 00:22:52.140
Behind each of the other
doors is a booby

00:22:52.140 --> 00:22:55.840
prize, typically a goat.

00:22:55.840 --> 00:22:58.580
I don't know why people don't
like goats, but apparently

00:22:58.580 --> 00:23:00.250
they don't.

00:23:00.250 --> 00:23:03.900
So the way it works is Monty
invites someone from the

00:23:03.900 --> 00:23:08.850
audience, chosen on the basis of
their outlandish costumes.

00:23:08.850 --> 00:23:11.760
And they come down and they're
told what wonderful prize is

00:23:11.760 --> 00:23:14.300
behind one of the doors.

00:23:14.300 --> 00:23:18.390
And then they're asked
to choose a door.

00:23:18.390 --> 00:23:21.470
So the person might choose a
door and say, I'll choose door

00:23:21.470 --> 00:23:22.720
number one.

00:23:24.950 --> 00:23:28.760
Monty then opens one of
the other two doors.

00:23:28.760 --> 00:23:31.230
He knows which doors have
the goats and which

00:23:31.230 --> 00:23:32.580
door has the car.

00:23:32.580 --> 00:23:35.570
He opens a door with the goat.

00:23:35.570 --> 00:23:39.070
So now there are
two doors left.

00:23:39.070 --> 00:23:42.680
And he asks the contestant,
do you want to switch.

00:23:42.680 --> 00:23:44.780
Do you want to stick with door
one or would you like to

00:23:44.780 --> 00:23:47.400
switch to door two?

00:23:47.400 --> 00:23:53.810
And the Monty Hall problem
is, what should she do?

00:23:53.810 --> 00:23:56.440
And the audience will always
shout out advice.

00:23:56.440 --> 00:23:58.210
So I do have a simulation
of that.

00:23:58.210 --> 00:23:59.320
I'd like to run.

00:23:59.320 --> 00:24:03.320
I need three people to volunteer
to be doors.

00:24:03.320 --> 00:24:05.140
Come on, three doors.

00:24:05.140 --> 00:24:05.920
It's not so hard.

00:24:05.920 --> 00:24:07.470
Come on down.

00:24:07.470 --> 00:24:10.240
And I need one person to
volunteer to be the contest.

00:24:10.240 --> 00:24:14.680
Is anybody in a costume here?

00:24:14.680 --> 00:24:15.690
I don't know.

00:24:15.690 --> 00:24:18.330
Mitch is kind of in one, but--

00:24:18.330 --> 00:24:18.770
all right.

00:24:18.770 --> 00:24:20.530
These are the contestants.

00:24:20.530 --> 00:24:22.820
All right, you're
door number (2).

00:24:22.820 --> 00:24:24.060
You're door number (1).

00:24:24.060 --> 00:24:26.290
You are door number (3).

00:24:26.290 --> 00:24:29.040
A contestant please.

00:24:29.040 --> 00:24:30.260
There's $1 in one of these.

00:24:30.260 --> 00:24:32.040
You can actually win
something of value.

00:24:32.040 --> 00:24:34.365
All right, we have a contestant
coming down.

00:24:34.365 --> 00:24:37.920
Oh, all right, we have two
contestants coming down.

00:24:37.920 --> 00:24:39.180
All right.

00:24:39.180 --> 00:24:40.430
The aisle wins.

00:24:42.830 --> 00:24:44.140
All right, choose a door.

00:24:52.050 --> 00:24:53.600
You choose door number (2).

00:24:53.600 --> 00:24:56.450
All right, let us open
door number (1).

00:24:56.450 --> 00:25:00.780
And let's see what's
in door number (1).

00:25:00.780 --> 00:25:02.870
Show it to the class.

00:25:02.870 --> 00:25:05.330
It is a goat.

00:25:05.330 --> 00:25:06.690
Now you have a choice.

00:25:06.690 --> 00:25:10.150
You can stick with your original
decision, or you can

00:25:10.150 --> 00:25:13.380
switch to door number (3).

00:25:13.380 --> 00:25:15.152
Suggestions?

00:25:15.152 --> 00:25:16.096
AUDIENCE: Switch.

00:25:16.096 --> 00:25:16.570
AUDIENCE: Switch.

00:25:16.570 --> 00:25:16.910
AUDIENCE: Switch.

00:25:16.910 --> 00:25:17.250
AUDIENCE: Switch.

00:25:17.250 --> 00:25:17.590
AUDIENCE: Lower one.

00:25:17.590 --> 00:25:18.270
AUDIENCE: Don't switch it.

00:25:18.270 --> 00:25:20.605
AUDIENCE: Switch.

00:25:20.605 --> 00:25:22.006
PROFESSOR: All right.

00:25:22.006 --> 00:25:25.330
She is going to stick with
door number (2).

00:25:25.330 --> 00:25:27.225
Let us open door number (2).

00:25:35.040 --> 00:25:36.130
She wins $1.

00:25:36.130 --> 00:25:38.320
It is yours.

00:25:38.320 --> 00:25:40.800
Don't spend it all at once.

00:25:40.800 --> 00:25:42.440
Thank you, everybody.

00:25:42.440 --> 00:25:46.490
All right, now, was she
lucky or was she

00:25:46.490 --> 00:25:49.270
smart, is the question?

00:25:49.270 --> 00:25:50.520
Does it matter?

00:25:53.020 --> 00:25:55.760
This was a subject of enormous
debate in the

00:25:55.760 --> 00:25:57.960
mathematical community.

00:25:57.960 --> 00:26:03.550
In 1991, Parade magazine
published a correct solution

00:26:03.550 --> 00:26:08.040
to the problem, and
approximately 10,000 readers,

00:26:08.040 --> 00:26:13.050
including a 1,000 with PhDs in
mathematics, wrote to Parade

00:26:13.050 --> 00:26:16.730
telling them they had published
the wrong solution.

00:26:16.730 --> 00:26:19.640
And the debate roiled on.

00:26:19.640 --> 00:26:23.040
So who thinks she was lucky
and who thinks it actually

00:26:23.040 --> 00:26:25.500
matters whether you switch?

00:26:25.500 --> 00:26:28.610
Who thinks it matters, those
who don't know the problem?

00:26:28.610 --> 00:26:31.130
Who thinks it doesn't matter?

00:26:31.130 --> 00:26:32.240
All right.

00:26:32.240 --> 00:26:35.760
The doesn't-matters win
by a small margin.

00:26:35.760 --> 00:26:39.010
And in fact, that's what the
readers of Parade thought.

00:26:39.010 --> 00:26:40.810
But they were wrong.

00:26:40.810 --> 00:26:44.660
It matters a lot whether
you switch.

00:26:44.660 --> 00:26:48.000
Let's do the analysis first,
analytically, and then we'll

00:26:48.000 --> 00:26:50.220
do a simulation.

00:26:50.220 --> 00:26:52.180
So the player makes a choice.

00:26:52.180 --> 00:26:54.350
And this is some interesting
ways to think about

00:26:54.350 --> 00:26:56.030
probability.

00:26:56.030 --> 00:27:01.800
And with the probability of 1/3,
the player has chosen the

00:27:01.800 --> 00:27:03.050
correct door.

00:27:06.080 --> 00:27:08.200
All right?

00:27:08.200 --> 00:27:16.970
Now that means that with a
probability of 2 out of 3, the

00:27:16.970 --> 00:27:21.510
car lies behind one of
the other two doors.

00:27:21.510 --> 00:27:23.710
Now here's the key step.

00:27:23.710 --> 00:27:27.560
Monty opens a door that
he knows does

00:27:27.560 --> 00:27:30.880
not contain the prize.

00:27:30.880 --> 00:27:41.950
The key thing to notice here is
the choice of doors is not

00:27:41.950 --> 00:27:56.910
independent of the choice of the
player, because Monty will

00:27:56.910 --> 00:28:00.635
never choose the door that the
player has initially picked.

00:28:06.100 --> 00:28:13.790
Now since the probability of the
prize being behind the two

00:28:13.790 --> 00:28:22.320
remaining doors is 2 out of 3,
the probability of the prize

00:28:22.320 --> 00:28:27.590
being behind one of the doors
that he did not open

00:28:27.590 --> 00:28:28.840
is 2 out of 3 --

00:28:31.710 --> 00:28:34.400
in fact, behind the
other door.

00:28:34.400 --> 00:28:37.560
In fact, you were
extraordinarily lucky to win

00:28:37.560 --> 00:28:42.930
the dollar, because switching
doubles the odds of winning.

00:28:46.890 --> 00:28:51.510
Because remember, your odds of
winning were 1 out of 3 when

00:28:51.510 --> 00:28:53.360
you first chose the door.

00:28:53.360 --> 00:28:56.020
That left two doors.

00:28:56.020 --> 00:28:59.070
The probability of the car being
behind one of those two

00:28:59.070 --> 00:29:01.850
doors was 2/3.

00:29:01.850 --> 00:29:06.440
Monty opened the one that
didn't contain the car,

00:29:06.440 --> 00:29:08.870
because he knew it
contained a goat.

00:29:08.870 --> 00:29:12.050
So that must mean the
probability of the car being

00:29:12.050 --> 00:29:15.620
behind the remaining
door is 2 out of 3.

00:29:15.620 --> 00:29:19.710
So you double your
odds of winning.

00:29:19.710 --> 00:29:23.570
The logic is kind of clear.

00:29:23.570 --> 00:29:26.730
It didn't stop people from
aggressively debating it for

00:29:26.730 --> 00:29:29.040
the longest of times.

00:29:29.040 --> 00:29:32.540
And I kind of didn't
believe it myself.

00:29:32.540 --> 00:29:37.250
So I did what I usually do,
is I wrote some code.

00:29:37.250 --> 00:29:41.900
And let's look at two
pieces of code here.

00:29:41.900 --> 00:29:45.460
And again, the theme here is
how we can use simulation

00:29:45.460 --> 00:29:50.040
models to understand slightly
complex, or more than slightly

00:29:50.040 --> 00:29:54.390
complex, situations.

00:29:54.390 --> 00:29:58.860
So here's the way
the game works.

00:29:58.860 --> 00:30:03.980
So I've got a simple simulation
that counts the

00:30:03.980 --> 00:30:05.230
number of wins.

00:30:07.440 --> 00:30:15.570
And the way it's done is, for
t in range number of trials,

00:30:15.570 --> 00:30:18.740
the contestant picks 1,
2, or 3 at random.

00:30:18.740 --> 00:30:20.775
I've tried to mimic
exactly the game.

00:30:24.270 --> 00:30:27.000
So the car is behind
one of the doors.

00:30:27.000 --> 00:30:29.340
The contestant guesses a door.

00:30:29.340 --> 00:30:33.280
And then there's this
'choose' function to

00:30:33.280 --> 00:30:35.760
open one of the two.

00:30:35.760 --> 00:30:39.410
And we're going to have
2 ways of choosing

00:30:39.410 --> 00:30:42.970
which door gets opened.

00:30:42.970 --> 00:30:44.980
So the Monty Hall way--

00:30:44.980 --> 00:30:47.070
Monty chooses.

00:30:47.070 --> 00:30:51.690
He takes the guessed door and
the prize door, and he opens

00:30:51.690 --> 00:30:58.300
the non-guess that contains
the goat.

00:30:58.300 --> 00:31:02.180
So if (1) is the guessed door,
and (1) is not the guessed

00:31:02.180 --> 00:31:06.590
door and it's not the prize
door, then he opens (1).

00:31:06.590 --> 00:31:07.670
Same thing for (2).

00:31:07.670 --> 00:31:12.430
And if (1) or (2) is not the
choice, he opens (3).

00:31:12.430 --> 00:31:18.140
As opposed to the random choose
function, which just

00:31:18.140 --> 00:31:23.430
chooses at random between the
doors that weren't guessed.

00:31:23.430 --> 00:31:27.220
So it might open the car, at
which point the contest is

00:31:27.220 --> 00:31:28.850
told, sorry, you lose,
you don't even

00:31:28.850 --> 00:31:30.100
have a choice anymore.

00:31:33.840 --> 00:31:40.890
We're then going to run the
simulation with Monty choosing

00:31:40.890 --> 00:31:45.530
and random choice, and
see what we get.

00:31:45.530 --> 00:31:48.070
So you've got the code on
the handout to do this.

00:31:48.070 --> 00:31:50.280
I'm not going to go
over the details.

00:31:50.280 --> 00:31:54.360
The thing to notice about it is
it's yet another example of

00:31:54.360 --> 00:31:58.790
how we can use PyLab to do
some interesting plots.

00:31:58.790 --> 00:32:01.750
This time I'm going to print a
pie chart, just to show that

00:32:01.750 --> 00:32:03.000
we can do those.

00:32:06.170 --> 00:32:08.600
And let's see what happens.

00:32:08.600 --> 00:32:10.390
So people understand
what's going on?

00:32:10.390 --> 00:32:14.330
That I've got these two
functions, montyChoose and

00:32:14.330 --> 00:32:15.790
randomChoose.

00:32:15.790 --> 00:32:19.160
I'm using those functions as
parameters, a very convenient

00:32:19.160 --> 00:32:22.180
thing, and running the
simulation each way.

00:32:25.220 --> 00:32:26.525
And let's see what happens.

00:32:31.070 --> 00:32:33.120
All right.

00:32:33.120 --> 00:32:39.210
So what we see here is, when I
run montyChoose, sure enough,

00:32:39.210 --> 00:32:43.380
it comes out to about 2/3 of
the time, you win if you

00:32:43.380 --> 00:32:47.290
change, and only 1/3 of the
time if you don't, pretty

00:32:47.290 --> 00:32:50.100
close to what the
math predicts.

00:32:50.100 --> 00:32:53.660
In fact, sort of astonishingly
close.

00:32:53.660 --> 00:32:58.170
On the other hand, if Monte
had been just choosing at

00:32:58.170 --> 00:33:02.110
random, then we see it really
doesn't matter whether you

00:33:02.110 --> 00:33:03.360
switch or not.

00:33:05.800 --> 00:33:10.220
So again, from a probability
point of view, we see how

00:33:10.220 --> 00:33:14.150
subtle these things can be based
upon whether decisions

00:33:14.150 --> 00:33:18.930
are independent of previous
decisions, or not independent.

00:33:18.930 --> 00:33:23.430
And we also see, in some sense,
that we can write a

00:33:23.430 --> 00:33:28.200
very small piece of code that
actually provides a simulation

00:33:28.200 --> 00:33:32.480
of a real, in this case, game,
and we can have, I think, a

00:33:32.480 --> 00:33:33.490
lot of confidence.

00:33:33.490 --> 00:33:36.760
We can look at the code and say,
is it really the way the

00:33:36.760 --> 00:33:38.270
game is described?

00:33:38.270 --> 00:33:39.250
Yes.

00:33:39.250 --> 00:33:42.800
And then we get nice results
that tell us what to do.

00:33:42.800 --> 00:33:46.400
And in this case it tells us
that, if Monty is choosing

00:33:46.400 --> 00:33:50.420
based upon what he knows,
then by all

00:33:50.420 --> 00:33:52.480
means, you should switch.

00:33:52.480 --> 00:33:57.260
And I'm sorry that it didn't
work out that way when we

00:33:57.260 --> 00:34:00.560
played the game, but that's
the way probabilities are,

00:34:00.560 --> 00:34:04.080
that you didn't switch
and you lucked out.

00:34:04.080 --> 00:34:05.970
So now you're a rich lady.

00:34:05.970 --> 00:34:08.260
All right.

00:34:08.260 --> 00:34:12.989
So that's one thing we can do.

00:34:12.989 --> 00:34:15.650
One more thing I want to talk
about, before we leave the

00:34:15.650 --> 00:34:17.336
subject of Monte Carlo
simulations--

00:34:20.130 --> 00:34:25.020
it's pretty clear that these
kind of simulations are very

00:34:25.020 --> 00:34:31.000
useful for tackling problems
in which predictive

00:34:31.000 --> 00:34:32.829
non-determinism plays a role.

00:34:35.639 --> 00:34:38.929
And at first blush, you might
think that, OK, that's the

00:34:38.929 --> 00:34:42.630
only time we should use a Monte
Carlo simulation, when

00:34:42.630 --> 00:34:45.969
there's some inherent randomness
in the problem, and

00:34:45.969 --> 00:34:50.880
therefore it's hard to model
analytically, and therefore

00:34:50.880 --> 00:34:54.610
we'll use randomness
in the code.

00:34:54.610 --> 00:34:58.630
Interestingly enough,
particularly in recent years,

00:34:58.630 --> 00:35:04.100
but for quite a while, people
have understood the notion of

00:35:04.100 --> 00:35:08.910
using randomized algorithms
to solve problems in which

00:35:08.910 --> 00:35:11.085
randomness plays no role.

00:35:13.980 --> 00:35:17.610
And that's a little surprising,
but an incredibly

00:35:17.610 --> 00:35:22.160
useful concept to put in your
bag of tricks, the ability to

00:35:22.160 --> 00:35:27.120
use randomization to solve
problems that are not random.

00:35:27.120 --> 00:35:29.930
So let me talk about
an example.

00:35:29.930 --> 00:35:32.410
Consider the concept of pi.

00:35:37.080 --> 00:35:40.230
Pi has been around
for a long time.

00:35:40.230 --> 00:35:42.250
For thousands of years,
people have known

00:35:42.250 --> 00:35:44.720
that there's a constant--

00:35:44.720 --> 00:35:48.800
called pi since about
the 18th century--

00:35:48.800 --> 00:35:52.710
associated with circles, such
that the circumference of a

00:35:52.710 --> 00:35:55.020
circle is always going
to be equal to

00:35:55.020 --> 00:35:57.300
pi times the diameter.

00:35:57.300 --> 00:35:59.690
The area of a circle is
always going to be pi

00:35:59.690 --> 00:36:01.630
r-squared, et cetera.

00:36:01.630 --> 00:36:05.540
So for thousands of years,
people knew that there was

00:36:05.540 --> 00:36:07.990
such a constant.

00:36:07.990 --> 00:36:10.560
They just didn't know
what it was.

00:36:10.560 --> 00:36:14.130
And there's a long and beautiful
history of people

00:36:14.130 --> 00:36:18.330
attempting to estimate pi.

00:36:18.330 --> 00:36:21.860
About the earliest estimate
I've found is from the

00:36:21.860 --> 00:36:28.630
Egyptians, in something called
the Rhind Papyrus, from 1650

00:36:28.630 --> 00:36:31.150
BC, or thereabouts.

00:36:31.150 --> 00:36:36.120
And it estimated pi
to be 4 times--

00:36:36.120 --> 00:36:38.030
let me get this right--

00:36:38.030 --> 00:36:49.530
8/9 squared, which is
3.16, more or less.

00:36:49.530 --> 00:36:52.660
That was pretty good.

00:36:52.660 --> 00:36:57.970
About a 1,000 years later,
an estimate of pi

00:36:57.970 --> 00:36:59.220
appears in the Bible.

00:37:03.350 --> 00:37:05.640
Or at least, it's implied by the
Bible in a description of

00:37:05.640 --> 00:37:08.650
one of Solomon's construction
projects.

00:37:08.650 --> 00:37:12.730
It says, "And he made a molten
sea, 10 cubits from the one

00:37:12.730 --> 00:37:14.020
brim to the other.

00:37:14.020 --> 00:37:19.040
It was round all about, and his
height was five cubits.

00:37:19.040 --> 00:37:25.150
And a line of 30 cubits did
compass it round about."

00:37:25.150 --> 00:37:30.700
So you can take that and solve
for pi, because you've given

00:37:30.700 --> 00:37:34.770
the circumference, and other
details, the diameter.

00:37:34.770 --> 00:37:36.550
You can solve for pi.

00:37:36.550 --> 00:37:40.055
And you see, if you do that, pi
comes out to be exactly 3.

00:37:43.310 --> 00:37:45.910
Not quite as accurate
as the Egyptians

00:37:45.910 --> 00:37:48.470
had 1,000 years earlier.

00:37:48.470 --> 00:37:50.940
Now perhaps the Bible
is wrong.

00:37:50.940 --> 00:37:54.000
I don't want to offend
anybody.

00:37:54.000 --> 00:37:57.830
Or perhaps the molten sea wasn't
perfectly circular.

00:37:57.830 --> 00:38:01.100
Or maybe the circumference was
measured from the wall outside

00:38:01.100 --> 00:38:03.160
and the diameter from
the inside.

00:38:03.160 --> 00:38:08.050
Or maybe it was just that was a
good enough number to use in

00:38:08.050 --> 00:38:10.730
construction, because a cubit
was something like the length

00:38:10.730 --> 00:38:12.010
of your forearm.

00:38:12.010 --> 00:38:14.690
Different people have different
length forearms, and

00:38:14.690 --> 00:38:17.010
there was no reason to try
and be more precise.

00:38:17.010 --> 00:38:18.260
Who knows?

00:38:20.310 --> 00:38:23.300
The best estimate of pi in
ancient times was from

00:38:23.300 --> 00:38:25.816
Archimedes of Syracuse.

00:38:28.320 --> 00:38:35.560
And he did something quite
amazing for around 200 BC.

00:38:35.560 --> 00:38:37.120
He didn't give the
value of pi.

00:38:37.120 --> 00:38:39.460
He said, I don't know what the
value is, but I can give you

00:38:39.460 --> 00:38:42.000
an upper bound and
a lower bound.

00:38:42.000 --> 00:38:46.310
And he did this by carefully
constructing a polygon with a

00:38:46.310 --> 00:38:49.880
huge number of tiny little
straight lines that would

00:38:49.880 --> 00:38:54.370
approximate a circle, and then
actually measuring things.

00:38:54.370 --> 00:38:59.310
So he built a polygon with 96
sides, and concluded that pi

00:38:59.310 --> 00:39:12.670
was somewhere between 223
divided by 71, and 22/7.

00:39:17.690 --> 00:39:20.240
Very sophisticated at the time,
to be giving upper and

00:39:20.240 --> 00:39:23.180
lower bounds.

00:39:23.180 --> 00:39:26.150
If we look at what the middle
of that is, it's actually

00:39:26.150 --> 00:39:27.170
amazingly good.

00:39:27.170 --> 00:39:32.780
It's 3.1418.

00:39:32.780 --> 00:39:34.880
Not bad.

00:39:34.880 --> 00:39:36.170
All right.

00:39:36.170 --> 00:39:38.113
What does this have to do with
Monte Carlo simulations?

00:39:42.730 --> 00:39:46.160
Many years later--

00:39:46.160 --> 00:39:53.070
in fact, in the 1700s, two
French mathematicians invented

00:39:53.070 --> 00:39:55.430
another way of computing pi.

00:39:55.430 --> 00:39:58.090
Buffon and Laplace.

00:39:58.090 --> 00:39:59.870
Actually Buffon first
proposed it.

00:39:59.870 --> 00:40:01.300
He got it wrong.

00:40:01.300 --> 00:40:03.420
Laplace corrected it.

00:40:03.420 --> 00:40:09.680
And they said, we can find pi
using a stochastic simulation.

00:40:09.680 --> 00:40:11.440
They didn't use those words,
but that's what

00:40:11.440 --> 00:40:13.720
they basically described.

00:40:13.720 --> 00:40:16.330
And they talked about it in
terms of needle-dropping.

00:40:18.900 --> 00:40:28.970
So think about having a square,
and inscribing in the

00:40:28.970 --> 00:40:30.830
square a circle.

00:40:30.830 --> 00:40:35.520
And you'll excuse my lack
of artistic ability.

00:40:35.520 --> 00:40:39.800
So they put one of those
on the floor.

00:40:39.800 --> 00:40:42.770
And then they dropped needles,
which would get carried around

00:40:42.770 --> 00:40:46.910
by the wind and land in
some random place.

00:40:46.910 --> 00:40:51.530
And they counted the number of
needles that landed in the

00:40:51.530 --> 00:40:57.650
circle, and the number of
needles that landed in the

00:40:57.650 --> 00:41:00.060
square but not in the circle.

00:41:03.270 --> 00:41:05.820
And then they did
a little math.

00:41:05.820 --> 00:41:09.730
Let's assume for the sake of
argument here that the radius

00:41:09.730 --> 00:41:11.970
of the circle is 1.

00:41:18.100 --> 00:41:25.730
They observed the following
equation must hold, that the

00:41:25.730 --> 00:41:36.220
needles in the circle over the
needles in the square should

00:41:36.220 --> 00:41:43.750
be equal to the area of the
circle divided by the area of

00:41:43.750 --> 00:41:45.000
the square.

00:41:46.830 --> 00:41:50.650
It seems logical, if they're
landing at random, that they

00:41:50.650 --> 00:41:58.610
would get distributed
proportional to the area.

00:41:58.610 --> 00:42:04.750
And then they solved for pi,
knowing that the area of the

00:42:04.750 --> 00:42:06.473
circle is pi r-squared.

00:42:09.080 --> 00:42:10.890
They could then say that pi--

00:42:14.580 --> 00:42:18.440
in fact, in this case, since we
know the radius is 1, and 1

00:42:18.440 --> 00:42:23.350
squared is 1, that tells us that
the area of the circle

00:42:23.350 --> 00:42:26.410
should be pi, right?

00:42:26.410 --> 00:42:28.420
Pi times 1.

00:42:28.420 --> 00:42:34.810
So they said pi is equal to the
area of the circle, which

00:42:34.810 --> 00:42:46.670
is equal to the area of the
square times the needles in

00:42:46.670 --> 00:42:52.015
the circle, divided by the
needles in the square.

00:43:02.300 --> 00:43:04.320
So they had that formula.

00:43:04.320 --> 00:43:07.970
Unfortunately they couldn't drop
enough needles to get a

00:43:07.970 --> 00:43:09.690
very good estimate.

00:43:09.690 --> 00:43:11.800
So they described
how to do it.

00:43:11.800 --> 00:43:13.860
But this was an experiment.

00:43:13.860 --> 00:43:16.880
They did the math, they
had a nice formula.

00:43:16.880 --> 00:43:19.170
They did not have an
experimental apparatus that

00:43:19.170 --> 00:43:21.870
would actually let them drop
enough needles to get a very

00:43:21.870 --> 00:43:23.390
good estimate.

00:43:23.390 --> 00:43:25.270
It would take a lot
of patience.

00:43:25.270 --> 00:43:27.620
And maybe they wouldn't
land at random.

00:43:27.620 --> 00:43:28.980
Who knows what.

00:43:28.980 --> 00:43:33.290
Fortunately, today, we have a
much easier way to do that.

00:43:40.420 --> 00:43:43.486
So we can write some code that
does the simulation.

00:43:49.220 --> 00:43:50.860
We're going to have
a way to throw the

00:43:50.860 --> 00:43:53.640
needles or drop the needles.

00:43:53.640 --> 00:43:57.080
And then what we're going to
do is we're going to have a

00:43:57.080 --> 00:44:00.100
simulation that we're going
to run, that's going to--

00:44:00.100 --> 00:44:02.220
I don't know how many
needles to drop.

00:44:02.220 --> 00:44:06.360
I'm going to keep dropping
needles until I get a small

00:44:06.360 --> 00:44:12.890
enough standard deviation that I
can be confident that I have

00:44:12.890 --> 00:44:16.200
a bound on pi with some
confidence interval.

00:44:16.200 --> 00:44:20.700
In fact, I'm going to use 5%
here, and use that rule of

00:44:20.700 --> 00:44:23.320
thumb that Mitch talked about
last time, about standard

00:44:23.320 --> 00:44:24.770
deviations.

00:44:24.770 --> 00:44:27.010
And I say, all right, I'm going
to keep running the

00:44:27.010 --> 00:44:30.090
experiment until the standard
deviation of

00:44:30.090 --> 00:44:33.260
trials is 5% or less.

00:44:36.330 --> 00:44:39.820
Two standard deviations is small
enough that I get my

00:44:39.820 --> 00:44:42.320
answer within some precision.

00:44:42.320 --> 00:44:47.450
I'm going to ask here for
a precision of 0.01.

00:44:47.450 --> 00:44:51.100
And so therefore my standard
deviation should be that

00:44:51.100 --> 00:44:55.070
precision divided by 4, because
I'm looking for 2

00:44:55.070 --> 00:44:58.800
standard deviations on either
side of the mean, which is why

00:44:58.800 --> 00:45:01.880
I'm dividing by 4
and not by 2.

00:45:01.880 --> 00:45:04.800
So I divide by 4 and
I see what I get.

00:45:08.090 --> 00:45:09.530
So let's run it.

00:45:09.530 --> 00:45:13.460
And this will take a
little bit of time.

00:45:13.460 --> 00:45:18.950
It will take no time if I don't
uncomment the code to

00:45:18.950 --> 00:45:20.200
actually run the experiment.

00:45:23.910 --> 00:45:25.160
Estimate pi.

00:45:29.430 --> 00:45:30.680
And we'll get some estimates.

00:45:36.970 --> 00:45:41.510
So what we can see here is that
my estimates change as I

00:45:41.510 --> 00:45:43.990
run experiments.

00:45:43.990 --> 00:45:46.860
Every time I run this-- or not
every time, I often get a

00:45:46.860 --> 00:45:49.130
different number of
needles I need.

00:45:49.130 --> 00:45:54.440
But you can see that my first
estimate is not very good.

00:45:54.440 --> 00:45:58.290
My estimates do get
better, though not

00:45:58.290 --> 00:46:00.190
monotonically better.

00:46:00.190 --> 00:46:03.290
But what does get monotonically
better is the

00:46:03.290 --> 00:46:08.250
standard deviation gets smaller
and smaller, which is

00:46:08.250 --> 00:46:10.400
what you would expect.

00:46:10.400 --> 00:46:15.210
So there's no guarantee that by
running a bigger trial, I

00:46:15.210 --> 00:46:17.390
get a more accurate result.

00:46:17.390 --> 00:46:19.990
What there is a guarantee
is that I can have more

00:46:19.990 --> 00:46:22.410
confidence in my result.

00:46:22.410 --> 00:46:25.560
I could have gotten lucky and
run a small number of needles

00:46:25.560 --> 00:46:28.610
and gotten it exactly
right by chance.

00:46:28.610 --> 00:46:33.190
But I would have been wrong to
assume it was right, because

00:46:33.190 --> 00:46:34.830
let's pretend we didn't
know what the value

00:46:34.830 --> 00:46:37.800
of pi was, a priori.

00:46:37.800 --> 00:46:41.410
But what I can say here is since
my standard deviation is

00:46:41.410 --> 00:46:47.330
now 0.002, and if we look at
it, we'll see that these

00:46:47.330 --> 00:46:50.840
things are normally distributed,
I can be pretty

00:46:50.840 --> 00:46:59.950
sure that the true value of pi
is 3.1407 et cetera, plus or

00:46:59.950 --> 00:47:08.110
minus 0.00023, et cetera,
with a 95% confidence.

00:47:08.110 --> 00:47:10.570
So this is using the stuff
that you saw in the last

00:47:10.570 --> 00:47:15.170
lecture to now combine that
statistical background with

00:47:15.170 --> 00:47:17.960
this simulation to compute
a pretty darn

00:47:17.960 --> 00:47:19.840
good estimate of pi.

00:47:19.840 --> 00:47:23.140
And if I ran more needles, if I
wanted to get more precise,

00:47:23.140 --> 00:47:27.230
I can get as precise as I want
to be, as many digits of

00:47:27.230 --> 00:47:30.210
precision as I want.

00:47:30.210 --> 00:47:34.050
So again, what we see here is
that we've been able to solve

00:47:34.050 --> 00:47:37.500
a problem that had nothing
to do with randomness.

00:47:37.500 --> 00:47:40.320
The value of pi is not
a random number.

00:47:40.320 --> 00:47:43.502
And yet we used randomness
to solve it.

00:47:43.502 --> 00:47:45.730
A very common technique.

00:47:45.730 --> 00:47:51.050
And we use some very simple
statistics to know whether or

00:47:51.050 --> 00:47:53.980
not we should believe
our solution.

00:47:53.980 --> 00:47:55.740
And so those are the
two lessons I

00:47:55.740 --> 00:47:58.120
want you to take home.

00:47:58.120 --> 00:48:02.360
Now if you look at your handout,
you'll see that at

00:48:02.360 --> 00:48:07.700
the bottom, I've used the same
technique to do integration.

00:48:10.490 --> 00:48:13.650
If you think about what
integration means, when you

00:48:13.650 --> 00:48:17.510
ask, what is the integral of
some formula, what you learned

00:48:17.510 --> 00:48:20.520
when you first looked at
calculus was that that was the

00:48:20.520 --> 00:48:23.490
area under some curve, right?

00:48:23.490 --> 00:48:26.040
That's what the integral is.

00:48:26.040 --> 00:48:29.130
And you learned all sorts of
complicated mathematics to

00:48:29.130 --> 00:48:31.750
solve complicated integrals.

00:48:31.750 --> 00:48:35.700
Well, you can pose an
integration problem exactly

00:48:35.700 --> 00:48:38.480
analogous to this.

00:48:38.480 --> 00:48:40.000
You draw your curve.

00:48:40.000 --> 00:48:41.280
You drops some needles.

00:48:41.280 --> 00:48:44.030
You count how many fall under
the curve, how many don't fall

00:48:44.030 --> 00:48:47.790
under the curve in
some larger area.

00:48:47.790 --> 00:48:50.860
And you can solve
the integration.

00:48:50.860 --> 00:48:54.160
And that's exactly what I've
done here, where f is the

00:48:54.160 --> 00:48:56.280
function being integrated.

00:48:56.280 --> 00:48:58.550
I won't go through
the details.

00:48:58.550 --> 00:49:04.160
Now in fact, this kind of
simulation is not a good way

00:49:04.160 --> 00:49:06.230
to solve single integrals.

00:49:06.230 --> 00:49:10.100
It's much better to use
something like Simpson's rule,

00:49:10.100 --> 00:49:12.750
whatever that is.

00:49:12.750 --> 00:49:16.310
But in fact, it is frequently
used in practice for more

00:49:16.310 --> 00:49:19.870
complicated things, a double or
triple integration, where

00:49:19.870 --> 00:49:22.580
the mathematics gets
fairly complicated.

00:49:22.580 --> 00:49:25.950
People will often solve those
problems using a Monte Carlo

00:49:25.950 --> 00:49:27.390
simulation.

00:49:27.390 --> 00:49:30.110
It's a practical method
for tackling it.

00:49:30.110 --> 00:49:33.980
And again, in your handout,
you'll see a very simple piece

00:49:33.980 --> 00:49:37.000
of code that does a
double integral.

00:49:37.000 --> 00:49:37.820
All right.

00:49:37.820 --> 00:49:39.070
That's all for today.

