WEBVTT
Kind: captions
Language: en

00:00:01.680 --> 00:00:04.080
The following content is
provided under a Creative

00:00:04.080 --> 00:00:05.620
Commons license.

00:00:05.620 --> 00:00:07.920
Your support will help
MIT OpenCourseWare

00:00:07.920 --> 00:00:12.310
continue to offer high-quality
educational resources for free.

00:00:12.310 --> 00:00:14.910
To make a donation or
view additional materials

00:00:14.910 --> 00:00:18.870
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:18.870 --> 00:00:21.350
at ocw.mit.edu.

00:00:21.350 --> 00:00:23.100
ALIA MARTIN: I'm going
to be talking today

00:00:23.100 --> 00:00:25.215
about how infants and
kids start to develop

00:00:25.215 --> 00:00:26.610
an understanding
of communication

00:00:26.610 --> 00:00:28.776
and why this is an important
topic for understanding

00:00:28.776 --> 00:00:31.210
human intelligence.

00:00:31.210 --> 00:00:32.980
So what is communication?

00:00:32.980 --> 00:00:35.790
So really, basically,
communication

00:00:35.790 --> 00:00:38.354
is a transfer or
exchange of information.

00:00:38.354 --> 00:00:40.020
And importantly, in
human communication,

00:00:40.020 --> 00:00:41.754
this isn't just any
kind of information,

00:00:41.754 --> 00:00:43.920
but it's specifically the
kind of information that's

00:00:43.920 --> 00:00:46.114
in our heads and in our minds.

00:00:46.114 --> 00:00:48.030
So for example, there's
information in my head

00:00:48.030 --> 00:00:50.113
right now that I'm going
to be transferring to you

00:00:50.113 --> 00:00:51.420
over the course of this talk.

00:00:51.420 --> 00:00:53.460
And the reason we need
communication to do this

00:00:53.460 --> 00:00:55.710
and that we use it all
the time is obviously

00:00:55.710 --> 00:00:57.760
that everyone has
minds of their own

00:00:57.760 --> 00:01:00.630
and that we don't have access
to the mental states of others.

00:01:00.630 --> 00:01:03.120
And we can't automatically
transfer our own mental states

00:01:03.120 --> 00:01:06.840
to theirs without some means
of making those mental states

00:01:06.840 --> 00:01:10.110
observable in the form of
communicating with them.

00:01:10.110 --> 00:01:13.719
So people are both
cognitive beings--

00:01:13.719 --> 00:01:16.260
we have to sort of navigate the
thoughts in our heads and try

00:01:16.260 --> 00:01:18.240
to figure out the thoughts
that are in other's heads--

00:01:18.240 --> 00:01:19.448
but we're also social beings.

00:01:19.448 --> 00:01:21.150
We really benefit
from gaining access

00:01:21.150 --> 00:01:22.470
to the thoughts in
the minds of others

00:01:22.470 --> 00:01:24.261
and giving them access
to our own thoughts.

00:01:24.261 --> 00:01:27.450
So for example, for cooperation,
competition, learning,

00:01:27.450 --> 00:01:29.700
and teaching, and all the
kinds of social interactions

00:01:29.700 --> 00:01:31.200
we do with each
other, we have to be

00:01:31.200 --> 00:01:33.570
able to share the contents
of our mental states.

00:01:33.570 --> 00:01:36.420
And it's this sort of joint,
both cognitive and social

00:01:36.420 --> 00:01:37.920
nature of communication
that I think

00:01:37.920 --> 00:01:39.878
makes it especially
important for understanding

00:01:39.878 --> 00:01:41.550
the development of
human intelligence.

00:01:41.550 --> 00:01:44.010
It sort of crosscuts a lot
of these core knowledge

00:01:44.010 --> 00:01:47.010
domains that Liz talked
about in her talk.

00:01:47.010 --> 00:01:48.834
So human communication
requires reasoning

00:01:48.834 --> 00:01:50.250
about others'
cognitive states, so

00:01:50.250 --> 00:01:52.249
understanding what others'
beliefs, and desires,

00:01:52.249 --> 00:01:53.520
and intentions are.

00:01:53.520 --> 00:01:56.320
It also requires reasoning
about social interaction,

00:01:56.320 --> 00:01:58.752
so understanding that typically
these kinds of thoughts,

00:01:58.752 --> 00:02:00.210
and beliefs, and
intentions are not

00:02:00.210 --> 00:02:01.620
shared among different people.

00:02:01.620 --> 00:02:03.630
Everyone has their own
that are unobservable

00:02:03.630 --> 00:02:05.880
and housed in their own heads.

00:02:05.880 --> 00:02:07.770
But in the context
of a particular kind

00:02:07.770 --> 00:02:10.830
of social interaction,
these people

00:02:10.830 --> 00:02:13.440
can intentionally share their
thoughts with each other.

00:02:13.440 --> 00:02:15.199
And communication often
involves reasoning

00:02:15.199 --> 00:02:17.490
about a third thing, which
is language or communicative

00:02:17.490 --> 00:02:20.800
signals outside of
language as well.

00:02:20.800 --> 00:02:22.970
And so I'm going to back
to this point at the end,

00:02:22.970 --> 00:02:24.470
but all these types
of reasoning are

00:02:24.470 --> 00:02:27.540
going to come up in the studies
about infant communication

00:02:27.540 --> 00:02:29.580
that I describe in the talk.

00:02:32.950 --> 00:02:34.831
And so Liz talked about
how infants start out

00:02:34.831 --> 00:02:37.330
with these coherent, separate,
principle, and core knowledge

00:02:37.330 --> 00:02:39.910
systems that contain some
limited representations

00:02:39.910 --> 00:02:42.520
for reasoning about the world,
and which kind of come together

00:02:42.520 --> 00:02:44.219
around the end of
the first year.

00:02:44.219 --> 00:02:46.510
So if we want to figure out
how to build a model of how

00:02:46.510 --> 00:02:49.030
social cognitive
development works,

00:02:49.030 --> 00:02:52.090
we're going to need to
understand how an infant starts

00:02:52.090 --> 00:02:54.610
to figure out, using
the core knowledge

00:02:54.610 --> 00:02:58.000
that they have early in life,
the components of communication

00:02:58.000 --> 00:03:00.940
and also how these components
come together so that infants

00:03:00.940 --> 00:03:03.790
can build a more complex
causal model of communication

00:03:03.790 --> 00:03:04.600
like adults have.

00:03:07.620 --> 00:03:10.830
So this is just to
illustrate the points

00:03:10.830 --> 00:03:13.094
I'm making about the
communicative situation.

00:03:13.094 --> 00:03:14.760
So in any given
communicative situation,

00:03:14.760 --> 00:03:17.714
we can't just think about
the words that are being said

00:03:17.714 --> 00:03:18.630
or what we're hearing.

00:03:18.630 --> 00:03:21.088
We need to think about it in
this broader context of having

00:03:21.088 --> 00:03:24.120
a communicator or maybe multiple
communicators, an addressee

00:03:24.120 --> 00:03:26.730
or an audience, and also the
things that the communicator is

00:03:26.730 --> 00:03:28.177
saying in the
broader context that

00:03:28.177 --> 00:03:29.760
allow us to figure
out what's going on

00:03:29.760 --> 00:03:31.960
in this social interaction.

00:03:31.960 --> 00:03:33.540
So it really requires
understanding

00:03:33.540 --> 00:03:35.250
that the communicator's
mental states are

00:03:35.250 --> 00:03:37.320
being transferred
in this causal way

00:03:37.320 --> 00:03:40.809
to the mind of the addressee.

00:03:40.809 --> 00:03:42.600
So I'm going to structure
the talk in terms

00:03:42.600 --> 00:03:44.516
of some important insights
from the philosophy

00:03:44.516 --> 00:03:46.350
of human language
and communication

00:03:46.350 --> 00:03:49.830
that I think have
really guided the way

00:03:49.830 --> 00:03:51.780
researchers in the
last, say, 50 years have

00:03:51.780 --> 00:03:53.430
been thinking about
the development

00:03:53.430 --> 00:03:56.045
of human communication as well.

00:03:56.045 --> 00:03:58.170
So I'm going to broadly
illustrate the three points

00:03:58.170 --> 00:04:00.461
that I'm taking from each,
and then I'll expand on them

00:04:00.461 --> 00:04:03.035
in each section.

00:04:03.035 --> 00:04:04.410
So the first
insight that I think

00:04:04.410 --> 00:04:05.951
is really important
for understanding

00:04:05.951 --> 00:04:10.629
how we think about communication
comes from John Austin, who

00:04:10.629 --> 00:04:11.920
brought up the important point.

00:04:11.920 --> 00:04:13.586
So before Austin,
people tended to think

00:04:13.586 --> 00:04:16.079
about language or study language
a lot in terms of language

00:04:16.079 --> 00:04:19.440
itself, and the semantics, and
syntax, and just the language

00:04:19.440 --> 00:04:21.240
signal.

00:04:21.240 --> 00:04:23.250
But Austin pointed out
that language is actually

00:04:23.250 --> 00:04:26.670
not just about the content,
but it's also an action.

00:04:26.670 --> 00:04:30.750
It's actually something that we
use, and we do things with it,

00:04:30.750 --> 00:04:33.060
in the same way that we do
things and accomplish things

00:04:33.060 --> 00:04:37.969
in the world using other kinds
of actions that we engage in.

00:04:37.969 --> 00:04:40.260
So Austin sort of brought up
this important distinction

00:04:40.260 --> 00:04:43.770
that language is not
just about the content.

00:04:43.770 --> 00:04:45.150
So to illustrate
with an example,

00:04:45.150 --> 00:04:47.094
in this communicative
interaction,

00:04:47.094 --> 00:04:48.010
there's language here.

00:04:48.010 --> 00:04:50.160
This person is saying,
is there any salt?

00:04:50.160 --> 00:04:51.780
And Austin analyzed
this in terms

00:04:51.780 --> 00:04:54.180
of not only what
the words meant,

00:04:54.180 --> 00:04:57.090
but in terms of three
layers of intentionality.

00:04:57.090 --> 00:04:59.940
So in this simple
interaction, he pointed out

00:04:59.940 --> 00:05:03.057
that there's a locutionary act,
or the meaning of the sentence,

00:05:03.057 --> 00:05:04.890
which is that there's
a question being asked

00:05:04.890 --> 00:05:07.290
about the presence of
salt. But that there's

00:05:07.290 --> 00:05:08.920
actually something
else going on here

00:05:08.920 --> 00:05:12.210
as well, which is that there's
an illocutionary action, which

00:05:12.210 --> 00:05:14.910
is what he considers to be
the intention underlying

00:05:14.910 --> 00:05:17.920
the action, which is
to request the salt.

00:05:17.920 --> 00:05:19.830
So if you actually just
read this sentence,

00:05:19.830 --> 00:05:21.270
it's kind of under-determined.

00:05:21.270 --> 00:05:24.000
It's not necessarily
obvious that this person's

00:05:24.000 --> 00:05:28.759
asking the other person at
this table to pass the salt.

00:05:28.759 --> 00:05:30.300
But if you take it
within the broader

00:05:30.300 --> 00:05:32.216
context of the interaction,
you can understand

00:05:32.216 --> 00:05:34.920
that what's really going on here
is not just a sentence being

00:05:34.920 --> 00:05:38.800
produced, but rather one
individual requesting something

00:05:38.800 --> 00:05:40.800
from another, who is then
supposed to understand

00:05:40.800 --> 00:05:46.380
the request, and in the
third layer of analysis,

00:05:46.380 --> 00:05:48.990
cause the addressee
to provide the salt.

00:05:48.990 --> 00:05:52.246
So the idea is that there are
these multiple things going on

00:05:52.246 --> 00:05:54.120
in the context of a
communicative interaction

00:05:54.120 --> 00:05:58.079
involving language that
go beyond the words that

00:05:58.079 --> 00:05:59.370
are actually being spoken here.

00:06:02.105 --> 00:06:06.310
And so if you're an infant, just
like in philosophy of language,

00:06:06.310 --> 00:06:08.890
the focus in infant
cognitive development--

00:06:08.890 --> 00:06:10.660
also for a long
time, and still is,

00:06:10.660 --> 00:06:13.060
we still need to
understand these things--

00:06:13.060 --> 00:06:15.610
was on understanding
how infants learn words,

00:06:15.610 --> 00:06:17.889
or how infants figure out
the meaning of language,

00:06:17.889 --> 00:06:19.930
and how it relates to
objects in the environment,

00:06:19.930 --> 00:06:21.640
and later, to the
abstract concepts

00:06:21.640 --> 00:06:23.410
that language indicates.

00:06:23.410 --> 00:06:25.990
But importantly, understanding
communication for an infant

00:06:25.990 --> 00:06:27.989
is going to be more than
about just figuring out

00:06:27.989 --> 00:06:29.140
the meaning of these words.

00:06:29.140 --> 00:06:31.769
And so following the
philosophical tradition

00:06:31.769 --> 00:06:33.310
of people like
Austin, who introduced

00:06:33.310 --> 00:06:35.452
the study of
pragmatics to language,

00:06:35.452 --> 00:06:36.910
developmental
psychologists as well

00:06:36.910 --> 00:06:39.730
started thinking about the
importance of recognizing

00:06:39.730 --> 00:06:42.820
communication as this
broader action in its context

00:06:42.820 --> 00:06:46.150
for understanding how
infants come to be good

00:06:46.150 --> 00:06:47.812
communicators themselves.

00:06:51.510 --> 00:06:54.110
So if communication involves
this whole context of action

00:06:54.110 --> 00:06:56.135
and interaction between
people, if you're

00:06:56.135 --> 00:06:58.010
a baby who's in the
business of understanding

00:06:58.010 --> 00:07:00.010
the social world, the
agent world, and the world

00:07:00.010 --> 00:07:02.480
of language, you're going to
be well-served by developing

00:07:02.480 --> 00:07:05.000
an ability to identify these
kinds of communicative actions

00:07:05.000 --> 00:07:06.800
or situations and
their components,

00:07:06.800 --> 00:07:09.690
and to begin to
understand how they work.

00:07:09.690 --> 00:07:12.050
So how do infants
start to figure out

00:07:12.050 --> 00:07:14.840
when communication is going
on in the world around them,

00:07:14.840 --> 00:07:17.150
rather than just identifying
words and associating them

00:07:17.150 --> 00:07:18.777
with objects?

00:07:18.777 --> 00:07:20.360
So actually, there's
a lot of evidence

00:07:20.360 --> 00:07:24.080
that infants are
identifying key features

00:07:24.080 --> 00:07:27.540
of communicative situations
really early in life.

00:07:27.540 --> 00:07:30.140
So from the time they're
born, newborn human infants

00:07:30.140 --> 00:07:33.350
prefer listening to
speech over other sounds.

00:07:33.350 --> 00:07:35.060
So the typical
method that's used

00:07:35.060 --> 00:07:36.980
to measure the preference
of an infant who's

00:07:36.980 --> 00:07:39.080
only one to four
days old is to have

00:07:39.080 --> 00:07:42.020
them suck on a pacifier
that's connected

00:07:42.020 --> 00:07:45.380
to a machine that detects how
strongly infants are sucking.

00:07:45.380 --> 00:07:48.230
And then the sucking is
used as a measure of infants

00:07:48.230 --> 00:07:50.180
arousal upon hearing
a particular sound

00:07:50.180 --> 00:07:52.370
or being exposed to a
particular stimulus.

00:07:52.370 --> 00:07:56.210
And so what researchers found
is that if you have infants suck

00:07:56.210 --> 00:07:58.100
on this pacifier while
listening to speech

00:07:58.100 --> 00:08:01.110
sounds and nonspeech
sounds in alternation,

00:08:01.110 --> 00:08:03.860
nonspeech sounds being
sine wave-produced sounds

00:08:03.860 --> 00:08:05.962
that are very similar to
speech in their features.

00:08:05.962 --> 00:08:08.420
If you listen to it, it has
the prosodic contours of speech

00:08:08.420 --> 00:08:11.600
and sounds a lot like it,
but it's not actually speech.

00:08:11.600 --> 00:08:15.770
You can't actually
parse any words from it.

00:08:15.770 --> 00:08:18.140
Infants showed a
preference for listening

00:08:18.140 --> 00:08:19.900
to speech over nonspeech,
or more arousal

00:08:19.900 --> 00:08:21.108
when they listened to speech.

00:08:21.108 --> 00:08:24.234
So they maintained
their arousal for speech

00:08:24.234 --> 00:08:25.650
over the course
of the experiment,

00:08:25.650 --> 00:08:27.710
but for nonspeech, it declined.

00:08:27.710 --> 00:08:29.600
And so extremely
early in life, infants

00:08:29.600 --> 00:08:31.910
seem to have this bias
for paying attention

00:08:31.910 --> 00:08:34.820
to the primary communicative
signal of our species, that is,

00:08:34.820 --> 00:08:35.559
human speech.

00:08:39.640 --> 00:08:43.027
Quite early in life
as well, infants

00:08:43.027 --> 00:08:45.610
recognize some of the important
features of the social context

00:08:45.610 --> 00:08:47.260
surrounding speech,
so getting more

00:08:47.260 --> 00:08:50.300
into the domain of the important
features for communication.

00:08:50.300 --> 00:08:52.471
So by six months,
infants seem to recognize

00:08:52.471 --> 00:08:54.220
that speech is
human-produced, or at least

00:08:54.220 --> 00:08:56.020
associate speech
with other humans,

00:08:56.020 --> 00:08:59.110
and also human-directed.

00:08:59.110 --> 00:09:02.290
So in one study, infants
saw pictures of human faces

00:09:02.290 --> 00:09:06.474
or faces of monkeys, and
they heard different sounds.

00:09:06.474 --> 00:09:07.390
So they either heard--

00:09:11.374 --> 00:09:14.830
oh, it seems like the sound
is not on, but that's OK.

00:09:14.830 --> 00:09:17.332
So they either-- oops.

00:09:20.580 --> 00:09:22.820
So they either heard a
speech sound in a language

00:09:22.820 --> 00:09:24.980
they never heard before
repeating itself,

00:09:24.980 --> 00:09:27.470
or they heard a monkey call.

00:09:27.470 --> 00:09:30.335
And infants in one trial either
saw-- so in the first trial,

00:09:30.335 --> 00:09:32.210
say, they'd see the
human face, and then they

00:09:32.210 --> 00:09:36.080
could listen repeatedly
to a speech sound

00:09:36.080 --> 00:09:37.977
until they looked
away for two seconds.

00:09:37.977 --> 00:09:39.560
And then they would
see a monkey face,

00:09:39.560 --> 00:09:41.390
and then they would hear either
a speech sound or a monkey

00:09:41.390 --> 00:09:43.010
sound and be able to
look at this image

00:09:43.010 --> 00:09:44.780
while listening to that
sound until they looked away

00:09:44.780 --> 00:09:45.800
for two seconds.

00:09:45.800 --> 00:09:47.690
And so they got all
possible combinations.

00:09:47.690 --> 00:09:50.060
Sometimes they saw a human
face and listened to speech.

00:09:50.060 --> 00:09:51.893
Sometimes they saw a
human face and listened

00:09:51.893 --> 00:09:52.790
to the monkey sounds.

00:09:52.790 --> 00:09:54.373
And sometimes they
saw the monkey face

00:09:54.373 --> 00:09:57.666
and listened to either human
speech or the monkey sound.

00:09:57.666 --> 00:09:59.540
And the question was
whether infants actually

00:09:59.540 --> 00:10:02.507
could match speech
sounds to humans

00:10:02.507 --> 00:10:05.090
and recognize that they should
be produced by the human rather

00:10:05.090 --> 00:10:06.665
than the monkey.

00:10:06.665 --> 00:10:07.790
And that's what they found.

00:10:07.790 --> 00:10:11.270
So you can see that when
infants heard speech,

00:10:11.270 --> 00:10:13.790
they were much more
likely to look at the--

00:10:13.790 --> 00:10:16.654
yeah, they were looking at the
human when they heard speech,

00:10:16.654 --> 00:10:18.320
and then they were
looking at the monkey

00:10:18.320 --> 00:10:19.695
when they heard
the monkey calls.

00:10:22.116 --> 00:10:24.240
Similarly, infants seem to
understand by six months

00:10:24.240 --> 00:10:26.370
that speech is directed
at other humans.

00:10:26.370 --> 00:10:29.370
So when they saw
a person talking

00:10:29.370 --> 00:10:32.130
behind a barrier
versus acting, so

00:10:32.130 --> 00:10:34.080
swiping with her hand
behind a barrier,

00:10:34.080 --> 00:10:35.460
and then the
barrier was revealed

00:10:35.460 --> 00:10:39.060
to reveal either a
person or an object,

00:10:39.060 --> 00:10:41.975
infants looked longer for
the speaking familiarization

00:10:41.975 --> 00:10:43.350
when they saw that
there had been

00:10:43.350 --> 00:10:45.270
an object behind the
barrier than a person,

00:10:45.270 --> 00:10:46.860
suggesting that
they expected speech

00:10:46.860 --> 00:10:49.487
to be directed toward
another person.

00:10:49.487 --> 00:10:51.570
And in contrast, when they
saw the person swiping,

00:10:51.570 --> 00:10:53.190
they looked much longer
when they saw a person

00:10:53.190 --> 00:10:54.856
behind the barrier
because typically, we

00:10:54.856 --> 00:10:55.860
don't swipe at people.

00:10:55.860 --> 00:10:56.960
We tend to speak to them.

00:11:06.080 --> 00:11:07.910
So this suggests that
infants understand

00:11:07.910 --> 00:11:10.490
some of the features
of the context

00:11:10.490 --> 00:11:13.950
in which human
communication is produced.

00:11:13.950 --> 00:11:16.095
Importantly, infants
do still seem

00:11:16.095 --> 00:11:18.470
to be developing this ability
over the first year of life

00:11:18.470 --> 00:11:20.511
because it's not until 10
months that they expect

00:11:20.511 --> 00:11:22.250
mutual gaze between
speakers, which

00:11:22.250 --> 00:11:24.410
tends to be an important
part of understanding

00:11:24.410 --> 00:11:27.750
the social context
of communication.

00:11:27.750 --> 00:11:31.165
So in this study, infants saw
two people facing each other.

00:11:31.165 --> 00:11:33.290
This is just one of the
experiments from the study.

00:11:33.290 --> 00:11:35.600
But you can see that they
saw the two people looking

00:11:35.600 --> 00:11:37.308
at each other and
speaking to each other,

00:11:37.308 --> 00:11:41.540
or the two people looking apart
and speaking to each other.

00:11:41.540 --> 00:11:44.240
Infants at nine months
didn't differentiate

00:11:44.240 --> 00:11:45.470
between these at all.

00:11:45.470 --> 00:11:49.280
So at nine months,
they didn't necessarily

00:11:49.280 --> 00:11:51.530
think that the people were
going to look at each other

00:11:51.530 --> 00:11:52.760
when they were speaking.

00:11:52.760 --> 00:11:55.340
But at 10 months,
you can see here

00:11:55.340 --> 00:11:58.580
that infants looked longer
for the averted gaze

00:11:58.580 --> 00:11:59.840
than for the mutual gaze.

00:12:04.766 --> 00:12:06.390
So infants seem to
be able to recognize

00:12:06.390 --> 00:12:10.250
when a communicative context
is going on early in life.

00:12:10.250 --> 00:12:12.250
But we don't necessarily
know from these studies

00:12:12.250 --> 00:12:15.000
whether they really understand
that communication is happening

00:12:15.000 --> 00:12:17.442
or whether they're
just detecting

00:12:17.442 --> 00:12:19.650
some important features of
communicative interactions

00:12:19.650 --> 00:12:22.290
that might help them to glom
onto communication so that they

00:12:22.290 --> 00:12:24.324
can eventually develop
an ability to figure out

00:12:24.324 --> 00:12:26.490
what's going on within the
communicative interaction

00:12:26.490 --> 00:12:27.604
themselves.

00:12:27.604 --> 00:12:29.520
So, so far in the studies
that I've mentioned,

00:12:29.520 --> 00:12:30.570
there's nothing cognitive here.

00:12:30.570 --> 00:12:31.770
There's nothing
really about infants

00:12:31.770 --> 00:12:33.870
having to understand the
intentions or the mental states

00:12:33.870 --> 00:12:36.036
of the speaker going into
the mind of the addressee,

00:12:36.036 --> 00:12:38.170
like I was talking about before.

00:12:38.170 --> 00:12:40.195
So a question I've
explored in my research

00:12:40.195 --> 00:12:42.570
is whether infants recognize
that when these features are

00:12:42.570 --> 00:12:44.490
in place, when you have a
communicative signal, which

00:12:44.490 --> 00:12:45.872
is something they
recognize, when

00:12:45.872 --> 00:12:47.580
you have a communicator
and addressee who

00:12:47.580 --> 00:12:49.430
are socially engaged
with each other,

00:12:49.430 --> 00:12:52.050
do infants recognize that
communication can actually lead

00:12:52.050 --> 00:12:53.954
to the transfer of information?

00:12:56.920 --> 00:12:59.857
So do infants understand
that speech, using speech,

00:12:59.857 --> 00:13:02.190
because this is something
that infants seem to recognize

00:13:02.190 --> 00:13:04.590
as a signal that's important
in communicative context,

00:13:04.590 --> 00:13:07.107
can transfer information
between individuals?

00:13:10.690 --> 00:13:14.160
So we can use speech to
communicate with each other

00:13:14.160 --> 00:13:16.210
about what we're interested in.

00:13:16.210 --> 00:13:18.180
So if I'm observing
this interaction

00:13:18.180 --> 00:13:20.040
between a communicator
and an addressee,

00:13:20.040 --> 00:13:22.686
I can infer that if the
communicator says, the cup,

00:13:22.686 --> 00:13:24.060
and there's only
one cup present,

00:13:24.060 --> 00:13:25.560
the addressee's
probably going to be

00:13:25.560 --> 00:13:28.470
able to figure out what it is
that the communicator wants.

00:13:28.470 --> 00:13:31.392
And I can figure this out even
from a third party perspective.

00:13:31.392 --> 00:13:33.600
And I can also understand
that other kinds of sounds,

00:13:33.600 --> 00:13:35.760
like perhaps a positive
emotional vocalization,

00:13:35.760 --> 00:13:38.430
are not going to be as
effective in communicating

00:13:38.430 --> 00:13:42.060
to the addressee what the
communicator is interested in.

00:13:42.060 --> 00:13:44.130
So speech and also
other communicative

00:13:44.130 --> 00:13:46.590
signals as well that can specify
this sort of information,

00:13:46.590 --> 00:13:49.410
perhaps like pointing or
particular kinds of gestures,

00:13:49.410 --> 00:13:53.340
can transfer information from
one individual to another.

00:13:53.340 --> 00:13:56.010
So speech is going to be more
effective for communicating

00:13:56.010 --> 00:14:00.210
than other kinds of
noncommunicative actions.

00:14:00.210 --> 00:14:02.700
And importantly, for the
purposes of this study,

00:14:02.700 --> 00:14:05.520
you're not just going to know
that communicative information

00:14:05.520 --> 00:14:09.990
transfer is going on because you
know what the word cup means,

00:14:09.990 --> 00:14:13.150
even in a situation
where you're listening

00:14:13.150 --> 00:14:15.150
to a foreign language,
and you have no idea what

00:14:15.150 --> 00:14:16.501
the meaning of the words are.

00:14:16.501 --> 00:14:18.000
Even in this
situation, you're going

00:14:18.000 --> 00:14:20.375
to understand that some kind
of communicative information

00:14:20.375 --> 00:14:21.577
transfer can happen.

00:14:21.577 --> 00:14:24.160
So we've all had the experience
of being in a foreign country,

00:14:24.160 --> 00:14:25.410
presumably, where
you're listening

00:14:25.410 --> 00:14:26.650
to people speak to each other.

00:14:26.650 --> 00:14:28.858
You can't necessarily
understand what they're saying,

00:14:28.858 --> 00:14:31.090
but you know that information
transfer is happening.

00:14:31.090 --> 00:14:33.256
So the interesting thing
about communicative actions

00:14:33.256 --> 00:14:35.040
like speech is that
when we witness them,

00:14:35.040 --> 00:14:36.831
we can know that people
are communicatively

00:14:36.831 --> 00:14:38.490
sharing information,
even when we

00:14:38.490 --> 00:14:42.480
don't know what information is
being communicated ourselves.

00:14:42.480 --> 00:14:45.450
And this insight
suggests that maybe,

00:14:45.450 --> 00:14:47.790
if you're an infant,
one really good way

00:14:47.790 --> 00:14:50.430
to jump into the communicative
interactions around you

00:14:50.430 --> 00:14:55.440
and start to understand
what's going on

00:14:55.440 --> 00:14:57.810
is to be able to identify
when others are communicating.

00:14:57.810 --> 00:14:59.630
And hearing the sounds
of speech exchanged

00:14:59.630 --> 00:15:02.490
between two people in the
context of a social interaction

00:15:02.490 --> 00:15:05.380
might be a really
good way to do this.

00:15:05.380 --> 00:15:07.800
So an ability to figure out
when communication's going on

00:15:07.800 --> 00:15:10.740
like this might provide infants
with this really powerful way

00:15:10.740 --> 00:15:13.080
of being able to track the
information flow between two

00:15:13.080 --> 00:15:15.720
other people's minds
and also to figure out,

00:15:15.720 --> 00:15:17.760
based on their responses
to each other, what

00:15:17.760 --> 00:15:21.870
the actual content of
the words might mean.

00:15:21.870 --> 00:15:24.210
So we asked whether
infants recognize

00:15:24.210 --> 00:15:28.447
that speech is communicative
at 12 months of age.

00:15:28.447 --> 00:15:30.030
And so in the procedure
of this study,

00:15:30.030 --> 00:15:32.280
infants were privy
to a third party

00:15:32.280 --> 00:15:34.950
interaction between a
communicator and an addressee.

00:15:34.950 --> 00:15:38.440
And the infant is always just
observing the interaction.

00:15:38.440 --> 00:15:41.120
This is so that we can
isolate whether infants think

00:15:41.120 --> 00:15:43.620
that certain communicative
vocalizations can transfer

00:15:43.620 --> 00:15:46.230
information from the
communicator to an addressee,

00:15:46.230 --> 00:15:49.179
even when the infant themselves
has all the information.

00:15:49.179 --> 00:15:50.970
So the third party
nature of this procedure

00:15:50.970 --> 00:15:53.310
is important here for seeing
whether infants really

00:15:53.310 --> 00:15:56.370
are thinking about the fact that
thoughts are typically isolated

00:15:56.370 --> 00:15:59.040
in particular people's minds,
but with communication, they

00:15:59.040 --> 00:15:59.700
can be shared.

00:16:02.417 --> 00:16:04.500
So infants in these studies
were given a violation

00:16:04.500 --> 00:16:05.860
of expectation paradigm.

00:16:05.860 --> 00:16:08.340
In this kind of experiment,
as many of you probably know,

00:16:08.340 --> 00:16:11.610
infants are shown a story
through a series of scenes.

00:16:11.610 --> 00:16:14.910
And then in the last
scene or series of scenes,

00:16:14.910 --> 00:16:16.800
they're shown different
kinds of endings.

00:16:16.800 --> 00:16:19.800
And we're interested in whether
infants are surprised or look

00:16:19.800 --> 00:16:23.610
longer at some endings more
than they do at others.

00:16:23.610 --> 00:16:25.890
So infants in these studies
were shown a live display

00:16:25.890 --> 00:16:28.152
where they had an actor in
front of them in a stage.

00:16:28.152 --> 00:16:30.360
First, they were familiarized
with this actor showing

00:16:30.360 --> 00:16:32.730
a preference for an object
by picking it up and playing

00:16:32.730 --> 00:16:36.090
with it repeatedly in
three separate scenes.

00:16:36.090 --> 00:16:38.670
And so, as in the studies
by Amanda Woodward that Liz

00:16:38.670 --> 00:16:42.400
already mentioned,
infants, by 12 months

00:16:42.400 --> 00:16:45.010
and as early as three
months, will attribute a goal

00:16:45.010 --> 00:16:48.811
to this person for reaching for
that particular target object.

00:16:48.811 --> 00:16:50.310
So after being
familiarized to this,

00:16:50.310 --> 00:16:52.799
infants saw an addressee,
who was a new person,

00:16:52.799 --> 00:16:54.840
present in a totally
different part of the stage.

00:16:54.840 --> 00:16:56.464
They had never seen
this person before,

00:16:56.464 --> 00:16:59.010
and they'd never seen the
two people together before.

00:16:59.010 --> 00:17:01.230
This person reached for
both objects in turn.

00:17:01.230 --> 00:17:03.180
So first, she grabbed
this one, then this one,

00:17:03.180 --> 00:17:04.640
and then this one, and
then this one again

00:17:04.640 --> 00:17:07.181
to show that she didn't have a
preference between the objects

00:17:07.181 --> 00:17:10.069
and could reach both of them.

00:17:10.069 --> 00:17:12.680
Then in the test scene,
so this is the ending

00:17:12.680 --> 00:17:15.167
that we showed infants, they
saw the two people together

00:17:15.167 --> 00:17:17.000
for the first time, but
now the communicator

00:17:17.000 --> 00:17:19.730
couldn't reach the objects
because only her face had

00:17:19.730 --> 00:17:21.020
access to the stage.

00:17:21.020 --> 00:17:24.470
But the addressee could
still reach them just fine.

00:17:24.470 --> 00:17:27.560
At this point, the
crucial manipulation

00:17:27.560 --> 00:17:30.750
was the vocalization
uttered by the communicator.

00:17:30.750 --> 00:17:34.390
So she either produced a speech
sound, the nonsense word koba,

00:17:34.390 --> 00:17:38.300
which infants had not
heard before, she produced

00:17:38.300 --> 00:17:40.520
a coughing sound, so
something that would typically

00:17:40.520 --> 00:17:42.920
be physiological and not
intentional or communicative

00:17:42.920 --> 00:17:45.867
in any way, or an emotional
vocalization, so a sound

00:17:45.867 --> 00:17:47.450
that perhaps could
convey information.

00:17:47.450 --> 00:17:50.720
If I say, ooh, you might think
I'm interested in something,

00:17:50.720 --> 00:17:52.814
I'm feeling positive,
but you won't necessarily

00:17:52.814 --> 00:17:53.480
know what it is.

00:17:53.480 --> 00:17:57.570
So this one's sort of in
the middle of the other two.

00:17:57.570 --> 00:18:00.025
And then, infants saw
the addressee either

00:18:00.025 --> 00:18:02.150
provide the target object
that the communicator had

00:18:02.150 --> 00:18:04.720
reached for before or
the nontarget object.

00:18:04.720 --> 00:18:07.640
And the question is, do
infants understand that speech

00:18:07.640 --> 00:18:09.980
as a communicative signal,
do they have some expectation

00:18:09.980 --> 00:18:12.438
that even though they've never
heard this particular speech

00:18:12.438 --> 00:18:15.230
sound used before, that speech
can transfer information such

00:18:15.230 --> 00:18:18.320
that the addressee will
now be able to select

00:18:18.320 --> 00:18:19.550
the correct object?

00:18:19.550 --> 00:18:22.310
Whereas nonspeech vocalizations
like coughing and emotional

00:18:22.310 --> 00:18:23.900
vocalizations can't.

00:18:23.900 --> 00:18:25.970
So if so, infants in
the speech condition

00:18:25.970 --> 00:18:30.020
should look longer to nontarget
than target actions, responses,

00:18:30.020 --> 00:18:31.666
finding these unexpected.

00:18:31.666 --> 00:18:33.290
And infants in the
other two conditions

00:18:33.290 --> 00:18:34.956
shouldn't differentiate
between the two.

00:18:37.537 --> 00:18:38.620
And this is what we found.

00:18:38.620 --> 00:18:40.150
So in the speech
condition, infants

00:18:40.150 --> 00:18:42.139
are looking longer to
nontarget than target,

00:18:42.139 --> 00:18:43.930
suggesting that they
understand that speech

00:18:43.930 --> 00:18:46.747
can transfer information
about the communicator's goal.

00:18:46.747 --> 00:18:48.580
But when the communicator
coughs or produces

00:18:48.580 --> 00:18:50.350
an emotional
vocalization, infants

00:18:50.350 --> 00:18:54.280
don't show these
same expectations.

00:18:54.280 --> 00:18:56.709
So this is some initial
evidence that by 12 months,

00:18:56.709 --> 00:18:59.250
infants not only recognize the
context in which communication

00:18:59.250 --> 00:19:02.130
occurs and attend to
speech as a special signal

00:19:02.130 --> 00:19:06.240
for communication, but
they also understand

00:19:06.240 --> 00:19:09.360
that speech is something that's
able to transfer information

00:19:09.360 --> 00:19:12.360
between two people.

00:19:12.360 --> 00:19:14.190
So we also ran a few
control conditions

00:19:14.190 --> 00:19:17.534
to rule out alternative
explanations for this.

00:19:17.534 --> 00:19:19.950
So one important question is,
are infants really reasoning

00:19:19.950 --> 00:19:26.230
about the addressee's access to
information in this situation?

00:19:26.230 --> 00:19:30.092
So for example, in
the case where the--

00:19:30.092 --> 00:19:32.550
if infants are really reasoning
with the addressee's access

00:19:32.550 --> 00:19:35.460
to information, then in a case
where the communicator makes

00:19:35.460 --> 00:19:37.322
a positive emotional
vocalization,

00:19:37.322 --> 00:19:39.780
and the addressee has previous
information about what she's

00:19:39.780 --> 00:19:41.880
interested in, so for
example, if she just

00:19:41.880 --> 00:19:44.820
saw that the communicator
was trying to feed her child

00:19:44.820 --> 00:19:47.100
or wanted a drink of
water, she might know now

00:19:47.100 --> 00:19:49.562
that a positive emotional
vocalization is indicating

00:19:49.562 --> 00:19:50.520
something like the cup.

00:19:54.040 --> 00:19:56.514
So we set up a scenario
like this as well.

00:19:56.514 --> 00:19:58.930
In this case, it's exactly the
same as the previous study,

00:19:58.930 --> 00:20:01.150
except that the addressee
had visual access

00:20:01.150 --> 00:20:04.351
to the communicators preference
during the familiarization

00:20:04.351 --> 00:20:04.850
phase.

00:20:04.850 --> 00:20:07.540
So now she knows what it is
that the communicator likes.

00:20:07.540 --> 00:20:10.000
And this is important for making
sure the infants recognize

00:20:10.000 --> 00:20:11.770
that something
like visual access

00:20:11.770 --> 00:20:13.630
can provide the addressee
with information

00:20:13.630 --> 00:20:17.300
about the
communicator's interest.

00:20:17.300 --> 00:20:20.072
So now infants saw the same
addressee familiarization.

00:20:20.072 --> 00:20:22.030
And then in the test,
they saw the communicator

00:20:22.030 --> 00:20:25.570
produce the vocalization
ooh once again.

00:20:25.570 --> 00:20:28.930
So now even though
ooh was not treated

00:20:28.930 --> 00:20:31.319
as a communicative vocalization
in the previous studies,

00:20:31.319 --> 00:20:33.610
if infants are reasoning
about the kinds of information

00:20:33.610 --> 00:20:35.290
that the addressee
has access to,

00:20:35.290 --> 00:20:37.702
they should now expect that
the addressee will provide

00:20:37.702 --> 00:20:39.160
the target object
because she knows

00:20:39.160 --> 00:20:42.709
from a previous scene what the
communicator was interested in.

00:20:42.709 --> 00:20:45.250
So this is important also for
ruling out the possibility that

00:20:45.250 --> 00:20:47.770
maybe just hearing these
noncommunicative vocalizations

00:20:47.770 --> 00:20:49.900
surprises or confuses
infants or makes

00:20:49.900 --> 00:20:52.360
them unable to reason
about the scenario anymore.

00:20:52.360 --> 00:20:54.670
Here, they're getting a
noncommunicative vocalization,

00:20:54.670 --> 00:20:58.180
but the addressee has
access to information.

00:20:58.180 --> 00:21:00.160
And here, as in the
speech condition,

00:21:00.160 --> 00:21:02.650
infants looked longer at
the nontarget outcome.

00:21:02.650 --> 00:21:06.550
So this is just some evidence
that infants are really

00:21:06.550 --> 00:21:08.920
thinking about the idea
that relevant sources

00:21:08.920 --> 00:21:11.530
of information, such as a
communicative vocalization,

00:21:11.530 --> 00:21:13.450
but also prior
visual access, can

00:21:13.450 --> 00:21:18.070
give the addressee information
about the communicator's goal.

00:21:18.070 --> 00:21:20.519
So they are reasoning
about information access.

00:21:20.519 --> 00:21:22.810
Another important question
is, are they really thinking

00:21:22.810 --> 00:21:24.310
about the source of
information, or do they

00:21:24.310 --> 00:21:26.710
have-- so what's really the
mechanism behind what infants

00:21:26.710 --> 00:21:27.335
are doing here?

00:21:27.335 --> 00:21:29.980
Are they thinking something
like, when I hear speech,

00:21:29.980 --> 00:21:31.869
everything will go
well, or the speaker

00:21:31.869 --> 00:21:33.160
is going to get what she wants?

00:21:33.160 --> 00:21:35.876
Or are they really thinking
about communication

00:21:35.876 --> 00:21:37.750
in this causal way,
where the information has

00:21:37.750 --> 00:21:40.150
to come from the
speaker and be delivered

00:21:40.150 --> 00:21:43.430
to the listener in
order for it to work?

00:21:43.430 --> 00:21:46.000
So to test for this, infants
saw another communicator

00:21:46.000 --> 00:21:46.807
familiarization.

00:21:46.807 --> 00:21:49.390
Here, the communicator is alone,
so they've never seen the two

00:21:49.390 --> 00:21:51.130
people together before.

00:21:51.130 --> 00:21:52.750
She reaches for
the target object.

00:21:52.750 --> 00:21:55.390
Then they see the
addressee again.

00:21:55.390 --> 00:21:57.700
And then in the test
scene, in this case,

00:21:57.700 --> 00:22:00.130
the addressee is the one
who produces the speech.

00:22:00.130 --> 00:22:03.320
So speech is present in
the scene as it was before,

00:22:03.320 --> 00:22:06.100
but it's not being produced by
the communicator or the person

00:22:06.100 --> 00:22:08.470
who showed a preference.

00:22:08.470 --> 00:22:09.970
So if infants just
think that speech

00:22:09.970 --> 00:22:12.850
leads to people obtaining
their goals or magical outcomes

00:22:12.850 --> 00:22:15.280
happening, then they
should expect the addressee

00:22:15.280 --> 00:22:16.960
to provide the
target here as well.

00:22:16.960 --> 00:22:19.540
But if they understand that
they don't know anything

00:22:19.540 --> 00:22:21.610
about the addressee, in
which case, this is not

00:22:21.610 --> 00:22:23.500
really informative
about either object,

00:22:23.500 --> 00:22:26.710
then they should look
equally to both outcomes.

00:22:26.710 --> 00:22:29.740
And in fact, this is what
they do at 12 months.

00:22:29.740 --> 00:22:32.200
So infants here don't
expect information

00:22:32.200 --> 00:22:33.700
to be transferred
from one person

00:22:33.700 --> 00:22:36.370
to another, unless the first
person who communicated

00:22:36.370 --> 00:22:39.220
is the one who actually had
the information to provide.

00:22:44.340 --> 00:22:46.267
So by 12 months, infants
seem to recognize

00:22:46.267 --> 00:22:47.850
that speech is
communicative, and they

00:22:47.850 --> 00:22:49.850
seem to have some of the
parts of a causal model

00:22:49.850 --> 00:22:50.620
of communication.

00:22:50.620 --> 00:22:52.203
They're not just
thinking about speech

00:22:52.203 --> 00:22:55.600
as something that can
produce successful outcomes,

00:22:55.600 --> 00:22:57.690
but as something
that can be used

00:22:57.690 --> 00:23:00.120
to have information move from
the mind of one individual

00:23:00.120 --> 00:23:01.920
to another.

00:23:01.920 --> 00:23:03.510
So a 12-month-old
seemed to recognize

00:23:03.510 --> 00:23:05.580
that speech is communicative.

00:23:05.580 --> 00:23:07.260
But we really wanted
to get at the idea

00:23:07.260 --> 00:23:09.300
that understanding that
speech is communicative

00:23:09.300 --> 00:23:11.610
might be something
that drives and guides

00:23:11.610 --> 00:23:13.560
word learning and language
acquisition, rather

00:23:13.560 --> 00:23:15.018
than something that
is as a result.

00:23:15.018 --> 00:23:17.250
So what a 12-month-old
could be doing in this study

00:23:17.250 --> 00:23:19.740
is hearing the word koba,
associating it with the object

00:23:19.740 --> 00:23:21.420
that the communicator
had reached for,

00:23:21.420 --> 00:23:23.260
and then thinking, OK,
that one's the koba,

00:23:23.260 --> 00:23:26.280
so that's what the
addressee should reach for.

00:23:26.280 --> 00:23:29.040
But in these studies, we were
interested in whether infants

00:23:29.040 --> 00:23:31.770
at an even younger age,
who would be very, very

00:23:31.770 --> 00:23:34.037
unlikely to be associating
the word with the object

00:23:34.037 --> 00:23:36.120
or learning a label for
the object over the course

00:23:36.120 --> 00:23:37.800
of the study, would
also recognize

00:23:37.800 --> 00:23:40.470
that speech can transfer
information about one person

00:23:40.470 --> 00:23:41.890
to another person.

00:23:41.890 --> 00:23:44.700
And so for this reason,
we tested 6-month-olds,

00:23:44.700 --> 00:23:47.466
because 6-month-olds
understand only some very, very

00:23:47.466 --> 00:23:48.840
common words in
their environment

00:23:48.840 --> 00:23:50.214
and will look to
the right object

00:23:50.214 --> 00:23:52.930
when they hear the label for it.

00:23:52.930 --> 00:23:54.841
But these are very,
very limited words,

00:23:54.841 --> 00:23:56.340
and there's no
evidence for learning

00:23:56.340 --> 00:23:58.020
a word in a single
trial, which is what they

00:23:58.020 --> 00:23:59.200
would have to do in this study.

00:23:59.200 --> 00:24:01.241
They would have to hear
koba, and then think back

00:24:01.241 --> 00:24:03.327
to what the communicator
had reached for,

00:24:03.327 --> 00:24:05.910
and really learn that word over
the course of the study, which

00:24:05.910 --> 00:24:08.910
we have no evidence that
a 6-month-old can do.

00:24:08.910 --> 00:24:10.590
So the goal of looking
at this age group

00:24:10.590 --> 00:24:12.131
was to see whether
infants might have

00:24:12.131 --> 00:24:15.270
a more abstract understanding
of the idea that when speech

00:24:15.270 --> 00:24:18.030
is produced, information can
be transferred from one person

00:24:18.030 --> 00:24:21.240
to another, even
when they themselves

00:24:21.240 --> 00:24:22.830
don't know what
that information--

00:24:22.830 --> 00:24:29.250
or what the link between
the word and the object.

00:24:29.250 --> 00:24:32.460
So a 6-month-old
saw the same scenes.

00:24:32.460 --> 00:24:34.839
We gave them the speech
versus cough contrast.

00:24:34.839 --> 00:24:36.880
And they look the same as
the 12-month-olds here.

00:24:36.880 --> 00:24:38.250
So you can see that
in the speech case,

00:24:38.250 --> 00:24:39.840
they're looking longer
for the nontarget outcome.

00:24:39.840 --> 00:24:41.423
And in the cough
case, they're looking

00:24:41.423 --> 00:24:42.940
longer for the target outcome.

00:24:42.940 --> 00:24:45.539
And so we haven't done all of
the same control conditions

00:24:45.539 --> 00:24:46.830
as with the 12-month-olds here.

00:24:46.830 --> 00:24:49.200
So I think there's a lot of
room for questions about how

00:24:49.200 --> 00:24:51.300
a 6-month-old's understanding
of communication

00:24:51.300 --> 00:24:53.610
in this causal way more
limited than the understanding

00:24:53.610 --> 00:24:54.660
of 12-month-olds.

00:24:54.660 --> 00:24:57.180
Would a six-month-old
think that if speech

00:24:57.180 --> 00:24:59.610
was produced by a loudspeaker
or by the addressee,

00:24:59.610 --> 00:25:01.960
that the communicator would
still get the right object?

00:25:01.960 --> 00:25:06.160
So there are a lot of
open questions about--

00:25:06.160 --> 00:25:08.520
these basic questions about
how infants' understanding

00:25:08.520 --> 00:25:10.561
of communicative information
transfer starts out.

00:25:12.840 --> 00:25:14.840
So these experiments
suggest that by six months,

00:25:14.840 --> 00:25:17.260
infants seem to understand
that speech is communicative,

00:25:17.260 --> 00:25:18.850
in addition to the other
studies that suggest

00:25:18.850 --> 00:25:20.350
they understand
some of the features

00:25:20.350 --> 00:25:21.847
of communicative interactions.

00:25:21.847 --> 00:25:23.680
They recognize that it
transfers information

00:25:23.680 --> 00:25:25.109
from one person to another.

00:25:25.109 --> 00:25:26.650
And I'd like to
argue that this might

00:25:26.650 --> 00:25:28.774
be something that provides
a mechanism for language

00:25:28.774 --> 00:25:32.099
and knowledge acquisition,
so sort of guides infants

00:25:32.099 --> 00:25:33.640
to the kinds of
relevant interactions

00:25:33.640 --> 00:25:35.390
where they might want to
learn things about people,

00:25:35.390 --> 00:25:37.930
and their mental states, and
the words that they're using,

00:25:37.930 --> 00:25:41.770
rather than first learning
those words through association

00:25:41.770 --> 00:25:44.692
and then later coming to this
more abstract understanding.

00:25:47.059 --> 00:25:48.850
So the idea is that
infants might start out

00:25:48.850 --> 00:25:50.590
with this understanding
of what communication is

00:25:50.590 --> 00:25:52.330
and when it's happening,
and then can sort of fill

00:25:52.330 --> 00:25:54.490
in the rest from there,
and that this might be one

00:25:54.490 --> 00:25:57.530
of the earlier blocks of that.

00:25:57.530 --> 00:25:59.730
So I'll try to go fairly
quickly through the rest.

00:25:59.730 --> 00:26:01.480
So the second insight
I wanted to bring up

00:26:01.480 --> 00:26:02.710
that I think is
especially important

00:26:02.710 --> 00:26:05.043
is that communication requires
this focus on intentions.

00:26:05.043 --> 00:26:06.700
And this was really
the work of Grice

00:26:06.700 --> 00:26:10.750
that highlighted this, and
in particular, a special type

00:26:10.750 --> 00:26:12.560
of communicative intention.

00:26:12.560 --> 00:26:14.560
So going back to the
example from the beginning.

00:26:14.560 --> 00:26:16.390
When someone asks,
is there any salt,

00:26:16.390 --> 00:26:17.800
Austin proposed that
there are these three

00:26:17.800 --> 00:26:19.660
levels on which we can think
about this communicative

00:26:19.660 --> 00:26:20.440
action.

00:26:20.440 --> 00:26:22.540
And Grice was the one who
really formalized this

00:26:22.540 --> 00:26:24.640
by talking about this
special kind of intention

00:26:24.640 --> 00:26:27.310
that we see in the
domain of communication,

00:26:27.310 --> 00:26:29.590
human communication
in particular, which

00:26:29.590 --> 00:26:32.080
is the idea of speaker meaning.

00:26:32.080 --> 00:26:35.324
And so his idea is that there's
this double-layered intention

00:26:35.324 --> 00:26:37.490
that comes when we're
communicating with each other.

00:26:37.490 --> 00:26:40.030
So we have a communicator
who intends the addressee

00:26:40.030 --> 00:26:41.510
to respond in a particular way.

00:26:41.510 --> 00:26:43.630
So here, the communicator
wants the addressee

00:26:43.630 --> 00:26:47.290
to provide some salt.
The communicator

00:26:47.290 --> 00:26:50.350
intends for the addressee to
recognize that the communicator

00:26:50.350 --> 00:26:52.040
intends to have that response.

00:26:52.040 --> 00:26:57.820
So this person not only wants
this person to pass the salt,

00:26:57.820 --> 00:26:59.560
but wants her to
recognize that that

00:26:59.560 --> 00:27:02.080
is what he's asking for, that
that is the request that he's

00:27:02.080 --> 00:27:02.860
making.

00:27:02.860 --> 00:27:04.520
And importantly,
this third point,

00:27:04.520 --> 00:27:08.650
which is that the communicator
intends the addressee

00:27:08.650 --> 00:27:11.920
to respond that way on the
basis of the recognition

00:27:11.920 --> 00:27:13.120
of that intention.

00:27:13.120 --> 00:27:15.220
And so to make this a
little more concrete,

00:27:15.220 --> 00:27:17.279
in this case, if he
asks her for the salt,

00:27:17.279 --> 00:27:19.570
and she passes it because
she heard him and understands

00:27:19.570 --> 00:27:21.850
that's what he's asking
for, that's great.

00:27:21.850 --> 00:27:24.160
But the argument is that
communication wouldn't really

00:27:24.160 --> 00:27:25.900
be happening if,
for example, she

00:27:25.900 --> 00:27:27.850
was wearing headphones
and listening to music,

00:27:27.850 --> 00:27:29.350
and she hadn't really
been listening to him,

00:27:29.350 --> 00:27:32.140
and she just happened to pick
up the salt and pass it to him.

00:27:32.140 --> 00:27:35.027
So communication,
I mean, it would

00:27:35.027 --> 00:27:36.610
look like a communicative
interaction.

00:27:36.610 --> 00:27:38.980
The right kind of outcome is
still happening in response

00:27:38.980 --> 00:27:40.060
to what he said.

00:27:40.060 --> 00:27:43.270
But if she has no access
to the actual message,

00:27:43.270 --> 00:27:46.300
if she doesn't produce
the response by virtue

00:27:46.300 --> 00:27:50.911
of understanding what the
communicator is trying to say,

00:27:50.911 --> 00:27:52.660
then communication
hasn't really occurred.

00:27:52.660 --> 00:27:54.118
It's just sort of
a lucky accident.

00:27:58.670 --> 00:28:01.709
So I'll skip this part.

00:28:01.709 --> 00:28:03.500
So this is this important
kind of intention

00:28:03.500 --> 00:28:04.980
that we see in human
communication, in which I'll

00:28:04.980 --> 00:28:06.563
later briefly mention,
we don't really

00:28:06.563 --> 00:28:10.520
see in animal communication
in the same sort of way.

00:28:10.520 --> 00:28:13.701
So how do infants start to get
this idea about communication,

00:28:13.701 --> 00:28:15.200
that it's not just
about identifying

00:28:15.200 --> 00:28:16.700
communicative
interactions, but also

00:28:16.700 --> 00:28:20.270
about understanding these
particular kinds of intentions?

00:28:20.270 --> 00:28:22.250
So in the '90s,
there was this shift

00:28:22.250 --> 00:28:25.640
in developmental psychology
to looking at word learning,

00:28:25.640 --> 00:28:30.440
not only in terms of infants'
associations of words

00:28:30.440 --> 00:28:33.560
in the environment, but to also,
with the work of Dare Baldwin,

00:28:33.560 --> 00:28:35.780
to thinking about other
people's intentions

00:28:35.780 --> 00:28:37.190
when they're using words.

00:28:37.190 --> 00:28:41.030
And so she had these really
elegant studies where--

00:28:41.030 --> 00:28:43.280
with this funny image--

00:28:43.280 --> 00:28:46.670
where she pointed out
that if infants really

00:28:46.670 --> 00:28:48.830
were learning words
through association,

00:28:48.830 --> 00:28:51.160
then it wouldn't be
very efficient for them

00:28:51.160 --> 00:28:52.910
because they would
make a lot of mistakes.

00:28:52.910 --> 00:28:54.680
So for example, in
this kind of situation,

00:28:54.680 --> 00:28:56.340
here's a dad and his baby.

00:28:56.340 --> 00:28:58.910
The baby is looking
at this lizard.

00:28:58.910 --> 00:29:00.500
The dad is looking
at this rooster.

00:29:00.500 --> 00:29:03.200
And the dad says,
what a cheeky rooster.

00:29:03.200 --> 00:29:05.840
So if you as the infant
are only learning words

00:29:05.840 --> 00:29:09.110
on the basis of associating
what you hear with what you see,

00:29:09.110 --> 00:29:11.674
you're going to learn that
the word rooster refers

00:29:11.674 --> 00:29:13.340
to this thing rather
than to this thing.

00:29:13.340 --> 00:29:15.660
And you're going
to get it wrong.

00:29:15.660 --> 00:29:18.500
So Baldwin did a
whole host of studies

00:29:18.500 --> 00:29:24.020
in the second year of life
where she set up situations

00:29:24.020 --> 00:29:26.510
where infants were looking at
particular objects like here.

00:29:26.510 --> 00:29:29.000
And then she had their parents
or an experimenter look

00:29:29.000 --> 00:29:30.680
at a different object
and label that one

00:29:30.680 --> 00:29:32.720
to see what infants would do.

00:29:32.720 --> 00:29:36.380
And what she found is
that infants actually

00:29:36.380 --> 00:29:39.440
would consult their
parent or consult

00:29:39.440 --> 00:29:41.840
the other person for cues to
reference, to what they're

00:29:41.840 --> 00:29:43.197
intending to label.

00:29:43.197 --> 00:29:44.780
So if, for example,
in this situation,

00:29:44.780 --> 00:29:47.309
the infant, when hearing
this, instead of just assuming

00:29:47.309 --> 00:29:49.100
the word refers to what
they're looking at,

00:29:49.100 --> 00:29:51.890
would actually look up to dad
to see what he's looking at

00:29:51.890 --> 00:29:53.956
and then follow his line
of gaze to understand

00:29:53.956 --> 00:29:56.330
that this is the object that
he's actually talking about.

00:29:56.330 --> 00:29:58.490
AUDIENCE: At this age?

00:29:58.490 --> 00:29:58.990
At this age?

00:29:58.990 --> 00:30:00.281
ALIA MARTIN: Yeah, at this age.

00:30:00.281 --> 00:30:02.270
Yeah.

00:30:02.270 --> 00:30:04.730
So the idea is that infants
in the second year of life,

00:30:04.730 --> 00:30:07.880
at least, are understanding that
understanding what someone's

00:30:07.880 --> 00:30:10.415
referring to involves consulting
cues to their attention

00:30:10.415 --> 00:30:13.700
and intentions rather than
just the infant's own.

00:30:17.260 --> 00:30:19.091
And I think I'll skip this one.

00:30:19.091 --> 00:30:20.840
There are other studies
showing this, too.

00:30:20.840 --> 00:30:22.790
So in this one,
there's an experimenter

00:30:22.790 --> 00:30:24.420
who puts these two
objects in a box.

00:30:24.420 --> 00:30:27.200
The objects switch
while she's absent.

00:30:27.200 --> 00:30:30.230
And then she looks
in one box and says--

00:30:30.230 --> 00:30:32.850
the boxes are closed, and she
says, there's a sefo in here.

00:30:32.850 --> 00:30:35.350
So if the infant understands
that they have to pay attention

00:30:35.350 --> 00:30:38.046
to what the person knows about
or what the person thinks

00:30:38.046 --> 00:30:39.920
rather than their own
knowledge to figure out

00:30:39.920 --> 00:30:42.000
what she's labeling,
then now when she says,

00:30:42.000 --> 00:30:44.060
can you get the sefo, the
infant should actually

00:30:44.060 --> 00:30:46.670
pull the object out
of here, assuming

00:30:46.670 --> 00:30:48.170
that this is the
one she's labeling,

00:30:48.170 --> 00:30:51.890
because that's the one that
she was intending to label.

00:30:51.890 --> 00:30:56.150
And in fact, that's what
infants do at 17 months.

00:30:56.150 --> 00:31:01.040
In the case where the
experimenter had a false belief

00:31:01.040 --> 00:31:02.600
about the location
of the object,

00:31:02.600 --> 00:31:05.302
infants tend to go to
the non-referred box

00:31:05.302 --> 00:31:07.010
more often because
they think that that's

00:31:07.010 --> 00:31:08.176
the one that she's labeling.

00:31:08.176 --> 00:31:10.797
But in the case where she saw
the switch happen, so now she

00:31:10.797 --> 00:31:13.130
knows what's everywhere,
infants will just go to the box

00:31:13.130 --> 00:31:15.710
that she's referring to figure
out the location of the object

00:31:15.710 --> 00:31:17.574
that she's naming.

00:31:17.574 --> 00:31:19.490
So this is all in the
second year of life, not

00:31:19.490 --> 00:31:21.485
those younger core
knowledge ages

00:31:21.485 --> 00:31:22.610
that Liz was talking about.

00:31:25.530 --> 00:31:28.320
So this is evidence that
infants consult speaker cues

00:31:28.320 --> 00:31:30.780
to intentions, but not of
this special kind of intention

00:31:30.780 --> 00:31:32.484
that Grice was pointing out.

00:31:32.484 --> 00:31:34.650
So I'm just going to tell
you about a couple-- well,

00:31:34.650 --> 00:31:37.149
one of my favorite studies, I
just think that this is really

00:31:37.149 --> 00:31:37.680
neat--

00:31:37.680 --> 00:31:41.130
where Ellen Markman's
lab and then later

00:31:41.130 --> 00:31:43.500
replicated by
Tomasello's lab, showed

00:31:43.500 --> 00:31:45.870
that it seems like
children, by 30 months

00:31:45.870 --> 00:31:49.830
and then gotten down to
18 months by Grosse et al,

00:31:49.830 --> 00:31:54.450
actually do seem to care
about not only the effects

00:31:54.450 --> 00:31:56.790
of communication, but
also that the effects

00:31:56.790 --> 00:32:00.870
are produced by virtue of
the message being understood.

00:32:00.870 --> 00:32:02.580
So you're probably
wondering why there's

00:32:02.580 --> 00:32:03.970
a dirty sock on the screen.

00:32:03.970 --> 00:32:10.122
So in this study, children were
presented with two objects.

00:32:10.122 --> 00:32:11.580
So they saw, on a
table, there were

00:32:11.580 --> 00:32:13.621
two objects that were out
of their reach, a truck

00:32:13.621 --> 00:32:15.210
and a dirty sock.

00:32:15.210 --> 00:32:18.259
And the idea was to elicit
children to request an object.

00:32:18.259 --> 00:32:19.800
Now obviously, the
children are going

00:32:19.800 --> 00:32:22.174
to request this object, which
is what the researchers had

00:32:22.174 --> 00:32:23.490
intended in this case.

00:32:23.490 --> 00:32:25.549
So children tended to
point at this object.

00:32:25.549 --> 00:32:27.840
So they had children producing
their own communication,

00:32:27.840 --> 00:32:29.334
and then the
experimenter responded

00:32:29.334 --> 00:32:30.750
to the communication
of the infant

00:32:30.750 --> 00:32:32.430
in one of four different ways.

00:32:32.430 --> 00:32:34.847
So she either said, you
asked for the truck?

00:32:34.847 --> 00:32:36.180
I'm going to give you the truck.

00:32:36.180 --> 00:32:38.220
So she expressed
understanding of the request,

00:32:38.220 --> 00:32:41.124
and she provided the
requested object.

00:32:41.124 --> 00:32:43.290
In a second case, she said,
you asked for the truck?

00:32:43.290 --> 00:32:44.581
I'm going to give you the sock.

00:32:44.581 --> 00:32:46.290
So here, she expressed
understanding,

00:32:46.290 --> 00:32:48.810
but refused to commit
to the request,

00:32:48.810 --> 00:32:51.590
to give the thing the
child had asked for.

00:32:51.590 --> 00:32:53.490
In a third case, the
experimenter said,

00:32:53.490 --> 00:32:54.840
you asked for the sock?

00:32:54.840 --> 00:32:56.770
I'm going to give you the truck.

00:32:56.770 --> 00:32:59.827
So this is kind of a strange
pragmatic situation where

00:32:59.827 --> 00:33:02.160
the experimenter actually
gave the child the object they

00:33:02.160 --> 00:33:05.040
wanted, but she expressed a
misunderstanding of the child's

00:33:05.040 --> 00:33:05.790
request.

00:33:05.790 --> 00:33:07.530
And this is the
crucial case here.

00:33:07.530 --> 00:33:10.740
So the question is,
obviously, in the case where

00:33:10.740 --> 00:33:12.270
the experimenter
provides the thing

00:33:12.270 --> 00:33:15.960
and expresses understanding,
children should be quite happy.

00:33:15.960 --> 00:33:17.610
And in this situation,
they probably

00:33:17.610 --> 00:33:20.172
shouldn't be very happy.

00:33:20.172 --> 00:33:21.630
And what the
experimenters measured

00:33:21.630 --> 00:33:23.940
was the amount of
times that the child

00:33:23.940 --> 00:33:26.820
repeated the label of the
object that they had asked for.

00:33:26.820 --> 00:33:30.150
And they also measured
other behaviors as well.

00:33:30.150 --> 00:33:34.155
It's this situation that's
important for understanding

00:33:34.155 --> 00:33:35.970
what kids care
about in the context

00:33:35.970 --> 00:33:37.560
of this communicative
interaction.

00:33:37.560 --> 00:33:40.342
So the question is, are
infants perfectly happy here

00:33:40.342 --> 00:33:42.300
to take the truck and
not complain because they

00:33:42.300 --> 00:33:43.410
got what they wanted?

00:33:43.410 --> 00:33:45.810
Or do they care about the
experimenter giving them

00:33:45.810 --> 00:33:49.080
what they wanted because
their communicated message had

00:33:49.080 --> 00:33:53.820
the proper effect
on the addressee?

00:33:53.820 --> 00:34:00.390
And what they find is that when
the correct object is provided,

00:34:00.390 --> 00:34:02.520
and the experimenter does
not express understanding

00:34:02.520 --> 00:34:04.144
of the request,
infants actually showed

00:34:04.144 --> 00:34:06.660
the most repetitions of the
name of the requested object

00:34:06.660 --> 00:34:07.260
in this case.

00:34:10.686 --> 00:34:12.475
The researchers
concluded from this

00:34:12.475 --> 00:34:14.850
that infants don't just care
about getting what they want

00:34:14.850 --> 00:34:19.710
or using communication
as a sort of instrumental

00:34:19.710 --> 00:34:21.690
means of getting people
to act in certain ways,

00:34:21.690 --> 00:34:26.699
but rather as an intention to
have their messages understood

00:34:26.699 --> 00:34:29.811
and delivered to
the other person.

00:34:29.811 --> 00:34:32.310
So they care about the impact
of their communicative signals

00:34:32.310 --> 00:34:33.929
on the understanding
of the addressee,

00:34:33.929 --> 00:34:36.102
not just on the response
of the addressee,

00:34:36.102 --> 00:34:38.310
which is sort of like the
idea that Grice was talking

00:34:38.310 --> 00:34:40.320
about with speaker meaning.

00:34:40.320 --> 00:34:42.570
Similarly, when
children are responding

00:34:42.570 --> 00:34:44.820
to other people's requests,
they also care about this.

00:34:44.820 --> 00:34:47.280
So this is a study that
I did in graduate school.

00:34:47.280 --> 00:34:50.230
It's sort of the opposite of the
previous study, or the inverse.

00:34:50.230 --> 00:34:53.580
So we had an experimenter
requesting from the child

00:34:53.580 --> 00:34:57.380
specific objects for
doing specific tasks.

00:34:57.380 --> 00:34:58.530
This is 3-year-olds.

00:34:58.530 --> 00:35:00.960
So she would request
something like a cup

00:35:00.960 --> 00:35:02.670
to pour a cup of water.

00:35:02.670 --> 00:35:05.340
The child had previous
information from playing games

00:35:05.340 --> 00:35:07.110
with the objects with
another experimenter

00:35:07.110 --> 00:35:09.037
that one of the cups
was perfectly fine,

00:35:09.037 --> 00:35:10.620
and one of the cups
was broken and had

00:35:10.620 --> 00:35:12.540
a big hole in the bottom.

00:35:12.540 --> 00:35:14.670
And so when the experimenter
asked for a cup,

00:35:14.670 --> 00:35:17.440
the child could either give the
cup the experimenter asked for,

00:35:17.440 --> 00:35:20.479
which was sometimes
the perfectly good cup,

00:35:20.479 --> 00:35:22.770
or sometimes the experimenter
requested the broken cup.

00:35:22.770 --> 00:35:26.400
And the question was, do
children pay attention

00:35:26.400 --> 00:35:28.290
to the fit between
the task and what

00:35:28.290 --> 00:35:30.420
the experimenter
wanted when they're

00:35:30.420 --> 00:35:33.430
responding to her request?

00:35:33.430 --> 00:35:36.120
And what we found is that
children were much more

00:35:36.120 --> 00:35:37.800
likely to give the
requested object when

00:35:37.800 --> 00:35:40.320
the experimenter had requested
a functional object than when

00:35:40.320 --> 00:35:41.920
she'd requested a
dysfunctional object.

00:35:41.920 --> 00:35:43.711
So if I say, I need to
pour a cup of water,

00:35:43.711 --> 00:35:45.870
can you give me that cup,
and the cup is broken,

00:35:45.870 --> 00:35:49.770
children tended to go and get
a better cup instead of the one

00:35:49.770 --> 00:35:51.570
that I had requested.

00:35:51.570 --> 00:35:54.570
Interestingly, though, even
though children did this,

00:35:54.570 --> 00:35:57.240
it didn't seem to be enough for
them to give the experimenter

00:35:57.240 --> 00:35:58.770
something good that she wanted.

00:35:58.770 --> 00:36:00.660
This is a graph of the
comments that children

00:36:00.660 --> 00:36:02.460
made about the
function of the objects

00:36:02.460 --> 00:36:05.300
depending on the kind of
request that was made.

00:36:05.300 --> 00:36:07.800
And what you can see is that
when a dysfunctional object was

00:36:07.800 --> 00:36:10.200
requested, when children
tended to provide

00:36:10.200 --> 00:36:13.115
the functional object instead
and not respond to the request,

00:36:13.115 --> 00:36:14.490
they were much
more likely to try

00:36:14.490 --> 00:36:17.010
to explain their behavior
to the experimenter

00:36:17.010 --> 00:36:20.190
and acknowledge what it was
the experiment had originally

00:36:20.190 --> 00:36:21.060
wanted.

00:36:21.060 --> 00:36:23.521
So it seems like children
in their own behavior,

00:36:23.521 --> 00:36:25.270
by at least three,
which is a little older

00:36:25.270 --> 00:36:27.942
than the other
studies, acknowledge

00:36:27.942 --> 00:36:30.400
what the speaker meant to ask
for and explain while they're

00:36:30.400 --> 00:36:33.109
doing something else,
even when they're not

00:36:33.109 --> 00:36:34.150
responding to that thing.

00:36:36.780 --> 00:36:39.005
And so, just briefly,
in the last section,

00:36:39.005 --> 00:36:41.130
I'll talk about a third
insight about communication

00:36:41.130 --> 00:36:42.810
that I think is really
important, which

00:36:42.810 --> 00:36:45.210
comes from Clark, which
is that communication

00:36:45.210 --> 00:36:49.480
is this joint action of
accumulating common ground.

00:36:49.480 --> 00:36:52.530
And so in an example of
an adult study about this,

00:36:52.530 --> 00:36:55.770
they showed adults pictures
like this one of New York City,

00:36:55.770 --> 00:36:58.119
and they had people
play this game in pairs.

00:36:58.119 --> 00:37:00.660
They had people who knew about
New York City who were experts

00:37:00.660 --> 00:37:01.530
and who lived
there, and then they

00:37:01.530 --> 00:37:04.113
had other people who didn't know
anything about New York City.

00:37:04.113 --> 00:37:06.720
And they gave them
a bunch of pictures.

00:37:06.720 --> 00:37:10.910
They told them that
their goal was to--

00:37:10.910 --> 00:37:12.630
the person who was
the addressee had

00:37:12.630 --> 00:37:15.600
to sort the objects in the way
that the communicator told them

00:37:15.600 --> 00:37:16.230
to.

00:37:16.230 --> 00:37:18.720
And so as a communicator, the
communicator had to indicate,

00:37:18.720 --> 00:37:22.140
because they couldn't see
the pictures, which picture

00:37:22.140 --> 00:37:23.940
the addressee should put where.

00:37:23.940 --> 00:37:26.880
And to do this, the
communicator had

00:37:26.880 --> 00:37:30.330
to refer to things like the
picture with the Empire State

00:37:30.330 --> 00:37:31.830
Building in it.

00:37:31.830 --> 00:37:35.430
And what they looked at was how
people in these interactions

00:37:35.430 --> 00:37:38.490
accumulated shared knowledge
or common ground over time

00:37:38.490 --> 00:37:40.650
and coordinated so their
communication could

00:37:40.650 --> 00:37:41.709
become more efficient.

00:37:41.709 --> 00:37:44.250
And what they found is that when
they had two New Yorkers who

00:37:44.250 --> 00:37:45.624
were interacting
with each other,

00:37:45.624 --> 00:37:49.037
they tended to very quickly
do the task because they could

00:37:49.037 --> 00:37:51.120
recognize immediately,
that person's a New Yorker,

00:37:51.120 --> 00:37:52.380
and would just say
things like, oh, it's

00:37:52.380 --> 00:37:54.030
the one with the
Empire State Building.

00:37:54.030 --> 00:37:55.890
Whereas when they were talking
to someone who wasn't a New

00:37:55.890 --> 00:37:58.200
Yorker, they had to sort
of ground the conversation

00:37:58.200 --> 00:38:00.990
by establishing these common
reference before getting

00:38:00.990 --> 00:38:01.774
to this point.

00:38:01.774 --> 00:38:03.940
And so they might start out
with saying things like,

00:38:03.940 --> 00:38:07.280
oh, move the one with the
building with the pointy top.

00:38:07.280 --> 00:38:09.030
And then eventually,
they would coordinate

00:38:09.030 --> 00:38:13.450
on what the actual labels
for these things were.

00:38:13.450 --> 00:38:16.260
And so Clark's idea
is that communication

00:38:16.260 --> 00:38:18.210
is really efficient,
and we're able to do it

00:38:18.210 --> 00:38:20.987
in the way we are
because we're thinking

00:38:20.987 --> 00:38:23.070
about the common ground
we have with other people.

00:38:23.070 --> 00:38:24.900
And we're able to figure out
what kind of common ground

00:38:24.900 --> 00:38:26.610
we have with others
fairly quickly.

00:38:26.610 --> 00:38:28.470
So if I'm interacting
with one of you,

00:38:28.470 --> 00:38:31.290
I might assume, OK, we both know
a lot about cognitive science

00:38:31.290 --> 00:38:31.920
already.

00:38:31.920 --> 00:38:33.570
So I can sort of start
at a different level

00:38:33.570 --> 00:38:35.670
than I might start with, say,
a child or someone who didn't

00:38:35.670 --> 00:38:36.990
know anything about this area.

00:38:39.560 --> 00:38:43.325
And so this is an important
piece of human communication.

00:38:43.325 --> 00:38:45.450
It seems like-- and Liz
talked a little about this,

00:38:45.450 --> 00:38:47.116
too-- it seems like
infants are starting

00:38:47.116 --> 00:38:49.502
to show some signs
of understanding

00:38:49.502 --> 00:38:51.210
the importance of
common ground or shared

00:38:51.210 --> 00:38:54.180
knowledge in communication
from a really early age.

00:38:54.180 --> 00:38:56.640
But importantly, this seems to
come in around the same time

00:38:56.640 --> 00:38:58.556
that they recognize the
importance of speakers

00:38:58.556 --> 00:39:00.325
facing each other
in conversation

00:39:00.325 --> 00:39:02.700
and perhaps putting together
some of their core knowledge

00:39:02.700 --> 00:39:07.200
domains, which is around
nine months to a year.

00:39:07.200 --> 00:39:09.330
A lot of work in
this domain has been

00:39:09.330 --> 00:39:12.411
done by Tomasello, who showed
that around nine months,

00:39:12.411 --> 00:39:14.910
children were starting to do
something different than they'd

00:39:14.910 --> 00:39:15.701
been doing earlier.

00:39:15.701 --> 00:39:19.610
So under nine months,
children tend to--

00:39:19.610 --> 00:39:22.230
they play with objects,
they interact with people,

00:39:22.230 --> 00:39:25.480
but they don't seem to put
these two things together.

00:39:25.480 --> 00:39:27.750
Whereas at nine months,
what they start doing

00:39:27.750 --> 00:39:30.510
is paying attention, not
just to objects or to people,

00:39:30.510 --> 00:39:33.360
but to objects and people at
the same time in the context

00:39:33.360 --> 00:39:34.780
of a joint interaction.

00:39:34.780 --> 00:39:37.050
So they might do things
like look at an object

00:39:37.050 --> 00:39:40.860
and then look at mom to make
sure mom is also looking at it.

00:39:40.860 --> 00:39:42.780
Or they might point
at things, not just

00:39:42.780 --> 00:39:45.030
because they want the things,
as a younger child might

00:39:45.030 --> 00:39:48.750
do, but only to share
attention with a parent

00:39:48.750 --> 00:39:50.239
or with someone
else to point out

00:39:50.239 --> 00:39:51.780
that they're interested
in something,

00:39:51.780 --> 00:39:53.863
and to make sure that the
parent is looking and is

00:39:53.863 --> 00:39:56.070
interested in it as well.

00:39:56.070 --> 00:39:58.710
So Tomasello argues
that this ability

00:39:58.710 --> 00:40:03.780
for engaging in joint attention,
sharing attention with someone

00:40:03.780 --> 00:40:06.570
else, to an object or
external referent in the world

00:40:06.570 --> 00:40:09.210
is the foundation of
linguistic communication

00:40:09.210 --> 00:40:12.150
and also cooperation in
other very important human

00:40:12.150 --> 00:40:13.980
activities.

00:40:13.980 --> 00:40:16.740
And it's certainly going to be
important for an understanding

00:40:16.740 --> 00:40:21.352
of common ground, which is
important for communication.

00:40:21.352 --> 00:40:23.310
So there's also evidence
that around 12 months,

00:40:23.310 --> 00:40:25.245
infants start to use
prior shared experience

00:40:25.245 --> 00:40:26.370
to interpret communication.

00:40:26.370 --> 00:40:27.900
I'm going to skip this, I think.

00:40:27.900 --> 00:40:28.995
But basically, the idea--

00:40:28.995 --> 00:40:30.620
well, I'll just go
through it quickly--

00:40:30.620 --> 00:40:33.900
the idea is that infants will
use the activities and objects

00:40:33.900 --> 00:40:36.632
that they've shared
with people previously

00:40:36.632 --> 00:40:38.715
to figure out what the
person means in a new case.

00:40:38.715 --> 00:40:41.550
So if the infant interacts with
one communicator with one toy

00:40:41.550 --> 00:40:43.633
and with another communicator
with a different toy

00:40:43.633 --> 00:40:47.220
separately, they will
figure out the referent

00:40:47.220 --> 00:40:49.020
of a communicator's
ambiguous request

00:40:49.020 --> 00:40:50.520
by thinking about
what information

00:40:50.520 --> 00:40:51.880
they've shared in the past.

00:40:51.880 --> 00:40:52.860
So it seems like
they're starting

00:40:52.860 --> 00:40:54.610
to track what kinds
of knowledge is shared

00:40:54.610 --> 00:40:57.090
and what isn't in order
to effectively communicate

00:40:57.090 --> 00:40:57.600
with others.

00:41:04.320 --> 00:41:05.535
OK.

00:41:05.535 --> 00:41:07.410
So there's a lot of
other important questions

00:41:07.410 --> 00:41:09.618
about common ground, but
I'm going to skip those now.

00:41:09.618 --> 00:41:13.355
I just want to come back
to the question of why

00:41:13.355 --> 00:41:15.480
infants' understanding and
children's understanding

00:41:15.480 --> 00:41:17.438
of communication is
important for understanding

00:41:17.438 --> 00:41:19.480
human intelligence.

00:41:19.480 --> 00:41:21.210
So I think that one
reason is that when

00:41:21.210 --> 00:41:25.080
you think about the insights
these philosophers had

00:41:25.080 --> 00:41:28.680
and how they seemed
to be realized

00:41:28.680 --> 00:41:30.720
in fairly young infants early--

00:41:30.720 --> 00:41:33.419
children and infants
early in development,

00:41:33.419 --> 00:41:35.460
when you look at these
abilities that humans have

00:41:35.460 --> 00:41:38.880
and even that very young humans
have, and you compare them

00:41:38.880 --> 00:41:40.650
to what nonhuman
animals are doing,

00:41:40.650 --> 00:41:44.220
things look really different.

00:41:44.220 --> 00:41:48.180
And so, just briefly,
in animal communication,

00:41:48.180 --> 00:41:49.890
we see some of the
same kinds of features

00:41:49.890 --> 00:41:51.790
that we see in
human communication.

00:41:51.790 --> 00:41:53.850
So for one thing, animal
communication clearly

00:41:53.850 --> 00:41:55.470
has a social function
in the same way

00:41:55.470 --> 00:41:57.190
that human communication does.

00:41:57.190 --> 00:41:59.815
So it's socially rich
in a number of ways.

00:41:59.815 --> 00:42:01.440
I'm not going to over
specific species,

00:42:01.440 --> 00:42:04.030
but just to gloss over it,
most animal communication

00:42:04.030 --> 00:42:05.994
is sensitive to the
presence of an audience.

00:42:05.994 --> 00:42:07.410
So it matters that
someone's there

00:42:07.410 --> 00:42:09.360
to hear your communication.

00:42:09.360 --> 00:42:10.890
For example,
species that produce

00:42:10.890 --> 00:42:15.159
alarm calls to warn others
in their group of predators

00:42:15.159 --> 00:42:17.700
will rarely produce these calls
if there are no other members

00:42:17.700 --> 00:42:19.560
of their species present.

00:42:19.560 --> 00:42:21.810
In many cases, the
sensitivity to the audience

00:42:21.810 --> 00:42:23.920
depends on the identity
of the audience.

00:42:23.920 --> 00:42:26.950
So for example, in some species
such as ground squirrels,

00:42:26.950 --> 00:42:28.950
they call much more in
the presence of their kin

00:42:28.950 --> 00:42:30.366
than when their
kin are not around

00:42:30.366 --> 00:42:32.654
or when there are other
individuals there.

00:42:32.654 --> 00:42:35.070
And in some cases, it seems
like there might actually even

00:42:35.070 --> 00:42:36.330
be a sensitivity
to the knowledge

00:42:36.330 --> 00:42:37.246
state of the audience.

00:42:37.246 --> 00:42:39.180
So this is looking a
little more like the kind

00:42:39.180 --> 00:42:41.970
of sophisticated communication
we see in humans.

00:42:41.970 --> 00:42:44.010
So a wild chimpanzee,
for example,

00:42:44.010 --> 00:42:46.350
will produce an alarm call,
will start to alarm call

00:42:46.350 --> 00:42:48.210
more if other
chimpanzees come over

00:42:48.210 --> 00:42:50.670
who hadn't heard the
original alarm call

00:42:50.670 --> 00:42:52.290
or who hadn't seen the predator.

00:42:52.290 --> 00:42:53.760
But if everyone around
has already seen it,

00:42:53.760 --> 00:42:55.218
they'll reduce
their alarm calling.

00:42:55.218 --> 00:42:57.690
So it seems like they tailor
it to how much information

00:42:57.690 --> 00:42:58.860
others around them have had.

00:43:02.010 --> 00:43:04.020
However, despite these
really interesting ways

00:43:04.020 --> 00:43:07.170
in which animal communication
is social and complex,

00:43:07.170 --> 00:43:08.760
it's also limited
in a number of ways

00:43:08.760 --> 00:43:10.500
that human communication is not.

00:43:10.500 --> 00:43:13.320
So the eliciting stimuli for
these communicative signals

00:43:13.320 --> 00:43:15.720
tend to be fairly limited,
as do the signals themselves.

00:43:15.720 --> 00:43:17.553
So there tends to be,
say in vervet monkeys,

00:43:17.553 --> 00:43:19.830
one cry for a hawk and
one cry for a snake,

00:43:19.830 --> 00:43:22.590
and they can't
realize new signals

00:43:22.590 --> 00:43:26.310
for new kinds of
predators and situations.

00:43:26.310 --> 00:43:28.980
As in humans, the
receivers-- or in humans,

00:43:28.980 --> 00:43:30.510
the addressees--
acquire information

00:43:30.510 --> 00:43:32.820
from the signals of others,
but there's no evidence

00:43:32.820 --> 00:43:37.140
that this information tells
the receivers in animal species

00:43:37.140 --> 00:43:41.457
anything about the mental
states of the communicator.

00:43:41.457 --> 00:43:43.290
And additionally, the
communicator's signals

00:43:43.290 --> 00:43:45.470
can often cause a response
in receivers that's

00:43:45.470 --> 00:43:46.770
beneficial to the communicator.

00:43:46.770 --> 00:43:49.080
For example, they get a
bump to indirect fitness

00:43:49.080 --> 00:43:53.160
if they're kin run away
and survive predators.

00:43:53.160 --> 00:43:56.130
So there can be benefits
of communication,

00:43:56.130 --> 00:43:58.380
but there's no evidence
that the communicator

00:43:58.380 --> 00:44:01.419
has any intention of changing
the receiver's mental state.

00:44:01.419 --> 00:44:03.960
So there's really no evidence
of this sort of speaker meaning

00:44:03.960 --> 00:44:06.570
or this special kind of
communicative intention

00:44:06.570 --> 00:44:09.600
we see in humans, which is that
a communicator doesn't just

00:44:09.600 --> 00:44:12.780
intend for the addressee to
respond in a particular way,

00:44:12.780 --> 00:44:16.830
but intends for the audience
to respond in a particular way

00:44:16.830 --> 00:44:19.170
by virtue of having
understood the intention

00:44:19.170 --> 00:44:21.480
of that communication.

00:44:21.480 --> 00:44:25.110
And so this is just a, I think,
particularly well-worded quote

00:44:25.110 --> 00:44:27.330
from Seyfarth and
Cheney who say basically

00:44:27.330 --> 00:44:30.570
that listeners can acquire
information from signallers,

00:44:30.570 --> 00:44:33.030
but the signallers themselves
don't, in the human sense,

00:44:33.030 --> 00:44:37.064
intend to provide
that information.

00:44:37.064 --> 00:44:38.730
So the reason, really,
for this contrast

00:44:38.730 --> 00:44:40.470
between the human
and animal cases

00:44:40.470 --> 00:44:45.447
that I think if we want to build
a model of human communication,

00:44:45.447 --> 00:44:47.280
we need to differentiate
it from other kinds

00:44:47.280 --> 00:44:48.890
of communicative
models we could have.

00:44:48.890 --> 00:44:50.910
And we also need it to
develop the types of abilities

00:44:50.910 --> 00:44:52.650
that human infants have,
but taking into account

00:44:52.650 --> 00:44:54.358
the resources that
infants start out with

00:44:54.358 --> 00:44:58.396
and the developments that we see
in the first few years of life.

00:44:58.396 --> 00:45:00.270
So it's not going to be
enough to have agents

00:45:00.270 --> 00:45:01.978
that can influence
each other's responses

00:45:01.978 --> 00:45:04.034
or who can understand
language, because it

00:45:04.034 --> 00:45:06.450
seems like the recognition of
these more abstract features

00:45:06.450 --> 00:45:08.783
of communication and its
causal effects on mental states

00:45:08.783 --> 00:45:11.520
is actually present
fairly early on as well.

00:45:11.520 --> 00:45:15.720
And I think just relating
this back to Liz's theory

00:45:15.720 --> 00:45:18.330
that infants might have these
different systems for agents,

00:45:18.330 --> 00:45:19.740
understanding agents
and their actions

00:45:19.740 --> 00:45:22.240
on objects and then for social
beings and their interactions

00:45:22.240 --> 00:45:22.990
with each other.

00:45:22.990 --> 00:45:24.570
It seems like
communication and this type

00:45:24.570 --> 00:45:25.986
of communicative
intention that we

00:45:25.986 --> 00:45:29.580
see combines these two kinds
of things, where you have

00:45:29.580 --> 00:45:32.370
an intention to produce
an effect on someone else,

00:45:32.370 --> 00:45:35.340
but by virtue of them
understanding the mental states

00:45:35.340 --> 00:45:39.000
that you have toward the world
and as well as toward them.

00:45:41.640 --> 00:45:44.820
And maybe it's the combining
of these different domains that

00:45:44.820 --> 00:45:47.550
helps infants put
together their possibly

00:45:47.550 --> 00:45:50.990
human-unique, but maybe
not, communication skills.

