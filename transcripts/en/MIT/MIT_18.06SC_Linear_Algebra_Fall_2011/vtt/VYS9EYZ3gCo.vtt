WEBVTT
Kind: captions
Language: en

00:00:04.852 --> 00:00:06.060
DAVID SHIROKOFF: Hi everyone.

00:00:06.060 --> 00:00:07.280
Welcome back.

00:00:07.280 --> 00:00:10.940
So today we're going to tackle
a problem in complex matrices.

00:00:10.940 --> 00:00:13.950
And specifically, we're going
to look at diagonalizing

00:00:13.950 --> 00:00:15.280
a complex matrix.

00:00:15.280 --> 00:00:17.890
So given this matrix
A, we're asked

00:00:17.890 --> 00:00:21.460
to find its eigenvalue matrix
lambda, and its eigenvector

00:00:21.460 --> 00:00:23.150
matrix S.

00:00:23.150 --> 00:00:25.480
And one thing to note
about this matrix A

00:00:25.480 --> 00:00:28.290
is that if we take its
conjugate transpose,

00:00:28.290 --> 00:00:30.310
it's actually equal to itself.

00:00:30.310 --> 00:00:33.810
So in Professor
Strang's book, he

00:00:33.810 --> 00:00:36.170
combines this notation
to be superscript

00:00:36.170 --> 00:00:38.856
H to mean conjugate transpose.

00:00:38.856 --> 00:00:40.980
So if you were to take the
transpose of this matrix

00:00:40.980 --> 00:00:42.510
and then conjugate
all the elements,

00:00:42.510 --> 00:00:46.540
you would find that A equals
its conjugate transpose,

00:00:46.540 --> 00:00:48.635
and we call this
property Hermitian.

00:00:48.635 --> 00:00:50.510
So I'll let you think
about this for a moment

00:00:50.510 --> 00:00:51.718
and I'll be back in a second.

00:01:03.360 --> 00:01:05.120
OK, welcome back.

00:01:05.120 --> 00:01:08.021
So what's the first step in
computing the eigenvectors

00:01:08.021 --> 00:01:09.270
and eigenvalues of the matrix?

00:01:09.270 --> 00:01:13.670
It's to take a look at the
characteristic equation.

00:01:13.670 --> 00:01:16.790
So specifically, we take
det of A minus lambda i.

00:01:21.830 --> 00:01:25.080
And quite possibly, the only
thing new with this problem

00:01:25.080 --> 00:01:29.130
is that the entries of
the matrix A are complex.

00:01:29.130 --> 00:01:34.370
Now, you may have already seen
that lambda's being complex,

00:01:34.370 --> 00:01:36.760
but we're going to work
this out explicitly.

00:01:36.760 --> 00:01:38.700
So if I take the
determinant, we get

00:01:38.700 --> 00:01:45.280
det of 2 minus lambda, 3 minus
lambda, we have 1 minus i,

00:01:45.280 --> 00:01:46.000
1 plus i.

00:01:49.720 --> 00:01:50.950
We want to set this to 0.

00:01:53.664 --> 00:01:55.455
This then gives us a
polynomial for lambda.

00:02:02.630 --> 00:02:09.460
1 plus i, 1 minus i,
set it equal to 0.

00:02:09.460 --> 00:02:11.869
We can expand out this term.

00:02:11.869 --> 00:02:15.980
You get 6 minus 5 lambda
plus lambda squared.

00:02:19.150 --> 00:02:21.540
These two terms you'll
note are complex conjugates

00:02:21.540 --> 00:02:22.520
of each other.

00:02:22.520 --> 00:02:24.900
This tends to make
things simple.

00:02:24.900 --> 00:02:30.610
So we have minus 1 minus i
squared is going to give us 2.

00:02:30.610 --> 00:02:32.680
Because they're
differences of squares,

00:02:32.680 --> 00:02:36.846
the cross terms
involving i cancel,

00:02:36.846 --> 00:02:38.470
and we get the
characteristic equation.

00:02:43.570 --> 00:02:49.259
Lambda squared minus 5
lambda plus 4 equals 0.

00:02:49.259 --> 00:02:51.300
And specifically, we can
factorize this equation.

00:02:54.530 --> 00:03:00.360
We see that there's
roots of minus 1--

00:03:00.360 --> 00:03:02.750
or factorizes into
factors of lambda minus 1

00:03:02.750 --> 00:03:08.690
and lambda minus 4, which then
give us roots of lambda is 1

00:03:08.690 --> 00:03:10.390
and lambda is 4.

00:03:10.390 --> 00:03:12.890
So when one curious
point to note

00:03:12.890 --> 00:03:15.590
is that the eigenvalues
are real in this case.

00:03:15.590 --> 00:03:18.230
1 and 4 are real, whereas the
matrix that we started with

00:03:18.230 --> 00:03:19.430
was complex.

00:03:19.430 --> 00:03:22.720
And this is a general property
of Hermitian matrices.

00:03:22.720 --> 00:03:25.020
So even though they might
be complex matrices,

00:03:25.020 --> 00:03:29.290
Hermitian matrices always
have real eigenvalues.

00:03:29.290 --> 00:03:33.650
So this is the first step when
asked to diagonalize a matrix.

00:03:33.650 --> 00:03:36.030
The second step is to
find the eigenvectors.

00:03:45.195 --> 00:03:46.570
And to do that
what we have to do

00:03:46.570 --> 00:03:49.480
is we have to look at
the cases for lambda

00:03:49.480 --> 00:03:52.577
equals 1 and lambda
is equal 4 separately.

00:03:52.577 --> 00:03:54.910
So let's first look at the
case of lambda is equal to 1.

00:03:59.960 --> 00:04:02.950
And specifically, we're going
to be looking for a vector such

00:04:02.950 --> 00:04:13.210
that A minus lambda*I
times the vector v is 0.

00:04:13.210 --> 00:04:14.670
And if we've done
things properly,

00:04:14.670 --> 00:04:20.720
this matrix A minus
lambda*I should be singular.

00:04:20.720 --> 00:04:25.470
So if we take A minus
lambda*I, we're going to get 1,

00:04:25.470 --> 00:04:32.290
1 minus i; 1 plus
i, 3 minus 1 is 2.

00:04:32.290 --> 00:04:37.410
And I'll write out components
of v, which are v_1 and v_2.

00:04:37.410 --> 00:04:40.290
And we want this to be 0.

00:04:40.290 --> 00:04:46.380
And you'll note that it's almost
always the case that when we

00:04:46.380 --> 00:04:49.540
work out A minus lambda*I,
the second row is going to be

00:04:49.540 --> 00:04:52.050
a constant multiple
of the first row.

00:04:52.050 --> 00:04:56.090
And this must be the case
because these two rows must be

00:04:56.090 --> 00:04:59.040
linearly dependent on each other
for the matrix A minus lambda*I

00:04:59.040 --> 00:05:00.777
to be singular.

00:05:00.777 --> 00:05:02.360
So if you look at
this you might think

00:05:02.360 --> 00:05:04.380
that these two rows
aren't necessarily

00:05:04.380 --> 00:05:06.720
linearly independent.

00:05:06.720 --> 00:05:09.740
But the point is that there's
complex numbers involved.

00:05:09.740 --> 00:05:12.520
And indeed, actually if we
were to multiply this first row

00:05:12.520 --> 00:05:16.990
by 1 plus lambda, we would
get 1 plus lambda and 2.

00:05:16.990 --> 00:05:19.940
And you note that that's
exactly the second row.

00:05:19.940 --> 00:05:22.640
So this second row is
actually 1 plus lambda times

00:05:22.640 --> 00:05:23.880
the first row.

00:05:23.880 --> 00:05:25.550
So these rows are
actually linearly

00:05:25.550 --> 00:05:28.140
dependent on each other.

00:05:28.140 --> 00:05:30.820
So what values of v_1
and v_2 can we take?

00:05:30.820 --> 00:05:34.210
Well, we just need to make
this top row multiplied

00:05:34.210 --> 00:05:36.341
by v_1 and v_2 equal to 0.

00:05:36.341 --> 00:05:38.590
And then because the second
row is a constant multiple

00:05:38.590 --> 00:05:40.490
of the first row, we're
automatically guaranteed

00:05:40.490 --> 00:05:41.781
that the second equation holds.

00:05:44.790 --> 00:05:48.910
So just by looking
at it, I'm going

00:05:48.910 --> 00:05:57.260
to take v_1 is equal to 1
minus i, and v_2 is negative 1.

00:05:57.260 --> 00:06:02.290
So we see that 1 times 1 minus
i minus 1 times 1 minus i

00:06:02.290 --> 00:06:03.810
is going to give us 0.

00:06:03.810 --> 00:06:05.211
So this is one solution.

00:06:05.211 --> 00:06:07.460
And of course, we can take
any constant multiple times

00:06:07.460 --> 00:06:08.880
this eigenvector,
and that's also

00:06:08.880 --> 00:06:10.004
going to be an eigenvector.

00:06:14.810 --> 00:06:16.610
So I'll just write this out.

00:06:16.610 --> 00:06:21.630
1 minus i, minus 1 is the
eigenvector for lambda

00:06:21.630 --> 00:06:24.640
is equal to 1.

00:06:24.640 --> 00:06:29.660
For lambda is equal to 4,
again, A minus lambda*I is going

00:06:29.660 --> 00:06:37.620
to give us negative 2,
1 minus i; 1 plus i,

00:06:37.620 --> 00:06:41.440
3 minus lambda's
going to be minus 1.

00:06:41.440 --> 00:06:43.590
And I'll call this
vector u_1 and u_2.

00:06:47.400 --> 00:06:51.170
And again, we want u_1 and
u_2 equal to 0-- or sorry,

00:06:51.170 --> 00:06:54.880
the matrix multiplied by
[u 1,  u 2] is equal to 0.

00:06:54.880 --> 00:06:57.010
And just by looking
at this again,

00:06:57.010 --> 00:06:59.440
we see that the second row is
actually a constant multiple

00:06:59.440 --> 00:07:01.440
of the first row.

00:07:01.440 --> 00:07:05.720
For example, if we were
to multiply this row

00:07:05.720 --> 00:07:08.367
by negative 2, and
this row by 1 plus i,

00:07:08.367 --> 00:07:10.200
we would see that they're
constant multiples

00:07:10.200 --> 00:07:11.790
of each other.

00:07:11.790 --> 00:07:22.110
So I can take u to be, for
example, 1, and 1 plus i.

00:07:22.110 --> 00:07:23.770
How did I get this?

00:07:23.770 --> 00:07:25.650
Well I just looked at
the second equation

00:07:25.650 --> 00:07:28.580
because it's a little
simpler, and I said, well,

00:07:28.580 --> 00:07:32.470
if I have 1 plus I here, I
can just say multiply it by 1.

00:07:32.470 --> 00:07:35.720
And then minus 1 times 1
plus i, when I add them up,

00:07:35.720 --> 00:07:37.380
is going to vanish.

00:07:37.380 --> 00:07:40.880
So this is how I
get the second one.

00:07:40.880 --> 00:07:43.020
Now there's something
curious going on,

00:07:43.020 --> 00:07:45.740
and this is going to be another
property of Hermitian matrices.

00:07:45.740 --> 00:07:48.540
But if you actually take a
look at this eigenvector,

00:07:48.540 --> 00:07:50.760
it will be orthogonal
to this eigenvector

00:07:50.760 --> 00:07:53.260
when we conjugate the
elements and dot the two

00:07:53.260 --> 00:07:54.594
vectors together.

00:07:54.594 --> 00:07:56.260
So this is another
very special property

00:07:56.260 --> 00:07:59.850
of complex Hermitian matrices.

00:08:02.550 --> 00:08:05.790
OK, so the last step now is to
construct these matrices lambda

00:08:05.790 --> 00:08:08.440
and S. Now we already
know what lambda

00:08:08.440 --> 00:08:12.000
is because it's the diagonal
matrix with the eigenvalues 1

00:08:12.000 --> 00:08:13.580
and 4.

00:08:13.580 --> 00:08:15.620
So we have 1, 0; 0 and 4.

00:08:21.860 --> 00:08:24.920
Now I'm going to do
something special for S.

00:08:24.920 --> 00:08:28.300
I've noted that these
two vectors u and v

00:08:28.300 --> 00:08:30.210
are orthogonal to each other.

00:08:30.210 --> 00:08:32.169
So what do I mean by orthogonal?

00:08:32.169 --> 00:08:35.990
Specifically, if I were to
take v conjugate transpose

00:08:35.990 --> 00:08:38.820
and multiply it by
u, we would end up

00:08:38.820 --> 00:08:45.370
getting 1 plus i minus 1.

00:08:45.370 --> 00:08:48.210
This would be v
conjugate transpose.

00:08:48.210 --> 00:08:54.940
1, 1 plus i, and we see that
when we multiply these out

00:08:54.940 --> 00:08:55.580
we get 0.

00:08:59.460 --> 00:09:01.370
So when we have
orthogonal eigenvectors,

00:09:01.370 --> 00:09:04.240
there's a trick that we can do
to build up this matrix S and S

00:09:04.240 --> 00:09:06.150
inverse.

00:09:06.150 --> 00:09:09.540
What we can do is we
can normalize u and v.

00:09:09.540 --> 00:09:14.210
So specifically, we can take any
constant multiple of u and v,

00:09:14.210 --> 00:09:16.584
and it's still going
to be an eigenvector.

00:09:16.584 --> 00:09:18.750
So what I'm going to do is
I'm going to take u and v

00:09:18.750 --> 00:09:22.020
and multiply them
by their length.

00:09:22.020 --> 00:09:27.420
So for example u, the amplitude
of its top component is 1.

00:09:27.420 --> 00:09:30.310
The amplitude of its
bottom component is 2.

00:09:30.310 --> 00:09:32.910
So notice that the modulus of
the complex number 1 plus I

00:09:32.910 --> 00:09:34.430
is 2.

00:09:34.430 --> 00:09:44.680
So we have-- sorry, it's root 2,
the complex modulus is root 2.

00:09:44.680 --> 00:09:48.990
So the amplitude of the
entire vector is root 3.

00:09:48.990 --> 00:09:52.741
It's 1 plus 2 squared quantity
square rooted, so it's root 3.

00:09:52.741 --> 00:09:54.240
So what we can do
is we can build up

00:09:54.240 --> 00:09:59.450
this matrix S using a
normalization factor of 1

00:09:59.450 --> 00:10:00.220
over root 3.

00:10:05.020 --> 00:10:10.520
And I'm going to take
the-- the first column is

00:10:10.520 --> 00:10:13.980
the first eigenvector that
corresponds to eigenvalue 1.

00:10:13.980 --> 00:10:18.120
And then the second column is
the second eigenvector which

00:10:18.120 --> 00:10:20.870
corresponds to eigenvalue 4.

00:10:20.870 --> 00:10:22.650
And the reason I
put in this root 3

00:10:22.650 --> 00:10:27.670
here is to make this column unit
length 1, and this column unit

00:10:27.670 --> 00:10:29.280
length 1.

00:10:29.280 --> 00:10:38.440
And the reason I do this is
because now this matrix S,

00:10:38.440 --> 00:10:42.550
it's possible to check that this
matrix S is actually unitary,

00:10:42.550 --> 00:10:50.520
which means that its inverse
is actually just equal to it's

00:10:50.520 --> 00:10:53.690
conjugate transpose.

00:10:53.690 --> 00:10:57.100
So this is a very special
property of the eigenvectors

00:10:57.100 --> 00:10:58.090
of a Hermitian matrix.

00:11:00.895 --> 00:11:02.770
And then lastly, I'm
just going to write down

00:11:02.770 --> 00:11:07.390
the diagonalization
of A. So if I have A,

00:11:07.390 --> 00:11:09.580
because I have its
eigenvector matrix S,

00:11:09.580 --> 00:11:12.320
and its eigenvalue
matrix lambda,

00:11:12.320 --> 00:11:16.300
it's possible to decompose A
into a product of S lambda S

00:11:16.300 --> 00:11:17.730
inverse.

00:11:17.730 --> 00:11:25.280
And because S is
unitary, its inverse

00:11:25.280 --> 00:11:29.940
is actually its
conjugate transpose.

00:11:29.940 --> 00:11:32.580
So just to put the
pieces together,

00:11:32.580 --> 00:11:41.520
we have A is equal to S-- which
is 1 over root 3 1 minus i,

00:11:41.520 --> 00:11:51.410
minus 1; 1, 1 plus i-- times
the diagonal matrix [1, 0; 0, 4]

00:11:51.410 --> 00:11:56.850
times S inverse, which is going
to be its conjugate transpose.

00:11:56.850 --> 00:11:59.850
So what I do is I conjugate
each element, so 1 minus i

00:11:59.850 --> 00:12:02.320
becomes 1 plus i and vice versa.

00:12:02.320 --> 00:12:04.530
And then I take the transpose.

00:12:04.530 --> 00:12:06.420
So I get 1 plus i.

00:12:06.420 --> 00:12:08.970
Transposing swaps
the minus 1 and 1.

00:12:12.090 --> 00:12:16.660
And at the end of the day, I get
S inverse is just this matrix

00:12:16.660 --> 00:12:19.120
here.

00:12:19.120 --> 00:12:21.870
And if you were to multiply
these matrices out,

00:12:21.870 --> 00:12:26.660
you would see it you
actually do recover A.

00:12:26.660 --> 00:12:29.900
So just to summarize
quickly, even though we

00:12:29.900 --> 00:12:33.760
were given a complex matrix A,
the process to diagonalize A

00:12:33.760 --> 00:12:35.580
is the same as what
we've seen before.

00:12:35.580 --> 00:12:38.770
The first step is to find
the characteristic equation

00:12:38.770 --> 00:12:39.950
and the eigenvalues.

00:12:39.950 --> 00:12:42.380
And then the second step is
to find the eigenvectors,

00:12:42.380 --> 00:12:44.580
and you do this in
the same procedure.

00:12:44.580 --> 00:12:48.150
But in general, the
eigenvectors can be complex.

00:12:48.150 --> 00:12:52.440
And for this very special
case, when A is Hermitian,

00:12:52.440 --> 00:12:54.530
the eigenvalues are real,
and the eigenvectors

00:12:54.530 --> 00:12:56.750
are orthogonal to each other.

00:12:56.750 --> 00:13:00.240
So I think I'll conclude here,
and I'll see you next time.

