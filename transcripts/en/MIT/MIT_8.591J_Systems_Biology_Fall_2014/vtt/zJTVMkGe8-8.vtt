WEBVTT
Kind: captions
Language: en

00:00:00.001 --> 00:00:02.500
NARRATOR: The following content
is provided under a Creative

00:00:02.500 --> 00:00:04.019
Commons license.

00:00:04.019 --> 00:00:06.360
Your support will help
MIT OpenCourseWare

00:00:06.360 --> 00:00:10.730
continue to offer high quality
educational resources for free.

00:00:10.730 --> 00:00:13.340
To make a donation or
view additional materials

00:00:13.340 --> 00:00:17.236
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:17.236 --> 00:00:17.861
at ocw.mit.edu.

00:00:21.950 --> 00:00:24.240
PROFESSOR: So in
terms of what we're

00:00:24.240 --> 00:00:26.007
going to be
discussing today, it's

00:00:26.007 --> 00:00:27.590
various aspects of
feed-forward loops.

00:00:27.590 --> 00:00:30.750
So first of all, we will go
over this idea of a network

00:00:30.750 --> 00:00:31.644
motif in more detail.

00:00:31.644 --> 00:00:33.560
We talked it about a
little bit in the context

00:00:33.560 --> 00:00:35.150
of auto regulation.

00:00:35.150 --> 00:00:38.140
There is a simple argument
there that auto regulation

00:00:38.140 --> 00:00:39.090
is a network motif.

00:00:39.090 --> 00:00:42.340
And in order to understand
how to detect network motifs,

00:00:42.340 --> 00:00:44.427
in general we have to look
at a little more detail

00:00:44.427 --> 00:00:46.760
at these subgraphs and the
frequency that they'll appear

00:00:46.760 --> 00:00:48.590
and so forth.

00:00:48.590 --> 00:00:51.260
And then after seeing that the
feed-forward loop is a network

00:00:51.260 --> 00:00:53.093
motif, then there's
this question-- oh, well

00:00:53.093 --> 00:00:55.150
what might be the
functional significance?

00:00:55.150 --> 00:00:57.720
And in the chapter
that you just read,

00:00:57.720 --> 00:01:00.720
you found this so-called
coherent type one

00:01:00.720 --> 00:01:03.560
feed-forward loop has a
nice attribute-- that it's

00:01:03.560 --> 00:01:06.530
sign sensitive delay element.

00:01:06.530 --> 00:01:10.180
The incoherent type
one has the feature

00:01:10.180 --> 00:01:12.850
that it's a pulse generator,
and kind of related to that,

00:01:12.850 --> 00:01:15.720
it can also speed up
the response time.

00:01:15.720 --> 00:01:19.370
So it can make the response
time for turning on shorter.

00:01:19.370 --> 00:01:21.332
So speed up response
rate if you'd like.

00:01:21.332 --> 00:01:22.707
We'll also maybe
say a little bit

00:01:22.707 --> 00:01:25.160
that there's been later
work demonstrating

00:01:25.160 --> 00:01:31.180
that the incoherent type one
can also access a fold detector.

00:01:31.180 --> 00:01:35.130
So it can sense changes
in the fold change

00:01:35.130 --> 00:01:36.739
of concentrations of proteins.

00:01:36.739 --> 00:01:38.280
And then finally,
we'll say something

00:01:38.280 --> 00:01:41.730
about how you can extend
these ideas of a network motif

00:01:41.730 --> 00:01:42.660
to larger structures.

00:01:42.660 --> 00:01:45.875
In particular, how you get
useful temporal programs.

00:01:54.180 --> 00:01:56.940
So we start out
with this network

00:01:56.940 --> 00:01:59.570
that is kind of--
our base network

00:01:59.570 --> 00:02:04.040
is this transcription network
characterized in E. coli.

00:02:04.040 --> 00:02:06.670
And we've already
talked about it some.

00:02:06.670 --> 00:02:12.590
So there's going to be some
measure the number of nodes

00:02:12.590 --> 00:02:14.660
and the number of edges.

00:02:14.660 --> 00:02:18.940
So we have N nodes,
and we have E edges.

00:02:21.660 --> 00:02:25.040
This is from experimental
measurements of-- what

00:02:25.040 --> 00:02:28.030
is it that regulates what?

00:02:28.030 --> 00:02:33.620
Now from this, we'll have
some set of directed edges,

00:02:33.620 --> 00:02:35.840
because indeed, we
know that there's

00:02:35.840 --> 00:02:38.500
going to be some transcription
factor that will regulates

00:02:38.500 --> 00:02:39.440
some other protein.

00:02:39.440 --> 00:02:40.981
And what we want to
know is are there

00:02:40.981 --> 00:02:43.440
patterns that occur
more regularly than what

00:02:43.440 --> 00:02:46.720
you'd expect based on chance.

00:02:46.720 --> 00:02:48.664
Now auto regulation
we found indeed

00:02:48.664 --> 00:02:50.830
appeared more regularly,
or more frequently than you

00:02:50.830 --> 00:02:52.340
would expect by chance.

00:02:52.340 --> 00:02:54.650
And there are a limited
number of other network motifs

00:02:54.650 --> 00:02:56.330
that have that property.

00:02:56.330 --> 00:02:58.720
And in particular, we'll
kind of analyze this idea

00:02:58.720 --> 00:03:03.120
of the feed-forward loop.

00:03:03.120 --> 00:03:08.360
Now in the network that we
kind of talked about a lot,

00:03:08.360 --> 00:03:16.720
there were around 400 genes or
proteins, and then around 500

00:03:16.720 --> 00:03:19.440
observed edges.

00:03:19.440 --> 00:03:23.460
And this would be
interactions or regulation.

00:03:28.670 --> 00:03:30.990
Now there's this
idea of sparseness.

00:03:34.230 --> 00:03:36.770
Can somebody remind
us maybe what this

00:03:36.770 --> 00:03:39.280
is supposed to tell us about?

00:03:39.280 --> 00:03:40.066
Yes.

00:03:40.066 --> 00:03:42.253
AUDIENCE: There
should be roughly N

00:03:42.253 --> 00:03:44.930
squared in total edges.

00:03:44.930 --> 00:03:48.674
PROFESSOR: So there's N
squared possible edges.

00:03:48.674 --> 00:03:51.804
AUDIENCE: If you just connected
everything that you connected,

00:03:51.804 --> 00:03:57.384
and so N is about the order of
E. So roughly, there's only 1

00:03:57.384 --> 00:03:58.694
out of 500--

00:03:58.694 --> 00:04:00.110
PROFESSOR: And we
should be clear,

00:04:00.110 --> 00:04:02.609
this N squared possible-- we
might even want to add directed

00:04:02.609 --> 00:04:12.340
edges since we're-- and what we
see is that the actual number

00:04:12.340 --> 00:04:16.130
of edges that we observe in this
real network is actually around

00:04:16.130 --> 00:04:22.810
order N. So this sparseness,
which is also this probability

00:04:22.810 --> 00:04:25.960
P-- if we're going to make a
network somehow that has some

00:04:25.960 --> 00:04:28.460
similar property to
the observed network,

00:04:28.460 --> 00:04:32.910
there's some probably P that
an actual edge will appear.

00:04:32.910 --> 00:04:35.850
And this is given by
the observed number

00:04:35.850 --> 00:04:39.967
of edges divided by the total
possible number of edges,

00:04:39.967 --> 00:04:41.050
which is indeed N squared.

00:04:44.140 --> 00:04:46.350
And what you see is that,
at least in this network,

00:04:46.350 --> 00:04:48.230
this P is much less than one.

00:04:51.049 --> 00:04:52.465
So this is what
we mean by sparse.

00:04:56.560 --> 00:04:59.270
Now you can also think
about the question

00:04:59.270 --> 00:05:06.720
of how many edges does a typical
gene have emanating from it?

00:05:06.720 --> 00:05:09.360
Well, you can see
that it's around one.

00:05:09.360 --> 00:05:11.490
Of course, each edge
connects two things,

00:05:11.490 --> 00:05:13.690
so if you were to
say on average,

00:05:13.690 --> 00:05:17.860
each gene has of one edge going
out, and one edge going in.

00:05:17.860 --> 00:05:19.375
Of course, there
might be a reason

00:05:19.375 --> 00:05:23.720
to believe that these
averages are not as--

00:05:23.720 --> 00:05:25.040
well they can be misleading.

00:05:25.040 --> 00:05:26.765
And why might the
average be misleading?

00:05:29.525 --> 00:05:30.025
Yes.

00:05:30.025 --> 00:05:32.070
AUDIENCE: The distribution
for heavy tails.

00:05:32.070 --> 00:05:33.020
PROFESSOR: Right,
it's going to be

00:05:33.020 --> 00:05:35.561
a distribution with heavy tails,
in particular on which side?

00:05:41.240 --> 00:05:42.810
So the average is
always the average,

00:05:42.810 --> 00:05:46.770
but I guess the
question is there

00:05:46.770 --> 00:05:49.350
are going to be some proteins,
or some genes with many

00:05:49.350 --> 00:05:52.500
of these outgoing edges.

00:05:52.500 --> 00:05:55.530
And more generally,
do you expect

00:05:55.530 --> 00:06:00.580
that-- there's a natural
limitation in all this.

00:06:00.580 --> 00:06:02.050
Part of the value
of this approach

00:06:02.050 --> 00:06:05.170
is that we're abstracting away
from a lot of the microscopic

00:06:05.170 --> 00:06:06.254
or the biological details.

00:06:06.254 --> 00:06:08.753
But every now and then it's
good to go in and think about it

00:06:08.753 --> 00:06:09.340
a little bit.

00:06:09.340 --> 00:06:12.680
So there's a good reason you'd
expect many proteins to not

00:06:12.680 --> 00:06:15.150
have any outgoing edges,
and why would that be?

00:06:20.450 --> 00:06:21.150
Yes.

00:06:21.150 --> 00:06:23.630
AUDIENCE: For example,
a detector protein,

00:06:23.630 --> 00:06:26.029
that only evolved one
specific function or another.

00:06:26.029 --> 00:06:27.570
PROFESSOR: So there
are some proteins

00:06:27.570 --> 00:06:30.050
that have rather specific
functions, you might say.

00:06:30.050 --> 00:06:31.130
And I think that's true.

00:06:31.130 --> 00:06:31.790
I think that's part of it.

00:06:31.790 --> 00:06:33.206
But there's maybe
something that's

00:06:33.206 --> 00:06:35.630
maybe even a little
bit more general that's

00:06:35.630 --> 00:06:36.650
worth pointing out here.

00:06:36.650 --> 00:06:37.150
Yeah.

00:06:37.150 --> 00:06:39.358
AUDIENCE: Anything that's
not a transcription factor.

00:06:39.358 --> 00:06:42.220
PROFESSOR: Anything that's not
a transcription factor, right.

00:06:42.220 --> 00:06:44.550
We say transcription factor,
we don't ever really quite

00:06:44.550 --> 00:06:45.110
specify.

00:06:45.110 --> 00:06:46.800
But what it means is
that it's something

00:06:46.800 --> 00:06:48.530
that can affect the
transcription of other things.

00:06:48.530 --> 00:06:50.532
So we're talking about
the function of it

00:06:50.532 --> 00:06:51.906
when we say
transcription factor.

00:06:51.906 --> 00:06:54.980
And a majority of the
proteins in any genome

00:06:54.980 --> 00:06:56.670
are not transcription factors.

00:06:56.670 --> 00:07:01.240
What that means is that
they, to first order, cannot,

00:07:01.240 --> 00:07:05.470
at least directly influence the
transcription of other genes.

00:07:05.470 --> 00:07:09.100
So this is a reflection of
this power law distribution

00:07:09.100 --> 00:07:10.210
that we observe.

00:07:10.210 --> 00:07:12.740
And so you could argue
well maybe not a surprise

00:07:12.740 --> 00:07:14.882
that this outgoing edge
distribution is power law,

00:07:14.882 --> 00:07:17.230
because we know that there are
some transcription factors that

00:07:17.230 --> 00:07:19.229
control many things, and
there are many proteins

00:07:19.229 --> 00:07:22.299
they don't control
the transcription

00:07:22.299 --> 00:07:23.590
of any other proteins directly.

00:07:26.280 --> 00:07:29.890
But at least it's
just useful to know

00:07:29.890 --> 00:07:32.060
what the properties of
this thing are on average

00:07:32.060 --> 00:07:34.810
even though, for
the outgoing edges,

00:07:34.810 --> 00:07:36.610
the average is a
little bit dangerous.

00:07:36.610 --> 00:07:39.450
Because it's really
that most proteins don't

00:07:39.450 --> 00:07:42.010
have any outgoing edges,
and then some have many.

00:07:46.014 --> 00:07:47.680
All right so this is
this probability P.

00:07:47.680 --> 00:07:50.790
And this is going to be
useful, because this P will

00:07:50.790 --> 00:07:52.350
appear when we're
trying to construct

00:07:52.350 --> 00:07:53.266
these random networks.

00:07:55.654 --> 00:07:57.070
So what we're going
to do is we're

00:07:57.070 --> 00:08:02.670
going to ask how frequently or
how many of a given subgraph

00:08:02.670 --> 00:08:05.840
you expect to appear
in this larger network

00:08:05.840 --> 00:08:06.590
that we have here?

00:08:09.710 --> 00:08:17.310
And we're going to characterize
each of these subgraphs

00:08:17.310 --> 00:08:19.425
by two properties.

00:08:25.120 --> 00:08:29.720
And in particular, if we're
going to analyze some smaller

00:08:29.720 --> 00:08:31.310
graph, we just
have to keep track

00:08:31.310 --> 00:08:37.020
of how many nodes
are in the subgraph,

00:08:37.020 --> 00:08:40.059
and how many edges
are in the subgraph.

00:08:52.710 --> 00:08:55.820
So for example, if we
have auto regulation,

00:08:55.820 --> 00:08:58.670
then we're just talking
about little n equal to one,

00:08:58.670 --> 00:09:00.490
little g equal to one.

00:09:00.490 --> 00:09:04.699
Whereas in the case of
this feed-forward loop,

00:09:04.699 --> 00:09:06.240
what is little n
and what's little g?

00:09:19.720 --> 00:09:23.030
Well we can count now.

00:09:23.030 --> 00:09:27.311
Here n is equal to three,
one, two, three, and g

00:09:27.311 --> 00:09:28.319
is also equal to three.

00:09:28.319 --> 00:09:29.860
And we're going to
find that actually

00:09:29.860 --> 00:09:32.390
the fact that these
two numbers are equal

00:09:32.390 --> 00:09:35.610
is somehow very
relevant in thinking

00:09:35.610 --> 00:09:37.760
about the dynamics of
these networks later.

00:09:42.100 --> 00:09:45.950
In this framework, when
I just draw an arrow

00:09:45.950 --> 00:09:48.710
in the context of
a generic subgraph,

00:09:48.710 --> 00:09:53.690
am I necessarily trying to
say that this is up regulation

00:09:53.690 --> 00:09:55.557
of x up regulating y?

00:09:55.557 --> 00:09:57.260
No.

00:09:57.260 --> 00:10:00.206
So this is a bit confusing
because depending

00:10:00.206 --> 00:10:02.080
on the context, sometimes
the arrows actually

00:10:02.080 --> 00:10:04.540
do mean up regulation, sometimes
they just mean regulate.

00:10:04.540 --> 00:10:06.790
And in this case, where we're
talking about subgraphs,

00:10:06.790 --> 00:10:09.710
we're just saying
that x regulates y

00:10:09.710 --> 00:10:11.380
in one way or another.

00:10:11.380 --> 00:10:13.880
This is also how
we're going to write

00:10:13.880 --> 00:10:16.120
the so-called coherent
type one feed-forward loop,

00:10:16.120 --> 00:10:20.850
but for right now this is just
a generic feed-forward loop.

00:10:20.850 --> 00:10:21.594
Yes.

00:10:21.594 --> 00:10:23.490
AUDIENCE: Regulate means
positive regulation?

00:10:23.490 --> 00:10:24.115
PROFESSOR: Yes.

00:10:26.319 --> 00:10:26.985
We say activate.

00:10:33.800 --> 00:10:36.130
So the way that we
think about is we ask,

00:10:36.130 --> 00:10:43.232
what's the expected
number of some subgraph G?

00:10:43.232 --> 00:10:45.440
And indeed what we're going
to be doing for right now

00:10:45.440 --> 00:10:50.670
is assuming this
Erdos-Renyi random network.

00:10:50.670 --> 00:10:53.300
Now what we're told is that
this is going to look something

00:10:53.300 --> 00:10:55.000
like the following.

00:11:05.490 --> 00:11:10.045
could somebody explain
one of these three terms?

00:11:16.690 --> 00:11:17.740
Yes.

00:11:17.740 --> 00:11:20.680
AUDIENCE: Well you
have to select edges,

00:11:20.680 --> 00:11:22.150
and you have choose
them correctly.

00:11:22.150 --> 00:11:25.805
So for each one, there's
a chance that [INAUDIBLE].

00:11:25.805 --> 00:11:27.680
PROFESSOR: So for here
what we're going to do

00:11:27.680 --> 00:11:32.050
is, for example in this
context, we'll say,

00:11:32.050 --> 00:11:34.090
we're going to
choose these three.

00:11:34.090 --> 00:11:38.430
And now the question is, we
have to put in three edges

00:11:38.430 --> 00:11:41.710
as well to connect those
nodes, and each one of them

00:11:41.710 --> 00:11:47.450
has some probability P of
actually somehow appearing.

00:11:47.450 --> 00:11:50.050
Because this is
what we're keeping

00:11:50.050 --> 00:11:53.140
constant from the
original network.

00:11:53.140 --> 00:11:55.670
So we're assuming that we
have this Erdos-Renyi network

00:11:55.670 --> 00:11:59.000
with the same number,
say roughly 400 nodes,

00:11:59.000 --> 00:12:03.140
and then what we're going to
do is grab maybe three of them

00:12:03.140 --> 00:12:05.760
and ask, all right, what's
the probability that we

00:12:05.760 --> 00:12:08.044
get these three actual edges?

00:12:08.044 --> 00:12:08.960
So you get P to the g.

00:12:11.650 --> 00:12:14.260
Now where does this
term come from?

00:12:22.236 --> 00:12:22.735
Yes.

00:12:22.735 --> 00:12:24.610
AUDIENCE: Selecting a node.

00:12:24.610 --> 00:12:27.030
PROFESSOR: So we're going
to be selecting N nodes.

00:12:27.030 --> 00:12:30.080
We're assuming that
this N is much larger.

00:12:30.080 --> 00:12:32.400
We're assuming that
we have a big network,

00:12:32.400 --> 00:12:35.374
so it's much larger than
the size of the subgraph

00:12:35.374 --> 00:12:36.790
we're looking at,
so we don't have

00:12:36.790 --> 00:12:39.780
to think about n times n minus
one, n minus two, and so forth.

00:12:42.910 --> 00:12:46.160
And then there's this
factor a here as well,

00:12:46.160 --> 00:12:50.870
which, depending on how
you do your counting--

00:12:50.870 --> 00:12:55.220
this is a little bit tricky,
but what was a again?

00:12:55.220 --> 00:12:56.154
Yes.

00:12:56.154 --> 00:12:59.402
AUDIENCE: It's the number of
ways to arrange the edges.

00:12:59.402 --> 00:13:00.885
It's a symmetry factor.

00:13:00.885 --> 00:13:02.510
PROFESSOR: Yes, it's
a symmetry factor,

00:13:02.510 --> 00:13:09.050
it's a way of-- there are
multiple ways of looking

00:13:09.050 --> 00:13:10.160
at this.

00:13:10.160 --> 00:13:11.820
You could think about
it as the number

00:13:11.820 --> 00:13:14.400
of ways of rearranging
x, y, and z

00:13:14.400 --> 00:13:21.599
and having the same
subgraph, the exact same one.

00:13:21.599 --> 00:13:23.140
In this case, there's
actually no way

00:13:23.140 --> 00:13:25.835
to rearrange x, y, and
z to have the same one.

00:13:25.835 --> 00:13:29.410
Because x occupies
a special spot,

00:13:29.410 --> 00:13:31.900
y is indeed again a
special spot. z is special.

00:13:31.900 --> 00:13:34.080
So there's no
permutations that you

00:13:34.080 --> 00:13:35.740
can do to get the same thing.

00:13:35.740 --> 00:13:40.280
Whereas if you have this
repressilator-- now here

00:13:40.280 --> 00:13:41.875
I'm just drawing
this as an arrow,

00:13:41.875 --> 00:13:43.250
because again
we're just thinking

00:13:43.250 --> 00:13:45.460
about the generic
version of these things.

00:13:45.460 --> 00:13:48.840
So it's just when we have x,
y, and z regulating each other.

00:13:48.840 --> 00:13:53.600
In this case, you can get the
same network by rotating these

00:13:53.600 --> 00:13:54.410
x's, y's, and z's.

00:13:54.410 --> 00:13:56.160
So in this case, you
get a equal to three.

00:14:00.570 --> 00:14:02.820
For pretty much
all the conclusions

00:14:02.820 --> 00:14:06.280
we're going to talk about,
these factors of one, two, three

00:14:06.280 --> 00:14:07.900
don't actually end
up being relevant.

00:14:07.900 --> 00:14:10.530
But it's good to know
that they indeed exist.

00:14:15.080 --> 00:14:25.960
So this is fine, but it's useful
to express this in another way.

00:14:25.960 --> 00:14:32.070
In particular, we can
always define this lambda,

00:14:32.070 --> 00:14:37.290
which is E/N, as the mean
number of incoming edges

00:14:37.290 --> 00:14:40.120
or the mean number
of outgoing edges.

00:14:40.120 --> 00:14:44.850
And with this, we
can express this guy

00:14:44.850 --> 00:14:47.510
in a way that is
surprisingly informative.

00:15:04.360 --> 00:15:07.260
Nothing happened
except that we just

00:15:07.260 --> 00:15:09.060
plugged this thing in here.

00:15:09.060 --> 00:15:11.151
But by doing, we
see something that's

00:15:11.151 --> 00:15:13.650
kind of interesting, which is
that there's reason to believe

00:15:13.650 --> 00:15:17.890
that for many of these networks,
this lambda, this mean number

00:15:17.890 --> 00:15:21.632
of incoming edges, that
lambda will be roughly

00:15:21.632 --> 00:15:23.840
similar-- whether you're
talking about a network that

00:15:23.840 --> 00:15:31.870
is 500 nodes large
or 5,000 nodes large.

00:15:31.870 --> 00:15:33.820
And indeed in this
case, it's around one.

00:15:33.820 --> 00:15:38.590
It's just over one.

00:15:38.590 --> 00:15:44.230
So that means that when we think
about the number of subgraphs

00:15:44.230 --> 00:15:47.210
that will be in
this large network,

00:15:47.210 --> 00:15:51.870
it scales with the size
of the overall network.

00:15:51.870 --> 00:15:54.110
We had this little
n minus little g.

00:15:56.670 --> 00:16:00.990
And in particular, in cases
when you're analyzing a subgraph

00:16:00.990 --> 00:16:03.640
with the same number
of nodes as edges,

00:16:03.640 --> 00:16:05.530
then you just get
n to the 0, and it

00:16:05.530 --> 00:16:09.200
doesn't scale with a number.

00:16:09.200 --> 00:16:11.540
So for those, and
indeed basically

00:16:11.540 --> 00:16:15.370
for all those subgraphs where
little n is equal to little g--

00:16:15.370 --> 00:16:19.770
then you expect of
order one of those--

00:16:19.770 --> 00:16:22.280
if lambda is around
one, then you

00:16:22.280 --> 00:16:25.480
expect of order one of those
to appear in the network.

00:16:25.480 --> 00:16:30.370
And so from a very simple
standpoint, the networks,

00:16:30.370 --> 00:16:33.497
like the feed-forward loop that
we see that is a network motif,

00:16:33.497 --> 00:16:35.330
the expectation is that
in a random network,

00:16:35.330 --> 00:16:37.500
you would get around
one, maybe two.

00:16:37.500 --> 00:16:41.310
Whereas if you see many
of them, dozens, then it's

00:16:41.310 --> 00:16:42.340
indeed a network motif.

00:16:47.840 --> 00:16:49.590
Are there any
questions about how

00:16:49.590 --> 00:16:52.410
that appeared in the chapter
or the argument there?

00:17:07.260 --> 00:17:13.910
So indeed, we can
actually just then say,

00:17:13.910 --> 00:17:17.220
for the feed-forward
loop, we can just

00:17:17.220 --> 00:17:22.440
go ahead and ask how many
were observed in E. coli,

00:17:22.440 --> 00:17:26.530
this network that was
actually observed?

00:17:26.530 --> 00:17:31.910
And this was 42 I believe.

00:17:31.910 --> 00:17:35.230
Whereas if you do this analysis
for the Erdos-Renyi network,

00:17:35.230 --> 00:17:39.710
you get 1.7 plus or minus 1.3.

00:17:39.710 --> 00:17:41.422
Because these things
appear randomly,

00:17:41.422 --> 00:17:42.880
they should be
Poisson distributed.

00:17:46.950 --> 00:17:50.409
So you expect of
order one of them

00:17:50.409 --> 00:17:52.450
to appear in a random
network with this same kind

00:17:52.450 --> 00:17:54.200
of sparseness, the
same number of edges.

00:17:54.200 --> 00:17:56.200
But we actually observe
this much larger number.

00:17:56.200 --> 00:17:58.610
So then you can
say, all right, this

00:17:58.610 --> 00:18:03.450
is evidence for the feed-forwad
loop being a network motif.

00:18:03.450 --> 00:18:06.770
That for some
reason, this subgraph

00:18:06.770 --> 00:18:08.150
appears more
frequently than what

00:18:08.150 --> 00:18:09.640
you'd expect based on genes.

00:18:12.560 --> 00:18:15.100
Of course, we alluded to
this on the end of class

00:18:15.100 --> 00:18:17.810
on Tuesday, that maybe this
Erdos-Renyi network is not

00:18:17.810 --> 00:18:21.200
the proper null model or
null network to be using.

00:18:21.200 --> 00:18:23.666
And maybe we should use one
of these degree-preserving

00:18:23.666 --> 00:18:24.166
networks.

00:18:28.700 --> 00:18:33.040
So maybe we should try to
preserve more the properties

00:18:33.040 --> 00:18:34.850
of the original network.

00:18:34.850 --> 00:18:42.492
And So can because somebody
say a little bit of what

00:18:42.492 --> 00:18:43.700
we mean by degree-preserving?

00:18:46.950 --> 00:18:49.600
There's an element that our null
model here already preserves

00:18:49.600 --> 00:18:52.110
something about the degree.

00:18:52.110 --> 00:18:54.530
It preserves the means.

00:18:54.530 --> 00:18:57.890
So it's not just that we picked
up some random null model,

00:18:57.890 --> 00:18:59.720
some random ER network.

00:18:59.720 --> 00:19:03.140
So what is it that
we want to keep

00:19:03.140 --> 00:19:07.210
track of in this
degree-preserving network?

00:19:07.210 --> 00:19:09.195
I saw a hand over there,
but I'm not trying

00:19:09.195 --> 00:19:10.320
to call on people randomly.

00:19:10.320 --> 00:19:12.410
Although I'm going to
start in the second half

00:19:12.410 --> 00:19:14.569
of the semester,
just after drop date.

00:19:14.569 --> 00:19:16.066
[LAUGHTER]

00:19:21.270 --> 00:19:24.080
So we're going to
preserve not only

00:19:24.080 --> 00:19:27.450
the mean of the incoming
and outgoing edges,

00:19:27.450 --> 00:19:30.120
but also the actual
degree distribution.

00:19:30.120 --> 00:19:32.080
In a very concrete
way, we can actually

00:19:32.080 --> 00:19:34.610
just say that each node
actually does maintain

00:19:34.610 --> 00:19:38.300
the exact same number of edges.

00:19:38.300 --> 00:19:42.890
So in particular, here
we say that all nodes

00:19:42.890 --> 00:19:49.556
maintain their
degree distribution

00:19:49.556 --> 00:19:54.574
or maintain number of
incoming and outgoing.

00:20:03.260 --> 00:20:05.786
And there was a simple
algorithm for doing that.

00:20:05.786 --> 00:20:07.160
If you recall,
what you can do is

00:20:07.160 --> 00:20:11.710
you can just take two edges
randomly and just swap

00:20:11.710 --> 00:20:13.080
the locations.

00:20:13.080 --> 00:20:14.940
And you do that
many, many times,

00:20:14.940 --> 00:20:19.290
and you end up maintaining both
the incoming and the outgoing

00:20:19.290 --> 00:20:20.410
number of edges.

00:20:23.350 --> 00:20:26.440
And if you do this analysis
on a degree-preserving random

00:20:26.440 --> 00:20:31.060
network, you get a seven
plus or minus five.

00:20:31.060 --> 00:20:35.030
So this makes a big difference.

00:20:35.030 --> 00:20:38.590
So if, for example, the
experimentally-observed network

00:20:38.590 --> 00:20:41.370
had one of these feed-forward
loops, then what you'd see

00:20:41.370 --> 00:20:44.036
is that actually, comparing
to the Erdos-Renyi,

00:20:44.036 --> 00:20:46.410
you would have said, oh well
that that's a network motif.

00:20:46.410 --> 00:20:48.243
Whereas comparing to
this degree-preserving,

00:20:48.243 --> 00:20:50.680
you would have said it's not.

00:20:50.680 --> 00:20:51.929
Yes.

00:20:51.929 --> 00:20:54.220
AUDIENCE: I don't know why
I haven't asked this before,

00:20:54.220 --> 00:20:58.475
but is it also true that this
degree-preserving thing is

00:20:58.475 --> 00:21:00.016
roughly Poisson in
terms of-- I mean,

00:21:00.016 --> 00:21:02.560
should we expect
deviations always?

00:21:02.560 --> 00:21:05.790
PROFESSOR: Yeah, it's close.

00:21:05.790 --> 00:21:10.850
But I think it ends
up not being quite.

00:21:10.850 --> 00:21:13.510
But it is close.

00:21:13.510 --> 00:21:15.510
AUDIENCE: So is the entire
transcription network

00:21:15.510 --> 00:21:18.810
for E. coli?

00:21:18.810 --> 00:21:22.870
PROFESSOR: So I think that
it is, certainly now--

00:21:22.870 --> 00:21:26.710
well you'll notice that
here there are 400 genes.

00:21:26.710 --> 00:21:29.935
How many genes does
E. coli have, anybody?

00:21:33.860 --> 00:21:35.950
A few thousand.

00:21:35.950 --> 00:21:39.957
So the network that we
analyzed in that original paper

00:21:39.957 --> 00:21:42.040
was not the full transcription
network of E. coli.

00:21:46.351 --> 00:21:48.746
AUDIENCE: How do people--
how do figure out

00:21:48.746 --> 00:21:50.183
the whole transcription network?

00:21:50.183 --> 00:21:51.810
It actually sounds pretty hard.

00:21:51.810 --> 00:21:53.768
PROFESSOR: Well figuring
out and any part of it

00:21:53.768 --> 00:21:56.940
is actually hard in some ways.

00:21:56.940 --> 00:21:58.440
The way that they
actually annotated

00:21:58.440 --> 00:22:02.380
this particular
network, I'm not sure.

00:22:02.380 --> 00:22:05.840
I mean what kind
of date would you

00:22:05.840 --> 00:22:07.620
need in order to get at this?

00:22:07.620 --> 00:22:12.160
Does anybody have any-- I
mean, if I asked you to do this

00:22:12.160 --> 00:22:13.510
in your lab, what would you do?

00:22:26.119 --> 00:22:28.160
So you could actually use
a computational program

00:22:28.160 --> 00:22:32.720
to try to actually
estimate binding affinities

00:22:32.720 --> 00:22:37.030
of these proteins to the DNA.

00:22:37.030 --> 00:22:38.660
And these days
actually experimentally

00:22:38.660 --> 00:22:42.360
you can actually just measure
for the entire proteome

00:22:42.360 --> 00:22:46.427
basically, just the affinity of
binding to different promoters.

00:22:46.427 --> 00:22:48.010
Of course that doesn't
prove that it's

00:22:48.010 --> 00:22:52.150
going to regulate expression,
but that at least points you

00:22:52.150 --> 00:22:53.619
in the right direction.

00:22:53.619 --> 00:22:55.160
Then you could
actually, if you want,

00:22:55.160 --> 00:22:58.910
you could just
experimentally go and put

00:22:58.910 --> 00:23:00.910
this protein on an
inducible promoter and just

00:23:00.910 --> 00:23:04.300
see if it does
regulate expression.

00:23:04.300 --> 00:23:07.050
At this stage, for
something like E. coli,

00:23:07.050 --> 00:23:11.390
we have collections
of strains where

00:23:11.390 --> 00:23:14.640
every gene has been removed.

00:23:14.640 --> 00:23:17.760
We have collections where
every gene has been tagged.

00:23:17.760 --> 00:23:21.350
And of course, when I say every,
this means that it was tried

00:23:21.350 --> 00:23:24.030
to make it for every and then
of course if it's an essential

00:23:24.030 --> 00:23:26.110
gene you can't remove it.

00:23:26.110 --> 00:23:26.677
And

00:23:26.677 --> 00:23:29.010
In some cases it's hard to
attack a fluorescent protein,

00:23:29.010 --> 00:23:30.170
and so forth.

00:23:30.170 --> 00:23:32.420
But there are
collections both E. coli

00:23:32.420 --> 00:23:37.014
and for budding yeast
where this has been done.

00:23:40.950 --> 00:23:42.010
Any other questions?

00:23:47.550 --> 00:23:50.910
Can somebody say
why it might be--

00:23:50.910 --> 00:23:52.540
is this a surprise
that this number is

00:23:52.540 --> 00:23:53.540
larger than this number?

00:23:58.010 --> 00:24:00.760
And in particular, would
the degree-preserving random

00:24:00.760 --> 00:24:04.600
network have a larger
expectation for every subgraph?

00:24:07.730 --> 00:24:08.955
No.

00:24:08.955 --> 00:24:10.830
But in particular, for
the feed-forward loop,

00:24:10.830 --> 00:24:15.160
can hear somebody say why
we should have expected

00:24:15.160 --> 00:24:17.240
that the degree-preserving
would have a larger

00:24:17.240 --> 00:24:19.045
number than the-- yeah.

00:24:19.045 --> 00:24:22.510
AUDIENCE: All the measures
have one outgoing edge,

00:24:22.510 --> 00:24:26.470
and so [INAUDIBLE] distribution
towards lower numbers

00:24:26.470 --> 00:24:27.955
of outgoing edges.

00:24:27.955 --> 00:24:33.160
And so you would expect
more from forward loops.

00:24:36.320 --> 00:24:39.042
PROFESSOR: I think that
the explanation had

00:24:39.042 --> 00:24:40.500
the right flavor,
but I think there

00:24:40.500 --> 00:24:45.450
were two inversions in there
that-- like a not and a not

00:24:45.450 --> 00:24:50.880
turned into a-- Incidentally,
this is a non-sequitur,

00:24:50.880 --> 00:24:52.370
but this happened to me once.

00:24:52.370 --> 00:24:55.790
The airport in San Francisco--
I was going to the airport,

00:24:55.790 --> 00:24:57.984
I got the wrong
airline in my head.

00:24:57.984 --> 00:24:59.650
So I thought I was
on the wrong airline,

00:24:59.650 --> 00:25:03.920
so I went to the wrong
terminal, but then it turned out

00:25:03.920 --> 00:25:06.590
that I also was wrong about
which airline was in which

00:25:06.590 --> 00:25:09.110
terminal, so then I was
actually the right terminal even

00:25:09.110 --> 00:25:10.902
though I had just
made two mistakes.

00:25:10.902 --> 00:25:13.110
But you can't account on
this happening all the time.

00:25:16.350 --> 00:25:18.680
But I think there were two
things that were mixed up

00:25:18.680 --> 00:25:21.460
in that explanation.

00:25:21.460 --> 00:25:22.202
Yeah.

00:25:22.202 --> 00:25:23.743
AUDIENCE: For a
transcription factor,

00:25:23.743 --> 00:25:27.986
it has many outgoing--
outcoming edges.

00:25:27.986 --> 00:25:30.110
And you just have to--

00:25:30.110 --> 00:25:32.440
PROFESSOR: So in
the actual network,

00:25:32.440 --> 00:25:37.230
There are some nodes
with many outgoing edges.

00:25:37.230 --> 00:25:38.595
And then--

00:25:38.595 --> 00:25:40.860
AUDIENCE: You just need to
have another line between.

00:25:40.860 --> 00:25:41.860
PROFESSOR: That's right.

00:25:41.860 --> 00:25:43.800
You somehow just have
to add one more edge.

00:25:43.800 --> 00:25:45.780
Because x actually has
two outgoing edges.

00:25:48.529 --> 00:25:50.320
So there's a sense of
the feed-forward loop

00:25:50.320 --> 00:25:53.030
here-- you can think about
x being some transcription

00:25:53.030 --> 00:25:53.840
factor.

00:25:53.840 --> 00:25:58.260
And then what you need
is just to get-- x might

00:25:58.260 --> 00:26:00.100
have many, many outgoing edges.

00:26:00.100 --> 00:26:02.100
And so to get a feed-forward
loop, what you need

00:26:02.100 --> 00:26:06.424
is you need for one
of those genes that

00:26:06.424 --> 00:26:08.340
are targeted to just
target another one that's

00:26:08.340 --> 00:26:09.790
in that network.

00:26:09.790 --> 00:26:12.830
So if you have x that's
regulating one00,

00:26:12.830 --> 00:26:17.570
then that actually that
presents many opportunities

00:26:17.570 --> 00:26:19.217
to generate feed-forward loops.

00:26:19.217 --> 00:26:20.678
Yes.

00:26:20.678 --> 00:26:23.600
AUDIENCE: At the same time
z, it's just going in.

00:26:23.600 --> 00:26:28.957
So wouldn't that
make the [INAUDIBLE]?

00:26:28.957 --> 00:26:31.890
Is that why there's more ingoing
edges than outgoing edges?

00:26:31.890 --> 00:26:34.223
PROFESSOR: Now this is a
problem with verbal arguments--

00:26:34.223 --> 00:26:35.400
you can construct anything.

00:26:35.400 --> 00:26:38.880
And indeed, I would say
that this is an example.

00:26:38.880 --> 00:26:41.450
What we said is that the
distribution of incoming edges

00:26:41.450 --> 00:26:44.510
is roughly kind of similar
to an ER network in the sense

00:26:44.510 --> 00:26:47.210
that if the mean is
one, then sometimes you

00:26:47.210 --> 00:26:48.760
get 0, sometimes
one, sometimes two.

00:26:48.760 --> 00:26:50.680
And they're all
kind of reasonable.

00:26:50.680 --> 00:26:54.470
So in that sense, I'd
say this z node is not

00:26:54.470 --> 00:26:57.980
so unusual from the standpoint
of degree-preserving network.

00:26:57.980 --> 00:27:02.102
If z had one00 incoming
edges, then it's

00:27:02.102 --> 00:27:03.560
certainly true what
you're saying--

00:27:03.560 --> 00:27:06.110
that the degree-preserving
would then have fewer.

00:27:14.900 --> 00:27:15.810
All right.

00:27:15.810 --> 00:27:18.077
So this is the basic
argument for why

00:27:18.077 --> 00:27:19.827
you might go and look
at what the function

00:27:19.827 --> 00:27:21.243
of the feed-forward
loop might be.

00:27:21.243 --> 00:27:25.240
I just want to say a few things
about this original paper

00:27:25.240 --> 00:27:26.960
that Uri published.

00:27:26.960 --> 00:27:31.960
So it's in Science in 2002.

00:27:31.960 --> 00:27:36.130
"Network motifs: Simple Building
Blocks of Complex Networks."

00:27:36.130 --> 00:27:37.130
All right.

00:27:37.130 --> 00:27:39.102
So the authors did indeed
analyze both the E.

00:27:39.102 --> 00:27:41.060
coli and the yeast
transcription network.

00:27:41.060 --> 00:27:43.256
But they also analyzed a
number of other networks

00:27:43.256 --> 00:27:44.630
to look at these
networks motifs.

00:27:44.630 --> 00:27:49.490
So they also analyzed neurons
from C. elegans, the worm,

00:27:49.490 --> 00:27:52.111
where the connectome has been
known for several decades now.

00:27:52.111 --> 00:27:54.360
And again, they found that
feed-forward loops appeared

00:27:54.360 --> 00:27:56.480
more frequently than
what would be expected,

00:27:56.480 --> 00:28:00.660
based on the known model
of degree preserving.

00:28:00.660 --> 00:28:02.590
And that's encouraging
is that saying, oh

00:28:02.590 --> 00:28:05.160
maybe feed-forward
loops really are somehow

00:28:05.160 --> 00:28:07.460
preserving some--
they're performing

00:28:07.460 --> 00:28:12.090
some useful
information-processing task.

00:28:12.090 --> 00:28:14.320
Of course, you always have
to worry-- there's also

00:28:14.320 --> 00:28:15.790
the spatial arrangement.

00:28:15.790 --> 00:28:17.290
You can worry about
a lot of things.

00:28:17.290 --> 00:28:18.950
But that's encouraging.

00:28:18.950 --> 00:28:21.830
He also analyzed food
webs, where in that case

00:28:21.830 --> 00:28:24.620
feed-forward loops were
not a network motif,

00:28:24.620 --> 00:28:27.890
but other things were,
So that's interesting.

00:28:27.890 --> 00:28:31.870
He analyzed the design
of electronic circuits,

00:28:31.870 --> 00:28:34.160
a forward logic chip.

00:28:34.160 --> 00:28:35.270
I don't know that is.

00:28:35.270 --> 00:28:37.030
But then also the
worldwide web, it's

00:28:37.030 --> 00:28:38.830
another network people
love to analyze.

00:28:38.830 --> 00:28:41.250
And indeed, he saw
some other patterns.

00:28:41.250 --> 00:28:43.540
And the idea is that in
each of these contexts,

00:28:43.540 --> 00:28:45.200
the network motifs
are different,

00:28:45.200 --> 00:28:48.390
depending upon the microscopic
structure that's leading to it,

00:28:48.390 --> 00:28:52.960
or the function that it's maybe
evolving towards, or whatnot.

00:28:52.960 --> 00:28:55.420
So it's a way of getting
insight into the properties

00:28:55.420 --> 00:28:56.852
of these complex networks.

00:29:05.540 --> 00:29:08.644
Are there any questions
about these network--

00:29:08.644 --> 00:29:10.310
the global network
structures, before we

00:29:10.310 --> 00:29:12.185
get into the feed-forward
loop in particular?

00:29:17.530 --> 00:29:20.010
So first I want to
just go ahead and do

00:29:20.010 --> 00:29:21.940
a few of our little
concept questions.

00:29:21.940 --> 00:29:25.754
Just because you
have the cards, and I

00:29:25.754 --> 00:29:27.170
think that the
chapter is actually

00:29:27.170 --> 00:29:29.940
pretty nice in the
sense of you can

00:29:29.940 --> 00:29:34.240
read it, and get a clear
sense of what's going on.

00:29:34.240 --> 00:29:36.590
But let's start by
just considering

00:29:36.590 --> 00:29:40.230
this feed-forward loop, which
is this coherent type 1.

00:29:40.230 --> 00:29:43.050
So now the arrows
actually mean activating.

00:29:43.050 --> 00:29:47.890
So we have X going to Y. Now
it's going to be going to a Z.

00:29:47.890 --> 00:29:50.640
But we have to remember that
now that there are two inputs,

00:29:50.640 --> 00:29:52.680
we do have to specify
how the inputs are

00:29:52.680 --> 00:29:54.944
going to be combined.

00:29:54.944 --> 00:29:56.360
And for now what
we'll do is we'll

00:29:56.360 --> 00:29:57.568
assume that it's an AND gate.

00:30:01.930 --> 00:30:13.360
And that goes to Z. As always,
we're going to have to think.

00:30:13.360 --> 00:30:17.060
There's some signal x and
signal y that come in here.

00:30:17.060 --> 00:30:19.850
In many, many cases, these
transcription factors

00:30:19.850 --> 00:30:22.130
in addition to being
regulated by another,

00:30:22.130 --> 00:30:24.010
say transcription
factor, may also

00:30:24.010 --> 00:30:27.760
be responsive to some signal.

00:30:27.760 --> 00:30:32.880
And there was a nice example
of this in Uri's book

00:30:32.880 --> 00:30:37.900
which was how E. Coli
decide whether to make

00:30:37.900 --> 00:30:39.800
the suite of proteins
that are required

00:30:39.800 --> 00:30:45.350
to digest the carbon source
arabinose, the sugar arabinose.

00:30:45.350 --> 00:30:48.050
But for now, let's
just think about this.

00:30:48.050 --> 00:30:52.120
And we want to just make
sure that we remember.

00:30:52.120 --> 00:30:54.494
And once again, it's not
that you should necessarily

00:30:54.494 --> 00:30:55.410
memorize these things.

00:30:55.410 --> 00:30:57.860
But after having seen the
argument once or twice,

00:30:57.860 --> 00:31:00.020
you should be able
to reconstruct

00:31:00.020 --> 00:31:02.320
all of these things.

00:31:02.320 --> 00:31:05.160
So I claimed that
somewhere in here there's

00:31:05.160 --> 00:31:06.410
a sign sensitive delay.

00:31:16.960 --> 00:31:20.570
Now the question is, in which
direction is there a delay.

00:31:27.274 --> 00:31:28.940
And so it's going to
be some combination

00:31:28.940 --> 00:31:30.120
of on and off perhaps.

00:31:42.900 --> 00:31:46.230
And check means that it's
a delay in that direction.

00:31:46.230 --> 00:31:53.630
Well actually we should
just from nothing there--

00:31:53.630 --> 00:31:55.910
and D is don't know.

00:31:55.910 --> 00:31:57.750
AUDIENCE: In that
direction you mean?

00:31:57.750 --> 00:32:02.569
PROFESSOR: That there's a--
this means that there's a sign.

00:32:02.569 --> 00:32:03.110
That's right.

00:32:03.110 --> 00:32:07.010
So this would be going from
off to on, so turning on.

00:32:07.010 --> 00:32:11.310
So this is turning on, as
compared to turning off.

00:32:11.310 --> 00:32:15.810
And we're looking
at this is delay.

00:32:15.810 --> 00:32:20.010
We're talking about,
this is in response to Sx

00:32:20.010 --> 00:32:28.710
changing concentration of Z.

00:32:28.710 --> 00:32:31.706
Any questions about what
I'm referring to in this?

00:32:31.706 --> 00:32:33.615
AUDIENCE: Is there any Sy?

00:32:33.615 --> 00:32:34.240
PROFESSOR: Yes.

00:32:34.240 --> 00:32:37.860
Good question I like
that right Sy is present.

00:32:46.140 --> 00:32:47.056
AUDIENCE: [INAUDIBLE]?

00:32:49.082 --> 00:32:49.790
PROFESSOR: Right.

00:32:49.790 --> 00:32:53.820
So this is compared to
simple regulation, or i.e.

00:32:53.820 --> 00:32:56.570
does the concentration
of Z immediately

00:32:56.570 --> 00:32:59.855
start to change after
this Sx changes?

00:32:59.855 --> 00:33:05.330
It goes from either
0 to 1, or 1 to 0.

00:33:05.330 --> 00:33:07.574
AUDIENCE: So simple
regulation in this case

00:33:07.574 --> 00:33:09.930
would be erase that
line between X and Y?

00:33:09.930 --> 00:33:12.520
PROFESSOR: Yes.

00:33:12.520 --> 00:33:15.197
And make the AND gate a--

00:33:15.197 --> 00:33:16.280
AUDIENCE: Not an AND gate?

00:33:16.280 --> 00:33:19.870
PROFESSOR: Not an AND
gate, exactly, yeah.

00:33:19.870 --> 00:33:22.280
We're comparing to just if X
is just directly regulating

00:33:22.280 --> 00:33:26.090
Z. Because what we
want to know is,

00:33:26.090 --> 00:33:31.750
I mean what might a function
of the feed-forward loop be.

00:33:31.750 --> 00:33:35.129
So I'll give you 15 seconds
to think through this.

00:33:35.129 --> 00:33:37.420
Once again, it's not that
you should have memorized it.

00:33:44.480 --> 00:33:46.230
I don't want anybody
saying that they just

00:33:46.230 --> 00:33:47.438
couldn't read my handwriting.

00:33:52.190 --> 00:33:55.520
AUDIENCE: So this is for the
second case we're asking?

00:33:55.520 --> 00:33:57.160
PROFESSOR: I'm sorry.

00:33:57.160 --> 00:34:02.380
So this is-- I'm asking about
for this feed-forward loop,

00:34:02.380 --> 00:34:04.290
the coherent type
1 with an AND gate.

00:34:04.290 --> 00:34:07.530
And I'm comparing,
I'm asking is there

00:34:07.530 --> 00:34:13.230
a delay in either turning
on or turning off,

00:34:13.230 --> 00:34:18.590
as compared to the simple
regulation of X regulating Z.

00:34:18.590 --> 00:34:20.830
And of course, this
is my [INAUDIBLE] Sx.

00:34:24.630 --> 00:34:26.425
And we assume that X
is already present.

00:34:32.840 --> 00:34:35.139
Do you need more time?

00:34:35.139 --> 00:34:35.889
All right, ready?

00:34:35.889 --> 00:34:39.580
Three, two, one.

00:34:39.580 --> 00:34:40.080
OK.

00:34:40.080 --> 00:34:45.730
We got a clear majority of the
group actually is saying C.

00:34:45.730 --> 00:34:53.016
And so we can get at this
kind of visually, graphically.

00:34:53.016 --> 00:34:55.010
I really like graphs.

00:34:55.010 --> 00:34:57.970
I think they're much
nicer than equations.

00:34:57.970 --> 00:35:00.600
Different people can
agree or disagree.

00:35:00.600 --> 00:35:01.570
but that's my--

00:35:05.049 --> 00:35:08.080
The idea is that we have Sx.

00:35:08.080 --> 00:35:10.370
It starts out off
and say turns on.

00:35:13.060 --> 00:35:16.930
So if we think about the X
star, X was always around.

00:35:16.930 --> 00:35:20.250
So means that X
star immediately--

00:35:20.250 --> 00:35:23.450
so the signal immediately
changes X into X

00:35:23.450 --> 00:35:26.690
star, the active version.

00:35:26.690 --> 00:35:30.000
Now Y, and this
is why we can even

00:35:30.000 --> 00:35:33.080
say Y star, because the
signal Y is always there.

00:35:33.080 --> 00:35:34.450
It starts our here.

00:35:34.450 --> 00:35:35.750
It immediately gets the signal.

00:35:35.750 --> 00:35:38.370
So it starts coming up.

00:35:41.410 --> 00:35:44.525
But of course, this
is an AND gate.

00:35:44.525 --> 00:35:45.900
Which means that
you need to have

00:35:45.900 --> 00:35:47.950
both active Y and
active X in order

00:35:47.950 --> 00:35:50.700
to start getting
expression of Z.

00:35:50.700 --> 00:35:58.480
So we have if we
look at Z, there's

00:35:58.480 --> 00:36:03.700
something threshold at
which is Y starts allowing

00:36:03.700 --> 00:36:06.170
for expression of Z. So just
because we have active X,

00:36:06.170 --> 00:36:08.545
doesn't mean that we immediately
start getting expression

00:36:08.545 --> 00:36:10.530
of Z. We need Y as well.

00:36:10.530 --> 00:36:11.490
So this comes up.

00:36:16.560 --> 00:36:19.400
However, when the
signal here goes away,

00:36:19.400 --> 00:36:20.830
X star immediately goes away.

00:36:20.830 --> 00:36:23.970
This is the separation
of timescale idea.

00:36:23.970 --> 00:36:26.930
This is just a binding of
a small molecule or so.

00:36:26.930 --> 00:36:32.050
What that means is that Y star--
is there a delay on Y star?

00:36:36.730 --> 00:36:38.100
We're going to do a verbal.

00:36:38.100 --> 00:36:41.567
Is there a delay before Y
star just starts coming down?

00:36:41.567 --> 00:36:43.650
So the question, it's going
to decay exponentially

00:36:43.650 --> 00:36:44.370
once it starts going.

00:36:44.370 --> 00:36:45.786
Does it a start
going immediately,

00:36:45.786 --> 00:36:47.940
or is there a delay?

00:36:47.940 --> 00:36:50.750
So the question is, is there
a delay before the exponential

00:36:50.750 --> 00:36:52.430
fall off of Y star.

00:36:52.430 --> 00:36:55.630
You're going to say yes or
no, ready, three, two, one.

00:36:55.630 --> 00:36:56.877
AUDIENCE: No.

00:36:56.877 --> 00:36:57.710
PROFESSOR: No delay.

00:36:57.710 --> 00:36:58.210
Great.

00:37:01.550 --> 00:37:06.470
And indeed over here it's
the same thing, no delay

00:37:06.470 --> 00:37:09.420
because of the AND gate.

00:37:09.420 --> 00:37:13.370
Expression of Z requires
both X star and Y star.

00:37:13.370 --> 00:37:18.670
So although Y star still
there, since it's an AND gate,

00:37:18.670 --> 00:37:19.470
Z goes down.

00:37:24.350 --> 00:37:28.740
That means that in this case
we have a sign sensitive delay

00:37:28.740 --> 00:37:36.164
for turning on Z, but
not for turning off Z.

00:37:36.164 --> 00:37:37.580
And of course,
this can be useful,

00:37:37.580 --> 00:37:39.560
depending upon the
costs and benefits

00:37:39.560 --> 00:37:42.930
of having false positives and
false negatives in the signal.

00:37:46.744 --> 00:37:51.020
If this AND gate were
switched to an OR gate,

00:37:51.020 --> 00:37:53.690
how does this thing change?

00:37:53.690 --> 00:37:56.460
I'm going to give
you 10 seconds.

00:37:56.460 --> 00:37:57.160
All right.

00:37:57.160 --> 00:38:00.090
So, question is, if I
convert this to an OR gate,

00:38:00.090 --> 00:38:01.470
does it change anything or not.

00:38:15.810 --> 00:38:18.760
Do you need more time?

00:38:18.760 --> 00:38:23.030
Ready, three two one.

00:38:23.030 --> 00:38:25.210
Now we got a lot of B's.

00:38:25.210 --> 00:38:26.250
Great.

00:38:26.250 --> 00:38:29.570
So in this case it's coherent
type 1, feed-forward loop

00:38:29.570 --> 00:38:31.490
with an OR gate.

00:38:31.490 --> 00:38:33.010
I'm not going to
go over the logic.

00:38:33.010 --> 00:38:36.300
But I encourage you, if
you're confused by this,

00:38:36.300 --> 00:38:39.560
just make sure that you can
reconstruct the argument.

00:38:39.560 --> 00:38:42.147
From my standpoint,
these equations I mean,

00:38:42.147 --> 00:38:43.230
it's good to do equations.

00:38:43.230 --> 00:38:46.030
But it's more important
to be able to understand

00:38:46.030 --> 00:38:46.925
the logic here.

00:38:46.925 --> 00:38:48.219
Did you have a question?

00:38:48.219 --> 00:38:48.802
AUDIENCE: Yes.

00:38:48.802 --> 00:38:51.257
So how is it easy to
prove experimentally

00:38:51.257 --> 00:38:53.660
what kind of gate there is?

00:38:53.660 --> 00:38:54.750
PROFESSOR: Yes.

00:38:54.750 --> 00:38:56.820
So the idea is
that in many cases

00:38:56.820 --> 00:39:00.240
you can put X on an
inducible promoter.

00:39:00.240 --> 00:39:02.040
You could put Y on an
inducible promoter.

00:39:02.040 --> 00:39:03.790
So you can-- just some
small molecule will

00:39:03.790 --> 00:39:06.720
allow you to control these.

00:39:06.720 --> 00:39:10.660
And then you can measure,
say fluorescence, on Z.

00:39:10.660 --> 00:39:12.077
And that's the
most direct things.

00:39:12.077 --> 00:39:13.659
It's experimentally
doing it yourself.

00:39:13.659 --> 00:39:15.840
Of course, much of the data
that you see the chapter

00:39:15.840 --> 00:39:18.680
is kind of just looking at the
fluorescent Z as a function

00:39:18.680 --> 00:39:21.560
of the signals that you put in.

00:39:21.560 --> 00:39:23.910
And that's certainly
an argument for it.

00:39:23.910 --> 00:39:25.880
And then ultimately
what you'd like

00:39:25.880 --> 00:39:27.990
is to measure things in
multiple different ways,

00:39:27.990 --> 00:39:29.420
confirm that it's
all consistent.

00:39:34.110 --> 00:39:35.610
Any other questions
about this idea

00:39:35.610 --> 00:39:37.070
of sign sensitive delay element?

00:39:41.043 --> 00:39:41.543
Yeah?

00:39:41.543 --> 00:39:42.209
AUDIENCE: Sorry.

00:39:42.209 --> 00:39:47.010
So among these 42--
these that are this type,

00:39:47.010 --> 00:39:50.489
is it possible to look
at the actual genes,

00:39:50.489 --> 00:39:52.477
and see if that
interrelationship actually

00:39:52.477 --> 00:39:54.000
makes sense?

00:39:54.000 --> 00:39:55.900
PROFESSOR: That's
a good question.

00:39:55.900 --> 00:39:58.925
So if you look at across
both E. coli and yeast, what

00:39:58.925 --> 00:40:02.750
you see is that of the
feed-forward loops, about half

00:40:02.750 --> 00:40:06.940
of them are coherent
type 1, which

00:40:06.940 --> 00:40:10.549
is one of the eight possible
kinds of feed-forward loops.

00:40:10.549 --> 00:40:12.340
And so what you're
asking is, in this case,

00:40:12.340 --> 00:40:14.200
so let's say there are
20 coherent type 1,

00:40:14.200 --> 00:40:16.060
how many of them,
what fraction of them

00:40:16.060 --> 00:40:17.820
does this all makes sense?

00:40:17.820 --> 00:40:19.630
And it's a good question.

00:40:19.630 --> 00:40:21.940
I don't know.

00:40:21.940 --> 00:40:23.192
I haven't looked at it.

00:40:23.192 --> 00:40:24.900
Because it's always
dangerous, of course,

00:40:24.900 --> 00:40:30.150
that we find one example of
the 20 where it kind of makes

00:40:30.150 --> 00:40:31.070
sense conceptually.

00:40:31.070 --> 00:40:32.945
And then we go and we
test it experimentally,

00:40:32.945 --> 00:40:35.030
and see that it all works.

00:40:35.030 --> 00:40:36.690
And then we're convinced.

00:40:36.690 --> 00:40:38.530
But you're pointing
out that maybe we

00:40:38.530 --> 00:40:40.305
shouldn't be convinced yet.

00:40:40.305 --> 00:40:41.700
AUDIENCE: But I'm just curious.

00:40:41.700 --> 00:40:44.955
If you're proposing a functional
kind of explanation, and if

00:40:44.955 --> 00:40:45.970
know what the genes are.

00:40:45.970 --> 00:40:46.970
PROFESSOR: That's right.

00:40:46.970 --> 00:40:50.460
You should be able to go and see
whether it somehow make sense.

00:40:50.460 --> 00:40:56.010
And of course makes sense is
always a slippery concept.

00:40:56.010 --> 00:40:59.300
Because we can always--
it's not that this radically

00:40:59.300 --> 00:41:01.710
changes the logic.

00:41:01.710 --> 00:41:03.430
And then in any
given circumstance

00:41:03.430 --> 00:41:06.150
you may be say, oh well.

00:41:06.150 --> 00:41:09.689
You can kind of wave
your arms and make up

00:41:09.689 --> 00:41:11.230
a story where it
kind of makes sense.

00:41:11.230 --> 00:41:14.324
But then the only way to
really feel comfortable

00:41:14.324 --> 00:41:16.740
with it or not, is for you
yourself to go on look at them,

00:41:16.740 --> 00:41:19.690
and see how comfortable you are
with each of those arguments.

00:41:19.690 --> 00:41:21.588
And I haven't
actually done that.

00:41:27.030 --> 00:41:28.970
So one more question
in this regard.

00:41:28.970 --> 00:41:29.470
All right.

00:41:29.470 --> 00:41:34.870
So let's imagine that instead
of thinking about changes in Sx,

00:41:34.870 --> 00:41:36.540
with Sy present,
let's now flip things.

00:41:36.540 --> 00:41:39.560
Let's assume that Sx
is present and ask

00:41:39.560 --> 00:41:42.040
about Sy turning on and off.

00:41:47.020 --> 00:41:51.710
Again with the AND
gate, I want to know

00:41:51.710 --> 00:41:55.160
in which direction
is there a delay when

00:41:55.160 --> 00:41:56.690
turning either on or off.

00:41:56.690 --> 00:41:59.060
Now we're talking about
with Sy turning on or off.

00:42:01.975 --> 00:42:03.600
Does everybody
understand the question?

00:42:06.810 --> 00:42:08.565
I'll give you 10
seconds to make sure.

00:42:38.880 --> 00:42:40.910
Do need more time?

00:42:40.910 --> 00:42:42.050
Let's go ahead and vote.

00:42:42.050 --> 00:42:46.671
Ready, three, two, one.

00:42:46.671 --> 00:42:47.800
All right.

00:42:47.800 --> 00:42:50.605
OK, so I'd say now it's
pretty overwhelming

00:42:50.605 --> 00:42:54.140
that the group again
agrees that now it'll be A.

00:42:54.140 --> 00:43:00.480
So if we have Sx equal to
1, and Sy is changing, then

00:43:00.480 --> 00:43:05.030
in this case we don't
get any of these delays.

00:43:05.030 --> 00:43:09.500
So there's sort of immediate
changes in Z as Sy changes.

00:43:09.500 --> 00:43:12.015
And that's because
this is an AND gate.

00:43:12.015 --> 00:43:14.140
If X is already there that
means that we've already

00:43:14.140 --> 00:43:16.060
satisfied this half of it.

00:43:16.060 --> 00:43:18.550
So then we're just reduced
to simple regulation.

00:43:18.550 --> 00:43:20.907
This is just equivalent
to Y regulating Z.

00:43:20.907 --> 00:43:23.240
So there are no delays either
turning on or turning off.

00:43:38.200 --> 00:43:40.020
So what you read
about from Uri's book

00:43:40.020 --> 00:43:44.037
is what is that the
coherent type 1 is perhaps

00:43:44.037 --> 00:43:46.120
the most common of the
feed-forward loops observed

00:43:46.120 --> 00:43:47.750
in these transportation
networks.

00:43:47.750 --> 00:43:50.140
The other of the
feed-forward loops

00:43:50.140 --> 00:43:52.540
that is distinctly
overrepresented

00:43:52.540 --> 00:43:54.090
is this incoherent type 1.

00:43:56.772 --> 00:43:59.580
So it's very similar, with the
exception that now what we have

00:43:59.580 --> 00:44:08.300
is X activating Y, but now Y
is going to be repressing Z.

00:44:08.300 --> 00:44:16.172
And we have X
again activating Z.

00:44:16.172 --> 00:44:17.880
And we're going to
use an AND gate again.

00:44:26.460 --> 00:44:34.140
Its edge going to Z. For me, I
find it sometimes a little bit

00:44:34.140 --> 00:44:38.130
confusing to think about a
repression and an AND gate.

00:44:38.130 --> 00:44:41.540
So it is useful to make sure
that we kind of understand

00:44:41.540 --> 00:44:43.380
the logic of all these things.

00:44:43.380 --> 00:44:47.260
So if we have say
X star, Y star,

00:44:47.260 --> 00:44:53.890
and we can just
make sure this is

00:44:53.890 --> 00:44:57.380
absence or presence, digital
approximation of each

00:44:57.380 --> 00:44:58.470
of these things.

00:44:58.470 --> 00:45:07.671
And the question is, if
we have expression of Z.

00:45:07.671 --> 00:45:09.170
Now the way to just
think about this

00:45:09.170 --> 00:45:13.170
is that this guy is equivalent
to kind of inverting

00:45:13.170 --> 00:45:17.812
the sign of Y star.

00:45:17.812 --> 00:45:19.020
And then we have an AND gate.

00:45:19.020 --> 00:45:20.630
So this is a 0,1.

00:45:20.630 --> 00:45:23.500
That's not an AND.

00:45:23.500 --> 00:45:26.800
Well 0 is enough to give us a 0.

00:45:26.800 --> 00:45:27.940
So here we get activation.

00:45:27.940 --> 00:45:29.374
Here we don't.

00:45:38.740 --> 00:45:41.740
And so we can do a similar kind
of story of what we did here.

00:45:41.740 --> 00:45:44.620
Except that now instead
of Y being an activator,

00:45:44.620 --> 00:45:49.000
it's now a repressor.

00:45:49.000 --> 00:45:51.670
And again, we're going to
think about what happens

00:45:51.670 --> 00:45:53.498
with the signal coming in.

00:46:11.200 --> 00:46:13.900
Is any difference
up to this point?

00:46:18.856 --> 00:46:19.730
Let's think about it.

00:46:19.730 --> 00:46:21.104
Everything but
this for a second.

00:46:21.104 --> 00:46:21.690
All right.

00:46:21.690 --> 00:46:23.250
So this is a case
where we already

00:46:23.250 --> 00:46:28.930
have signal Y that's allowing,
say, the Y repressor to bind.

00:46:28.930 --> 00:46:30.300
Then we make Sx appear.

00:46:35.270 --> 00:46:37.110
I want to know
verbally, yes or no.

00:46:39.900 --> 00:46:43.680
Do I have to draw something
new up to this point here?

00:46:43.680 --> 00:46:46.330
Ready, so what do I want to say?

00:46:46.330 --> 00:46:49.540
Is there a change from this
drawing up to this point?

00:46:49.540 --> 00:46:52.485
Ready, three, two, one.

00:46:52.485 --> 00:46:53.790
AUDIENCE: Yes.

00:46:53.790 --> 00:46:54.570
PROFESSOR: Yes.

00:46:54.570 --> 00:46:55.310
All right.

00:46:55.310 --> 00:46:58.720
And that's because actually Z
starts coming up at this point.

00:46:58.720 --> 00:47:01.960
It's very, very nerve-wracking,
these quizzes, I know.

00:47:06.180 --> 00:47:09.360
The idea is that here
Y is now a repressor.

00:47:09.360 --> 00:47:11.860
So it's not that you need Y in
order to get expression of Z.

00:47:11.860 --> 00:47:14.680
Is that once you
have Y star, then you

00:47:14.680 --> 00:47:23.000
stop getting expression of Z.
So it looks like maybe I'll

00:47:23.000 --> 00:47:26.860
make a-- so in this case
everything's the same here.

00:47:26.860 --> 00:47:32.720
Except that in this case you
start getting Z coming up.

00:47:32.720 --> 00:47:36.400
And then once Y gets up to
a sufficiently high level,

00:47:36.400 --> 00:47:39.300
it starts repressing.

00:47:39.300 --> 00:47:43.750
In that case it might
do something like this.

00:47:47.120 --> 00:47:50.180
Now, depending upon the
strength of that repression,

00:47:50.180 --> 00:47:52.680
this curve might look different.

00:47:52.680 --> 00:47:54.640
Because it could come
all the way down to 0.

00:47:54.640 --> 00:47:59.400
Depending on if it's a
very effective repressor.

00:47:59.400 --> 00:48:02.105
And depending upon whether
it's fully repressed or only

00:48:02.105 --> 00:48:03.980
partially repressed,
you might think about it

00:48:03.980 --> 00:48:07.730
as either being a pulse
generator, so you get some Z,

00:48:07.730 --> 00:48:09.970
and then it goes away.

00:48:09.970 --> 00:48:11.500
Or you could think
about it as a way

00:48:11.500 --> 00:48:14.050
of increasing the
rate at which you're

00:48:14.050 --> 00:48:15.980
able to turn this gene on.

00:48:15.980 --> 00:48:18.582
Because it's sort of like
this negative autoregulation

00:48:18.582 --> 00:48:20.540
idea that initially you
get lots of expression.

00:48:20.540 --> 00:48:23.020
And then later you
stop getting as much.

00:48:23.020 --> 00:48:25.920
Of course, here you
would get an overshoot.

00:48:25.920 --> 00:48:30.230
But maybe that's not all bad.

00:48:30.230 --> 00:48:32.955
So in this what you might say
is this is a pulse generator.

00:48:38.440 --> 00:48:44.540
And this here is a way
of making t on go down.

00:48:50.705 --> 00:48:52.330
Are there any questions
about the logic

00:48:52.330 --> 00:48:57.088
of what happens in
this incoherent type 1?

00:48:57.088 --> 00:48:57.588
Yes?

00:48:57.588 --> 00:48:59.580
AUDIENCE: Can you
explain the t on?

00:48:59.580 --> 00:49:00.990
PROFESSOR: Sure.

00:49:00.990 --> 00:49:04.400
So maybe let's zoom in.

00:49:04.400 --> 00:49:09.940
And we can look at Z. So
it kind of gets expressed.

00:49:09.940 --> 00:49:13.320
And then it represses like this.

00:49:13.320 --> 00:49:16.150
And then you always have to ask,
well what do you mean by t on?

00:49:16.150 --> 00:49:18.110
And then we have is
working definition,

00:49:18.110 --> 00:49:21.590
which is that we say t
on is defined as there's

00:49:21.590 --> 00:49:24.960
some equilibrium concentration.

00:49:24.960 --> 00:49:28.410
So this is Z equilibrium.

00:49:28.410 --> 00:49:31.080
And we often define t on
as the time in which you

00:49:31.080 --> 00:49:34.380
get half of that concentration.

00:49:34.380 --> 00:49:37.900
So what we do is we
take half of that.

00:49:37.900 --> 00:49:39.915
And we say, where
does this cross?

00:49:39.915 --> 00:49:41.420
It crosses right here.

00:49:41.420 --> 00:49:44.050
I maybe overdid my drawing.

00:49:44.050 --> 00:49:46.580
It's too good of a--
So t on, in this case,

00:49:46.580 --> 00:49:53.502
would be that time right there.

00:49:53.502 --> 00:49:54.960
Now of course you
have to say, well

00:49:54.960 --> 00:49:57.330
what should we compare that to?

00:49:57.330 --> 00:50:00.789
And the comparison
should be the t

00:50:00.789 --> 00:50:03.080
on that you would have had
with just simple regulation.

00:50:03.080 --> 00:50:04.705
So that's based on
the generation time.

00:50:04.705 --> 00:50:07.121
And you can actually see what
the generation time is here.

00:50:07.121 --> 00:50:09.670
Because this thing in the
absence of the repression

00:50:09.670 --> 00:50:14.410
would have done
something like that.

00:50:14.410 --> 00:50:18.170
So this tells us that
the simple regulation

00:50:18.170 --> 00:50:20.840
would have lead to something
that looks like this.

00:50:20.840 --> 00:50:29.670
So you see the t on here,
this is t on simple,

00:50:29.670 --> 00:50:32.140
is much larger than the t on
that you actually get here.

00:50:39.180 --> 00:50:41.600
So from this
argument there are--

00:50:41.600 --> 00:50:45.480
we can now try to recapitulate
or recall for ourselves

00:50:45.480 --> 00:50:51.305
the various strategies for
increasing the rate of response

00:50:51.305 --> 00:50:51.805
to signals.

00:50:55.200 --> 00:51:02.270
So we have, we can think about,
you want to decrease t on,

00:51:02.270 --> 00:51:03.710
and you want to decrease t off.

00:51:06.740 --> 00:51:10.780
And we want to think about
maybe different strategies

00:51:10.780 --> 00:51:14.810
that we've encountered
over the last few weeks.

00:51:14.810 --> 00:51:16.185
What were some of
the strategies?

00:51:22.428 --> 00:51:22.928
Yes?

00:51:22.928 --> 00:51:25.042
AUDIENCE: Just having
a higher degradation?

00:51:25.042 --> 00:51:26.750
PROFESSOR: All right,
higher degradation.

00:51:26.750 --> 00:51:28.470
Right.

00:51:28.470 --> 00:51:34.385
So increase degradation,
well maybe I'll

00:51:34.385 --> 00:51:35.510
just say decrease lifetime.

00:51:38.040 --> 00:51:39.470
Well it's the same thing.

00:51:39.470 --> 00:51:43.470
So decrease the
protein lifetime.

00:51:43.470 --> 00:51:44.865
And what does that do for us?

00:51:49.110 --> 00:51:51.930
Does that decrease t on,
or does it decrease t off?

00:51:55.594 --> 00:51:56.450
Both.

00:51:56.450 --> 00:51:56.950
All right.

00:51:56.950 --> 00:52:01.775
So this decreases t on,
and it decreases t off.

00:52:01.775 --> 00:52:03.400
What were some of
the other strategies?

00:52:06.641 --> 00:52:07.544
Yes?

00:52:07.544 --> 00:52:08.960
AUDIENCE: Negative
autoregulation.

00:52:08.960 --> 00:52:10.370
PROFESSOR: Negative
autoregulation.

00:52:10.370 --> 00:52:10.730
Great.

00:52:10.730 --> 00:52:11.938
And what does that do for us?

00:52:19.500 --> 00:52:25.925
AUDIENCE: I think it
decreases t off and on also.

00:52:25.925 --> 00:52:26.800
PROFESSOR: All right.

00:52:26.800 --> 00:52:29.760
So let's do a vote.

00:52:29.760 --> 00:52:31.170
This is a good opportunity.

00:52:31.170 --> 00:52:33.911
This is like review for
exams for you guys right now.

00:52:33.911 --> 00:52:34.410
All right.

00:52:34.410 --> 00:52:38.260
So negative autoregulation,
does it decrease t on,

00:52:38.260 --> 00:52:41.700
t off, both, neither,
or something or another?

00:52:41.700 --> 00:52:42.745
All right, eight seconds.

00:52:50.670 --> 00:52:53.505
Ready, three, two, one.

00:52:56.180 --> 00:52:56.680
All right.

00:52:56.680 --> 00:53:01.600
So we got many C's, but
many other things as well.

00:53:01.600 --> 00:53:02.100
Right.

00:53:02.100 --> 00:53:06.249
But indeed it's only going
to decrease t on, actually.

00:53:06.249 --> 00:53:08.790
And that's because remember,
the negative autoregulation what

00:53:08.790 --> 00:53:12.860
it does, is initially, it
makes a lot of this protein.

00:53:12.860 --> 00:53:15.540
And then once you hit
the repression threshold,

00:53:15.540 --> 00:53:17.680
then it sort of
represses itself.

00:53:17.680 --> 00:53:20.690
And so you are able to kind of
rapidly get up to that level,

00:53:20.690 --> 00:53:22.530
and then you clamp it there.

00:53:22.530 --> 00:53:25.150
Whereas turning off that
just means that you just

00:53:25.150 --> 00:53:26.600
tell to stop making it.

00:53:26.600 --> 00:53:29.650
So it's always going to
then decay at the rate that

00:53:29.650 --> 00:53:32.630
is dictated by its
effective lifetime, which

00:53:32.630 --> 00:53:34.770
is kind of either
from the protein

00:53:34.770 --> 00:53:39.310
or from the actual degradation,
or from the growth of cell.

00:53:39.310 --> 00:53:42.137
So this only decreases t on.

00:53:42.137 --> 00:53:44.220
And then indeed, we just
learned about another one

00:53:44.220 --> 00:53:47.700
here, which was the
incoherent, incoherent type 1

00:53:47.700 --> 00:53:51.320
feed-forward loop, with
kind of modest amounts

00:53:51.320 --> 00:53:55.635
of repression, incomplete
repression or so.

00:53:55.635 --> 00:53:56.760
And what does that do here?

00:54:00.770 --> 00:54:02.890
Did we actually even figure
out what it did here?

00:54:09.930 --> 00:54:12.000
Oh, we maybe didn't say.

00:54:12.000 --> 00:54:16.630
Five seconds, again over here.

00:54:16.630 --> 00:54:20.590
What does it-- we've-- well
I told you one half of it

00:54:20.590 --> 00:54:21.090
already.

00:54:21.090 --> 00:54:22.340
But what about the other half?

00:54:24.141 --> 00:54:24.640
All right.

00:54:37.190 --> 00:54:39.430
All right, ready?

00:54:39.430 --> 00:54:41.780
Incoherent type 1 feed-forward
loop, what does it do?

00:54:41.780 --> 00:54:45.250
Ready, three, two, one.

00:54:45.250 --> 00:54:45.750
OK.

00:54:45.750 --> 00:54:49.440
We've got again, a bunch of C's.

00:54:49.440 --> 00:54:53.390
Indeed this is--
and of course, I'm

00:54:53.390 --> 00:54:55.520
using the same chart for
the sign sensitive delay,

00:54:55.520 --> 00:54:58.820
and for the time to
turn on turn off.

00:54:58.820 --> 00:55:00.790
So I hope that that
doesn't confuse you.

00:55:00.790 --> 00:55:01.840
If it does, I'm sorry.

00:55:01.840 --> 00:55:02.340
All right.

00:55:02.340 --> 00:55:06.340
So this is, it decreases
t on, but not t off.

00:55:06.340 --> 00:55:07.640
This is an AND gate.

00:55:07.640 --> 00:55:10.950
So you need both active
X star and Y star.

00:55:10.950 --> 00:55:16.390
So the moment that
you make Sx go away,

00:55:16.390 --> 00:55:19.229
then it's going to
start-- oh wait.

00:55:19.229 --> 00:55:20.520
I'm explaining a different one.

00:55:20.520 --> 00:55:20.720
OK.

00:55:20.720 --> 00:55:21.220
Sorry.

00:55:21.220 --> 00:55:23.210
This is the time.

00:55:23.210 --> 00:55:28.440
So we're at Z. But yeah, it
immediately starts going down.

00:55:28.440 --> 00:55:31.830
But at the same normal
rate of effective lifetime.

00:55:35.710 --> 00:55:39.870
Many more ways to make a protein
quickly, than to get rid of it

00:55:39.870 --> 00:55:40.370
quickly.

00:55:43.785 --> 00:55:45.910
Are there any questions
about what we've said here?

00:55:55.460 --> 00:55:58.900
So while we're on the topic
of kind of response times

00:55:58.900 --> 00:56:01.720
and so forth, it's
important to remember

00:56:01.720 --> 00:56:04.650
that the characteristic
time for all these things

00:56:04.650 --> 00:56:07.720
is kind of the generation
time, or the protein lifetime.

00:56:07.720 --> 00:56:11.940
So these are ways of processing
information over time scales

00:56:11.940 --> 00:56:14.820
that are kind of like
minutes, maybe even

00:56:14.820 --> 00:56:16.650
tens of minutes, maybe hours.

00:56:16.650 --> 00:56:19.600
So it's rather slow.

00:56:19.600 --> 00:56:21.060
Now is that, in general.

00:56:21.060 --> 00:56:22.651
Going to be good
enough for everything

00:56:22.651 --> 00:56:23.650
that a cell needs to do?

00:56:26.210 --> 00:56:27.390
No.

00:56:27.390 --> 00:56:31.210
So it's important to highlight
that transcription is slow.

00:56:36.280 --> 00:56:39.601
So that means that transcription
networks are going to be slow.

00:56:39.601 --> 00:56:41.100
And that's both
because you actually

00:56:41.100 --> 00:56:43.220
have to do transcription and
translation, and so forth.

00:56:43.220 --> 00:56:45.886
But also you just have to change
the concentrations of proteins.

00:56:48.520 --> 00:56:52.060
So if you need to kind of
respond to things more rapidly,

00:56:52.060 --> 00:56:53.570
what is it then you need to do?

00:56:57.049 --> 00:56:58.409
AUDIENCE: Phosphorylate.

00:56:58.409 --> 00:56:59.700
PROFESSOR: Phosphorylate, yeah.

00:56:59.700 --> 00:57:03.180
It's all about
phosphorylation, yes.

00:57:03.180 --> 00:57:08.380
Indeed, phosphorylate-- so you
need, if you want to be fast,

00:57:08.380 --> 00:57:10.690
you can't be changing overall
protein concentrations.

00:57:10.690 --> 00:57:13.010
You have to change
protein state.

00:57:13.010 --> 00:57:16.120
Right, and phosphorylation
is kind of the classic way

00:57:16.120 --> 00:57:17.660
of doing that.

00:57:17.660 --> 00:57:28.170
so I just want to highlight
that for speed you need just

00:57:28.170 --> 00:57:30.310
to do kind of protein networks.

00:57:33.196 --> 00:57:34.570
So we're not
actually going to be

00:57:34.570 --> 00:57:39.520
reading the chapter analyzing
these map kinase cascades,

00:57:39.520 --> 00:57:41.394
and so forth.

00:57:41.394 --> 00:57:43.060
But if you're interested
in such things,

00:57:43.060 --> 00:57:44.590
I very much encourage you do so.

00:57:44.590 --> 00:57:48.640
It's also nice
chapters, maybe not

00:57:48.640 --> 00:57:51.100
as nice as the first
four, which is part

00:57:51.100 --> 00:57:52.600
of why we're not reading them.

00:57:52.600 --> 00:57:54.774
But it's a very important
insight, in the sense

00:57:54.774 --> 00:57:57.190
that we've spent a lot of time
talking about transcription

00:57:57.190 --> 00:58:00.110
networks, just because
there's a lot of, I think,

00:58:00.110 --> 00:58:03.070
simple, beautiful things
that you can say about them.

00:58:03.070 --> 00:58:07.170
Whereas they are intrinsically
limited in terms of speed.

00:58:07.170 --> 00:58:10.110
So for much of what
a cell needs to do,

00:58:10.110 --> 00:58:13.330
it has to already have
the proteins there.

00:58:13.330 --> 00:58:17.190
And then you can take advantage
of these rapid processes.

00:58:17.190 --> 00:58:19.810
So we talked about
Sx rapidly binding,

00:58:19.810 --> 00:58:23.230
changing the state of X. From
the standpoint of transcription

00:58:23.230 --> 00:58:26.540
networks, we just draw
this as a straight line.

00:58:26.540 --> 00:58:27.420
It's rapid.

00:58:27.420 --> 00:58:30.660
But what that's saying
is that if you just

00:58:30.660 --> 00:58:33.190
change states of
proteins, then you

00:58:33.190 --> 00:58:36.180
can do a lot of information
processing rather rapidly.

00:58:36.180 --> 00:58:39.520
And you don't have to do just
a simple thing of Sx binding

00:58:39.520 --> 00:58:42.780
X. You can also have proteins
regulating each other,

00:58:42.780 --> 00:58:46.400
and performing logic functions
at the protein-only level.

00:58:53.520 --> 00:58:55.430
What I want to do for
the last 20 minutes

00:58:55.430 --> 00:58:58.540
is say something about
temporal programs

00:58:58.540 --> 00:59:01.237
that can be implemented with
sort of larger network motifs.

00:59:01.237 --> 00:59:03.070
And in particular this
is material basically

00:59:03.070 --> 00:59:06.710
from chapter five of the
book, which again we're

00:59:06.710 --> 00:59:08.155
not to be reading.

00:59:08.155 --> 00:59:09.730
I think it's again,
it's beautiful

00:59:09.730 --> 00:59:10.790
but it's really simple.

00:59:10.790 --> 00:59:14.590
So I think that in 20 minutes
we can cover it just fine.

00:59:21.160 --> 00:59:26.370
So for many cases, for example,
in the context of metabolic

00:59:26.370 --> 00:59:36.210
pathways, it might be the case
that you have some protein

00:59:36.210 --> 00:59:37.330
we'll call them Z's.

00:59:37.330 --> 00:59:42.130
So you'll have some protein
Z1 that does something.

00:59:42.130 --> 00:59:47.330
So that catalyzes-- so we might
have some molecule one that's

00:59:47.330 --> 00:59:50.220
converted into module
two, by Z1, converted

00:59:50.220 --> 00:59:53.420
into molecules three by Z2.

00:59:57.764 --> 00:59:59.680
So many metabolic pathways
have this structure

00:59:59.680 --> 01:00:01.820
where there are a
series of enzymes

01:00:01.820 --> 01:00:06.720
that are doing something to the
product of the previous enzyme.

01:00:06.720 --> 01:00:11.000
Now the question is, let's say
that this is some carbon source

01:00:11.000 --> 01:00:12.390
and we didn't before.

01:00:12.390 --> 01:00:16.889
But now it's appeared
in our environment.

01:00:16.889 --> 01:00:18.680
So what we would like
is we'd like to start

01:00:18.680 --> 01:00:24.390
digesting that carbon source.

01:00:24.390 --> 01:00:27.740
Or in the flip
side, maybe we have

01:00:27.740 --> 01:00:31.177
to make some complex molecule
or an amino acid or so.

01:00:31.177 --> 01:00:33.510
And so then what we're doing
is we're building something

01:00:33.510 --> 01:00:36.350
up, coming down.

01:00:36.350 --> 01:00:40.900
Now in either case, if before
you weren't making these Z

01:00:40.900 --> 01:00:47.310
proteins, but now you
want them, a question is,

01:00:47.310 --> 01:00:49.680
maybe you could just make
them all at the same time.

01:00:49.680 --> 01:00:52.650
But maybe it would be better
to make some of them first,

01:00:52.650 --> 01:00:53.640
and some of them later.

01:00:56.060 --> 01:00:56.810
What do you think?

01:00:59.764 --> 01:01:01.180
Let's say for the
sake of argument

01:01:01.180 --> 01:01:03.471
that you would want to have
some first, and some later,

01:01:03.471 --> 01:01:06.757
which ones would you want first?

01:01:06.757 --> 01:01:08.340
AUDIENCE: The ones
that you use first?

01:01:08.340 --> 01:01:10.048
PROFESSOR: Yeah, the
ones you need first.

01:01:10.048 --> 01:01:14.755
So you'd maybe want to first
have Z1, then Z2, et cetera.

01:01:14.755 --> 01:01:17.440
It's a trivial statement,
but you might not actually

01:01:17.440 --> 01:01:18.680
think about it.

01:01:18.680 --> 01:01:21.020
And the question is how
might we be able to do this.

01:01:25.180 --> 01:01:30.040
Well there's a very simple thing
called a single input module.

01:01:30.040 --> 01:01:32.800
The idea here is there's
some transcription factor

01:01:32.800 --> 01:01:36.320
X, which actually does
this fabulous thing where

01:01:36.320 --> 01:01:40.640
it creates all these guys.

01:01:47.320 --> 01:01:54.930
Interestingly, this also often
has autoregulation in order to,

01:01:54.930 --> 01:01:57.300
for example, stabilize
the concentration of it.

01:01:57.300 --> 01:02:01.130
But the reason it's called
a single input module is

01:02:01.130 --> 01:02:06.890
because the network motif is
saying not just that X makes

01:02:06.890 --> 01:02:08.620
many Z's.

01:02:08.620 --> 01:02:11.020
That actually you
can't actually argue

01:02:11.020 --> 01:02:14.470
that that's a network
motif, from the standpoint

01:02:14.470 --> 01:02:15.920
of a degree preserving network.

01:02:15.920 --> 01:02:18.320
Because of course, this
is just saying well

01:02:18.320 --> 01:02:21.930
some nodes activate
many other nodes.

01:02:21.930 --> 01:02:24.210
And in a degree preserving
network that's always

01:02:24.210 --> 01:02:25.460
still going to be true, right?

01:02:25.460 --> 01:02:28.680
But you can say that such a
thing is a network motif, when

01:02:28.680 --> 01:02:33.370
you say that these Z's
are only regulated by X.

01:02:33.370 --> 01:02:35.536
So that happens
somehow more frequently

01:02:35.536 --> 01:02:36.660
than what you would expect.

01:02:45.304 --> 01:02:47.470
Although now that I just
said that, I'm a little bit

01:02:47.470 --> 01:02:51.890
worried that even the
degree preserving would--

01:02:51.890 --> 01:02:54.300
I think you have to be a
little more subtle in defining

01:02:54.300 --> 01:02:55.650
your null model in that case.

01:02:55.650 --> 01:02:58.530
But I'll just say
that this happens

01:02:58.530 --> 01:03:00.460
more frequently than
you might expect,

01:03:00.460 --> 01:03:03.830
which is that you have
one transcription factor,

01:03:03.830 --> 01:03:06.610
say activating many,
many different proteins.

01:03:06.610 --> 01:03:07.950
And this makes sense.

01:03:07.950 --> 01:03:10.030
Because if all these
Z's are involved

01:03:10.030 --> 01:03:13.620
in the same metabolic program,
then when you want Z1,

01:03:13.620 --> 01:03:15.800
you also want Z2,
and you also want Z3.

01:03:15.800 --> 01:03:18.060
So this makes a lot of sense.

01:03:18.060 --> 01:03:21.000
But what is a little bit
less obvious perhaps,

01:03:21.000 --> 01:03:27.400
is that it's possible to do this
such that you first make one,

01:03:27.400 --> 01:03:28.997
and then you make the other.

01:03:28.997 --> 01:03:30.830
And the way that you
can do this is just by,

01:03:30.830 --> 01:03:35.580
you have different activation
thresholds, K1, K2, et cetera,

01:03:35.580 --> 01:03:39.000
up to Kn for each of these.

01:03:39.000 --> 01:03:43.470
So then if X is
turned on, so let's

01:03:43.470 --> 01:03:46.020
say that you first
see something.

01:03:46.020 --> 01:03:48.980
So this you actually have
to have X start at 0,

01:03:48.980 --> 01:03:50.800
and then grow over time.

01:03:50.800 --> 01:03:56.410
But then if you just have
different thresholds,

01:03:56.410 --> 01:03:59.060
the question is where
should I draw K1,

01:03:59.060 --> 01:04:02.760
and where should I
draw-- Do I draw K1

01:04:02.760 --> 01:04:07.110
the low position or
the high position?

01:04:07.110 --> 01:04:07.791
Low.

01:04:07.791 --> 01:04:08.290
Perfect.

01:04:08.290 --> 01:04:08.789
All right.

01:04:08.789 --> 01:04:09.910
So we say K1.

01:04:09.910 --> 01:04:11.250
Here's K2.

01:04:11.250 --> 01:04:13.290
Here is Kn.

01:04:13.290 --> 01:04:15.520
And then there might be
some others in between.

01:04:15.520 --> 01:04:19.830
So the idea is that
X grows over time.

01:04:19.830 --> 01:04:24.337
Then you first activate
expression of gene one,

01:04:24.337 --> 01:04:25.670
and then gene two, and so forth.

01:04:25.670 --> 01:04:27.170
And then the proteins
will naturally

01:04:27.170 --> 01:04:28.580
appear in the proper order.

01:04:28.580 --> 01:04:30.038
And there's actually
beautiful data

01:04:30.038 --> 01:04:33.714
in chapter five illustrating
this in the context of our gene

01:04:33.714 --> 01:04:34.255
biosynthesis.

01:04:37.790 --> 01:04:42.600
So it's quite neat to see that
it's not just-- of course,

01:04:42.600 --> 01:04:44.240
it's easy to think up this idea.

01:04:44.240 --> 01:04:45.000
And say, oh yeah.

01:04:45.000 --> 01:04:46.220
Maybe the cell might
want to do this.

01:04:46.220 --> 01:04:47.595
But then it's
quite cool when you

01:04:47.595 --> 01:04:49.678
see that actually in some
cases, the cell actually

01:04:49.678 --> 01:04:50.534
really does do this.

01:04:50.534 --> 01:04:53.075
And you can actually see that
they're expressed sequentially,

01:04:53.075 --> 01:04:56.810
in the same order as they appear
in the biosynthetic pathway.

01:05:02.750 --> 01:05:07.436
So this kind of gives you a
warm, fuzzy feeling inside.

01:05:07.436 --> 01:05:09.310
I'm not going to make
you vote on whether you

01:05:09.310 --> 01:05:10.393
have a warm fuzzy feeling.

01:05:10.393 --> 01:05:11.560
But, yeah?

01:05:11.560 --> 01:05:15.710
AUDIENCE: Could you also
have just some sort of Z1

01:05:15.710 --> 01:05:17.262
required for transcription?

01:05:17.262 --> 01:05:18.090
PROFESSOR: Ah, yes.

01:05:18.090 --> 01:05:21.694
So you could have a
cascade in that way.

01:05:21.694 --> 01:05:23.110
And that's a really
good question.

01:05:23.110 --> 01:05:24.630
That would work.

01:05:24.630 --> 01:05:28.690
But there's a problem, which
is that it's super slow.

01:05:28.690 --> 01:05:30.489
Because there's a
characteristic timescale

01:05:30.489 --> 01:05:33.030
for each of these things, which
is this cell generation time.

01:05:33.030 --> 01:05:37.890
And here when I say you want
it after the other, what

01:05:37.890 --> 01:05:42.450
I'm saying is you might want it
a few minutes after the other.

01:05:42.450 --> 01:05:44.736
So in the context of
development, in some cases

01:05:44.736 --> 01:05:46.110
some things really
are very slow.

01:05:46.110 --> 01:05:48.090
Then that is actually
what happens.

01:05:48.090 --> 01:05:51.570
There's a long cascade of one
activating two, activiating--

01:05:51.570 --> 01:05:54.127
But in the context
of this, you really

01:05:54.127 --> 01:05:56.460
want something that's just
delayed by five minutes each,

01:05:56.460 --> 01:05:58.920
or maybe even just a
couple minutes each.

01:05:58.920 --> 01:06:02.370
And in that case, because
really the range over which you

01:06:02.370 --> 01:06:06.365
can have this sort of delay
like this, from the beginning

01:06:06.365 --> 01:06:11.220
to the end, I mean this is
still-- it might be one to two,

01:06:11.220 --> 01:06:14.700
say cell generations/lifetimes.

01:06:14.700 --> 01:06:17.124
So you just can't get much
more of a dynamic range.

01:06:17.124 --> 01:06:18.790
Otherwise you're going
to be in trouble.

01:06:18.790 --> 01:06:20.960
Because you can't have this
be too close to the top.

01:06:20.960 --> 01:06:23.190
Otherwise if you're a
little bit off, you're off.

01:06:23.190 --> 01:06:26.560
So we really maybe we should
just even say one generation.

01:06:26.560 --> 01:06:28.690
So that's kind of
how much of a delay

01:06:28.690 --> 01:06:31.150
you might reasonably be able
to get from this mechanism.

01:06:31.150 --> 01:06:32.586
And indeed, and
that's as much as

01:06:32.586 --> 01:06:34.210
you would want for
something like this.

01:06:38.650 --> 01:06:41.185
So this is great.

01:06:41.185 --> 01:06:42.810
When I first read
this, I was like, oh.

01:06:42.810 --> 01:06:44.270
I was feeling it.

01:06:44.270 --> 01:06:48.960
Now the question is, after
this carbon source, or the need

01:06:48.960 --> 01:06:52.250
to make our gene or
whatnot, after it goes away,

01:06:52.250 --> 01:06:55.920
then we'll stop
making these proteins.

01:06:55.920 --> 01:06:59.750
And the question is,
is this what we call

01:06:59.750 --> 01:07:07.880
a FIFO queue, or a LIFO queue?

01:07:07.880 --> 01:07:09.540
LIFO, LIFO?

01:07:09.540 --> 01:07:10.840
It's been a long time.

01:07:10.840 --> 01:07:14.350
I have a lot of faces that are
like, what are talking about?

01:07:14.350 --> 01:07:23.160
So this is a First
in, first out.

01:07:23.160 --> 01:07:24.990
Have you guys really
not-- you never

01:07:24.990 --> 01:07:26.110
took any of these
computer science classes

01:07:26.110 --> 01:07:27.318
where they talked about this?

01:07:27.318 --> 01:07:29.370
And this is a Last
in, first out.

01:07:32.640 --> 01:07:39.090
So just to be clear, what this
means at the grocery store

01:07:39.090 --> 01:07:42.740
is that a first in, first out,
or a last in, in first out.

01:07:42.740 --> 01:07:43.990
AUDIENCE: First in, first out.

01:07:43.990 --> 01:07:44.880
PROFESSOR: It's a
first in, first out.

01:07:44.880 --> 01:07:45.380
Right?

01:07:45.380 --> 01:07:48.536
If you get in line first,
you get out first, hopefully.

01:07:48.536 --> 01:07:49.910
And when that
doesn't happen, you

01:07:49.910 --> 01:07:51.650
get very annoyed, and so forth.

01:07:51.650 --> 01:07:54.430
But last in, first out,
this is for example

01:07:54.430 --> 01:07:57.780
what happens in your inbox.

01:07:57.780 --> 01:07:59.182
So you have a stack of paper.

01:07:59.182 --> 01:08:00.640
People are giving
you things you're

01:08:00.640 --> 01:08:02.970
supposed to sign or fill out.

01:08:02.970 --> 01:08:05.990
And the pile kind of comes
up, and then you handle things

01:08:05.990 --> 01:08:07.390
on top of the pile first.

01:08:07.390 --> 01:08:09.170
So the things that get
stuck at the bottom

01:08:09.170 --> 01:08:10.420
you never get to them.

01:08:10.420 --> 01:08:15.620
And that's because that's
a last in, first out queue.

01:08:15.620 --> 01:08:18.764
And so different, depending on--
well and in computer science,

01:08:18.764 --> 01:08:20.180
then they can
choose these things.

01:08:20.180 --> 01:08:21.859
And it's relevant and so forth.

01:08:21.859 --> 01:08:25.240
But there are many situations
where this sort of idea

01:08:25.240 --> 01:08:26.220
appears.

01:08:26.220 --> 01:08:29.550
And so the question is, in
the single input module,

01:08:29.550 --> 01:08:33.130
do we have a first in, first
out, or a last in, first

01:08:33.130 --> 01:08:34.090
out queue?

01:08:34.090 --> 01:08:37.020
I'll give you 15 seconds
to think about this.

01:08:37.020 --> 01:08:37.720
Yeah, question?

01:08:37.720 --> 01:08:39.428
AUDIENCE: What do you
mean by in and out?

01:08:39.428 --> 01:08:41.149
PROFESSOR: So in
and out, what I mean

01:08:41.149 --> 01:08:46.779
is that the concentration
of each of these Z's,

01:08:46.779 --> 01:08:51.010
these guys they were
produced in some order.

01:08:51.010 --> 01:08:51.510
Right?

01:08:51.510 --> 01:08:55.670
So first we started producing
Z1, then Z2's and then so forth

01:08:55.670 --> 01:08:57.279
up to Zn.

01:08:57.279 --> 01:09:01.060
And what I want to know is what
order will the concentration

01:09:01.060 --> 01:09:02.530
kind of go away in?

01:09:05.930 --> 01:09:10.340
And you might want to
look at this figure.

01:09:10.340 --> 01:09:12.354
Because it's going
to be super useful.

01:09:16.380 --> 01:09:19.609
Any other questions about what
I-- all right, so in and out

01:09:19.609 --> 01:09:22.615
refers to concentrations
going up, and then going down.

01:09:27.871 --> 01:09:28.870
Let's go ahead and vote.

01:09:28.870 --> 01:09:31.390
Ready, three, two, one.

01:09:35.270 --> 01:09:39.500
See, I mean people learned
what FIFO and LIFO queues were.

01:09:39.500 --> 01:09:42.390
And now already we can use it.

01:09:42.390 --> 01:09:45.540
So this is a last
in, first out queue.

01:09:45.540 --> 01:09:50.319
And in general, which
kind of queue do we like?

01:09:50.319 --> 01:09:52.557
We like LIFO queues more.

01:09:52.557 --> 01:09:53.640
Well, OK, you could argue.

01:09:53.640 --> 01:09:59.050
But in this actuation would
we like a FIFO or LIFO queue?

01:09:59.050 --> 01:10:01.160
I'll give you 10 seconds.

01:10:01.160 --> 01:10:03.910
In a biosynthetic
pathway, would you

01:10:03.910 --> 01:10:05.940
want a LIFO or a FIFO queue?

01:10:13.340 --> 01:10:14.930
Yeah, and if you're
totally confused

01:10:14.930 --> 01:10:18.120
by everything I'm saying,
you can do the-- flash

01:10:18.120 --> 01:10:21.280
all the letters,
numbers, whatever.

01:10:21.280 --> 01:10:21.780
All right.

01:10:21.780 --> 01:10:25.460
Ready, three, two, one.

01:10:25.460 --> 01:10:25.960
All right.

01:10:25.960 --> 01:10:29.560
So there's some
disagreement we got.

01:10:29.560 --> 01:10:31.520
But now a majority
of people are saying

01:10:31.520 --> 01:10:34.340
that although the single
input module gives us

01:10:34.340 --> 01:10:37.050
a LIFO queue, what we might
really like is a FIFO queue.

01:10:37.050 --> 01:10:39.450
And can somebody say
why that would be?

01:10:39.450 --> 01:10:42.062
AUDIENCE: We don't want
that much intermediates.

01:10:42.062 --> 01:10:42.770
PROFESSOR: Right.

01:10:42.770 --> 01:10:45.320
We don't want to pile
up those intermediates.

01:10:45.320 --> 01:10:48.490
So just for the same reason
that we wanted to start with Z1,

01:10:48.490 --> 01:10:50.166
and then get Z2 and so forth.

01:10:50.166 --> 01:10:51.790
And the reason that
was because there's

01:10:51.790 --> 01:10:54.940
no point in having Z2
until after we have Z1.

01:10:54.940 --> 01:10:56.670
Because there's
nothing for Z2 to do.

01:10:56.670 --> 01:10:59.090
It would be wasted
energy to make it.

01:10:59.090 --> 01:11:01.860
In the same way, when we're
getting rid of these proteins,

01:11:01.860 --> 01:11:04.970
we would actually like to get
rid of them first this one

01:11:04.970 --> 01:11:06.017
and then later.

01:11:06.017 --> 01:11:06.600
AUDIENCE: Why?

01:11:10.150 --> 01:11:12.805
There's no point in having
Z2 if you don't have Z1.

01:11:12.805 --> 01:11:15.787
You technically want to get
rid of them in the other way.

01:11:15.787 --> 01:11:18.769
Because then if the carbon
source shows up again,

01:11:18.769 --> 01:11:19.520
you want to have--

01:11:19.520 --> 01:11:21.727
PROFESSOR: Well yeah, carbon
source showing up again.

01:11:21.727 --> 01:11:23.360
I think that's a
separate argument.

01:11:23.360 --> 01:11:25.360
So the reason that
we-- the statement

01:11:25.360 --> 01:11:28.600
is really just that if
we first get rid of Zn.

01:11:28.600 --> 01:11:33.906
Then we are just going to
pile up molecule n minus 1.

01:11:33.906 --> 01:11:37.411
AUDIENCE: So the
metabolism is down.

01:11:37.411 --> 01:11:38.410
PROFESSOR: That's right.

01:11:38.410 --> 01:11:38.790
That's right.

01:11:38.790 --> 01:11:40.350
So you can just
think about the flow

01:11:40.350 --> 01:11:43.520
of those of the metabolites
and the molecules in there.

01:11:43.520 --> 01:11:46.150
And you kind of want to
first get rid of this.

01:11:46.150 --> 01:11:48.230
So then we stop making this.

01:11:48.230 --> 01:11:50.490
And then we kind
of travel on down.

01:11:50.490 --> 01:11:53.660
So there are many contexts in
which you would perhaps really

01:11:53.660 --> 01:11:57.530
like to have a FIFO queue.

01:11:57.530 --> 01:11:59.240
And indeed, one
of the things that

01:11:59.240 --> 01:12:03.190
had been studied previously
was the flagellar biosynthesis

01:12:03.190 --> 01:12:03.950
pathway.

01:12:03.950 --> 01:12:06.060
So E. coli and many
other bacteria,

01:12:06.060 --> 01:12:08.550
they make these flagella
that allows them to swim.

01:12:08.550 --> 01:12:10.758
We're going to talk a lot
about that in coming weeks.

01:12:10.758 --> 01:12:13.810
But in this context what
had been found actually

01:12:13.810 --> 01:12:16.050
is that it is
indeed a FIFO queue.

01:12:16.050 --> 01:12:19.080
So when they first start to
make these little flagella,

01:12:19.080 --> 01:12:19.860
they make.

01:12:19.860 --> 01:12:21.500
And it's a big
complicated, machine.

01:12:21.500 --> 01:12:22.000
Right?

01:12:22.000 --> 01:12:25.200
But they make it in the order
that it's transported and put

01:12:25.200 --> 01:12:26.800
in the membrane.

01:12:26.800 --> 01:12:28.300
But then when it
is taken away, when

01:12:28.300 --> 01:12:30.280
you stop making the
flagella components,

01:12:30.280 --> 01:12:34.040
then it's again
in the same order

01:12:34.040 --> 01:12:37.560
as they were made in,
which kind of makes sense.

01:12:37.560 --> 01:12:40.548
Now the question is, how
might we be able to do that.

01:12:48.390 --> 01:12:53.340
So let me explain it.

01:12:53.340 --> 01:12:55.720
The basic answer
is via an extension

01:12:55.720 --> 01:12:57.490
of these feed-forward loops.

01:13:01.730 --> 01:13:04.510
So it's what we call a
multi-output feed-forward loop.

01:13:14.830 --> 01:13:16.780
What we have here
is we have some X,

01:13:16.780 --> 01:13:21.420
and it is going to
come to Y. And then

01:13:21.420 --> 01:13:26.780
Y again is going to do
this thing to Z1 and Z2,

01:13:26.780 --> 01:13:27.730
and all the others.

01:13:32.450 --> 01:13:34.380
But it's a feed-forward
loop, because we also

01:13:34.380 --> 01:13:36.890
have X coming in here as so.

01:13:43.259 --> 01:13:45.550
And I think that we do want
to have these be AND gates.

01:13:45.550 --> 01:13:51.780
Let me just make sure I'm not--
no here's it's an OR gate.

01:13:58.970 --> 01:14:01.930
So we're going to assume
that all of these inputs

01:14:01.930 --> 01:14:05.320
are combined via an OR gate.

01:14:05.320 --> 01:14:12.230
And what we have is we have some
K1, K2, et cetera, up to Kn.

01:14:12.230 --> 01:14:14.140
Then we have another
set of K's which are

01:14:14.140 --> 01:14:22.090
K1 primes, K2 prime, Kn prime.

01:14:22.090 --> 01:14:24.260
So we have a set of
K's corresponding

01:14:24.260 --> 01:14:27.242
to how X interacts with
the promoter at the Z.

01:14:27.242 --> 01:14:29.200
We have different set of
K primes that tells us

01:14:29.200 --> 01:14:36.300
how Y interacts with
the promoter at Z.

01:14:36.300 --> 01:14:39.185
And the question is how
can we get a FIFO order.

01:14:51.070 --> 01:14:53.220
I'm going to illustrate
some options.

01:14:53.220 --> 01:14:56.518
And you can think
about it while I do it.

01:16:03.883 --> 01:16:07.785
AUDIENCE: Are those
associations or dissociations?

01:16:07.785 --> 01:16:09.820
PROFESSOR: These are
dissociation constants.

01:16:09.820 --> 01:16:14.330
So these are again, this can be
thought of as the concentration

01:16:14.330 --> 01:16:18.150
of the active protein
which it starts

01:16:18.150 --> 01:16:22.085
being effective in sending
a signal to Z. Question?

01:16:22.085 --> 01:16:24.065
AUDIENCE: Would you
not like [INAUDIBLE]?

01:16:30.314 --> 01:16:31.230
PROFESSOR: I hope not.

01:16:31.230 --> 01:16:33.105
Because otherwise I'm
going to be in trouble.

01:16:35.610 --> 01:16:39.190
Maybe for now let's, assume that
I've written the right thing.

01:16:39.190 --> 01:16:43.210
And then we'll find
out soon enough.

01:16:51.350 --> 01:16:54.150
Does everyone understand
the question here?

01:16:54.150 --> 01:16:56.919
I'll just give you another
15 seconds to think about it.

01:17:25.660 --> 01:17:26.160
All right.

01:17:26.160 --> 01:17:27.226
Do you need more time?

01:17:30.431 --> 01:17:30.930
All right.

01:17:30.930 --> 01:17:32.096
Just a little bit more then.

01:17:43.860 --> 01:17:44.360
All right.

01:17:44.360 --> 01:17:45.693
Let's go ahead and give it a go.

01:17:45.693 --> 01:17:47.245
Ready, three, two, one.

01:17:49.870 --> 01:17:51.280
OK.

01:17:51.280 --> 01:17:54.685
So we got a majority
B, but some C's.

01:17:57.680 --> 01:17:58.180
All right.

01:17:58.180 --> 01:17:59.513
So let's try to figure this out.

01:18:01.780 --> 01:18:03.902
So what we assume
is that X comes

01:18:03.902 --> 01:18:07.300
and it's going to do this.

01:18:07.300 --> 01:18:09.440
And then it's going to do this.

01:18:09.440 --> 01:18:14.800
And we can just have two
values for now, K1 and K2.

01:18:14.800 --> 01:18:19.010
So this is X. Now
we're going to have Y.

01:18:19.010 --> 01:18:21.240
And we can talk
about-- this is also

01:18:21.240 --> 01:18:24.210
X star Y. We'll assume that
we always have these things.

01:18:24.210 --> 01:18:27.000
So Y is also going to come.

01:18:27.000 --> 01:18:33.710
It'll be activated
here at some time,

01:18:33.710 --> 01:18:36.960
which we don't-- it's going
to be delayed by a little bit,

01:18:36.960 --> 01:18:38.480
right?

01:18:38.480 --> 01:18:38.980
Maybe.

01:18:49.510 --> 01:18:51.180
So that's what Y is going to do.

01:18:51.180 --> 01:18:54.940
Now we want to know
about Z1 and Z2, right?

01:18:54.940 --> 01:18:57.440
Well, the idea here
is that it's going

01:18:57.440 --> 01:19:03.930
to be the K, the regular
K1 and K2 that determine

01:19:03.930 --> 01:19:05.450
the order that it appears.

01:19:05.450 --> 01:19:06.560
We have an OR gate.

01:19:06.560 --> 01:19:08.440
Y is going to be delayed.

01:19:08.440 --> 01:19:13.270
So it's really, the important
thing is what the normal K's do

01:19:13.270 --> 01:19:16.795
in terms of turning on Z's.

01:19:16.795 --> 01:19:17.295
Yes?

01:19:20.650 --> 01:19:23.090
And this is especially true
because Y is again delayed.

01:19:23.090 --> 01:19:26.404
Because it has its own
threshold for turning on.

01:19:26.404 --> 01:19:28.570
So since Y is delayed, it
won't really have a chance

01:19:28.570 --> 01:19:33.310
to influence the
behavior of the X's.

01:19:33.310 --> 01:19:35.780
And actually I should have
drawn this delayed too, as well.

01:19:45.250 --> 01:19:46.640
So it's the order
of the K's that

01:19:46.640 --> 01:19:49.910
determine how Z is turned on.

01:19:49.910 --> 01:19:51.780
But it's the order
of the K primes

01:19:51.780 --> 01:19:55.490
that tell us how the
Z's are turned off.

01:19:55.490 --> 01:20:00.860
And that's again because Y
is delayed relative to X.

01:20:00.860 --> 01:20:04.160
And we have an OR gate.

01:20:04.160 --> 01:20:08.792
So indeed, in this case,
if we have like this,

01:20:08.792 --> 01:20:11.250
and we want things to be in
the opposite order with respect

01:20:11.250 --> 01:20:14.340
to Y. So if we wanted K1
to be less than K2, then

01:20:14.340 --> 01:20:20.380
we actually want say
Kn to be-- I'm sorry.

01:20:20.380 --> 01:20:23.360
We want K1 here, and then
we want Kn down below.

01:20:27.110 --> 01:20:29.390
And the heart of this is
really because of the fact

01:20:29.390 --> 01:20:37.760
that X is also regulating Y
with some other constant Ky.

01:20:37.760 --> 01:20:40.220
And this is going to tell us
how much Y is delayed relative

01:20:40.220 --> 01:20:46.040
to X. But the heart of this
is that since Y is delayed,

01:20:46.040 --> 01:20:48.810
it's really the dynamics of X
at the beginning that tell us

01:20:48.810 --> 01:20:50.900
how the Z's are turned on.

01:20:50.900 --> 01:20:56.870
But it's the dynamic of the Y
and the K primes, K1 prime, Kn

01:20:56.870 --> 01:21:01.280
prime, that tell us the
order at which those Z's

01:21:01.280 --> 01:21:02.860
are going to be turned off.

01:21:02.860 --> 01:21:06.170
So with the proper choice
of orderings of K's and K

01:21:06.170 --> 01:21:15.680
primes is you can
then get a FIFO queue.

01:21:19.580 --> 01:21:21.220
With that I think
we should quit.

01:21:21.220 --> 01:21:23.740
Please read Sunney Xie's
paper very carefully,

01:21:23.740 --> 01:21:26.680
because it's going to be focused
on a lot over the next lecture.

01:21:26.680 --> 01:21:27.180
All right.

01:21:27.180 --> 01:21:29.330
Have a good weekend.

