WEBVTT
Kind: captions
Language: en

00:00:00.050 --> 00:00:01.670
The following
content is provided

00:00:01.670 --> 00:00:03.810
under a Creative
Commons license.

00:00:03.810 --> 00:00:06.540
Your support will help MIT
OpenCourseWare continue

00:00:06.540 --> 00:00:10.120
to offer high-quality
educational resources for free.

00:00:10.120 --> 00:00:12.700
To make a donation or to
view additional materials

00:00:12.700 --> 00:00:16.600
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:16.600 --> 00:00:17.282
at ocw.mit.edu.

00:00:21.630 --> 00:00:26.540
PROFESSOR: Last time we
talked about the spin operator

00:00:26.540 --> 00:00:30.810
pointing in some
particular direction.

00:00:30.810 --> 00:00:32.740
There were questions.

00:00:32.740 --> 00:00:35.160
In fact, there was
a useful question

00:00:35.160 --> 00:00:42.110
that I think I want to begin
the lecture by going back to it.

00:00:42.110 --> 00:00:47.740
And this, you received
an email from me.

00:00:47.740 --> 00:00:53.880
The notes have an extra section
added to it that is stuff

00:00:53.880 --> 00:00:56.140
that I didn't do
in class last time,

00:00:56.140 --> 00:01:02.570
but I was told in fact some
of the recitation instructors

00:01:02.570 --> 00:01:06.100
did discuss this
matter And I'm going

00:01:06.100 --> 00:01:07.920
to say a few words about it.

00:01:07.920 --> 00:01:11.990
Now, I do expect you
to read the notes.

00:01:11.990 --> 00:01:16.780
So things that you will need for
the homework, all the material

00:01:16.780 --> 00:01:20.500
that is in the notes is
material that I kind of

00:01:20.500 --> 00:01:23.690
assume you're familiar with.

00:01:23.690 --> 00:01:27.118
And you've read it
and understood it.

00:01:27.118 --> 00:01:31.560
And I probably don't cover
all what is in the notes,

00:01:31.560 --> 00:01:34.440
especially examples
or some things

00:01:34.440 --> 00:01:36.000
don't go into so much detail.

00:01:36.000 --> 00:01:39.540
But the notes should really be
helping you understand things

00:01:39.540 --> 00:01:40.670
well.

00:01:40.670 --> 00:01:47.490
So the remark I want to make
is that-- there was a question

00:01:47.490 --> 00:01:53.330
last time that better that
we think about it more

00:01:53.330 --> 00:01:57.760
deliberately in which we saw
there that Pauli matrices,

00:01:57.760 --> 00:02:03.170
sigma 1 squared was equal
to sigma 2 squared equal

00:02:03.170 --> 00:02:07.360
to 2 sigma 3 squared
was equal to 1.

00:02:07.360 --> 00:02:09.810
Well, that, indeed,
tells you something

00:02:09.810 --> 00:02:17.170
important about the
eigenvalues of this matrices.

00:02:17.170 --> 00:02:20.280
And it's a general fact.

00:02:20.280 --> 00:02:26.585
If you have some matrix M
that satisfies an equation.

00:02:26.585 --> 00:02:28.800
Now, let me write an equation.

00:02:28.800 --> 00:02:35.560
The matrix M squared plus alpha
M plus beta times the identity

00:02:35.560 --> 00:02:37.570
is equal to 0.

00:02:37.570 --> 00:02:39.230
This is a matrix equation.

00:02:39.230 --> 00:02:43.210
It takes the whole matrix,
square it, add alpha times

00:02:43.210 --> 00:02:46.390
the matrix, and then beta
times the identity matrix

00:02:46.390 --> 00:02:47.470
is equal to 0.

00:02:47.470 --> 00:02:52.440
Suppose you discover that
such an equation holds

00:02:52.440 --> 00:02:57.050
for that matrix M. Then,
suppose you are also

00:02:57.050 --> 00:03:01.010
asked to find eigenvalues
of this matrix M. So suppose

00:03:01.010 --> 00:03:04.200
there is a vector--
that is, an eigenvector

00:03:04.200 --> 00:03:06.850
with eigenvalue lambda.

00:03:06.850 --> 00:03:09.130
That's what having
an eigenvector

00:03:09.130 --> 00:03:12.880
with eigenvalue lambda means.

00:03:12.880 --> 00:03:17.300
And you're supposed to calculate
these values of lambda.

00:03:17.300 --> 00:03:21.280
So what you do here
is let this equation,

00:03:21.280 --> 00:03:25.240
this matrix on the left,
act on the vector v.

00:03:25.240 --> 00:03:32.970
So you have M squared plus
alpha M plus beta 1 act

00:03:32.970 --> 00:03:41.630
on v. Since the matrix
is 0, it should be 0.

00:03:41.630 --> 00:03:44.410
And now you come and
say, well, let's see.

00:03:44.410 --> 00:03:48.920
Beta times 1 on v. Well,
that's just beta times

00:03:48.920 --> 00:03:53.140
v, the vector v.

00:03:53.140 --> 00:03:58.020
Alpha M on v, but M on
v is lambda v. So this

00:03:58.020 --> 00:04:06.400
is alpha lambda v. And M squared
on v, as you can imagine,

00:04:06.400 --> 00:04:09.100
you act with another M here.

00:04:09.100 --> 00:04:10.500
Then you go to this side.

00:04:10.500 --> 00:04:14.130
You get lambda Mv, which
is, again, another lambda

00:04:14.130 --> 00:04:19.300
times v. So M squared
on v is lambda squared

00:04:19.300 --> 00:04:25.960
v. If acts two times on v.

00:04:25.960 --> 00:04:28.540
Therefore, this is 0.

00:04:28.540 --> 00:04:31.190
And here you have, for
example, that lambda

00:04:31.190 --> 00:04:40.020
squared plus alpha lambda
plus beta on v is equal to 0.

00:04:40.020 --> 00:04:43.460
Well, v cannot be 0.

00:04:43.460 --> 00:04:49.500
Any eigenvector-- by definition,
eigenvectors are not 0 vectors.

00:04:49.500 --> 00:04:54.179
You can have 0 eigenvalues
but not 0 eigenvectors.

00:04:54.179 --> 00:04:54.970
That doesn't exist.

00:04:54.970 --> 00:04:58.720
An eigenvector that
is 0 is a crazy thing

00:04:58.720 --> 00:05:01.240
because this would
be 0, and then it

00:05:01.240 --> 00:05:05.780
would be-- the eigenvalue
would not be determined.

00:05:05.780 --> 00:05:07.190
It just makes no sense.

00:05:07.190 --> 00:05:09.190
So v is different from 0.

00:05:09.190 --> 00:05:16.300
So you see that lambda squared
plus alpha lambda plus beta is

00:05:16.300 --> 00:05:17.820
equal to 0.

00:05:17.820 --> 00:05:22.490
And the eigenvalues, any
eigenvalue of this matrix,

00:05:22.490 --> 00:05:26.660
must satisfy this equation.

00:05:26.660 --> 00:05:29.410
So the eigenvalues
of sigma 1, you

00:05:29.410 --> 00:05:33.270
have sigma 1 squared, for
example, is equal to 1.

00:05:33.270 --> 00:05:38.880
So the eigenvalues,
any lambda squared

00:05:38.880 --> 00:05:42.170
must be equal to
1, the number 1.

00:05:44.790 --> 00:05:47.810
And therefore, the
eigenvalues of sigma 1

00:05:47.810 --> 00:05:51.260
are possibly plus or minus 1.

00:05:51.260 --> 00:05:54.080
We don't know yet.

00:05:54.080 --> 00:06:00.730
Could be two 1's, 2 minus
1's, one 1 and one minus 1.

00:06:00.730 --> 00:06:07.420
But there's another nice
thing, the trace of sigma 1.

00:06:07.420 --> 00:06:09.970
We'll study more the
trace, don't worry.

00:06:09.970 --> 00:06:12.430
If you are not that
familiar with it,

00:06:12.430 --> 00:06:15.620
it will become
more familiar soon.

00:06:15.620 --> 00:06:18.290
The trace of sigma
1 or any matrix

00:06:18.290 --> 00:06:20.540
is the sum of elements
in the diagonal.

00:06:20.540 --> 00:06:25.290
Sigma 1, if you remember,
was of this form.

00:06:25.290 --> 00:06:27.580
Therefore, the trace is 0.

00:06:27.580 --> 00:06:33.910
And in fact, the traces of any
of the Pauli matrices are 0.

00:06:33.910 --> 00:06:37.010
Another little theorem
of linear algebra

00:06:37.010 --> 00:06:43.430
shows that the
trace of a matrix is

00:06:43.430 --> 00:06:45.540
equal to the sum of eigenvalues.

00:06:45.540 --> 00:06:49.020
So whatever two
eigenvlaues sigma 1 has,

00:06:49.020 --> 00:06:50.970
they must add up to 0.

00:06:50.970 --> 00:06:55.810
Because the trace is 0
and it's equal to the sum

00:06:55.810 --> 00:06:57.015
of eigenvalues.

00:07:01.310 --> 00:07:04.930
And therefore, if the
eigenvalues can only

00:07:04.930 --> 00:07:10.510
be plus or minus 1,
you have the result

00:07:10.510 --> 00:07:13.920
that one eigenvalue
must be plus 1.

00:07:13.920 --> 00:07:16.290
The other eigenvalue
must be minus 1,

00:07:16.290 --> 00:07:19.480
is the only way you
can get that to work.

00:07:19.480 --> 00:07:33.451
So two sigma 1 eigenvalues of
sigma 1 are plus 1 and minus 1.

00:07:33.451 --> 00:07:34.700
Those are the two eigenvalues.

00:07:38.390 --> 00:07:43.980
So in that section
as well, there's

00:07:43.980 --> 00:07:48.260
some discussion about properties
of the Pauli matrices.

00:07:48.260 --> 00:07:54.390
And two basic properties
of Pauli matrices

00:07:54.390 --> 00:07:56.680
are the following.

00:07:56.680 --> 00:08:00.780
Remember that the spin
matrices, the spin operators,

00:08:00.780 --> 00:08:05.220
are h bar over 2 times
the Pauli matrices.

00:08:05.220 --> 00:08:09.850
And the spin operators had the
algebra for angular momentum.

00:08:09.850 --> 00:08:12.510
So from the algebra
of angular momentum

00:08:12.510 --> 00:08:23.820
that says that Si Sj is equal
to i h bar epsilon i j k Sk,

00:08:23.820 --> 00:08:29.860
you deduce after plugging
this that sigma i sigma

00:08:29.860 --> 00:08:36.320
j is 2i epsilon i j k sigma k.

00:08:45.130 --> 00:08:47.480
Moreover, there's
another nice property

00:08:47.480 --> 00:08:52.800
of the Pauli matrices having
to deal with anticommutators.

00:08:52.800 --> 00:08:58.150
If you do experimentally
try multiplying

00:08:58.150 --> 00:09:01.710
Pauli matrices,
sigma 1 and sigma 2,

00:09:01.710 --> 00:09:04.970
you will find out that if you
compare it with sigma 2 sigma

00:09:04.970 --> 00:09:06.750
1, it's different.

00:09:06.750 --> 00:09:09.950
Of course, it's not the same.

00:09:09.950 --> 00:09:11.460
These matrices don't commute.

00:09:11.460 --> 00:09:15.000
But they actually-- while
they fail to commute,

00:09:15.000 --> 00:09:17.470
they still fail to
commute in a nice way.

00:09:17.470 --> 00:09:21.530
Actually, these are
minus each other.

00:09:21.530 --> 00:09:28.130
So in fact, sigma 1 sigma 2 plus
sigma 2 sigma 1 is equal to 0.

00:09:28.130 --> 00:09:31.470
And by this, we mean
that they anticommute.

00:09:31.470 --> 00:09:35.050
And we have a brief
way of calling this.

00:09:35.050 --> 00:09:38.580
When this sign was a minus,
it was called the commutator.

00:09:38.580 --> 00:09:42.460
When this is a plus, it's
called an anticommutator.

00:09:42.460 --> 00:09:48.930
So the anticommutator of sigma
1 with sigma 2 is equal to 0.

00:09:48.930 --> 00:09:53.730
Anticommutator defined
in general by A,

00:09:53.730 --> 00:09:58.090
B. Two operators is AB plus BA.

00:10:01.100 --> 00:10:03.540
And as you will
read in the notes,

00:10:03.540 --> 00:10:06.955
a little more analysis
shows that, in fact,

00:10:06.955 --> 00:10:10.290
the anticommutator of
sigma i and sigma j

00:10:10.290 --> 00:10:16.300
has a nice formula,
which is 2 delta ij times

00:10:16.300 --> 00:10:19.490
the unit matrix, the
2 by 2 unit matrix.

00:10:25.640 --> 00:10:29.860
With this result, you
get a general formula.

00:10:29.860 --> 00:10:36.190
Any product of two operators,
AB, you can write as 1/2

00:10:36.190 --> 00:10:41.569
of the anticommutator plus
1-- no, 1/2 of the commutator

00:10:41.569 --> 00:10:42.860
plus 1/2 of the anticommutator.

00:10:46.510 --> 00:10:50.450
Expand it out, that
right-hand side,

00:10:50.450 --> 00:10:52.520
and you will see
quite quickly this

00:10:52.520 --> 00:10:55.980
is true for any two operators.

00:10:55.980 --> 00:11:00.450
This has AB minus BA
and this has AB plus BA.

00:11:00.450 --> 00:11:05.370
The BA term cancels and the
AB terms are [INAUDIBLE].

00:11:05.370 --> 00:11:13.140
So sigma i sigma j
would be equal to 1/2.

00:11:13.140 --> 00:11:15.450
And then they put down
the anticommutator first.

00:11:15.450 --> 00:11:19.700
So you get delta ij
times the identity, which

00:11:19.700 --> 00:11:22.960
is 1/2 of the
anticommutator plus 1/2

00:11:22.960 --> 00:11:30.129
of the commutator, which
is i epsilon i j k sigma k.

00:11:35.510 --> 00:11:37.530
It's a very useful formula.

00:11:40.930 --> 00:11:46.130
In order to make those
formulas look neater,

00:11:46.130 --> 00:11:54.400
we invent a notation in which
we think of sigma as a triplet--

00:11:54.400 --> 00:11:58.440
sigma 1, sigma 2, and sigma 3.

00:11:58.440 --> 00:12:04.470
And then we have vectors,
like a-- normal vectors,

00:12:04.470 --> 00:12:06.170
components a1, a2, a3.

00:12:09.080 --> 00:12:17.520
And then we have a dot
sigma must be defined.

00:12:17.520 --> 00:12:19.480
Well, there's an
obvious definition

00:12:19.480 --> 00:12:22.180
of what this should
mean, but it's not

00:12:22.180 --> 00:12:24.390
something you're accustomed to.

00:12:24.390 --> 00:12:27.340
And one should pause
before saying this.

00:12:27.340 --> 00:12:31.440
You're having a normal
vector, a triplet of numbers,

00:12:31.440 --> 00:12:34.780
multiplied by a
triplet of matrices,

00:12:34.780 --> 00:12:38.370
or a triplet of operators.

00:12:38.370 --> 00:12:41.930
Since numbers commute
with matrices,

00:12:41.930 --> 00:12:45.000
the order in which you
write this doesn't matter.

00:12:45.000 --> 00:12:49.135
But this is defined
to be a1 sigma 1

00:12:49.135 --> 00:12:52.930
plus a2 sigma 2 plus a3 sigma 3.

00:12:56.250 --> 00:13:02.990
This can be written as ai
sigma i with our repeated index

00:13:02.990 --> 00:13:06.550
convention that you sum
over the possibilities.

00:13:06.550 --> 00:13:10.360
So here is what you're
supposed to do here

00:13:10.360 --> 00:13:14.070
to maybe interpret
this equation nicely.

00:13:14.070 --> 00:13:18.850
You multiply this
equation n by ai bj.

00:13:21.480 --> 00:13:22.930
Now, these are numbers.

00:13:22.930 --> 00:13:24.210
These are matrices.

00:13:24.210 --> 00:13:27.810
I better not change this
order, but I can certainly,

00:13:27.810 --> 00:13:34.590
by multiplying that way, I
have ai sigma i bj sigma j

00:13:34.590 --> 00:13:46.070
equals 2 ai bj delta ij
times the matrix 1 plus i

00:13:46.070 --> 00:13:52.740
epsilon i j k ai bj sigma k.

00:14:01.660 --> 00:14:02.860
Now, what?

00:14:02.860 --> 00:14:06.490
Well, write it in terms
of things that look neat.

00:14:06.490 --> 00:14:11.420
a dot sigma, that's a matrix.

00:14:11.420 --> 00:14:15.010
This whole thing is a matrix
multiplied by the matrix

00:14:15.010 --> 00:14:20.750
b dot sigma gives you--

00:14:20.750 --> 00:14:29.580
Well, ai bj delta ij, this
delta ij forces j to become i.

00:14:29.580 --> 00:14:34.460
In other words, you can replace
these two terms by just bi.

00:14:34.460 --> 00:14:36.980
And then you have ai bi.

00:14:36.980 --> 00:14:39.934
So this is twice.

00:14:39.934 --> 00:14:42.640
I don't know why I have a 2.

00:14:42.640 --> 00:14:44.780
No 2.

00:14:44.780 --> 00:14:48.300
There was no 2 there, sorry.

00:14:48.300 --> 00:14:49.650
So what do we get here?

00:14:49.650 --> 00:14:54.300
We get a dot b, the dot product.

00:14:54.300 --> 00:14:57.050
This is a normal dot product.

00:14:57.050 --> 00:15:02.690
This is just a number
times 1 plus i.

00:15:02.690 --> 00:15:05.580
Now, what is this thing?

00:15:05.580 --> 00:15:09.740
You should try to remember
how the epsilon tensor can

00:15:09.740 --> 00:15:11.880
be used to do cross products.

00:15:11.880 --> 00:15:16.820
This, there's just one
free index, the index k.

00:15:16.820 --> 00:15:19.000
So this must be
some sort of vector.

00:15:19.000 --> 00:15:24.090
And in fact, if you try the
definition of epsilon and look

00:15:24.090 --> 00:15:26.670
in detail what this
is, you will find

00:15:26.670 --> 00:15:35.410
that this is nothing but
the k component of a dot b.

00:15:35.410 --> 00:15:37.280
The k-- so I'll write it here.

00:15:37.280 --> 00:15:42.710
This is a cross b sub k.

00:15:42.710 --> 00:15:47.230
But now you have a cross
b sub k times sigma k.

00:15:47.230 --> 00:15:52.255
So this is the same as
a cross b dot sigma.

00:15:55.960 --> 00:16:03.375
And here you got a pretty nice
equation for Pauli matrices.

00:16:06.490 --> 00:16:10.930
It expresses the general
product of Pauli matrices

00:16:10.930 --> 00:16:14.090
in somewhat geometric terms.

00:16:14.090 --> 00:16:25.490
So if you take, for
example here, an operator.

00:16:25.490 --> 00:16:26.420
No.

00:16:26.420 --> 00:16:29.640
If you take, for
example, a equals

00:16:29.640 --> 00:16:38.680
b equal to a unit vector,
then what do we get?

00:16:38.680 --> 00:16:41.717
You get n dot sigma squared.

00:16:46.250 --> 00:16:48.530
And here you have
the dot product of n

00:16:48.530 --> 00:16:50.210
with n, which is 1.

00:16:50.210 --> 00:16:53.420
So this is 1.

00:16:53.420 --> 00:16:56.960
And the cross product of two
equal vectors, of course,

00:16:56.960 --> 00:17:03.970
is 0 so you get
this, which is nice.

00:17:03.970 --> 00:17:05.380
Why is this useful?

00:17:05.380 --> 00:17:11.760
It's because with this identity,
you can understand better

00:17:11.760 --> 00:17:15.410
the operator S hat
n that we introduced

00:17:15.410 --> 00:17:22.950
last time, which was n
dot the spin triplet.

00:17:22.950 --> 00:17:28.990
So nx, sx, ny, sy, nz, sc.

00:17:28.990 --> 00:17:30.370
So what is this?

00:17:30.370 --> 00:17:35.260
This is h bar over
2 and dot sigma.

00:17:40.320 --> 00:17:42.310
And let's square this.

00:17:42.310 --> 00:17:46.510
So Sn vector squared.

00:17:46.510 --> 00:17:52.420
This matrix squared would be
h bar over 2 squared times

00:17:52.420 --> 00:17:55.085
n dot sigma squared, which is 1.

00:18:04.600 --> 00:18:06.330
And sigma squared is 1.

00:18:06.330 --> 00:18:13.540
Therefore, this spin operator
along the n direction squares

00:18:13.540 --> 00:18:16.620
to h bar r squared
over 2 times 1.

00:18:16.620 --> 00:18:25.500
Now, the trace of this
Sn operator is also 0.

00:18:25.500 --> 00:18:26.860
Why?

00:18:26.860 --> 00:18:29.390
Because the trace
means that you're

00:18:29.390 --> 00:18:32.280
going to sum the
elements in the diagonal.

00:18:32.280 --> 00:18:36.260
Well, you have a sum
of matrices here.

00:18:36.260 --> 00:18:40.310
And therefore, you will have
to sum the diagonals of each.

00:18:40.310 --> 00:18:43.690
But each of the
sigmas has 0 trace.

00:18:43.690 --> 00:18:46.380
We wrote it there.

00:18:46.380 --> 00:18:48.310
Trace of sigma 1 is 0.

00:18:48.310 --> 00:18:53.660
All the Pauli matrices have
0 trace, so this has 0 trace.

00:18:53.660 --> 00:18:57.930
So you have these two relations.

00:18:57.930 --> 00:19:03.250
And again, this tells you that
the eigenvalues of this matrix

00:19:03.250 --> 00:19:07.210
can be plus minus h bar over 2.

00:19:07.210 --> 00:19:10.010
Because the eigenvalues
satisfy the same equation

00:19:10.010 --> 00:19:11.250
as the matrix.

00:19:11.250 --> 00:19:14.460
Therefor,e plus
minus h bar over 2.

00:19:14.460 --> 00:19:19.090
And this one says that the
eigenvalues add up to 0.

00:19:19.090 --> 00:19:29.070
So the eigenvalues of S hat n
vector are plus h bar over 2

00:19:29.070 --> 00:19:31.410
and minus h bar over 2.

00:19:31.410 --> 00:19:36.170
We did that last time, but we do
that by just taking that matrix

00:19:36.170 --> 00:19:37.820
and finding the eigenvalues.

00:19:37.820 --> 00:19:44.340
But this shows that its
property is almost manifest.

00:19:44.340 --> 00:19:47.180
And this is fundamental
for the interpretation

00:19:47.180 --> 00:19:49.310
of this operator.

00:19:49.310 --> 00:19:50.310
Why?

00:19:50.310 --> 00:19:54.110
Well, we saw that if n
points along the z-direction,

00:19:54.110 --> 00:19:56.340
it becomes the operator sz.

00:19:56.340 --> 00:19:58.490
If it points about
the x-direction,

00:19:58.490 --> 00:20:00.810
it becomes the operator sx.

00:20:00.810 --> 00:20:03.890
If it points along
y, it becomes sy.

00:20:03.890 --> 00:20:07.460
But in an arbitrary
direction, it's a funny thing.

00:20:07.460 --> 00:20:10.410
But it still has
the key property.

00:20:10.410 --> 00:20:14.200
If you measured the spin
along an arbitrary direction,

00:20:14.200 --> 00:20:19.740
you should find only plus h bar
over 2 or minus h bar over 2.

00:20:19.740 --> 00:20:23.320
Because after all, the
universe is isotopic.

00:20:23.320 --> 00:20:25.560
It doesn't depend on direction.

00:20:25.560 --> 00:20:27.500
So a spin one-half particle.

00:20:27.500 --> 00:20:30.660
If you find out that whenever
you measure the z component,

00:20:30.660 --> 00:20:33.250
it's either plus
minus h bar over 2.

00:20:33.250 --> 00:20:35.355
Well, when you
measure any direction,

00:20:35.355 --> 00:20:39.120
it should be plus
minus h bar over 2.

00:20:39.120 --> 00:20:42.940
And this shows that this
operator has those eigenvalues.

00:20:42.940 --> 00:20:47.570
And therefore, it makes sense
that this is the operator

00:20:47.570 --> 00:20:52.180
that measures spins in
an arbitrary direction.

00:20:52.180 --> 00:20:56.595
There's a little more
of an aside in there,

00:20:56.595 --> 00:20:58.610
in the notes about
something that

00:20:58.610 --> 00:21:02.590
will be useful and fun to do.

00:21:02.590 --> 00:21:04.830
And it corresponds to
the case in which you

00:21:04.830 --> 00:21:10.150
have two triplets of
operators-- x1, x2, x3.

00:21:10.150 --> 00:21:12.700
These are operators now.

00:21:12.700 --> 00:21:18.945
And y equal y1, y2, y3.

00:21:22.120 --> 00:21:24.160
Two triplets of operators.

00:21:24.160 --> 00:21:29.585
So you define the dot
product of these two triplets

00:21:29.585 --> 00:21:36.149
as xi yi summed.

00:21:36.149 --> 00:21:37.065
That's the definition.

00:21:41.920 --> 00:21:45.190
Now, the dot product of
two triplets of operators

00:21:45.190 --> 00:21:48.680
defined that way
may not commute.

00:21:48.680 --> 00:21:52.190
Because the operators x
and y may not commute.

00:21:52.190 --> 00:21:58.150
So this new dot product
of both phase operators

00:21:58.150 --> 00:22:01.380
is not commutative-- probably.

00:22:01.380 --> 00:22:03.800
It may happen that
these operators commute,

00:22:03.800 --> 00:22:07.630
in which case x dot y
is equal to y dot x.

00:22:07.630 --> 00:22:10.620
Similarly, you can
define the cross product

00:22:10.620 --> 00:22:14.000
of these two things.

00:22:14.000 --> 00:22:23.610
And the k-th component is
epsilon i j k xi yj like this.

00:22:26.830 --> 00:22:30.565
Just like you would define
it for two number vectors.

00:22:33.460 --> 00:22:36.860
Now, what do you know about
the cross product in general?

00:22:36.860 --> 00:22:37.875
It's anti-symmetric.

00:22:37.875 --> 00:22:40.400
A cross B is equal
to minus B cross A.

00:22:40.400 --> 00:22:48.290
But this one won't be
because the operators x and y

00:22:48.290 --> 00:22:49.490
may not commute.

00:22:49.490 --> 00:22:56.490
Even x cross x may be nonzero.

00:22:56.490 --> 00:23:00.180
So one thing I will ask you
to compute in the homework

00:23:00.180 --> 00:23:03.180
is not a long calculation.

00:23:03.180 --> 00:23:04.150
It's three lines.

00:23:04.150 --> 00:23:14.300
But what is S cross S equal to?

00:23:14.300 --> 00:23:15.040
Question there?

00:23:15.040 --> 00:23:15.956
AUDIENCE: [INAUDIBLE].

00:23:19.770 --> 00:23:21.860
PROFESSOR: Yes, it's
the sum [INAUDIBLE].

00:23:21.860 --> 00:23:24.710
Just in the same
way that here you're

00:23:24.710 --> 00:23:29.270
summing over i's and j's to
produce the cross product.

00:23:29.270 --> 00:23:31.810
So whenever an
index is repeated,

00:23:31.810 --> 00:23:34.780
we'll assume it's summed.

00:23:34.780 --> 00:23:37.920
And when it is not summed,
I will put to the right,

00:23:37.920 --> 00:23:41.110
not summed explicitly--
the words-.

00:23:41.110 --> 00:23:45.040
Because in some
occasions, it matters.

00:23:45.040 --> 00:23:46.820
So how much is this?

00:23:46.820 --> 00:23:50.840
It will involve i, h
bar, and something.

00:23:50.840 --> 00:23:53.790
And you will try to
find out what this is.

00:23:53.790 --> 00:23:56.930
It's a cute thing.

00:23:56.930 --> 00:23:59.533
All right, any other questions?

00:24:07.880 --> 00:24:09.270
More questions?

00:24:09.270 --> 00:24:09.770
Nope.

00:24:13.120 --> 00:24:13.800
OK.

00:24:13.800 --> 00:24:16.950
So now, finally,
we get to that part

00:24:16.950 --> 00:24:20.980
of the course that has to
do with linear algebra.

00:24:20.980 --> 00:24:25.050
And I'm going to
do an experiment.

00:24:25.050 --> 00:24:27.710
I'm going to do it
differently than I did it

00:24:27.710 --> 00:24:28.815
in the previous years.

00:24:32.450 --> 00:24:35.720
There is this nice book.

00:24:35.720 --> 00:24:37.710
It's here.

00:24:37.710 --> 00:24:40.090
I don't know if you
can read from that far,

00:24:40.090 --> 00:24:47.430
but it has a pretty-- you might
almost say an arrogant title.

00:24:47.430 --> 00:24:54.280
It says, Linear Algebra
Done Right by Sheldon Axler.

00:24:54.280 --> 00:25:00.140
This is the book, actually,
MIT's course 18.700 of linear

00:25:00.140 --> 00:25:02.560
algebra uses.

00:25:02.560 --> 00:25:05.450
And when you first get the
book that looks like that,

00:25:05.450 --> 00:25:08.340
you read it and open--
I'm going to show you

00:25:08.340 --> 00:25:11.760
that this is not that well done.

00:25:11.760 --> 00:25:15.510
But actually, I think
it's actually true.

00:25:15.510 --> 00:25:18.200
The title is not a lie.

00:25:18.200 --> 00:25:21.530
It's really done right.

00:25:21.530 --> 00:25:26.370
I actually wish I had learned
linear algebra this way.

00:25:26.370 --> 00:25:29.500
It may be a little
difficult if you've never

00:25:29.500 --> 00:25:32.550
done any linear algebra.

00:25:32.550 --> 00:25:34.780
You don't know what
the matrix is--

00:25:34.780 --> 00:25:36.640
I don't think that's
the case anybody here.

00:25:36.640 --> 00:25:41.580
A determinant, or eigenvalue.

00:25:41.580 --> 00:25:43.670
If you never heard
any of those words,

00:25:43.670 --> 00:25:46.050
this might be a little hard.

00:25:46.050 --> 00:25:48.110
But if you've heard
those words and you've

00:25:48.110 --> 00:25:50.930
had a little linear
algebra, this is quite nice.

00:25:50.930 --> 00:25:54.125
Now, this book has
also a small problem.

00:25:57.000 --> 00:25:59.930
Unless you study
it seriously, it's

00:25:59.930 --> 00:26:03.750
not all that easy to grab
results that you need from it.

00:26:03.750 --> 00:26:05.860
You have to study it.

00:26:05.860 --> 00:26:08.180
So I don't know if
it might help you

00:26:08.180 --> 00:26:10.420
or not during this semester.

00:26:10.420 --> 00:26:12.290
It may.

00:26:12.290 --> 00:26:14.060
It's not necessary to get it.

00:26:14.060 --> 00:26:15.620
Absolutely not.

00:26:15.620 --> 00:26:19.090
But it is quite lovely.

00:26:19.090 --> 00:26:21.630
And the emphasis is
quite interesting.

00:26:21.630 --> 00:26:25.780
It really begins from
very basic things

00:26:25.780 --> 00:26:28.520
and logically
develops everything

00:26:28.520 --> 00:26:31.520
and asks at every point
the right questions.

00:26:31.520 --> 00:26:32.580
It's quite nice.

00:26:32.580 --> 00:26:36.860
So what I'm going to do
is-- inspired by that,

00:26:36.860 --> 00:26:42.220
I want to introduce some of
the linear algebra little

00:26:42.220 --> 00:26:42.960
by little.

00:26:42.960 --> 00:26:45.910
And I don't know very
well how this will go.

00:26:45.910 --> 00:26:47.630
Maybe there's too much detail.

00:26:47.630 --> 00:26:52.120
Maybe it's a lot of
detail, but not enough so

00:26:52.120 --> 00:26:53.530
it's not all that great.

00:26:53.530 --> 00:26:55.750
I don't know, you
will have to tell me.

00:26:58.490 --> 00:27:01.130
But we'll try to get
some ideas clear.

00:27:01.130 --> 00:27:03.990
And the reason I want
to get some ideas clear

00:27:03.990 --> 00:27:08.880
is that good books
on this subject

00:27:08.880 --> 00:27:12.070
allow you to understand
how much structure you

00:27:12.070 --> 00:27:16.680
have to put in a vector space
to define certain things.

00:27:16.680 --> 00:27:20.470
And unless you do
this carefully,

00:27:20.470 --> 00:27:25.730
you probably miss some
of the basic things.

00:27:25.730 --> 00:27:30.240
Like many physicists
don't quite realize

00:27:30.240 --> 00:27:32.980
that talking about the
matrix representation,

00:27:32.980 --> 00:27:34.970
you don't need brass
and [INAUDIBLE]

00:27:34.970 --> 00:27:38.040
to talk about the matrix
representation of an operator.

00:27:38.040 --> 00:27:40.670
At first sight, it seems
like you'd need it,

00:27:40.670 --> 00:27:42.970
but you actually don't.

00:27:42.970 --> 00:27:46.640
Then, the differences between
a complex and a vector space--

00:27:46.640 --> 00:27:51.300
complex and a real vector
space become much clearer

00:27:51.300 --> 00:27:53.570
if you take your time
to understand it.

00:27:53.570 --> 00:27:55.320
They are very different.

00:27:55.320 --> 00:27:57.740
And in a sense,
complex vector spaces

00:27:57.740 --> 00:28:01.350
are more powerful, more
elegant, have stronger results.

00:28:04.260 --> 00:28:07.870
So anyway, it's enough
of an introduction.

00:28:07.870 --> 00:28:10.710
Let's see how we do.

00:28:10.710 --> 00:28:14.870
And let's just begin
there for our story.

00:28:14.870 --> 00:28:21.770
So we begin with vector
spaces and dimensionality.

00:28:21.770 --> 00:28:22.510
Yes.

00:28:22.510 --> 00:28:24.438
AUDIENCE: Quick question.

00:28:24.438 --> 00:28:28.776
The length between
the trace of matrix

00:28:28.776 --> 00:28:33.450
equals 0 and [INAUDIBLE] is
proportional to the identity.

00:28:33.450 --> 00:28:35.997
One is the product of
the eigenvalues is 1

00:28:35.997 --> 00:28:39.893
and the other one was
the sum is equal to 0.

00:28:39.893 --> 00:28:42.328
Are those two statements
related causally,

00:28:42.328 --> 00:28:44.710
or are they just separate
statements [INAUDIBLE]?

00:28:44.710 --> 00:28:46.210
PROFESSOR: OK, the
question is, what

00:28:46.210 --> 00:28:48.560
is the relation between
these two statements?

00:28:48.560 --> 00:28:50.570
Those are separate observations.

00:28:50.570 --> 00:28:53.050
One does not imply the other.

00:28:53.050 --> 00:28:56.490
You can have matrices that
square to the identity,

00:28:56.490 --> 00:29:00.290
like the identity itself,
and don't have 0 trace.

00:29:00.290 --> 00:29:02.590
So these are
separate properties.

00:29:02.590 --> 00:29:06.785
This tells us that
the eigenvalue squared

00:29:06.785 --> 00:29:10.010
are h bar over 2.

00:29:10.010 --> 00:29:14.280
And this one tells me that
lambda 1 plus lambda 2--

00:29:14.280 --> 00:29:16.780
there are two
eigenvalues-- are 0.

00:29:16.780 --> 00:29:20.250
So from here, you deduce
that the eigenvalues

00:29:20.250 --> 00:29:22.350
could be plus
minus h bar over 2.

00:29:22.350 --> 00:29:25.450
And in fact, have to be
plus minus h bar over 2.

00:29:28.520 --> 00:29:32.850
All right, so let's
talk about vector spaces

00:29:32.850 --> 00:29:35.590
and dimensionality.

00:29:35.590 --> 00:29:39.273
Spaces and dimensionality.

00:29:47.260 --> 00:29:50.480
So why do we care about this?

00:29:50.480 --> 00:29:53.060
Because the end result
of our discussion

00:29:53.060 --> 00:29:56.600
is that the states
of a physical system

00:29:56.600 --> 00:30:01.050
are vectors in a
complex vector space.

00:30:01.050 --> 00:30:04.820
That's, in a sense, the
result we're going to get.

00:30:04.820 --> 00:30:09.520
Observables, moreover,
are linear operators

00:30:09.520 --> 00:30:11.420
on those vector spaces.

00:30:11.420 --> 00:30:15.070
So we need to understand what
are complex vector spaces, what

00:30:15.070 --> 00:30:18.930
linear operators on them mean.

00:30:18.930 --> 00:30:22.650
So as I said,
complex vector spaces

00:30:22.650 --> 00:30:26.350
have subtle properties that make
them different from real vector

00:30:26.350 --> 00:30:28.840
spaces and we want
to appreciate that.

00:30:28.840 --> 00:30:32.110
In a vector space,
what do you have?

00:30:32.110 --> 00:30:36.830
You have vectors and
you have numbers.

00:30:36.830 --> 00:30:39.280
So the two things must exist.

00:30:39.280 --> 00:30:43.710
The numbers could be the
real numbers, in which case

00:30:43.710 --> 00:30:46.310
we're talking about
the real vector space.

00:30:46.310 --> 00:30:49.680
And the numbers could be
complex numbers, in which case

00:30:49.680 --> 00:30:52.530
we're talking about the
complex vector space.

00:30:52.530 --> 00:30:58.670
We don't say the vectors are
real, or complex, or imaginary.

00:30:58.670 --> 00:31:03.620
We just say there are vectors
and there are numbers.

00:31:03.620 --> 00:31:08.930
Now, the vectors can be
added and the numbers

00:31:08.930 --> 00:31:12.180
can be multiplied by
vectors to give vectors.

00:31:12.180 --> 00:31:15.500
That's basically
what is happening.

00:31:15.500 --> 00:31:20.320
Now, these numbers can
be real or complex.

00:31:20.320 --> 00:31:26.933
And the numbers-- so there
are vectors and numbers.

00:31:30.050 --> 00:31:33.550
And we will focus on
just either real numbers

00:31:33.550 --> 00:31:36.720
or complex numbers,
but either one.

00:31:36.720 --> 00:31:41.400
So these sets of
numbers form what

00:31:41.400 --> 00:31:43.770
is called in
mathematics a field.

00:31:43.770 --> 00:31:46.970
So I will not define the field.

00:31:46.970 --> 00:31:52.430
But a field-- use the
letter F for field.

00:31:52.430 --> 00:31:53.720
And our results.

00:31:53.720 --> 00:31:58.220
I will state results whenever--
it doesn't matter whether it's

00:31:58.220 --> 00:32:01.460
real or complex, I
may use the letter F

00:32:01.460 --> 00:32:05.480
to say the numbers are in F.
And you say real or complex.

00:32:10.260 --> 00:32:12.250
What is a vector space?

00:32:12.250 --> 00:32:22.310
So the vector space,
V. Vector space, V,

00:32:22.310 --> 00:32:36.410
is a set of vectors with an
operation called addition--

00:32:36.410 --> 00:32:54.160
and we represent it as plus--
that assigns a vector u plus v

00:32:54.160 --> 00:33:05.320
in the vector space when u and
v belong to the vector space.

00:33:05.320 --> 00:33:08.170
So for any u and v
in the vector space,

00:33:08.170 --> 00:33:14.170
there's a rule called addition
that assigns another vector.

00:33:14.170 --> 00:33:18.410
This also means that this
space is closed under addition.

00:33:18.410 --> 00:33:21.500
That is, you cannot get out
of the vector space by adding

00:33:21.500 --> 00:33:22.640
vectors.

00:33:22.640 --> 00:33:25.930
The vector space must
contain a set that

00:33:25.930 --> 00:33:28.390
is consistent in that
you can add vectors

00:33:28.390 --> 00:33:29.896
and you're always there.

00:33:29.896 --> 00:33:31.104
And there's a multiplication.

00:33:33.732 --> 00:33:49.420
And a scalar
multiplication by elements

00:33:49.420 --> 00:34:02.130
of the numbers of F such
that a, which is a number,

00:34:02.130 --> 00:34:07.110
times v belongs to
the vector space

00:34:07.110 --> 00:34:16.889
when a belongs to the numbers
and v belongs to the vectors.

00:34:16.889 --> 00:34:19.050
So every time you
have a vector, you

00:34:19.050 --> 00:34:22.730
can multiply by those
numbers and the result

00:34:22.730 --> 00:34:25.940
of that multiplication
is another vector.

00:34:25.940 --> 00:34:31.610
So we say the space is also
closed under multiplication.

00:34:31.610 --> 00:34:33.800
Now, these properties
exist, but they

00:34:33.800 --> 00:34:37.710
must-- these operations
exist, but they

00:34:37.710 --> 00:34:39.870
must satisfy the
following properties.

00:34:39.870 --> 00:34:41.809
So the definition
is not really over.

00:34:45.590 --> 00:34:49.753
These operations satisfy--

00:34:54.520 --> 00:34:56.030
1.

00:34:56.030 --> 00:34:59.770
u plus v is equal to v plus u.

00:34:59.770 --> 00:35:03.150
The order doesn't matter
how you sum vectors.

00:35:03.150 --> 00:35:07.830
And here, u and v in V.

00:35:07.830 --> 00:35:09.490
2.

00:35:09.490 --> 00:35:10.480
Associative.

00:35:10.480 --> 00:35:21.130
So u plus v plus w is
equal to u plus v plus w.

00:35:21.130 --> 00:35:30.950
Moreover, two numbers a times b
times v is the same as a times

00:35:30.950 --> 00:35:33.420
bv.

00:35:33.420 --> 00:35:35.624
You can add with the
first number on the vector

00:35:35.624 --> 00:35:36.790
and you add with the second.

00:35:41.920 --> 00:35:42.420
3.

00:35:45.400 --> 00:35:52.245
There is an additive identity.

00:35:55.930 --> 00:35:57.130
And that is what?

00:35:57.130 --> 00:36:01.450
It's a vector 0 belonging
to the vector space.

00:36:01.450 --> 00:36:03.370
I could write an arrow.

00:36:03.370 --> 00:36:07.570
But actually, for
some reason they just

00:36:07.570 --> 00:36:09.280
don't like to write
it because they say

00:36:09.280 --> 00:36:11.780
it's always ambiguous
whether you're

00:36:11.780 --> 00:36:15.910
talking about the 0
number or the 0 vector.

00:36:15.910 --> 00:36:18.050
We do have that problem
also in the notation

00:36:18.050 --> 00:36:19.480
in quantum mechanics.

00:36:19.480 --> 00:36:28.950
But here it is, here is
a 0 vector such that 0

00:36:28.950 --> 00:36:37.812
plus any vector v is equal to v.

00:36:37.812 --> 00:36:40.200
4.

00:36:40.200 --> 00:36:42.850
Well, in the field,
in the set of numbers,

00:36:42.850 --> 00:36:47.420
there's the number 1, which
multiplied by any other number

00:36:47.420 --> 00:36:49.790
keeps that number.

00:36:49.790 --> 00:36:58.210
So the number 1 that
belongs to the field

00:36:58.210 --> 00:37:08.050
satisfies that 1 times any
vector is equal to the vector.

00:37:08.050 --> 00:37:13.540
So we declare that that number
multiplied by other numbers

00:37:13.540 --> 00:37:14.780
is an identity.

00:37:14.780 --> 00:37:17.302
[INAUDIBLE] identity
also multiplying vectors.

00:37:17.302 --> 00:37:18.385
Yes, there was a question.

00:37:18.385 --> 00:37:21.120
AUDIENCE: [INAUDIBLE].

00:37:21.120 --> 00:37:24.945
PROFESSOR: There is
an additive identity.

00:37:24.945 --> 00:37:31.130
Additive identity, the 0 vector.

00:37:31.130 --> 00:37:35.532
Finally, distributive laws.

00:37:35.532 --> 00:37:37.850
No.

00:37:37.850 --> 00:37:38.690
One second.

00:37:38.690 --> 00:37:46.290
One, two, three--
the zero vector.

00:37:46.290 --> 00:37:50.670
Oh, actually in my list I
put them in different orders

00:37:50.670 --> 00:37:53.141
in the notes, but never mind.

00:37:53.141 --> 00:37:53.640
5.

00:37:56.560 --> 00:38:00.540
There's an additive inverse
in the vector space.

00:38:00.540 --> 00:38:07.230
So for each v belonging
to the vector space,

00:38:07.230 --> 00:38:17.310
there is a u belonging
to the vector space such

00:38:17.310 --> 00:38:25.000
that v plus u is equal to 0.

00:38:25.000 --> 00:38:31.250
So additive identity
you can find

00:38:31.250 --> 00:38:34.780
for every element
its opposite vector.

00:38:34.780 --> 00:38:36.150
It always can be found.

00:38:39.670 --> 00:38:44.240
And last is this
[INAUDIBLE] which

00:38:44.240 --> 00:38:52.820
says that a times u plus
v is equal to au plus av,

00:38:52.820 --> 00:39:01.660
and a plus b on v is
equal to av plus bv.

00:39:01.660 --> 00:39:06.220
And a's and b's
belong to the numbers.

00:39:06.220 --> 00:39:08.760
a and b's belong to the field.

00:39:08.760 --> 00:39:14.675
And u and v belong
to the vector space.

00:39:14.675 --> 00:39:15.175
OK.

00:39:18.180 --> 00:39:20.450
It's a little disconcerting.

00:39:20.450 --> 00:39:21.820
There's a lot of things.

00:39:21.820 --> 00:39:26.630
But actually, they
are quite minimal.

00:39:26.630 --> 00:39:28.422
It's well done, this definition.

00:39:28.422 --> 00:39:29.880
They're all kind
of things that you

00:39:29.880 --> 00:39:36.930
know that follow quite
immediately by little proofs.

00:39:36.930 --> 00:39:38.800
You will see more in
the notes, but let

00:39:38.800 --> 00:39:42.030
me just say briefly
a few of them.

00:39:42.030 --> 00:39:48.740
So here is the additive
identity, the vector 0.

00:39:48.740 --> 00:39:53.880
It's easy to prove that
this vector 0 is unique.

00:39:53.880 --> 00:39:58.890
If you find another 0 prime that
also satisfies this property,

00:39:58.890 --> 00:40:00.650
0 is equal to 0 prime.

00:40:00.650 --> 00:40:03.690
So it's unique.

00:40:03.690 --> 00:40:16.570
You can also show that 0 times
any vector is equal to 0.

00:40:16.570 --> 00:40:20.320
And here, this 0
belongs to the field

00:40:20.320 --> 00:40:23.250
and this 0 belongs
to the vector space.

00:40:23.250 --> 00:40:27.340
So the 0-- you had to postulate
that the 1 in the field

00:40:27.340 --> 00:40:29.710
does the right thing, but
you don't need to postulate

00:40:29.710 --> 00:40:33.730
that 0, the number 0,
multiplied by a vector is 0.

00:40:33.730 --> 00:40:35.480
You can prove that.

00:40:35.480 --> 00:40:37.930
And these are not
difficult to prove.

00:40:37.930 --> 00:40:41.210
All of them are
one-line exercises.

00:40:41.210 --> 00:40:43.110
They're done in that book.

00:40:43.110 --> 00:40:46.060
You can look at them.

00:40:46.060 --> 00:40:48.520
Moreover, another one.

00:40:48.520 --> 00:40:56.940
a any number times the 0 vector
is equal to the 0 vector.

00:40:56.940 --> 00:40:59.810
So in this case, those
both are vectors.

00:40:59.810 --> 00:41:03.690
That's also another property.

00:41:03.690 --> 00:41:08.740
So the 0 vector and the 0 number
really do the right thing.

00:41:08.740 --> 00:41:12.960
Then, another property,
the additive inverse.

00:41:12.960 --> 00:41:14.560
This is sort of interesting.

00:41:14.560 --> 00:41:21.240
So the additive inverse,
you can prove it's unique.

00:41:21.240 --> 00:41:22.960
So the additive
inverse is unique.

00:41:31.420 --> 00:41:44.040
And it's called-- for v, it's
called minus v, just a name.

00:41:44.040 --> 00:41:49.420
And actually, you can prove
it's equal to the number minus 1

00:41:49.420 --> 00:41:50.185
times the vector.

00:41:54.390 --> 00:41:59.380
Might sound totally trivial
but try to prove them.

00:41:59.380 --> 00:42:02.950
They're all simple, but they're
not trivial, all these things.

00:42:02.950 --> 00:42:08.200
So you call it minus v, but
it's actually-- this is a proof.

00:42:12.420 --> 00:42:14.170
OK.

00:42:14.170 --> 00:42:16.910
So examples.

00:42:16.910 --> 00:42:21.010
Let's do a few examples.

00:42:21.010 --> 00:42:24.125
I'll have five examples
that we're going to use.

00:42:28.330 --> 00:42:35.180
So I think the main thing for
a physicist that I remember

00:42:35.180 --> 00:42:37.930
being confused about
is the statement

00:42:37.930 --> 00:42:41.500
that there's no characterization
that the vectors are

00:42:41.500 --> 00:42:42.930
real or complex.

00:42:42.930 --> 00:42:45.240
The vectors are
the vectors and you

00:42:45.240 --> 00:42:47.690
multiply by a real
or complex numbers.

00:42:47.690 --> 00:42:51.293
So I will have one example
that makes that very dramatic.

00:42:54.520 --> 00:42:57.320
As dramatic as it can be.

00:42:57.320 --> 00:43:10.280
So one example of vector spaces,
the set of N component vectors.

00:43:10.280 --> 00:43:16.055
So here it is,
a1, a2, up to a n.

00:43:16.055 --> 00:43:23.030
For example, with capital N.
With a i belongs to the real

00:43:23.030 --> 00:43:35.140
and i going from 1 up
to N is a vector space

00:43:35.140 --> 00:43:41.330
over r, the real numbers.

00:43:41.330 --> 00:43:45.930
So people use that
terminology, a vector space

00:43:45.930 --> 00:43:49.240
over the kind of numbers.

00:43:49.240 --> 00:43:51.270
You could call it
also a real vector

00:43:51.270 --> 00:43:52.920
space, that would be the same.

00:43:52.920 --> 00:43:55.490
You see, these
components are real.

00:43:55.490 --> 00:43:58.430
And you have to
think for a second

00:43:58.430 --> 00:44:02.020
if you believe all of them are
true or how would you do it.

00:44:02.020 --> 00:44:05.330
Well, if I would
be really precise,

00:44:05.330 --> 00:44:07.060
I would have to tell
you a lot of things

00:44:07.060 --> 00:44:08.370
that you would find boring.

00:44:08.370 --> 00:44:12.430
That, for example, you have
this vector and you add a set

00:44:12.430 --> 00:44:13.120
of b's.

00:44:13.120 --> 00:44:14.990
Well, you add the components.

00:44:14.990 --> 00:44:17.140
That's the definition of plus.

00:44:17.140 --> 00:44:19.930
And what's the definition
of multiplying by a number?

00:44:19.930 --> 00:44:22.860
Well, if a number is
multiplied by this vector,

00:44:22.860 --> 00:44:25.950
it goes in and
multiplies everybody.

00:44:25.950 --> 00:44:29.160
Those are implicit, or you
can fill-in the details.

00:44:29.160 --> 00:44:31.110
But if you define
them that way, it

00:44:31.110 --> 00:44:33.340
will satisfy all the properties.

00:44:33.340 --> 00:44:35.040
What is the 0 vector?

00:44:35.040 --> 00:44:39.220
It must be the one
with all entries 0.

00:44:39.220 --> 00:44:41.360
What is the additive inverse?

00:44:41.360 --> 00:44:43.920
Well, change the sign
of all these things.

00:44:43.920 --> 00:44:48.380
So it's kind of obvious that
this satisfies everything,

00:44:48.380 --> 00:44:52.250
if you understand how the sum
and the multiplication goes.

00:44:54.970 --> 00:44:57.970
Another one, it's
kind of similar.

00:44:57.970 --> 00:44:59.800
2.

00:44:59.800 --> 00:45:10.625
The set of M cross N matrices
with complex entries.

00:45:13.966 --> 00:45:18.120
Complex entries.

00:45:18.120 --> 00:45:24.400
So here you have it,
a1 1, a1 2, a1 N.

00:45:24.400 --> 00:45:30.330
And here it goes up
to aM1, aM2, aMN.

00:45:35.560 --> 00:45:45.630
With all the a i j's belonging
to the complex numbers,

00:45:45.630 --> 00:45:52.540
then-- I'll erase here.

00:45:52.540 --> 00:45:56.300
Then you have that this
is a complex vector space.

00:46:00.590 --> 00:46:09.415
Is a complex vector space.

00:46:12.760 --> 00:46:14.710
How do you multiply by a number?

00:46:14.710 --> 00:46:18.070
You multiply a number times
every entry of the matrices.

00:46:18.070 --> 00:46:20.590
How do sum two matrices?

00:46:20.590 --> 00:46:25.000
They have the same size, so
you sum each element the way

00:46:25.000 --> 00:46:25.740
it should be.

00:46:25.740 --> 00:46:28.860
And that should
be a vector space.

00:46:31.630 --> 00:46:34.100
Here is an example
that is, perhaps,

00:46:34.100 --> 00:46:37.070
a little more surprising.

00:46:37.070 --> 00:46:54.150
So the space of 2 by
2 Hermitian matrices

00:46:54.150 --> 00:46:58.415
is a real vector space.

00:47:06.450 --> 00:47:11.050
You see, this can be easily
thought [INAUDIBLE] naturally

00:47:11.050 --> 00:47:12.600
thought as a real vector space.

00:47:12.600 --> 00:47:16.750
This is a little surprising
because Hermitian matrices have

00:47:16.750 --> 00:47:17.640
i's.

00:47:17.640 --> 00:47:21.370
You remember the most
general Hermitian matrix

00:47:21.370 --> 00:47:30.470
was of the form--
well, a plus-- no,

00:47:30.470 --> 00:47:38.790
c plus d, c minus d,
a plus ib, a minus ib,

00:47:38.790 --> 00:47:44.480
with all these numbers
c, d, b in real.

00:47:44.480 --> 00:47:47.870
But they're complex numbers.

00:47:47.870 --> 00:47:51.960
Why is this naturally
a real vector space?

00:47:51.960 --> 00:47:56.590
The problem is that if
you multiply by a number,

00:47:56.590 --> 00:47:59.530
it should still be a
Hermitian matrix in order

00:47:59.530 --> 00:48:01.825
for it to be a vector space.

00:48:01.825 --> 00:48:03.250
It should be in the vector.

00:48:03.250 --> 00:48:06.430
But if you multiply by a real
number, there's no problem.

00:48:06.430 --> 00:48:08.670
The matrix remains Hermitian.

00:48:08.670 --> 00:48:10.640
You multiplied by
a complex number,

00:48:10.640 --> 00:48:12.550
you use the Hermiticity.

00:48:12.550 --> 00:48:16.440
But an i somewhere here
for all the factors and it

00:48:16.440 --> 00:48:18.790
will not be Hermitian.

00:48:18.790 --> 00:48:22.620
So this is why it's
a real vector space.

00:48:22.620 --> 00:48:31.180
Multiplication by real
numbers preserves Hermiticity.

00:48:38.400 --> 00:48:41.620
So that's surprising.

00:48:41.620 --> 00:48:44.520
So again, illustrates
that nobody

00:48:44.520 --> 00:48:47.170
would say this is a real vector.

00:48:47.170 --> 00:48:52.130
But it really should be thought
as a vector over real numbers.

00:48:52.130 --> 00:48:56.130
Vector space over real numbers.

00:48:56.130 --> 00:48:58.640
Two more examples.

00:48:58.640 --> 00:49:04.250
And they are kind
of interesting.

00:49:16.210 --> 00:49:22.710
So the next example is the set
of polynomials as vector space.

00:49:22.710 --> 00:49:26.210
So that, again, is sort of
a very imaginative thing.

00:49:26.210 --> 00:49:33.600
The set of polynomials p of z.

00:49:37.380 --> 00:49:45.230
Here, z belongs to some
field and p of z, which

00:49:45.230 --> 00:49:50.120
is a function of z, also
belongs to the same field.

00:49:50.120 --> 00:49:52.700
And each polynomial
has coefficient.

00:49:52.700 --> 00:50:01.790
So any p of z is a0
plus a1 z plus a2 z

00:50:01.790 --> 00:50:07.170
squared plus-- up to some an zn.

00:50:07.170 --> 00:50:10.580
A polynomial is
supposed to end That's

00:50:10.580 --> 00:50:12.160
pretty important
about polynomials.

00:50:12.160 --> 00:50:16.330
So the dots don't go up forever.

00:50:16.330 --> 00:50:21.770
So here it is, the a i's
also belong to the field.

00:50:21.770 --> 00:50:23.030
So looked at this polynomials.

00:50:26.310 --> 00:50:29.630
We have the letter z and
they have these coefficients

00:50:29.630 --> 00:50:30.520
which are numbers.

00:50:30.520 --> 00:50:38.230
So a real polynomial-- you
know 2 plus x plus x squared.

00:50:38.230 --> 00:50:42.380
So you have your real numbers
times this general variable

00:50:42.380 --> 00:50:44.910
that it's also
supposed to be real.

00:50:44.910 --> 00:50:47.250
So you could have it real.

00:50:47.250 --> 00:50:48.370
You could have it complex.

00:50:48.370 --> 00:50:50.540
So that's a polynomial.

00:50:50.540 --> 00:50:53.170
How is that a vector space?

00:50:53.170 --> 00:51:00.190
Well, it's a vector
space-- the space

00:51:00.190 --> 00:51:16.490
p of F of those polynomials--
of all polynomials

00:51:16.490 --> 00:51:25.410
is a vector space over
F. And why is that?

00:51:25.410 --> 00:51:27.910
Well, you can take--
again, there's

00:51:27.910 --> 00:51:29.620
some implicit definitions.

00:51:29.620 --> 00:51:31.410
How do you sum polynomials?

00:51:31.410 --> 00:51:34.540
Well, you sum the
independent coefficients.

00:51:34.540 --> 00:51:37.440
You just sum them
and factor out.

00:51:37.440 --> 00:51:40.910
So there's an obvious
definition of sum.

00:51:40.910 --> 00:51:44.120
How do you multiply a
polynomial by a number?

00:51:44.120 --> 00:51:47.550
Obvious definition, you
multiply everything by a number.

00:51:47.550 --> 00:51:50.150
If you sum polynomials,
you get polynomials.

00:51:50.150 --> 00:51:53.690
Given a polynomial, there
is a negative polynomial

00:51:53.690 --> 00:51:56.410
that adds up to 0.

00:51:56.410 --> 00:52:00.480
There's a 0 when all
the coefficients is 0.

00:52:00.480 --> 00:52:02.760
And it has all the
nice properties.

00:52:02.760 --> 00:52:06.710
Now, this example
is more nontrivial

00:52:06.710 --> 00:52:10.710
because you would
think, as opposed

00:52:10.710 --> 00:52:13.830
to the previous examples,
that this is probably

00:52:13.830 --> 00:52:17.960
infinite dimensional because
it has the linear polynomial,

00:52:17.960 --> 00:52:21.360
the quadratic, the cubic,
the quartic, the quintic, all

00:52:21.360 --> 00:52:23.500
of them together.

00:52:23.500 --> 00:52:28.090
And yes, we'll see
that in a second.

00:52:28.090 --> 00:52:31.900
So set of polynomials.

00:52:31.900 --> 00:52:32.740
5.

00:52:32.740 --> 00:52:34.210
Another example, 5.

00:52:37.200 --> 00:52:43.660
The set F infinity of
infinite sequences.

00:52:49.680 --> 00:52:55.800
Sequences x1, x2, infinite
sequences where the x i's

00:52:55.800 --> 00:52:59.170
are in the field.

00:52:59.170 --> 00:53:01.210
So you've got an
infinite sequence

00:53:01.210 --> 00:53:03.610
and you want to add
another infinite sequence.

00:53:03.610 --> 00:53:05.890
Well, you add the first
element, the second elements.

00:53:05.890 --> 00:53:08.433
It's like an infinite
column vector.

00:53:08.433 --> 00:53:12.900
Sometimes mathematicians like to
write column vectors like that

00:53:12.900 --> 00:53:14.460
because it's practical.

00:53:14.460 --> 00:53:16.680
It saves space on a page.

00:53:16.680 --> 00:53:21.010
The vertical one, you
start writing and the pages

00:53:21.010 --> 00:53:22.020
grow very fast.

00:53:22.020 --> 00:53:24.840
So here's an infinite sequence.

00:53:24.840 --> 00:53:28.330
And think of it as a
vertical one if you wish.

00:53:28.330 --> 00:53:30.350
And all elements
are here, but there

00:53:30.350 --> 00:53:34.310
are infinitely many
in every sequence.

00:53:34.310 --> 00:53:40.140
And of course, the set of all
infinite sequences is infinite.

00:53:40.140 --> 00:53:43.380
So this is a vector
space over F.

00:53:43.380 --> 00:53:45.580
Again, because all
the numbers are here,

00:53:45.580 --> 00:53:55.820
so it's a vector space over F.

00:53:55.820 --> 00:53:57.400
And last example.

00:54:07.340 --> 00:54:12.470
Our last example is a
familiar one in physics,

00:54:12.470 --> 00:54:18.010
is the set of complex
functions in an interval.

00:54:18.010 --> 00:54:36.110
Set of complex functions on
an interval x from 0 to L.

00:54:36.110 --> 00:54:39.490
So a set of complex
functions f of x

00:54:39.490 --> 00:54:41.930
I could put here on an
interval [INAUDIBLE].

00:54:41.930 --> 00:54:47.810
So this is a complex
vector space.

00:54:47.810 --> 00:54:49.060
Vector space.

00:54:54.290 --> 00:54:58.080
The last three
examples, probably you

00:54:58.080 --> 00:55:01.570
would agree that there
are infinite dimensional,

00:55:01.570 --> 00:55:06.920
even though I've not defined
what that means very precisely.

00:55:06.920 --> 00:55:09.340
But that's what we're going
to try to understand now.

00:55:09.340 --> 00:55:12.490
We're supposed to understand
the concept of dimensionality.

00:55:12.490 --> 00:55:16.580
So let's get to
that concept now.

00:55:16.580 --> 00:55:23.010
So in terms of dimensionality,
to build this idea

00:55:23.010 --> 00:55:24.743
you need a definition.

00:55:27.830 --> 00:55:32.670
You need to know the term
subspace of a vector space.

00:55:32.670 --> 00:55:36.160
What is a subspace
of a vector space?

00:55:36.160 --> 00:55:41.320
A subspace of a vector space
is a subset of the vector space

00:55:41.320 --> 00:55:43.400
that is still a vector space.

00:55:43.400 --> 00:55:45.920
So that's why it's
called subspace.

00:55:45.920 --> 00:55:47.560
It's different from subset.

00:55:47.560 --> 00:56:08.870
So a subspace of V is a subset
of V that is a vector space.

00:56:14.690 --> 00:56:18.800
So in particular, it
must contain the vector 0

00:56:18.800 --> 00:56:23.535
because any vector space
contains the vector 0.

00:56:27.410 --> 00:56:31.060
One of the ways you sometimes
want to understand the vector

00:56:31.060 --> 00:56:37.500
space is by representing it as
a sum of smaller vector spaces.

00:56:37.500 --> 00:56:40.180
And we will do that when
we consider, for example,

00:56:40.180 --> 00:56:42.160
angular momentum in detail.

00:56:42.160 --> 00:56:51.770
So you want to write a vector
space as a sum of subspaces.

00:56:51.770 --> 00:56:53.780
So what is that called?

00:56:53.780 --> 00:56:56.220
It's called a direct sum.

00:56:56.220 --> 00:57:02.400
So if you can write--
here is the equation.

00:57:02.400 --> 00:57:09.570
You say V is equal to u1
direct sum with u2 direct sum

00:57:09.570 --> 00:57:16.680
with u3 direct sum with u m.

00:57:16.680 --> 00:57:23.970
When we say this, we
mean the following.

00:57:23.970 --> 00:57:33.276
That the ui's are
subspaces of V.

00:57:33.276 --> 00:57:42.760
And any V in the
vector space can

00:57:42.760 --> 00:58:01.550
be written uniquely as a1
u1 plus a2 u2 plus a n u

00:58:01.550 --> 00:58:10.130
n with ui [INAUDIBLE]
capital Ui.

00:58:10.130 --> 00:58:14.500
So let me review
what we just said.

00:58:14.500 --> 00:58:17.190
So you have a
vector space and you

00:58:17.190 --> 00:58:21.750
want to decompose it in
sort of basic ingredients.

00:58:21.750 --> 00:58:23.680
This is called a direct sum.

00:58:26.460 --> 00:58:30.270
V is a direct sum of subspaces.

00:58:30.270 --> 00:58:31.237
Direct sum.

00:58:35.140 --> 00:58:39.300
And the Ui's are
subspaces of V. But what

00:58:39.300 --> 00:58:42.090
must happen for
this to be true is

00:58:42.090 --> 00:58:45.310
that once you take
any vector here,

00:58:45.310 --> 00:58:47.800
you can write it as
a sum of a vector

00:58:47.800 --> 00:58:51.530
here, a vector here, a vector
here, a vector everywhere.

00:58:51.530 --> 00:58:54.040
And it must be done uniquely.

00:58:54.040 --> 00:58:56.810
If you can do this
in more than one way,

00:58:56.810 --> 00:58:59.160
this is not a direct sum.

00:58:59.160 --> 00:59:02.270
These subspaces kind of overlap.

00:59:02.270 --> 00:59:06.056
They're not doing the
decomposition in a minimal way.

00:59:06.056 --> 00:59:06.760
Yes.

00:59:06.760 --> 00:59:09.010
AUDIENCE: Does the expression
of V have to be a linear

00:59:09.010 --> 00:59:10.600
combination of the
vectors of the U,

00:59:10.600 --> 00:59:15.367
or just sums of the U sub i's?

00:59:15.367 --> 00:59:17.033
PROFESSOR: It's some
linear combination.

00:59:21.430 --> 00:59:23.900
Look, the interpretation,
for example, R2.

00:59:26.670 --> 00:59:29.880
The normal vector space R2.

00:59:29.880 --> 00:59:34.100
You have an intuition quite
clearly that any vector here

00:59:34.100 --> 00:59:41.150
is a unique sum of this
component along this subspace

00:59:41.150 --> 00:59:45.220
and this component
along this subspace.

00:59:45.220 --> 00:59:52.730
So it's a trivial example,
but the vector space R2

00:59:52.730 --> 00:59:58.120
has a vector subspace R1 here
and a vector subspace R1.

00:59:58.120 --> 01:00:01.250
Any vector in R2
is uniquely written

01:00:01.250 --> 01:00:03.780
as a sum of these two vectors.

01:00:03.780 --> 01:00:09.345
That means that R2
is really R1 plus R1.

01:00:12.020 --> 01:00:13.093
Yes.

01:00:13.093 --> 01:00:14.905
AUDIENCE: [INAUDIBLE].

01:00:14.905 --> 01:00:19.520
Is it redundant to say that
that-- because a1 u1 is also

01:00:19.520 --> 01:00:22.030
in big U sub 1.

01:00:22.030 --> 01:00:22.900
PROFESSOR: Oh.

01:00:22.900 --> 01:00:23.590
Oh, yes.

01:00:23.590 --> 01:00:24.430
You're right.

01:00:24.430 --> 01:00:25.460
No, I'm sorry.

01:00:25.460 --> 01:00:26.520
I shouldn't write those.

01:00:26.520 --> 01:00:28.720
I'm sorry.

01:00:28.720 --> 01:00:31.040
That's absolutely right.

01:00:31.040 --> 01:00:34.770
If I had that in my
notes, it was a mistake.

01:00:34.770 --> 01:00:35.370
Thank you.

01:00:35.370 --> 01:00:36.380
That was very good.

01:00:36.380 --> 01:00:38.470
Did I have that in my notes?

01:00:38.470 --> 01:00:42.030
No, I had it as you said it.

01:00:42.030 --> 01:00:42.560
True.

01:00:42.560 --> 01:00:46.770
So can be written
uniquely as a vector in

01:00:46.770 --> 01:00:48.310
first, a vector in the second.

01:00:48.310 --> 01:00:52.220
And the a's are
absolutely not necessary.

01:00:52.220 --> 01:00:53.200
OK.

01:00:53.200 --> 01:01:06.070
So let's go ahead then and
say the following things.

01:01:06.070 --> 01:01:07.870
So here we're
going to try to get

01:01:07.870 --> 01:01:14.210
to the concept of
dimensionality in a precise way.

01:01:14.210 --> 01:01:16.269
Yes.

01:01:16.269 --> 01:01:18.684
AUDIENCE: [INAUDIBLE].

01:01:18.684 --> 01:01:21.082
PROFESSOR: Right,
the last one is m.

01:01:21.082 --> 01:01:21.582
Thank you.

01:01:38.600 --> 01:01:39.290
All right.

01:01:46.220 --> 01:01:49.070
The concept of dimensionality
of a vector space

01:01:49.070 --> 01:01:51.350
is something that you
intuitively understand.

01:01:51.350 --> 01:01:56.900
It's sort of how many
linearly independent vectors

01:01:56.900 --> 01:02:01.610
you need to describe the
whole set of vectors.

01:02:01.610 --> 01:02:05.970
So that is the number
you're trying to get to.

01:02:05.970 --> 01:02:10.320
I'll follow it up in a
slightly rigorous way

01:02:10.320 --> 01:02:13.150
to be able to do infinite
dimensional space as well.

01:02:13.150 --> 01:02:18.470
So we will consider something
called a list of vectors.

01:02:18.470 --> 01:02:22.210
List of vectors.

01:02:22.210 --> 01:02:27.020
And that will be something
like v1, v2 vectors in a vector

01:02:27.020 --> 01:02:28.050
space up to vn.

01:02:30.640 --> 01:02:38.650
Any list of vectors
has finite length.

01:02:38.650 --> 01:02:44.390
So we don't accept infinite
lists by definition.

01:02:48.480 --> 01:02:51.420
You can ask, once you
have a list of vectors,

01:02:51.420 --> 01:02:57.580
what is the vector subspace
spanned by this list?

01:02:57.580 --> 01:03:00.420
How much do you
reach with that list?

01:03:00.420 --> 01:03:04.440
So we call it the
span of the list.

01:03:04.440 --> 01:03:10.680
The span of the list, vn.

01:03:10.680 --> 01:03:23.570
And it's the set of all linear
combinations a1 v1 plus a2 v2

01:03:23.570 --> 01:03:32.500
plus a n vn for ai in the field.

01:03:32.500 --> 01:03:36.200
So the span of the list
is all possible products

01:03:36.200 --> 01:03:42.915
of your vectors on the list
are-- and put like that.

01:03:42.915 --> 01:03:51.620
So if we say that the
list spans a vector space,

01:03:51.620 --> 01:03:55.170
if the span of the list
is the vector space.

01:03:55.170 --> 01:03:57.650
So that's natural language.

01:03:57.650 --> 01:04:01.010
We say, OK, this list
spans the vector space.

01:04:01.010 --> 01:04:01.520
Why?

01:04:01.520 --> 01:04:04.170
Because if you produce
the span of the list,

01:04:04.170 --> 01:04:06.820
it fills a vector space.

01:04:06.820 --> 01:04:12.050
OK, so I could say it that way.

01:04:12.050 --> 01:04:26.710
So here is the definition,
V is finite dimensional

01:04:26.710 --> 01:04:29.180
if it's spanned by some list.

01:04:29.180 --> 01:04:35.480
If V is spanned by some list.

01:04:40.180 --> 01:04:41.620
So why is that?

01:04:41.620 --> 01:04:47.200
Because if the list is-- a
definition, finite dimensional.

01:04:47.200 --> 01:04:48.800
If it's spanned by some list.

01:04:48.800 --> 01:04:52.090
If you got your list, by
definition it's finite length.

01:04:52.090 --> 01:04:54.790
And with some set of
vectors, you span everything.

01:04:58.380 --> 01:05:02.990
And moreover, it's
infinite dimensional

01:05:02.990 --> 01:05:05.840
if it's not finite dimensional.

01:05:05.840 --> 01:05:10.775
It's kind of silly,
but infinite-- a space

01:05:10.775 --> 01:05:24.280
V is infinite dimensional if
it is not finite dimensional.

01:05:24.280 --> 01:05:32.370
Which is to say that there is
no list that spans the space.

01:05:32.370 --> 01:05:36.210
So for example, this definition
is tailored in a nice way.

01:05:36.210 --> 01:05:38.116
Like let's think
of the polynomials.

01:05:42.010 --> 01:05:45.270
And we want to see if it's
finite dimensional or infinite

01:05:45.270 --> 01:05:45.980
dimensional.

01:05:45.980 --> 01:05:51.160
So you claim it's
finite dimensional.

01:05:51.160 --> 01:05:53.020
Let's see if it's
finite dimensional.

01:05:53.020 --> 01:05:55.800
So we make a list
of polynomials.

01:05:55.800 --> 01:06:00.630
The list must have some length,
at least, that spans it.

01:06:00.630 --> 01:06:03.800
You put all these
730 polynomials

01:06:03.800 --> 01:06:09.830
that you think span the list,
span the space, in this list.

01:06:09.830 --> 01:06:12.900
Now, if you look at
the list, it's 720.

01:06:12.900 --> 01:06:14.800
You can check one
by one until you

01:06:14.800 --> 01:06:17.385
find what is the one
of highest order,

01:06:17.385 --> 01:06:20.700
the polynomial of
highest degree.

01:06:20.700 --> 01:06:26.560
But if the highest degree
is say, z to the 1 million,

01:06:26.560 --> 01:06:30.540
then any polynomial that has
a z to the 2 million cannot be

01:06:30.540 --> 01:06:32.110
spanned by this one.

01:06:32.110 --> 01:06:36.240
So there's no finite
list that can span this,

01:06:36.240 --> 01:06:40.820
so this set-- the
example in 4 is

01:06:40.820 --> 01:06:42.720
infinite dimensional for sure.

01:06:45.240 --> 01:06:49.590
Example 4 is
infinite dimensional.

01:06:57.060 --> 01:07:04.940
Well, example one is
finite dimensional.

01:07:07.560 --> 01:07:09.900
You can see that
because we can produce

01:07:09.900 --> 01:07:13.250
a list that spans the space.

01:07:13.250 --> 01:07:14.965
So look at the example 1.

01:07:17.620 --> 01:07:18.120
It's there.

01:07:22.710 --> 01:07:24.555
Well, what would be the list?

01:07:24.555 --> 01:07:28.090
The list would be-- list.

01:07:28.090 --> 01:07:33.310
You would put a vector
e1, e2, up to en.

01:07:33.310 --> 01:07:40.500
And the vector e1
would be 1, 0, 0, 0, 0.

01:07:40.500 --> 01:07:45.680
The vector e2 would
be 0, 1, 0, 0, 0.

01:07:45.680 --> 01:07:47.300
And go on like that.

01:07:47.300 --> 01:07:50.190
So you put 1's and 0's.

01:07:50.190 --> 01:07:52.000
And you have n of them.

01:07:52.000 --> 01:07:58.540
And certainly, the most general
one is a1 times e1 a2 times e2.

01:07:58.540 --> 01:08:00.550
And you got the list.

01:08:00.550 --> 01:08:06.160
So example 1 is
finite dimensional.

01:08:06.160 --> 01:08:10.320
A list of vectors is
linearly independent.

01:08:10.320 --> 01:08:23.250
A list is linearly independent
if a list v1 up to vn

01:08:23.250 --> 01:08:32.649
is linearly independent, If
a1 v1 plus a2 v2 plus a n vn

01:08:32.649 --> 01:08:44.710
is equal to 0 has the unique
solution a1 equal a2 equal

01:08:44.710 --> 01:08:48.649
all of them equal 0.

01:08:48.649 --> 01:08:57.990
So that is to mean that
whenever this list satisfies

01:08:57.990 --> 01:09:02.060
this property-- if you want
to represent the vector

01:09:02.060 --> 01:09:05.859
0 with this list, you
must set all of them

01:09:05.859 --> 01:09:08.260
equal to 0, all
the coefficients.

01:09:08.260 --> 01:09:10.850
That's clear as well
in this example.

01:09:10.850 --> 01:09:13.170
If you want to
represent the 0 vector,

01:09:13.170 --> 01:09:18.370
you must have 0 component
against the basis vector x

01:09:18.370 --> 01:09:19.920
and basis vector y.

01:09:19.920 --> 01:09:23.550
So the list of this
vector and this vector

01:09:23.550 --> 01:09:27.069
is linearly independent
because the 0 vector

01:09:27.069 --> 01:09:31.180
must have 0 numbers
multiplying each of them.

01:09:31.180 --> 01:09:36.830
So finally, we define
what is a basis.

01:09:36.830 --> 01:09:58.266
A basis of V is a
list of vectors in V

01:09:58.266 --> 01:10:07.255
that spans V and is
linearly independent.

01:10:13.500 --> 01:10:16.200
So what is a basis?

01:10:16.200 --> 01:10:18.420
Well, you should
have enough vectors

01:10:18.420 --> 01:10:21.970
to represent every vector.

01:10:21.970 --> 01:10:25.970
So it must span V. And
what else should it have?

01:10:25.970 --> 01:10:29.650
It shouldn't have extra
vectors that you don't need.

01:10:29.650 --> 01:10:31.110
It should be minimal.

01:10:31.110 --> 01:10:33.150
It should be all
linearly independent.

01:10:33.150 --> 01:10:36.610
You shouldn't have
added more stuff to it.

01:10:36.610 --> 01:10:43.040
So any finite dimensional
vector space has a basis.

01:10:45.740 --> 01:10:50.200
It's easy to do it.

01:10:50.200 --> 01:10:53.170
There's another thing
that one can prove.

01:10:53.170 --> 01:10:58.110
It may look kind of obvious,
but it requires a small proof

01:10:58.110 --> 01:11:00.940
that if you have-- the
bases are not unique.

01:11:00.940 --> 01:11:03.070
It's something we're going
to exploit all the time.

01:11:03.070 --> 01:11:05.800
One basis, another
basis, a third basis.

01:11:05.800 --> 01:11:08.650
We're going to change
basis all the time.

01:11:08.650 --> 01:11:13.070
Well, the bases are not
unique, but the length

01:11:13.070 --> 01:11:17.130
of the bases of a vector
space is always the same.

01:11:17.130 --> 01:11:20.850
So the length of the
list is-- a number

01:11:20.850 --> 01:11:23.810
is the same whatever
base you choose.

01:11:23.810 --> 01:11:25.920
And that length
is what is called

01:11:25.920 --> 01:11:28.610
the dimension of
the vector space.

01:11:28.610 --> 01:11:41.700
So the dimension
of a vector space

01:11:41.700 --> 01:12:00.230
is the length of any
bases of V. And therefore,

01:12:00.230 --> 01:12:01.850
it's a well-defined concept.

01:12:01.850 --> 01:12:06.060
Any base of a finite vector
space has the same length,

01:12:06.060 --> 01:12:08.860
and the dimension
is that number.

01:12:08.860 --> 01:12:11.070
So there was a question.

01:12:11.070 --> 01:12:12.658
Yes?

01:12:12.658 --> 01:12:14.514
AUDIENCE: Is there
any difference

01:12:14.514 --> 01:12:16.370
between bases [INAUDIBLE]?

01:12:20.900 --> 01:12:22.900
PROFESSOR: No, absolutely not.

01:12:22.900 --> 01:12:25.600
You could have a
basis, for example,

01:12:25.600 --> 01:12:28.570
of R2, which is this vector.

01:12:28.570 --> 01:12:33.010
The first and the
second is this vector.

01:12:33.010 --> 01:12:37.020
And any vector is a
linear superposition

01:12:37.020 --> 01:12:40.680
of these two vectors with some
coefficients and it's unique.

01:12:40.680 --> 01:12:43.580
You can find the coefficients.

01:12:43.580 --> 01:12:46.426
AUDIENCE: [INAUDIBLE].

01:12:46.426 --> 01:12:47.050
PROFESSOR: Yes.

01:12:47.050 --> 01:12:52.140
But you see, here is exactly
what I wanted to make clear.

01:12:52.140 --> 01:12:54.480
We're putting the
vector space and we're

01:12:54.480 --> 01:12:56.630
putting the least
possible structure.

01:12:56.630 --> 01:13:00.650
I didn't say how to take the
inner product of two vectors.

01:13:00.650 --> 01:13:02.660
It's not a definition
of a vector space.

01:13:02.660 --> 01:13:04.610
It's something we'll put later.

01:13:04.610 --> 01:13:08.190
And then, we will be able
to ask whether the basis is

01:13:08.190 --> 01:13:09.790
orthonormal or not.

01:13:09.790 --> 01:13:12.240
But the basis exists.

01:13:12.240 --> 01:13:15.520
Even though you have no
definition of an inner product,

01:13:15.520 --> 01:13:19.610
you can talk about basis
without any confusion.

01:13:19.610 --> 01:13:23.420
You can also talk about
the matrix representation

01:13:23.420 --> 01:13:24.530
of an operator.

01:13:24.530 --> 01:13:27.230
And you don't need
an inner product,

01:13:27.230 --> 01:13:30.370
which is sometimes very unclear.

01:13:30.370 --> 01:13:34.490
You can talk about the
trace of an operator

01:13:34.490 --> 01:13:37.390
and you don't need
an inner product.

01:13:37.390 --> 01:13:40.610
You can talk about
eigenvectors and eigenvalues

01:13:40.610 --> 01:13:43.470
and you don't need
an inner product.

01:13:43.470 --> 01:13:45.185
The only thing you
need the inner product

01:13:45.185 --> 01:13:46.820
is to get numbers.

01:13:46.820 --> 01:13:51.330
And we'll use them to use
[INAUDIBLE] to get numbers.

01:13:51.330 --> 01:13:53.380
But it can wait.

01:13:53.380 --> 01:13:55.490
It's better than
you see all that you

01:13:55.490 --> 01:13:58.770
can do without
introducing more things,

01:13:58.770 --> 01:14:00.980
and then introduce them.

01:14:00.980 --> 01:14:07.020
So let me explain a
little more this concept.

01:14:07.020 --> 01:14:12.900
We were talking about this
base, this vector space 1,

01:14:12.900 --> 01:14:13.590
for example.

01:14:13.590 --> 01:14:20.645
And we produced a list that
spans e1, e2, up to en.

01:14:20.645 --> 01:14:23.000
And those were these vectors.

01:14:23.000 --> 01:14:26.340
Now, this list not
only spans, but they

01:14:26.340 --> 01:14:28.010
are linearly independent.

01:14:28.010 --> 01:14:31.650
If you put a1 times
this plus a2 times

01:14:31.650 --> 01:14:33.520
this and you set
it all equal to 0.

01:14:33.520 --> 01:14:37.990
Well, each entry will be
0, and all the a's are 0.

01:14:37.990 --> 01:14:42.880
So these e's that you put
here on that list is actually

01:14:42.880 --> 01:14:44.520
a basis.

01:14:44.520 --> 01:14:47.810
Therefore, the length of that
basis is the dimensionality.

01:14:47.810 --> 01:14:54.700
And this space has
dimension N. You

01:14:54.700 --> 01:14:58.960
should be able to prove that
this space has been dimension

01:14:58.960 --> 01:15:12.550
m times N. Now, let me do the
Hermitian-- these matrices.

01:15:12.550 --> 01:15:15.670
And try to figure out
the dimensionality

01:15:15.670 --> 01:15:19.360
of the space of
Hermitian matrices.

01:15:19.360 --> 01:15:20.870
So here they are.

01:15:20.870 --> 01:15:24.390
This is the most general
Hermitian matrix.

01:15:24.390 --> 01:15:31.190
And I'm going to produce for
you a list of four vectors.

01:15:31.190 --> 01:15:34.570
Vectors-- yes, they're matrices,
but we call them vectors.

01:15:34.570 --> 01:15:35.900
So here is the list.

01:15:40.340 --> 01:15:45.110
The unit matrix, the first
Pauli matrix, the second Pauli

01:15:45.110 --> 01:15:49.270
matrix, and the
third Pauli matrix.

01:15:49.270 --> 01:15:53.330
All right, let's see how
far do we get from there.

01:15:53.330 --> 01:15:56.710
OK, this is a list of
vectors in the vector space

01:15:56.710 --> 01:15:59.090
because all of
them are Hermitian.

01:15:59.090 --> 01:15:59.590
Good.

01:16:02.690 --> 01:16:04.250
Do they span?

01:16:04.250 --> 01:16:08.570
Well, you calculate the most
general Hermitian matrix

01:16:08.570 --> 01:16:09.420
of this form.

01:16:09.420 --> 01:16:12.750
You just put arbitrary
complex numbers

01:16:12.750 --> 01:16:17.980
and require that the matrix
be equal to its matrix complex

01:16:17.980 --> 01:16:19.420
conjugate and transpose.

01:16:19.420 --> 01:16:21.245
So this is the most general one.

01:16:21.245 --> 01:16:25.210
Do I obtain this
matrix from this one's?

01:16:25.210 --> 01:16:34.440
Yes I just have to put 1 times
c plus a times sigma 1 plus b

01:16:34.440 --> 01:16:38.990
times sigma 2 plus
d times sigma 3.

01:16:38.990 --> 01:16:44.840
So any Hermitian
matrix can be obtained

01:16:44.840 --> 01:16:47.150
as the span of this list.

01:16:50.160 --> 01:16:53.630
Is this list
linearly independent?

01:16:53.630 --> 01:16:58.350
So I have to go here
and set this equal to 0

01:16:58.350 --> 01:17:03.890
and see if it sets to 0
all these coefficients.

01:17:03.890 --> 01:17:08.510
Well, it's the same thing as
setting to 0 all this matrix.

01:17:08.510 --> 01:17:15.160
Well, if c plus d and c minus
d are 0, then c and d are 0.

01:17:15.160 --> 01:17:20.030
If this is 0, it must be a 0
and b 0, so all of them are 0.

01:17:20.030 --> 01:17:22.970
So yes, it's
linearly independent.

01:17:22.970 --> 01:17:24.440
It spans.

01:17:24.440 --> 01:17:27.890
Therefore, you've proven
completely rigorously

01:17:27.890 --> 01:17:32.525
that this vector
space is dimension 4.

01:17:41.940 --> 01:17:45.270
This vector space--
I will actually

01:17:45.270 --> 01:17:49.890
leave it as an exercise for
you to show that this vector

01:17:49.890 --> 01:17:51.214
space is infinite dimensional.

01:17:51.214 --> 01:17:53.130
You say, of course, it's
infinite dimensional.

01:17:53.130 --> 01:17:55.530
It has infinite sequences.

01:17:55.530 --> 01:17:58.000
Well, you have to
show that if you

01:17:58.000 --> 01:18:01.740
have a finite list of
those infinite sequences,

01:18:01.740 --> 01:18:07.240
like 300 sequences,
they span that.

01:18:07.240 --> 01:18:08.650
They cannot span that.

01:18:08.650 --> 01:18:12.620
So it takes a little work.

01:18:12.620 --> 01:18:14.235
It's interesting
to think about it.

01:18:14.235 --> 01:18:18.510
I think you will enjoy trying
to think about this stuff.

01:18:18.510 --> 01:18:24.400
So that's our discussion
of dimensionality.

01:18:24.400 --> 01:18:29.620
So this one is a little
harder to make sure

01:18:29.620 --> 01:18:31.100
it's infinite dimensional.

01:18:31.100 --> 01:18:34.310
And this one is, yet, a
bit harder than that one

01:18:34.310 --> 01:18:36.210
but it can also be done.

01:18:36.210 --> 01:18:37.535
This is infinite dimensional.

01:18:40.356 --> 01:18:41.730
And this is infinite
dimensional.

01:18:44.600 --> 01:18:49.300
In the last two minute, I want
to tell you a little bit-- one

01:18:49.300 --> 01:18:53.130
definition and let
you go with that,

01:18:53.130 --> 01:18:56.413
is the definition of
a linear operator.

01:19:01.280 --> 01:19:03.130
So here is one thing.

01:19:03.130 --> 01:19:09.270
So you can be more general,
and we won't be that general.

01:19:09.270 --> 01:19:13.350
But when you talk
about linear maps,

01:19:13.350 --> 01:19:20.980
you have one vector space and
another vector space, v and w.

01:19:20.980 --> 01:19:26.930
This is a vector space and
this is a vector space.

01:19:26.930 --> 01:19:31.640
And in general, a map from
here is sometimes called,

01:19:31.640 --> 01:19:34.610
if it satisfies the
property, a linear map.

01:19:37.120 --> 01:19:39.970
And the key thing is
that in all generality,

01:19:39.970 --> 01:19:43.695
these two vector spaces may
not have the same dimension.

01:19:43.695 --> 01:19:46.901
It might be one vector space and
another very different vector

01:19:46.901 --> 01:19:47.400
space.

01:19:47.400 --> 01:19:50.230
You go from one to the other.

01:19:50.230 --> 01:19:54.530
Now, when you have
a vector space v

01:19:54.530 --> 01:19:57.770
and you map to the
same vector space,

01:19:57.770 --> 01:20:00.060
this is also a
linear map, but this

01:20:00.060 --> 01:20:04.860
is called an operator
or a linear operator.

01:20:07.600 --> 01:20:10.980
And what is a linear
operator therefore?

01:20:10.980 --> 01:20:20.310
A linear operator is
a function T. Let's

01:20:20.310 --> 01:20:26.480
call the linear operator T.
It takes v to v. In which way?

01:20:26.480 --> 01:20:35.110
Well, T acting u plus v,
on the sum of vectors,

01:20:35.110 --> 01:20:44.790
is Tu plus T v. And T
acting on a times a vector

01:20:44.790 --> 01:20:49.380
is a times T of the vector.

01:20:49.380 --> 01:20:53.160
These two things make
it into something

01:20:53.160 --> 01:20:55.710
we call a linear operator.

01:20:55.710 --> 01:21:00.400
It acts on the sum
of vectors linearly

01:21:00.400 --> 01:21:02.900
and on a number times a vector.

01:21:02.900 --> 01:21:06.236
The number goes out and
you act on the vector.

01:21:06.236 --> 01:21:11.300
So all you need to know for
what a linear operator is,

01:21:11.300 --> 01:21:14.890
is how it acts on basis vectors.

01:21:14.890 --> 01:21:17.620
Because any vector
on the vector space

01:21:17.620 --> 01:21:19.800
is a superposition
of basis vectors.

01:21:19.800 --> 01:21:23.410
So if you tell me how it
acts on the basis vectors,

01:21:23.410 --> 01:21:24.960
you know everything.

01:21:24.960 --> 01:21:29.000
So we will figure out how
the matrix representation

01:21:29.000 --> 01:21:34.530
of the operators arises from how
it acts on the basis vectors.

01:21:34.530 --> 01:21:36.940
And you don't need
an inner product.

01:21:36.940 --> 01:21:39.460
The reason people think
of this is they say,

01:21:39.460 --> 01:21:44.970
oh, the T i j
matrix element of T

01:21:44.970 --> 01:21:49.310
is the inner product of the
operator between i and j.

01:21:49.310 --> 01:21:51.960
And this is true.

01:21:51.960 --> 01:21:54.340
But for that you
need [? brass ?]

01:21:54.340 --> 01:21:56.690
and inner product,
all these things.

01:21:56.690 --> 01:21:58.460
And they're not necessary.

01:21:58.460 --> 01:22:00.620
We'll define this without that.

01:22:00.620 --> 01:22:02.100
We don't need it.

01:22:02.100 --> 01:22:06.640
So see you next time,
and we'll continue that.

01:22:06.640 --> 01:22:09.940
[APPLAUSE]

01:22:09.940 --> 01:22:11.790
Thank you.

