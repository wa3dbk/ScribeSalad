WEBVTT
Kind: captions
Language: en

00:00:01.510 --> 00:00:05.240
We now introduce normal random
variables, which are also

00:00:05.240 --> 00:00:08.029
often called Gaussian
random variables.

00:00:08.029 --> 00:00:10.930
Normal random variables are
perhaps the most important

00:00:10.930 --> 00:00:13.070
ones in probability theory.

00:00:13.070 --> 00:00:16.650
They play a key role in the
theory of the subject, as we

00:00:16.650 --> 00:00:19.860
will see later in this class in
the context of the central

00:00:19.860 --> 00:00:21.300
limit theorem.

00:00:21.300 --> 00:00:25.330
They're also prevalent in
applications for two reasons.

00:00:25.330 --> 00:00:30.120
They have some nice analytical
properties, and they're are

00:00:30.120 --> 00:00:34.470
also the most common model
of random noise.

00:00:34.470 --> 00:00:37.950
In general, they are a good
model of noise or randomness

00:00:37.950 --> 00:00:41.860
whenever that noise is due to
the addition of many small

00:00:41.860 --> 00:00:45.520
independent noise terms, and
this is a very common

00:00:45.520 --> 00:00:46.945
situation in the real world.

00:00:50.080 --> 00:00:52.890
We define normal random
variables by specifying their

00:00:52.890 --> 00:00:56.660
PDFs, and we start with the
simplest case of the so-called

00:00:56.660 --> 00:00:58.210
standard normal.

00:00:58.210 --> 00:01:01.370
The standard normal is indicated
with this shorthand

00:01:01.370 --> 00:01:06.080
notation, and we will see
shortly why this notation is

00:01:06.080 --> 00:01:07.410
being used.

00:01:07.410 --> 00:01:09.970
It is defined in
terms of a PDF.

00:01:09.970 --> 00:01:13.610
This PDF is defined for
all values of x. x

00:01:13.610 --> 00:01:15.750
can be any real number.

00:01:15.750 --> 00:01:19.100
So this random variable
can take values

00:01:19.100 --> 00:01:20.900
anywhere on the real line.

00:01:20.900 --> 00:01:23.630
And the formula for the
PDF is this one.

00:01:23.630 --> 00:01:26.820
Let us try to understand
this formula.

00:01:26.820 --> 00:01:31.660
So we have the exponential of
negative x squared over 2.

00:01:31.660 --> 00:01:37.229
Now, if we are to plot the x
squared over 2 function, it

00:01:37.229 --> 00:01:46.100
has a shape of this form, and
it is centered at zero.

00:01:46.100 --> 00:01:50.700
But then we take the negative
exponential of this function.

00:01:50.700 --> 00:01:54.360
Now, when you take the negative
exponential, whenever

00:01:54.360 --> 00:01:57.410
this thing is big, the negative
exponential is going

00:01:57.410 --> 00:01:58.530
to be small.

00:01:58.530 --> 00:02:03.170
So the negative exponential
would be equal to 1 when x is

00:02:03.170 --> 00:02:04.470
equal to 0.

00:02:04.470 --> 00:02:08.690
But then as x increases,
because x squared also

00:02:08.690 --> 00:02:12.170
increases, the negative
exponential will fall off.

00:02:12.170 --> 00:02:17.060
And so we obtain a shape of this
kind, and symmetrically

00:02:17.060 --> 00:02:21.220
on the other side as well.

00:02:21.220 --> 00:02:23.850
And finally, there
is this constant.

00:02:23.850 --> 00:02:26.570
Where [is] this constant
coming from?

00:02:26.570 --> 00:02:31.050
Well there's a nice and not
completely straightforward

00:02:31.050 --> 00:02:35.430
calculus exercise that tells
us that the integral from

00:02:35.430 --> 00:02:39.350
minus infinity to plus infinity
of e to the negative

00:02:39.350 --> 00:02:47.860
x squared over 2, dx, is equal
to the square root of 2 pi.

00:02:47.860 --> 00:02:51.210
Now, we need a PDF to
integrates to 1.

00:02:51.210 --> 00:02:55.360
And so for this to happen, this
is the constant that we

00:02:55.360 --> 00:02:58.630
need to put in front of this
expression so that the

00:02:58.630 --> 00:03:02.330
integral becomes 1, and that
explains the presence of this

00:03:02.330 --> 00:03:04.570
particular constant.

00:03:04.570 --> 00:03:08.260
What is the mean of this
random variable?

00:03:08.260 --> 00:03:12.280
Well, x squared is symmetric
around 0, and for this reason,

00:03:12.280 --> 00:03:15.740
the PDF itself is symmetric
around 0.

00:03:15.740 --> 00:03:21.800
And therefore, by symmetry, the
mean has to be equal to 0.

00:03:21.800 --> 00:03:24.540
And that explains
this entry here.

00:03:24.540 --> 00:03:26.430
How about the variance?

00:03:26.430 --> 00:03:30.150
Well, to calculate the variance,
you need to solve a

00:03:30.150 --> 00:03:31.930
calculus problem again.

00:03:31.930 --> 00:03:33.960
You need to integrate
by parts.

00:03:36.890 --> 00:03:41.380
And after you carry out the
calculation, then you find

00:03:41.380 --> 00:03:46.090
that the variance is equal to
1, and that explains this

00:03:46.090 --> 00:03:50.800
entry here in the notation
that we have been using.

00:03:50.800 --> 00:03:54.329
Let us now define general
normal random variables.

00:03:54.329 --> 00:03:57.070
General normal random variables
are once more

00:03:57.070 --> 00:04:01.440
specified in terms of the
corresponding PDF, but this

00:04:01.440 --> 00:04:04.810
PDF is a little more
complicated, and it involves

00:04:04.810 --> 00:04:06.190
two parameters--

00:04:06.190 --> 00:04:10.950
mu and sigma squared,
where sigma is a

00:04:10.950 --> 00:04:13.760
given positive parameter.

00:04:13.760 --> 00:04:19.050
Once more, it will have a bell
shape, but this bell is no

00:04:19.050 --> 00:04:23.150
longer symmetric around 0, and
there is some control over the

00:04:23.150 --> 00:04:25.060
width of it.

00:04:25.060 --> 00:04:29.610
Let us understand the form of
this PDF by focusing first on

00:04:29.610 --> 00:04:31.710
the exponent, exactly
as we did for the

00:04:31.710 --> 00:04:34.060
standard normal case.

00:04:34.060 --> 00:04:42.416
The exponent is a quadratic, and
that quadratic is centered

00:04:42.416 --> 00:04:46.290
at x equal to mu.

00:04:46.290 --> 00:04:49.750
So it vanishes when x
is equal to mu, and

00:04:49.750 --> 00:04:51.980
becomes positive elsewhere.

00:04:51.980 --> 00:04:55.340
Then we take the negative
exponential of this quadratic,

00:04:55.340 --> 00:05:00.640
and we obtain a function which
is largest at x equal to mu,

00:05:00.640 --> 00:05:05.440
and falls off as we go
further away from mu.

00:05:08.530 --> 00:05:11.880
What is the mean of this
random variable?

00:05:11.880 --> 00:05:16.550
Since this term is symmetric
around mu, the PDF is also

00:05:16.550 --> 00:05:20.770
symmetric around mu, and
therefore, the mean is also

00:05:20.770 --> 00:05:22.660
equal to mu.

00:05:22.660 --> 00:05:24.500
How about the variance?

00:05:24.500 --> 00:05:25.780
It turns out--

00:05:25.780 --> 00:05:28.620
and this is a calculus exercise
that we will omit--

00:05:28.620 --> 00:05:32.800
that the variance of this PDF
is equal to sigma squared.

00:05:32.800 --> 00:05:34.909
And this explains this
notation here.

00:05:34.909 --> 00:05:37.610
We're dealing with a normal that
has a mean of mu and a

00:05:37.610 --> 00:05:39.700
variance of sigma squared.

00:05:39.700 --> 00:05:43.380
To get a little bit of
understanding of the role of

00:05:43.380 --> 00:05:48.930
sigma in the form of this PDF,
let us consider the case where

00:05:48.930 --> 00:05:52.680
sigma is small, and see how the

00:05:52.680 --> 00:05:54.950
picture is going to change.

00:05:54.950 --> 00:05:59.890
When sigma is small, and we
plot the quadratic, sigma

00:05:59.890 --> 00:06:05.260
being small means that this
quadratic becomes larger, so

00:06:05.260 --> 00:06:10.290
it rises faster, so we get
a narrower quadratic.

00:06:10.290 --> 00:06:15.340
And in that case, the negative
exponential is going to fall

00:06:15.340 --> 00:06:18.920
off much faster.

00:06:18.920 --> 00:06:25.270
So when sigma is small, the PDF
that we get is a narrower

00:06:25.270 --> 00:06:31.370
PDF, and that reflects itself
into the property that the

00:06:31.370 --> 00:06:33.765
variance will also be smaller.

00:06:37.710 --> 00:06:40.650
An important property of normal
random variables is

00:06:40.650 --> 00:06:43.690
that they behave very nicely
when you form linear

00:06:43.690 --> 00:06:45.090
functions of them.

00:06:45.090 --> 00:06:48.280
And this is one of the reasons
why they're analytically

00:06:48.280 --> 00:06:51.450
tractable and analytically
very convenient.

00:06:51.450 --> 00:06:52.890
Here is what I mean.

00:06:52.890 --> 00:06:55.620
Let us start with a normal
random variable with a given

00:06:55.620 --> 00:06:58.810
mean and variance, and let us
form a linear function of that

00:06:58.810 --> 00:07:00.330
random variable.

00:07:00.330 --> 00:07:02.170
What is the mean of Y?

00:07:02.170 --> 00:07:05.060
Well, we know what it is.

00:07:05.060 --> 00:07:07.280
We have a linear function
of a random variable.

00:07:07.280 --> 00:07:10.600
The mean is going to be a times
the expected value of X,

00:07:10.600 --> 00:07:13.700
which is mu plus b.

00:07:13.700 --> 00:07:16.270
What is the variance of Y?

00:07:16.270 --> 00:07:19.030
We know what is the variance
of a linear function of a

00:07:19.030 --> 00:07:19.750
random variable.

00:07:19.750 --> 00:07:23.570
It is a squared times the
variance of X, which in our

00:07:23.570 --> 00:07:25.700
case is sigma squared.

00:07:25.700 --> 00:07:29.130
So there's nothing new so far,
but there is an additional

00:07:29.130 --> 00:07:30.435
important fact.

00:07:30.435 --> 00:07:34.590
The random variable Y, of
course, has the mean and

00:07:34.590 --> 00:07:38.080
variance that we know it should
have, but there is an

00:07:38.080 --> 00:07:39.500
additional fact--

00:07:39.500 --> 00:07:44.150
namely, that Y is a normal
random variable.

00:07:44.150 --> 00:07:50.080
So normality is preserved when
we form linear functions.

00:07:50.080 --> 00:07:52.440
There's one special case that's
we need to pay some

00:07:52.440 --> 00:07:53.780
attention to.

00:07:53.780 --> 00:07:56.750
Suppose that a is equal to 0.

00:07:56.750 --> 00:08:01.250
In this case, the random
variable Y is just equal to b.

00:08:01.250 --> 00:08:03.430
It's a constant random
variable.

00:08:03.430 --> 00:08:05.840
It does not have a PDF.

00:08:05.840 --> 00:08:10.790
It is a degenerate discrete
random variable.

00:08:10.790 --> 00:08:16.000
So could this fact be correct
that Y is also normal?

00:08:16.000 --> 00:08:19.980
Well, we'll adopt this
as [a] convention.

00:08:19.980 --> 00:08:25.420
When we have a discrete random
variable, which is constant,

00:08:25.420 --> 00:08:27.080
it takes a constant value.

00:08:27.080 --> 00:08:30.630
We can think of this as a
special degenerate case of the

00:08:30.630 --> 00:08:37.179
normal with mean equal to b and
with variance equal to 0.

00:08:37.179 --> 00:08:42.070
Even though it is discrete, not
continuous, we will still

00:08:42.070 --> 00:08:45.690
think of it as a degenerate
type of a normal random

00:08:45.690 --> 00:08:49.240
variable, and by adopting this
convention, then it will

00:08:49.240 --> 00:08:52.640
always be true that a linear
function of a normal random

00:08:52.640 --> 00:08:58.710
variable is normal, even
if a is equal to 0.

00:08:58.710 --> 00:09:01.080
Now that we have the definition
and some properties

00:09:01.080 --> 00:09:04.140
of normal random variables, the
next question is whether

00:09:04.140 --> 00:09:07.730
we can calculate probabilities
associated with

00:09:07.730 --> 00:09:09.410
normal random variables.

00:09:09.410 --> 00:09:11.320
This will be the subject
of the next segment.

