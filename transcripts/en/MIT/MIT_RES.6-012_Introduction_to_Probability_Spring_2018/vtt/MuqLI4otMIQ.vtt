WEBVTT
Kind: captions
Language: en

00:00:00.480 --> 00:00:03.600
We will now work with a
geometric random variable and

00:00:03.600 --> 00:00:06.830
put to use our understanding
of conditional PMFs and

00:00:06.830 --> 00:00:08.850
conditional expectations.

00:00:08.850 --> 00:00:11.810
Remember that a geometric random
variable corresponds to

00:00:11.810 --> 00:00:14.580
the number of independent
coin tosses until

00:00:14.580 --> 00:00:16.550
the first head occurs.

00:00:16.550 --> 00:00:20.445
And here p is a parameter
that describes the coin.

00:00:20.445 --> 00:00:24.600
It is the probability of heads
at each coin toss.

00:00:24.600 --> 00:00:28.430
We have already seen the formula
for the geometric PMF

00:00:28.430 --> 00:00:30.370
and the corresponding plot.

00:00:30.370 --> 00:00:34.380
We will now add one very
important property which is

00:00:34.380 --> 00:00:37.140
usually called Memorylessness.

00:00:37.140 --> 00:00:40.080
Ultimately, this property has
to do with the fact that

00:00:40.080 --> 00:00:43.850
independent coin tosses do
not have any memory.

00:00:43.850 --> 00:00:48.490
Past coin tosses do not affect
future coin tosses.

00:00:48.490 --> 00:00:52.290
So consider a coin-tossing
experiment with independent

00:00:52.290 --> 00:00:57.050
tosses and let X be the
number of tosses

00:00:57.050 --> 00:01:00.140
until the first heads.

00:01:00.140 --> 00:01:04.209
And X is a geometric
with parameter p.

00:01:04.209 --> 00:01:08.270
Suppose that you show up a
little after the experiment

00:01:08.270 --> 00:01:10.030
has started.

00:01:10.030 --> 00:01:15.000
And you're told that there was
so far just one coin toss.

00:01:15.000 --> 00:01:18.460
And that this coin toss
resulted in tails.

00:01:18.460 --> 00:01:23.940
Now you have to take over and
carry out the remaining tosses

00:01:23.940 --> 00:01:26.130
until heads are observed.

00:01:26.130 --> 00:01:29.980
What should your model
be about the future?

00:01:29.980 --> 00:01:34.440
Well, you will be making
independent coin tosses until

00:01:34.440 --> 00:01:36.400
the first heads.

00:01:36.400 --> 00:01:41.560
So the number of such tosses
will be a random variable,

00:01:41.560 --> 00:01:45.530
which is geometric
with parameter p.

00:01:45.530 --> 00:01:47.180
So this duration--

00:01:47.180 --> 00:01:49.479
as far as you are concerned--

00:01:49.479 --> 00:01:54.430
is geometric with parameter p.

00:01:54.430 --> 00:01:59.610
Therefore, the number of
remaining coin tosses starting

00:01:59.610 --> 00:02:00.920
from here--

00:02:00.920 --> 00:02:04.200
given that the first
toss was tails--

00:02:04.200 --> 00:02:07.990
has the same geometric
distribution as the original

00:02:07.990 --> 00:02:10.370
random variable X.

00:02:10.370 --> 00:02:13.290
This is the Memorylessness
property.

00:02:13.290 --> 00:02:18.100
Now, since X is the total number
of coin tosses and

00:02:18.100 --> 00:02:22.890
since your coin tosses were
all of them except for the

00:02:22.890 --> 00:02:27.190
first one, the random variable
that you are concerned

00:02:27.190 --> 00:02:30.430
with is X minus 1.

00:02:30.430 --> 00:02:33.030
And so the geometric
distribution that you are

00:02:33.030 --> 00:02:39.180
seeing here is the conditional
distribution of X minus 1

00:02:39.180 --> 00:02:43.440
given that the first toss
resulted in tails, which is

00:02:43.440 --> 00:02:49.520
the same as the event that X
is strictly larger than 1.

00:02:49.520 --> 00:02:53.210
So the statement that we have
been making is the following

00:02:53.210 --> 00:02:55.460
in more mathematical
language--

00:02:55.460 --> 00:03:00.930
that conditioned on X being
larger than 1, the random

00:03:00.930 --> 00:03:04.370
variable X minus 1, which is the
remaining number of coin

00:03:04.370 --> 00:03:10.100
tosses, has a geometric
distribution with parameter p.

00:03:10.100 --> 00:03:11.830
Let us now give a more precise,

00:03:11.830 --> 00:03:13.150
mathematical argument.

00:03:13.150 --> 00:03:15.620
But first, for a special case.

00:03:15.620 --> 00:03:19.210
Let's us look at the conditional
probabilities for

00:03:19.210 --> 00:03:22.430
the random variable X minus 1.

00:03:22.430 --> 00:03:25.560
And calculate, for example, the
conditional probability

00:03:25.560 --> 00:03:32.610
that X minus 1 is equal to 3,
given that X is larger than 1.

00:03:32.610 --> 00:03:34.780
Which is the same as saying
that the first

00:03:34.780 --> 00:03:36.730
toss resulted in tails.

00:03:39.460 --> 00:03:41.770
Now, the first toss
resulted in tails.

00:03:41.770 --> 00:03:45.480
This is the probability that
you will need three more

00:03:45.480 --> 00:03:48.970
tosses until you
observe heads.

00:03:48.970 --> 00:03:52.410
Needing three more tosses until
you observe heads is the

00:03:52.410 --> 00:03:58.079
event that you had tails in the
second toss, tails in the

00:03:58.079 --> 00:04:03.660
third toss, and heads
in the fourth toss.

00:04:03.660 --> 00:04:07.170
And all that is conditioned
on the first toss

00:04:07.170 --> 00:04:10.750
having resulted in tails.

00:04:10.750 --> 00:04:14.900
However, the different coin
tosses are independent.

00:04:14.900 --> 00:04:18.810
So the conditional
probabilities, given the event

00:04:18.810 --> 00:04:22.670
that the first toss was tails
should be the same as the

00:04:22.670 --> 00:04:25.050
unconditional probabilities.

00:04:25.050 --> 00:04:28.580
The first toss does not change
our beliefs about the

00:04:28.580 --> 00:04:34.470
probabilities associated with
the remaining tosses.

00:04:34.470 --> 00:04:36.760
Now, this unconditional

00:04:36.760 --> 00:04:40.190
probability is easy to calculate.

00:04:40.190 --> 00:04:43.550
It is 1 minus p squared--

00:04:43.550 --> 00:04:45.900
because we have two
tails in a row--

00:04:45.900 --> 00:04:48.920
times p.

00:04:48.920 --> 00:04:53.170
Now, we observe that this
quantity here is the

00:04:53.170 --> 00:04:57.670
probability that a geometric
random variable takes the

00:04:57.670 --> 00:05:00.580
value of three.

00:05:00.580 --> 00:05:03.240
Here what have we calculated?

00:05:03.240 --> 00:05:09.340
We have calculated the PMF of
the random variable X minus 1

00:05:09.340 --> 00:05:14.610
in a conditional universe where
X is larger than 1.

00:05:14.610 --> 00:05:18.510
And we evaluated it
for a value of 3.

00:05:18.510 --> 00:05:21.210
The probability that our random
variable X minus 1

00:05:21.210 --> 00:05:23.200
takes the value of 3.

00:05:23.200 --> 00:05:28.410
So what we have shown is that
this conditional PMF is the

00:05:28.410 --> 00:05:32.900
same as the unconditional PMF.

00:05:32.900 --> 00:05:36.110
Now, there is nothing special
about the number 3.

00:05:36.110 --> 00:05:40.600
You can generalize this argument
and establish that

00:05:40.600 --> 00:05:45.900
the conditional probability of
X minus 1 given that X is

00:05:45.900 --> 00:05:51.090
strictly larger than one, for
any particular k, is the same

00:05:51.090 --> 00:05:54.300
as the corresponding probability
for the random

00:05:54.300 --> 00:06:01.600
variable X, which is given
by the geometric PMF.

00:06:01.600 --> 00:06:07.715
Finally, there is nothing
special about the value of 1

00:06:07.715 --> 00:06:10.980
that we're using here.

00:06:10.980 --> 00:06:16.500
In fact, we can generalize
and argue as follows--

00:06:16.500 --> 00:06:20.410
suppose that I tell you that X
is strictly larger than n.

00:06:20.410 --> 00:06:24.880
That is, the first n tosses
resulted in tails.

00:06:24.880 --> 00:06:29.160
Once more, these past tosses
were wasted but have no effect

00:06:29.160 --> 00:06:30.200
on the future.

00:06:30.200 --> 00:06:34.909
So the conditional PMF of the
remaining number of tosses

00:06:34.909 --> 00:06:38.090
should be, again, the same.

00:06:38.090 --> 00:06:42.200
Therefore, the statement we're
making is that this geometric

00:06:42.200 --> 00:06:49.330
PMF will also be the PMF of
X minus n, given that X is

00:06:49.330 --> 00:06:53.659
strictly larger than n, and this
will be true no matter

00:06:53.659 --> 00:06:58.570
what argument we plug-in
into the PMF.

00:06:58.570 --> 00:07:01.640
We will now exploit the
Memorylessness property of the

00:07:01.640 --> 00:07:05.490
geometric PMF and use it
together with the total

00:07:05.490 --> 00:07:08.690
expectation theorem to
calculate the mean or

00:07:08.690 --> 00:07:11.620
expectation of the
geometric PMF.

00:07:11.620 --> 00:07:14.050
If we wanted to calculate the
expected value of the

00:07:14.050 --> 00:07:17.590
geometric using the definition
of the expectation, we would

00:07:17.590 --> 00:07:21.280
have to calculate this infinite
sum here, which is

00:07:21.280 --> 00:07:23.030
quite difficult.

00:07:23.030 --> 00:07:26.710
Instead, we're going to
use a certain trick.

00:07:26.710 --> 00:07:28.420
The trick is the following--

00:07:28.420 --> 00:07:32.120
to break down the expected value
calculation into two

00:07:32.120 --> 00:07:33.820
different scenarios.

00:07:33.820 --> 00:07:38.210
Under one scenario we obtain
heads in the first toss.

00:07:38.210 --> 00:07:42.430
And in that case the
random variable X--

00:07:42.430 --> 00:07:44.460
the number of tosses until
the first heads--

00:07:44.460 --> 00:07:45.730
is equal to 1.

00:07:45.730 --> 00:07:48.480
And this scenario occurs
with probability p.

00:07:48.480 --> 00:07:51.470
And we have another scenario
with probability 1 minus p

00:07:51.470 --> 00:07:54.580
where we obtain tails
in the first toss.

00:07:54.580 --> 00:07:56.830
And in that case, our
random variable is

00:07:56.830 --> 00:07:59.400
strictly larger than 1.

00:07:59.400 --> 00:08:05.340
Now, the expected value of
X consists of two pieces.

00:08:05.340 --> 00:08:08.930
We have a first toss
no matter what.

00:08:08.930 --> 00:08:12.990
And then we have the number
of remaining tosses,

00:08:12.990 --> 00:08:15.060
which is X minus 1.

00:08:15.060 --> 00:08:18.640
So this is true by linearity
of expectations.

00:08:18.640 --> 00:08:23.480
Now, the expected value of X
minus 1 consists of two pieces

00:08:23.480 --> 00:08:25.770
using the total expectation
theorem.

00:08:25.770 --> 00:08:29.300
The probability of the first
scenario times the expected

00:08:29.300 --> 00:08:34.450
value of X minus 1 given
that X is equal to 1,

00:08:34.450 --> 00:08:36.558
plus 1 minus p--

00:08:36.558 --> 00:08:38.970
the probability of the
second scenario--

00:08:38.970 --> 00:08:43.549
times the expected value of
X minus 1 given that X

00:08:43.549 --> 00:08:45.000
is bigger than 1.

00:08:47.660 --> 00:08:51.200
Now, this term here is 0.

00:08:51.200 --> 00:08:52.000
Why?

00:08:52.000 --> 00:08:55.730
If I tell you that X is equal
to 1, then you're certain

00:08:55.730 --> 00:08:58.350
that's X minus 1
is equal to 0.

00:08:58.350 --> 00:09:01.770
So this term gives
a 0 contribution.

00:09:01.770 --> 00:09:03.760
How about the next term?

00:09:03.760 --> 00:09:08.850
We have a 1 minus p here times
this expected value.

00:09:08.850 --> 00:09:15.560
Now this random variable,
conditioned on this event, has

00:09:15.560 --> 00:09:20.890
the same distribution as an
ordinary, unconditioned

00:09:20.890 --> 00:09:22.890
geometric random variable.

00:09:22.890 --> 00:09:27.450
So this expectation here must be
the same as the expectation

00:09:27.450 --> 00:09:32.050
of an ordinary, unconditioned,
geometric random variable.

00:09:32.050 --> 00:09:34.730
And this gives us an equality.

00:09:34.730 --> 00:09:38.900
Both sides involve the expected
value of X. But we

00:09:38.900 --> 00:09:42.780
can solve this equation for
the expected value.

00:09:42.780 --> 00:09:45.610
And we obtain the end result
that the expected

00:09:45.610 --> 00:09:49.540
value is 1 over p.

00:09:49.540 --> 00:09:53.550
By the way, this answer
makes intuitive sense.

00:09:53.550 --> 00:09:58.030
If p is small, this means
that the odds of

00:09:58.030 --> 00:10:00.860
seeing heads is small.

00:10:00.860 --> 00:10:05.040
Then in that case, we need to
wait longer and longer until

00:10:05.040 --> 00:10:07.720
we see heads for
the first time.

00:10:07.720 --> 00:10:10.740
Setting aside the specific form
of the answer that we

00:10:10.740 --> 00:10:15.510
found, what we have just done
actually illustrates that

00:10:15.510 --> 00:10:19.950
fairly difficult calculations
can become very simple if one

00:10:19.950 --> 00:10:23.740
breaks down a model or a problem
in a clever way.

00:10:23.740 --> 00:10:26.450
This is going to be a recurring
theme throughout

00:10:26.450 --> 00:10:27.700
this class.

