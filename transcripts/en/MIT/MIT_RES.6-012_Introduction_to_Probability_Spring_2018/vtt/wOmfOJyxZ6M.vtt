WEBVTT
Kind: captions
Language: en

00:00:01.780 --> 00:00:05.280
We now start with our agenda
of developing continuous

00:00:05.280 --> 00:00:07.970
counterparts of everything
we have done for

00:00:07.970 --> 00:00:10.160
discrete random variables.

00:00:10.160 --> 00:00:12.710
Let us look at the concept
of expectation.

00:00:12.710 --> 00:00:16.030
In the discrete case, we have
defined expectation as a

00:00:16.030 --> 00:00:20.400
weighted average of the values
X of the random variable,

00:00:20.400 --> 00:00:24.540
weighted according to their
corresponding probabilities.

00:00:24.540 --> 00:00:27.450
In the continuous case, we
define expectation in a

00:00:27.450 --> 00:00:28.890
similar way--

00:00:28.890 --> 00:00:33.820
as a weighted average over the
possible values of X, weighted

00:00:33.820 --> 00:00:38.020
according to the corresponding
value of the density.

00:00:38.020 --> 00:00:40.370
Points where the density
is higher--

00:00:40.370 --> 00:00:42.430
for example, here--

00:00:42.430 --> 00:00:46.730
will receive a higher weight
in this calculation.

00:00:46.730 --> 00:00:50.620
But of course, since we are
averaging over a continuous

00:00:50.620 --> 00:00:55.770
set, the summation will have to
be replaced by an integral.

00:00:55.770 --> 00:00:58.190
This will be a recurrent
theme in this unit.

00:00:58.190 --> 00:01:01.500
Definitions or formulas for
the continuous case look

00:01:01.500 --> 00:01:05.580
exactly like the discrete ones,
except that PMFs are

00:01:05.580 --> 00:01:08.730
replaced by densities,
as here.

00:01:08.730 --> 00:01:11.170
The PMF is replaced
by a density.

00:01:11.170 --> 00:01:15.600
And summations are replaced
by integrals.

00:01:15.600 --> 00:01:18.380
The intuition is usually the
same in both the discrete and

00:01:18.380 --> 00:01:19.680
the continuous case.

00:01:19.680 --> 00:01:23.030
However, the intuition is
usually much clearer, much

00:01:23.030 --> 00:01:26.330
easier to visualize in
the discrete case.

00:01:26.330 --> 00:01:30.180
So the best strategy is to make
sure to understand fully

00:01:30.180 --> 00:01:35.140
the intuition for the discrete
case and just rely on it.

00:01:35.140 --> 00:01:39.350
At this point, let me add
some fine print--

00:01:39.350 --> 00:01:41.630
a mathematical side point.

00:01:41.630 --> 00:01:45.780
This integral or the expectation
will not be always

00:01:45.780 --> 00:01:46.600
well defined.

00:01:46.600 --> 00:01:50.350
For this integral to make sense,
we will need to make

00:01:50.350 --> 00:01:53.620
the assumption that the integral
of the absolute value

00:01:53.620 --> 00:01:57.140
of little x, weighted according
to the density,

00:01:57.140 --> 00:01:59.500
gives us a finite result.

00:01:59.500 --> 00:02:02.540
Unless we explicitly say
something different, we will

00:02:02.540 --> 00:02:05.220
always assume that we're dealing
with random variables

00:02:05.220 --> 00:02:06.730
that satisfy this condition.

00:02:06.730 --> 00:02:11.130
And so the expectation is well
defined mathematically.

00:02:11.130 --> 00:02:13.520
Coming back to the big
picture, regarding

00:02:13.520 --> 00:02:16.600
expectations, the intuition
remains the same as in the

00:02:16.600 --> 00:02:19.620
discrete case-- that the
expectation represents the

00:02:19.620 --> 00:02:23.300
average of the values we expect
to see in a very large

00:02:23.300 --> 00:02:26.770
number of independent
repetitions of the experiment.

00:02:26.770 --> 00:02:30.030
In fact, there are also theorems
to this effect, but

00:02:30.030 --> 00:02:33.400
these will have to wait until
later in this class when we

00:02:33.400 --> 00:02:35.670
study limit theorems.

00:02:35.670 --> 00:02:38.200
Another intuitive interpretation
that is true

00:02:38.200 --> 00:02:41.510
for both the discrete and the
continuous case is that the

00:02:41.510 --> 00:02:45.100
expectation corresponds to the
center of gravity of the

00:02:45.100 --> 00:02:46.829
probability distribution.

00:02:46.829 --> 00:02:50.450
So in this diagram, it might
be somewhere around here.

00:02:50.450 --> 00:02:53.130
And similarly, for the
continuous diagram, the center

00:02:53.130 --> 00:02:57.680
of gravity might be somewhere
around here.

00:02:57.680 --> 00:03:01.160
And if it happens that the
distribution, the PMF or the

00:03:01.160 --> 00:03:05.580
PDF, happens to be symmetric
around a certain point, then

00:03:05.580 --> 00:03:08.930
that point will be equal
to the expectation.

00:03:08.930 --> 00:03:12.020
Expectations of continuous
random variables have all the

00:03:12.020 --> 00:03:14.030
properties you might expect.

00:03:14.030 --> 00:03:17.640
For example, non-negative
random variables have

00:03:17.640 --> 00:03:19.970
non-negative expectations.

00:03:19.970 --> 00:03:23.600
Random variables that lie
inside an interval have

00:03:23.600 --> 00:03:27.030
average values or expectations
that also lie

00:03:27.030 --> 00:03:28.920
inside the same interval.

00:03:28.920 --> 00:03:33.270
The derivation is exactly the
same as for the discrete case.

00:03:33.270 --> 00:03:35.329
There is also an expected
value rule.

00:03:35.329 --> 00:03:38.620
In the discrete case, it
took on this form.

00:03:38.620 --> 00:03:42.390
In the continuous case, we
obtain an analogous form in

00:03:42.390 --> 00:03:45.790
which the summation is replaced
by [an] integral.

00:03:45.790 --> 00:03:49.960
And instead of weighing
according to the PMF, we now

00:03:49.960 --> 00:03:53.240
weigh according to the
density function.

00:03:53.240 --> 00:03:56.090
The derivation of the expected
value rule for the continuous

00:03:56.090 --> 00:03:59.155
case is a little more
complicated than the one that

00:03:59.155 --> 00:04:01.230
we gave for the discrete case.

00:04:01.230 --> 00:04:06.620
But it's sufficient for us to
know that it is true and that

00:04:06.620 --> 00:04:10.380
it has an intuitive meaning that
runs along the same lines

00:04:10.380 --> 00:04:14.910
as the intuitive meaning that we
had for the discrete case.

00:04:14.910 --> 00:04:18.930
As an instance of how we might
apply the expected value rule,

00:04:18.930 --> 00:04:22.890
if you wish to calculate the
expected value of the square

00:04:22.890 --> 00:04:25.250
of a continuous random
variable, you

00:04:25.250 --> 00:04:26.820
would proceed as follows.

00:04:26.820 --> 00:04:32.330
You would integrate over the
entire real line the value of

00:04:32.330 --> 00:04:37.000
the function, which is X squared
in our case, weighted

00:04:37.000 --> 00:04:38.250
according to the density.

00:04:41.290 --> 00:04:43.190
Finally, a most important
property of

00:04:43.190 --> 00:04:45.870
expectations, is linearity.

00:04:45.870 --> 00:04:48.540
Linearity is still true
for continuous random

00:04:48.540 --> 00:04:50.100
variables as well.

00:04:50.100 --> 00:04:53.200
And the way it is derived is
exactly the same as in the

00:04:53.200 --> 00:04:54.470
discrete case.

00:04:54.470 --> 00:04:58.510
Namely, we apply the expected
value rule to this function of

00:04:58.510 --> 00:05:01.100
the random variable
X and separate

00:05:01.100 --> 00:05:04.650
out the various terms.

00:05:04.650 --> 00:05:08.200
The story regarding variances is
exactly the same as in the

00:05:08.200 --> 00:05:09.630
discrete case.

00:05:09.630 --> 00:05:13.010
We define variances using
the same definition.

00:05:13.010 --> 00:05:16.210
And of course, here, mu stands
for the expected value of the

00:05:16.210 --> 00:05:18.570
random variable X.

00:05:18.570 --> 00:05:22.470
To calculate the variance, we
can use the expected value

00:05:22.470 --> 00:05:25.860
rule, which takes this form
in the continuous case.

00:05:25.860 --> 00:05:29.230
And we apply the expected value
rule for the case where

00:05:29.230 --> 00:05:31.570
we're dealing with the expected
value of this

00:05:31.570 --> 00:05:34.630
particular function, so that
in this instance, the

00:05:34.630 --> 00:05:39.240
functions g of x is x
minus mu squared.

00:05:39.240 --> 00:05:43.409
So by applying the expected
value rule, we obtain the

00:05:43.409 --> 00:05:47.360
integral from minus infinity to
infinity, the functions g

00:05:47.360 --> 00:05:54.550
of x, weighted according to the
density, and then we carry

00:05:54.550 --> 00:05:57.960
out the integration.

00:05:57.960 --> 00:06:00.180
We also define the standard
deviation--

00:06:00.180 --> 00:06:03.480
same way as in the
discrete case.

00:06:03.480 --> 00:06:07.360
We have a property about a
variance of linear functions,

00:06:07.360 --> 00:06:11.600
of a random variable, namely,
that if we add a constant to a

00:06:11.600 --> 00:06:14.740
random variable, this has no
effect on the variance.

00:06:14.740 --> 00:06:17.850
But if we multiply a random
variable by a constant, the

00:06:17.850 --> 00:06:22.110
variance gets multiplied by the
square of that constant.

00:06:22.110 --> 00:06:25.030
Finally, when calculating the
variance, it is often

00:06:25.030 --> 00:06:29.810
convenient to use this
alternative formula in which

00:06:29.810 --> 00:06:34.360
the variance is calculated by
finding the expected value of

00:06:34.360 --> 00:06:37.740
the square of the random
variable and also using the

00:06:37.740 --> 00:06:40.980
expected value of the random
variable, but squared and

00:06:40.980 --> 00:06:44.880
subtracted from the
first term.

00:06:44.880 --> 00:06:48.650
This relation and this relation
are both derived

00:06:48.650 --> 00:06:51.920
exactly the same way as
in the discrete case.

00:06:51.920 --> 00:06:54.560
And there's no reason to repeat
those derivations.

