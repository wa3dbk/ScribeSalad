WEBVTT
Kind: captions
Language: en

00:00:00.610 --> 00:00:03.100
We have seen so far two ways of

00:00:03.100 --> 00:00:05.810
estimating an unknown parameter.

00:00:05.810 --> 00:00:08.470
We can use the maximum a
posteriori probability

00:00:08.470 --> 00:00:12.110
estimate, or we can use the
conditional expectation.

00:00:12.110 --> 00:00:16.350
That is, the mean of the
posterior distribution.

00:00:16.350 --> 00:00:19.900
These were, in some sense,
arbitrary choices.

00:00:19.900 --> 00:00:23.350
How about imposing a performance
criterion, and

00:00:23.350 --> 00:00:26.890
then finding an estimate which
is optimal with respect to

00:00:26.890 --> 00:00:28.720
that criterion?

00:00:28.720 --> 00:00:33.000
This is what we will be
doing in this lecture.

00:00:33.000 --> 00:00:36.310
We introduce a specific
performance criterion, the

00:00:36.310 --> 00:00:40.330
expected value of the squared
estimation error, and we look

00:00:40.330 --> 00:00:44.910
for an estimator that is optimal
under this criterion.

00:00:44.910 --> 00:00:48.510
It turns out that the optimal
estimator is the conditional

00:00:48.510 --> 00:00:49.850
expectation.

00:00:49.850 --> 00:00:53.370
And this is why we have been
calling it the least mean

00:00:53.370 --> 00:00:55.770
squares estimator.

00:00:55.770 --> 00:00:59.230
It plays a central role because
it is a canonical way

00:00:59.230 --> 00:01:02.230
of estimating unknown
random variables.

00:01:02.230 --> 00:01:06.010
We will study some of its
theoretical properties, and we

00:01:06.010 --> 00:01:09.490
will also illustrate its use and
the associated performance

00:01:09.490 --> 00:01:12.020
analysis in the context
of an example.

