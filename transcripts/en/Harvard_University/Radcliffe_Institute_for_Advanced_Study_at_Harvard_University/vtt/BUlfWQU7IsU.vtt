WEBVTT
Kind: captions
Language: en

00:00:03.820 --> 00:00:05.210
- Good morning, everyone.

00:00:05.210 --> 00:00:06.970
I'm Tomiko Brown-Nagin
and the dean

00:00:06.970 --> 00:00:10.330
of the Radcliffe Institute
for Advanced Study at Harvard

00:00:10.330 --> 00:00:11.380
University.

00:00:11.380 --> 00:00:15.340
Welcome to our Annual
Science Symposium.

00:00:15.340 --> 00:00:17.240
Let me begin with some things.

00:00:17.240 --> 00:00:19.660
First of all, I'm
grateful to the speakers

00:00:19.660 --> 00:00:22.060
who are here today and
participating in today's

00:00:22.060 --> 00:00:23.170
symposium.

00:00:23.170 --> 00:00:26.590
Thank you for taking the
time to be here with us.

00:00:26.590 --> 00:00:29.180
Many thanks, also,
to Alyssa Goodman,

00:00:29.180 --> 00:00:32.890
who conceived today's program
and will offer opening remarks

00:00:32.890 --> 00:00:34.700
in just a few minutes.

00:00:34.700 --> 00:00:37.720
I also want to express thanks
to Rebecca Wasserman, who

00:00:37.720 --> 00:00:41.590
is the executive director of
our Academic Ventures Program

00:00:41.590 --> 00:00:45.250
here at Radcliffe and also
to Jessica Viklund, who

00:00:45.250 --> 00:00:47.650
is the Director of Events.

00:00:47.650 --> 00:00:52.630
And I also thank the entire team
in Academic Ventures and Events

00:00:52.630 --> 00:00:56.620
for organizing this very
exciting program, today.

00:00:56.620 --> 00:01:00.010
I also want to acknowledge
members of the Radcliffe

00:01:00.010 --> 00:01:03.860
Institute Leadership Society
and our dedicated annual donors.

00:01:03.860 --> 00:01:06.730
It's because of you that
we're able to organize events

00:01:06.730 --> 00:01:09.850
like this and open them
free, to the public.

00:01:09.850 --> 00:01:11.350
Thank you.

00:01:11.350 --> 00:01:13.510
I'm also delighted
to note that we

00:01:13.510 --> 00:01:15.070
are joined by a
number of students

00:01:15.070 --> 00:01:17.710
today, including more than
40 from Barnstable High

00:01:17.710 --> 00:01:23.620
School, who are here with their
astronomy teacher Michael Gyra.

00:01:23.620 --> 00:01:25.890
We'll get to hear from
a couple of-- yes.

00:01:25.890 --> 00:01:27.384
[APPLAUSE]

00:01:27.384 --> 00:01:28.380
That's right.

00:01:31.370 --> 00:01:35.150
We'll be able to hear from
a couple of those students,

00:01:35.150 --> 00:01:37.880
later, in today's program.

00:01:37.880 --> 00:01:40.220
Today's symposium
will explore how

00:01:40.220 --> 00:01:43.160
scientists across
a range of fields

00:01:43.160 --> 00:01:47.870
tackle the undiscovered in
order to advance new knowledge.

00:01:47.870 --> 00:01:49.970
We're getting a
behind-the-scenes look

00:01:49.970 --> 00:01:53.580
at how science really works.

00:01:53.580 --> 00:01:55.640
Generally speaking,
there's a chasm

00:01:55.640 --> 00:01:58.280
between the way
scientists do their work,

00:01:58.280 --> 00:02:01.220
and the way the rest of
us tend to imagine it.

00:02:01.220 --> 00:02:04.070
Among non-scientists,
there's often the impression

00:02:04.070 --> 00:02:06.590
that scientific
discovery results

00:02:06.590 --> 00:02:10.340
from a linear process of
hypothesis formulation,

00:02:10.340 --> 00:02:13.070
empirical observation,
and accumulation

00:02:13.070 --> 00:02:15.320
of cold, hard facts.

00:02:15.320 --> 00:02:18.890
That this view is so
commonplace isn't surprising.

00:02:18.890 --> 00:02:21.560
It's called the scientific
method, and many of us

00:02:21.560 --> 00:02:23.750
grew up learning it.

00:02:23.750 --> 00:02:27.640
But the actual practice of
science is far different.

00:02:27.640 --> 00:02:30.940
Hypothesis, formulation,
and empirical observation

00:02:30.940 --> 00:02:33.250
are critical, to be sure.

00:02:33.250 --> 00:02:36.610
But as we'll hear
today, unpredictability,

00:02:36.610 --> 00:02:39.340
leaps of faith, the
element of chance,

00:02:39.340 --> 00:02:43.570
and rigorous preparation for
the wholly unanticipated,

00:02:43.570 --> 00:02:47.350
are equally important
to scientific discovery.

00:02:47.350 --> 00:02:51.850
The work of scientists is
complex, dynamic, and creative,

00:02:51.850 --> 00:02:54.370
not formulaic or rote.

00:02:54.370 --> 00:02:57.640
Our first keynote
speaker, Stuart Firestein,

00:02:57.640 --> 00:03:00.220
has compared scientific
work to searching

00:03:00.220 --> 00:03:04.510
for a black cat in a dark
room, when very often there

00:03:04.510 --> 00:03:05.200
is no cat.

00:03:08.280 --> 00:03:10.560
Today's symposium
provides an opportunity

00:03:10.560 --> 00:03:13.860
to explore what exactly
this means in practice,

00:03:13.860 --> 00:03:18.360
and to consider the implications
for how we, as a society,

00:03:18.360 --> 00:03:22.710
understand and value the
real work of science,

00:03:22.710 --> 00:03:26.070
how we support scientific
discovery through research

00:03:26.070 --> 00:03:28.410
funding and public
policy, and how

00:03:28.410 --> 00:03:31.710
we prepare students to
become the pathbreaking

00:03:31.710 --> 00:03:33.780
scientists of tomorrow.

00:03:33.780 --> 00:03:36.690
I encourage you to learn
more about this last point

00:03:36.690 --> 00:03:40.680
by visiting our student
poster session over lunch.

00:03:40.680 --> 00:03:43.410
Today, also, is an
opportunity to take advantage

00:03:43.410 --> 00:03:46.350
of Radcliffe's remarkable
interdisciplinarity

00:03:46.350 --> 00:03:50.100
and engage in exploration
across academic and professional

00:03:50.100 --> 00:03:51.210
boundaries.

00:03:51.210 --> 00:03:53.910
I think it's safe to
assume that we each have

00:03:53.910 --> 00:03:56.970
a more nuanced understanding
of our own disciplines

00:03:56.970 --> 00:04:00.840
than do our colleagues
or peers in other fields.

00:04:00.840 --> 00:04:03.810
The natural sciences
provide a particularly stark

00:04:03.810 --> 00:04:06.190
illustration, as we will see.

00:04:06.190 --> 00:04:08.430
But more generally,
we should never

00:04:08.430 --> 00:04:12.660
hesitate to ask one
another to explain how

00:04:12.660 --> 00:04:14.880
we go about our work and why.

00:04:14.880 --> 00:04:17.709
We can learn a lot
from those answers.

00:04:17.709 --> 00:04:20.070
Now, I'm pleased
to turn things over

00:04:20.070 --> 00:04:22.380
to my colleague, Alyssa Goodman.

00:04:22.380 --> 00:04:24.600
Alyssa is the
faculty co-director

00:04:24.600 --> 00:04:27.210
of the science program at
the Radcliffe Institute,

00:04:27.210 --> 00:04:29.880
a distinguished scholar
whose important work

00:04:29.880 --> 00:04:31.530
spans several fields.

00:04:31.530 --> 00:04:35.310
Alyssa also serves as
the Robert Wheeler Wilson

00:04:35.310 --> 00:04:38.550
professor of applied astronomy,
and Harvard's faculty

00:04:38.550 --> 00:04:39.690
of Arts and Sciences.

00:04:39.690 --> 00:04:41.618
And now, Alyssa.

00:04:41.618 --> 00:04:44.522
[APPLAUSE]

00:04:50.330 --> 00:04:53.270
- Well, thank you so much for
coming, and thank you, Tomiko,

00:04:53.270 --> 00:04:54.830
and thank you so
much to Radcliffe

00:04:54.830 --> 00:04:57.330
for making an event
like this possible.

00:04:57.330 --> 00:04:59.870
I should say that I've been at
Harvard for a very long time.

00:04:59.870 --> 00:05:01.536
And I've only been
affiliated officially

00:05:01.536 --> 00:05:03.320
with Radcliffe for a few years.

00:05:03.320 --> 00:05:05.630
And that started with the
Radcliffe Fellowship Program.

00:05:05.630 --> 00:05:07.880
And some of you in the
audience have had the privilege

00:05:07.880 --> 00:05:09.440
of being a Radcliffe Fellow.

00:05:09.440 --> 00:05:11.930
And I'll just tell you
that if you enjoy today,

00:05:11.930 --> 00:05:16.160
pretty much that's what being a
Radcliffe Fellow is, every day.

00:05:16.160 --> 00:05:19.530
So it's really terrific.

00:05:19.530 --> 00:05:22.040
So I think I have some
slides to show you,

00:05:22.040 --> 00:05:25.640
to try to explain what
really is going on here,

00:05:25.640 --> 00:05:29.270
today, because a lot of you may
be thinking, this looks cool,

00:05:29.270 --> 00:05:31.270
but I don't know, what
is the undiscovered, what

00:05:31.270 --> 00:05:32.960
is this symposium about?

00:05:32.960 --> 00:05:36.170
I will fix this for you
with literally one word.

00:05:36.170 --> 00:05:37.550
Are you ready?

00:05:37.550 --> 00:05:40.710
Watch carefully.

00:05:40.710 --> 00:05:41.580
OK?

00:05:41.580 --> 00:05:44.050
Got that?

00:05:44.050 --> 00:05:46.945
I don't know, and saying, I
don't know and I have no idea,

00:05:46.945 --> 00:05:48.820
but I'm going to try
and act like a scientist

00:05:48.820 --> 00:05:52.570
and figure it out, is actually
what the symposium is about.

00:05:52.570 --> 00:05:55.360
And I should say that the
original idea was actually

00:05:55.360 --> 00:05:59.440
to focus this, completely, on
education and communication,

00:05:59.440 --> 00:06:02.020
and to change the
way that science

00:06:02.020 --> 00:06:03.790
is perceived by the
public in the way

00:06:03.790 --> 00:06:05.459
that it's taught in schools.

00:06:05.459 --> 00:06:07.000
And we decided,
actually, in the end,

00:06:07.000 --> 00:06:09.040
that the best way to do
that is to demonstrate

00:06:09.040 --> 00:06:11.230
the way science
is actually done,

00:06:11.230 --> 00:06:14.710
and to have a focus on
education in the poster session

00:06:14.710 --> 00:06:16.220
that you've heard
about at lunch.

00:06:16.220 --> 00:06:17.470
So we'll explain the details--

00:06:17.470 --> 00:06:19.240
I'm sorry, not at
lunch yet, sorry,

00:06:19.240 --> 00:06:21.100
it will happen at lunch--

00:06:21.100 --> 00:06:24.770
and we'll explain the details
of that in just a minute.

00:06:24.770 --> 00:06:28.030
But before I continue, I
thought I would give you

00:06:28.030 --> 00:06:31.180
one small example
of a story that

00:06:31.180 --> 00:06:34.330
just encapsulates the
undiscovered, in one

00:06:34.330 --> 00:06:35.440
tiny vignette.

00:06:35.440 --> 00:06:37.270
And it's actually a
story that has a lot

00:06:37.270 --> 00:06:39.340
to do with my friend and
former colleague here,

00:06:39.340 --> 00:06:42.880
Bob Kirshner, who
will give a lecture

00:06:42.880 --> 00:06:45.174
in the undiscovered
series, which is described

00:06:45.174 --> 00:06:46.340
in the back of your program.

00:06:46.340 --> 00:06:47.980
So if you like what
you hear today,

00:06:47.980 --> 00:06:49.600
there are many events
over the course

00:06:49.600 --> 00:06:51.266
of the year-- some
of which have already

00:06:51.266 --> 00:06:53.320
happened-- one of which
I'll mention in a minute.

00:06:53.320 --> 00:06:55.220
But Bob Kirshner,
as many of you know,

00:06:55.220 --> 00:06:57.190
is a very prominent
astronomer who

00:06:57.190 --> 00:06:59.530
is involved in something
called dark energy.

00:06:59.530 --> 00:07:02.440
And the discovery
of dark energy.

00:07:02.440 --> 00:07:04.390
And what happened
was, a lot of you

00:07:04.390 --> 00:07:07.490
know that the
universe is expanding.

00:07:07.490 --> 00:07:09.880
And that's called Hubble's Law.

00:07:09.880 --> 00:07:14.020
And the thought was that that
expansion should decelerate.

00:07:14.020 --> 00:07:16.270
If you could measure
really, really accurately,

00:07:16.270 --> 00:07:20.080
the galaxies moving away from
us and from every galaxy, what

00:07:20.080 --> 00:07:23.530
the speed of that motion
is, exactly, that you

00:07:23.530 --> 00:07:25.430
could find a deceleration.

00:07:25.430 --> 00:07:27.490
So two teams, a team
that involved Bob here

00:07:27.490 --> 00:07:30.550
at Harvard and another team
led by Saul Perlmutter,

00:07:30.550 --> 00:07:31.960
went out to do this.

00:07:31.960 --> 00:07:34.420
And they had a very carefully
designed experiment.

00:07:34.420 --> 00:07:36.455
So as you just heard
Tomiko say, it's

00:07:36.455 --> 00:07:38.080
not that what we're
talking about today

00:07:38.080 --> 00:07:40.090
is total serendipitous luck.

00:07:40.090 --> 00:07:42.880
We're talking about
when you have a plan,

00:07:42.880 --> 00:07:46.490
but you don't usually find
exactly what you plan to find.

00:07:46.490 --> 00:07:48.640
And in that particular
case, they went out

00:07:48.640 --> 00:07:50.680
to measure the deceleration
of the universe,

00:07:50.680 --> 00:07:53.980
and they found the
acceleration of the universe.

00:07:53.980 --> 00:07:57.640
And Nobel prizes were
awarded, as a result. OK,

00:07:57.640 --> 00:08:00.860
so that is a perfect
example of the undiscovered.

00:08:00.860 --> 00:08:03.280
You do very careful work, and
occasionally you don't just

00:08:03.280 --> 00:08:05.280
find something surprising,
you find the opposite

00:08:05.280 --> 00:08:07.540
of what you set out to find.

00:08:07.540 --> 00:08:10.780
And so this, to us, is what
gets us up in the morning,

00:08:10.780 --> 00:08:13.840
not that we never think we're
going to find what we planned,

00:08:13.840 --> 00:08:16.780
but the idea that
science is so exciting,

00:08:16.780 --> 00:08:19.210
and that it's
undiscovered, that it's

00:08:19.210 --> 00:08:21.880
the stuff that
isn't found out yet,

00:08:21.880 --> 00:08:23.620
that is really interesting.

00:08:23.620 --> 00:08:28.210
And I have another quote
that is actually my favorite.

00:08:28.210 --> 00:08:32.470
And you say, why could Socrates,
Albert Einstein, and Barbra

00:08:32.470 --> 00:08:34.900
Streisand be on the same slide?

00:08:34.900 --> 00:08:37.600
And the answer is, if
you research this quote,

00:08:37.600 --> 00:08:39.309
they've all said it.

00:08:39.309 --> 00:08:42.690
So have many, many other
people, including me OK.

00:08:42.690 --> 00:08:45.320
And so, if you think about
this, "The more I learn,

00:08:45.320 --> 00:08:47.020
the less I know,"
what that means

00:08:47.020 --> 00:08:49.930
is the more you become
expert about something,

00:08:49.930 --> 00:08:51.790
the more you
realize that there's

00:08:51.790 --> 00:08:55.570
a whole lot more to know, and
you don't know very much, OK.

00:08:55.570 --> 00:08:58.210
And so the people who are
going to hear from today

00:08:58.210 --> 00:09:02.020
are experts on a wide
variety of scientific fields,

00:09:02.020 --> 00:09:06.280
and you'll hear them, hopefully,
be extremely honest with you

00:09:06.280 --> 00:09:07.600
about what they do.

00:09:07.600 --> 00:09:09.520
And so we've tried
to divide the program

00:09:09.520 --> 00:09:11.120
into kind of three sections.

00:09:11.120 --> 00:09:13.540
So we'll have a keynote in
the morning and another one

00:09:13.540 --> 00:09:15.370
at the conclusion,
and then we'll

00:09:15.370 --> 00:09:17.650
have a series of
other talks and panels

00:09:17.650 --> 00:09:19.900
that focus, roughly,
on what we're

00:09:19.900 --> 00:09:22.520
calling earth life and space.

00:09:22.520 --> 00:09:24.526
But because of the
interdisciplinary nature

00:09:24.526 --> 00:09:25.900
of the work being
discussed, they

00:09:25.900 --> 00:09:28.660
couldn't even put everybody
in the right categories,

00:09:28.660 --> 00:09:31.930
OK, so some of them kind
of bridge what's going on.

00:09:31.930 --> 00:09:34.540
And so, to just give
you a little taste, when

00:09:34.540 --> 00:09:36.700
it comes to Earth,
Nate Hultman will

00:09:36.700 --> 00:09:40.030
talk about energy, and
environment, and policy,

00:09:40.030 --> 00:09:41.980
and science, and a
mixture of those things,

00:09:41.980 --> 00:09:44.155
and how the undiscovered
plays into that.

00:09:44.155 --> 00:09:46.030
Stuart Firestein, who
you heard a minute ago,

00:09:46.030 --> 00:09:47.230
will be our first speaker.

00:09:47.230 --> 00:09:50.110
He will tell you about his
Ignorance Project, and he

00:09:50.110 --> 00:09:51.700
himself works on neuroscience.

00:09:51.700 --> 00:09:54.400
So I put him between Earth,
where we're ignorant,

00:09:54.400 --> 00:09:56.800
and Life, which is neuroscience.

00:09:56.800 --> 00:09:59.920
Jill Tarter, who will be
our last speaker today,

00:09:59.920 --> 00:10:03.370
is probably well known to
many of you as the real person

00:10:03.370 --> 00:10:06.280
upon whom the Jodie Foster
character in the movie Contact

00:10:06.280 --> 00:10:07.150
is based.

00:10:07.150 --> 00:10:09.340
And if you've seen that
movie or read that book,

00:10:09.340 --> 00:10:11.230
you know that Jill
has dedicated her life

00:10:11.230 --> 00:10:14.140
to a very systematic
search for radio signals

00:10:14.140 --> 00:10:17.120
from extraterrestrial life.

00:10:17.120 --> 00:10:18.580
Speaking of
extraterrestrial life,

00:10:18.580 --> 00:10:20.080
let's go round in a circle.

00:10:20.080 --> 00:10:24.160
When it comes to Space
and also Life in Space,

00:10:24.160 --> 00:10:27.100
we have two experts with
us today, Laura Kriedberg

00:10:27.100 --> 00:10:30.100
and Lisa Kaltenegger.

00:10:30.100 --> 00:10:32.020
And they'll talk
to-- both of them--

00:10:32.020 --> 00:10:34.480
about possibilities
for what we might

00:10:34.480 --> 00:10:36.760
find on planets
around other stars,

00:10:36.760 --> 00:10:39.970
in terms of the properties of
the planets and life there.

00:10:39.970 --> 00:10:41.980
Joel Dudley, squarely
in the middle,

00:10:41.980 --> 00:10:43.510
there, in terms of
Life, is actually

00:10:43.510 --> 00:10:45.593
going to tell you about
what happens when you take

00:10:45.593 --> 00:10:48.100
huge amounts of data
and look for things

00:10:48.100 --> 00:10:50.860
that have to do with
life but don't always

00:10:50.860 --> 00:10:52.090
find what you're looking for.

00:10:52.090 --> 00:10:53.810
And I'll just leave it there.

00:10:53.810 --> 00:10:55.930
And then Wally
Fulweiler is shown there

00:10:55.930 --> 00:10:58.240
as bridging Earth's
and Life, because she's

00:10:58.240 --> 00:11:01.112
going to talk about coastal
ecosystems and the effects

00:11:01.112 --> 00:11:03.070
that we have on the
chemistry of those systems,

00:11:03.070 --> 00:11:05.687
and then the effects that that
chemistry has back on life.

00:11:05.687 --> 00:11:07.270
So hopefully you see
that this is kind

00:11:07.270 --> 00:11:09.430
of a very interconnected web.

00:11:09.430 --> 00:11:12.640
And I'm very pleased
that several people

00:11:12.640 --> 00:11:15.840
are going to participate,
local people, as discussants.

00:11:15.840 --> 00:11:18.430
And so the way that this will
work is people will give talks,

00:11:18.430 --> 00:11:21.310
these discussants will have
time to ask their own questions,

00:11:21.310 --> 00:11:25.010
and then you, the audience,
will be asked to participate.

00:11:25.010 --> 00:11:29.170
So biographies for all of these
people and all of the speakers

00:11:29.170 --> 00:11:31.084
are in the program
that you have here,

00:11:31.084 --> 00:11:32.500
but I'm just going
to say that I'm

00:11:32.500 --> 00:11:36.970
honored to have Conevery
Valencius from Boston College

00:11:36.970 --> 00:11:39.760
here with us, for the Earth
session, Immaculata De

00:11:39.760 --> 00:11:42.350
Vivo, who is my co-director
for science this year

00:11:42.350 --> 00:11:44.602
here at the Radcliffe
Institute, for Life,

00:11:44.602 --> 00:11:46.060
and David Charbonneau,
my colleague

00:11:46.060 --> 00:11:48.220
in the astronomy
apartment, to tell us

00:11:48.220 --> 00:11:50.950
about Space and
extrasolar planets.

00:11:50.950 --> 00:11:53.440
So I just want to leave
you with one request.

00:11:53.440 --> 00:11:56.560
This is an article that
was in the Harvard Gazette,

00:11:56.560 --> 00:11:58.750
recently, about the ship, Tara.

00:11:58.750 --> 00:12:00.820
Is anybody here--
were you lucky enough

00:12:00.820 --> 00:12:02.290
to see Tara when
it was visiting?

00:12:02.290 --> 00:12:03.670
Just raise your hand.

00:12:03.670 --> 00:12:06.520
OK, so a bunch of the
fellows and a few of you--

00:12:06.520 --> 00:12:08.620
so what Tara is, we
brought Tara here

00:12:08.620 --> 00:12:12.910
because Tara was one of the
projects that actually inspired

00:12:12.910 --> 00:12:16.015
this whole undiscovered theme,
that and Stuart's famous talk

00:12:16.015 --> 00:12:18.680
that he's going to tell
you about in a moment.

00:12:18.680 --> 00:12:19.570
So what did Tara do?

00:12:19.570 --> 00:12:23.592
Tara Is a ship that's sponsored
by a French cosmetics company.

00:12:23.592 --> 00:12:25.300
And one of the projects
they did recently

00:12:25.300 --> 00:12:27.190
was to go around
the world and gene

00:12:27.190 --> 00:12:28.990
sequence all of the
plankton that they

00:12:28.990 --> 00:12:30.490
could find in the ocean.

00:12:30.490 --> 00:12:33.160
And they took the number of
known species of plankton

00:12:33.160 --> 00:12:37.510
from 15,000 to 150,000.

00:12:37.510 --> 00:12:41.860
So if you think that what we
know about science is in books,

00:12:41.860 --> 00:12:43.660
the whole goal today
is to encourage

00:12:43.660 --> 00:12:46.790
what we maybe should call
"out of the book thinking."

00:12:46.790 --> 00:12:51.160
OK, and we want to start
a conversation, both here

00:12:51.160 --> 00:12:55.120
at Radcliffe, at Harvard, with
educators and with the public,

00:12:55.120 --> 00:12:57.550
that science is not solved.

00:12:57.550 --> 00:12:58.700
It's not boring.

00:12:58.700 --> 00:13:03.230
It's not dry, and most
of it is undiscovered.

00:13:03.230 --> 00:13:04.790
So that's what I
would like to say.

00:13:04.790 --> 00:13:08.860
And then we're going to have
a very special invocation

00:13:08.860 --> 00:13:12.550
of our event, and that's going
to come from Ceili Magnus, who

00:13:12.550 --> 00:13:17.110
is one of the students from
Barnstable High School, which

00:13:17.110 --> 00:13:20.180
Mike Garro was so
kind to bring here.

00:13:20.180 --> 00:13:22.300
And he brought to
my attention a poem

00:13:22.300 --> 00:13:26.110
that she wrote, inspired
by Stuart Firestein's work.

00:13:26.110 --> 00:13:28.512
And we're going to have
her read her short poem,

00:13:28.512 --> 00:13:30.220
and then we'll go on
to Stuart Firestein,

00:13:30.220 --> 00:13:32.710
and hopefully you'll very
quickly see a connection.

00:13:32.710 --> 00:13:37.090
So Ceili is an
amazing student who's

00:13:37.090 --> 00:13:40.590
interested in both science and
the arts, which really embodies

00:13:40.590 --> 00:13:41.590
the spirit of Radcliffe.

00:13:41.590 --> 00:13:43.339
And I'm really pleased,
and I hope that we

00:13:43.339 --> 00:13:44.590
can welcome her here, now.

00:13:44.590 --> 00:13:45.470
Thank you.

00:13:45.470 --> 00:13:50.938
[APPLAUSE]

00:13:55.294 --> 00:13:57.670
- Hello.

00:13:57.670 --> 00:14:03.310
This poem that I wrote is
titled "Method Versus Muse."

00:14:03.310 --> 00:14:07.840
"People have drawn a thick
line between art and science,

00:14:07.840 --> 00:14:11.470
but what is science
without the arts?

00:14:11.470 --> 00:14:15.130
The questions that need to be
asked can't come from a formula

00:14:15.130 --> 00:14:17.740
when for centuries,
they've been deeply rooted

00:14:17.740 --> 00:14:20.410
in the hearts of
geniuses and prophets,

00:14:20.410 --> 00:14:22.810
with brains full of thought.

00:14:22.810 --> 00:14:24.850
It seems that over
time, humanity

00:14:24.850 --> 00:14:28.120
forgot how to think
critically and to question

00:14:28.120 --> 00:14:31.480
with care, because in an
age of internet access,

00:14:31.480 --> 00:14:34.370
the answers are
always right there.

00:14:34.370 --> 00:14:37.090
And schools are so
focused on students

00:14:37.090 --> 00:14:39.880
having all the right answers,
that they forget that we're

00:14:39.880 --> 00:14:44.600
poets, designers, and dancers.

00:14:44.600 --> 00:14:48.320
They drop facts on young minds
like piles of heavy bricks,

00:14:48.320 --> 00:14:50.990
and expect us to
absorb information

00:14:50.990 --> 00:14:53.360
stacked miles thick.

00:14:53.360 --> 00:14:58.340
They teach us so much, but
now, we need to build from it.

00:14:58.340 --> 00:15:00.050
They've marched with
us to base camp,

00:15:00.050 --> 00:15:03.620
but our goals are at
the summit, applying

00:15:03.620 --> 00:15:08.030
what we know to explore the
unforeseen, the undiscovered.

00:15:08.030 --> 00:15:11.780
It's easier said than done
when curiosities like dormant

00:15:11.780 --> 00:15:14.090
and smothered,
because every day I

00:15:14.090 --> 00:15:17.330
see young minds afraid
to ask questions.

00:15:17.330 --> 00:15:20.880
It cripples the scientific
world at its very foundation,

00:15:20.880 --> 00:15:26.700
and research never comes without
curiosity, without a spark.

00:15:26.700 --> 00:15:28.920
And my spark would
have died too,

00:15:28.920 --> 00:15:31.530
but I found my
light in the dark.

00:15:31.530 --> 00:15:35.130
My creativity led me to
ask all the right things,

00:15:35.130 --> 00:15:38.520
and now I stand here before
you to ask, when will you

00:15:38.520 --> 00:15:41.780
change the tune that you sing?

00:15:41.780 --> 00:15:44.480
What will it take for
schools to open their eyes

00:15:44.480 --> 00:15:47.300
to a world of unmatched
opportunity, that

00:15:47.300 --> 00:15:50.300
very clearly lies in the
minds of young people

00:15:50.300 --> 00:15:52.220
who still have their fire?

00:15:52.220 --> 00:15:54.350
When will you take
their thoughts

00:15:54.350 --> 00:15:56.240
and lift them up higher?

00:15:56.240 --> 00:15:58.520
Maybe you will be
the one to inspire

00:15:58.520 --> 00:16:02.910
someone's great questions,
or someone's desire.

00:16:02.910 --> 00:16:07.250
Teach young minds to fall
in love with the unknown,

00:16:07.250 --> 00:16:11.940
because for every question we
ask, there are many more to go.

00:16:11.940 --> 00:16:16.310
Nurture the creativity we
all harbor in our hearts,

00:16:16.310 --> 00:16:20.290
and maybe we'll give way for a
new way of thinking to start."

00:16:20.290 --> 00:16:21.836
Thank you.

00:16:21.836 --> 00:16:26.766
[APPLAUSE]

00:16:42.304 --> 00:16:43.720
- I can't thank
you enough, Ceili.

00:16:43.720 --> 00:16:46.340
That pretty much sums
it up in three minutes.

00:16:46.340 --> 00:16:48.495
And Stuart's got a
hard act to follow.

00:16:51.030 --> 00:16:55.360
So as I mentioned
at the outset, we

00:16:55.360 --> 00:16:58.330
have the biographies of our
incredibly impressive lineup

00:16:58.330 --> 00:17:00.882
of participants today in
the program that you have.

00:17:00.882 --> 00:17:02.590
And we're just going
to give you a couple

00:17:02.590 --> 00:17:05.770
of little reminders of who
each person is as we go along.

00:17:05.770 --> 00:17:08.829
And I'm sorry, but if we went
through all of their accolades

00:17:08.829 --> 00:17:11.750
that would take the
whole time today.

00:17:11.750 --> 00:17:13.930
So Stuart Firestein
is a professor

00:17:13.930 --> 00:17:16.420
at Columbia University
who technically

00:17:16.420 --> 00:17:19.839
teaches neuroscience there,
but he also teaches ignorance.

00:17:19.839 --> 00:17:22.569
And today, he's going to
teach us about ignorance.

00:17:22.569 --> 00:17:23.980
And just to say
a couple of words

00:17:23.980 --> 00:17:25.359
about his scientific
research, he

00:17:25.359 --> 00:17:27.160
studies the olfactory
system, the sense

00:17:27.160 --> 00:17:30.370
of smell in vertebrate animals.

00:17:30.370 --> 00:17:34.420
And he'll explain how he started
teaching about ignorance,

00:17:34.420 --> 00:17:36.820
but I'll just tell you that
I love the title of his two

00:17:36.820 --> 00:17:38.080
recent books, both titles.

00:17:38.080 --> 00:17:40.960
One is called Ignorance,
How it Drives Science,

00:17:40.960 --> 00:17:42.800
and the other one
is called Failure,

00:17:42.800 --> 00:17:45.770
why Science is so Successful.

00:17:45.770 --> 00:17:47.920
And so I'll just leave
it there and say, thank

00:17:47.920 --> 00:17:49.420
you for coming,
Stuart, and we can't

00:17:49.420 --> 00:17:51.385
wait to hear what you
have to say, thank you.

00:17:51.385 --> 00:17:54.850
[APPLAUSE]

00:18:00.300 --> 00:18:01.890
- Well, this is quite a crowd.

00:18:04.980 --> 00:18:07.070
Great thanks and appreciation
to the organizers

00:18:07.070 --> 00:18:09.511
of the symposium,
to Dean Brown-Nagin,

00:18:09.511 --> 00:18:11.010
even though she
stole my first three

00:18:11.010 --> 00:18:13.740
slides, to Alyssa
Goodman, who stole

00:18:13.740 --> 00:18:17.270
my second and fourth
slides, and to Ceili,

00:18:17.270 --> 00:18:20.910
who stole my whole talk.

00:18:20.910 --> 00:18:23.770
Nonetheless, I am
thrilled to be here today.

00:18:23.770 --> 00:18:26.850
And it's nice to see such a
large group of people come out

00:18:26.850 --> 00:18:28.240
for this, as well.

00:18:28.240 --> 00:18:30.610
So let me preface this,
to some extent, by saying,

00:18:30.610 --> 00:18:32.443
I don't think I'm
actually going to tell you

00:18:32.443 --> 00:18:35.370
anything you don't, somehow
or another, already know.

00:18:35.370 --> 00:18:38.280
I think the idea that science
is about ignorance and about

00:18:38.280 --> 00:18:40.890
failure in so many
ways is something

00:18:40.890 --> 00:18:45.140
that we almost all know,
in a kind of implicit way.

00:18:45.140 --> 00:18:48.090
What I hope to do today
is to take those ideas

00:18:48.090 --> 00:18:50.110
and make them
explicit, because I

00:18:50.110 --> 00:18:52.140
found that by making
these things explicit,

00:18:52.140 --> 00:18:54.510
we get to re-examine
them in ways that we

00:18:54.510 --> 00:18:57.090
may have forgotten about,
and that new things show up

00:18:57.090 --> 00:18:58.080
in that way.

00:18:58.080 --> 00:19:01.380
So I'm going to talk about
ignorance, doubt, uncertainty,

00:19:01.380 --> 00:19:03.780
and failure, which sounds
pretty existentially

00:19:03.780 --> 00:19:08.310
bleak on a beautiful Friday
morning, but with the--

00:19:08.310 --> 00:19:12.750
I hope-- aid of PowerPoint,
will turn these things

00:19:12.750 --> 00:19:16.320
into more positive ideas.

00:19:16.320 --> 00:19:19.610
So that's the notion here,
that science is successful.

00:19:19.610 --> 00:19:21.050
And many other
things in our lives

00:19:21.050 --> 00:19:23.860
are successful precisely
because of these things,

00:19:23.860 --> 00:19:25.795
and that they're not typically--

00:19:25.795 --> 00:19:27.920
or should not always be--
understood in a typically

00:19:27.920 --> 00:19:30.090
pejorative manner.

00:19:30.090 --> 00:19:35.100
So we might ask how successful
has science been, in fact?

00:19:35.100 --> 00:19:37.590
This is a picture of
the Achuelean hand axe.

00:19:37.590 --> 00:19:40.470
This was the first tools
made by human beings,

00:19:40.470 --> 00:19:41.730
as far as we know.

00:19:41.730 --> 00:19:46.630
This technology lasted for
some 1.2 million years.

00:19:46.630 --> 00:19:49.370
All right, that's kind of a
long time for one technology.

00:19:49.370 --> 00:19:51.180
But we could go a
little further forward.

00:19:51.180 --> 00:19:52.980
Most historians or
historians of science

00:19:52.980 --> 00:19:55.140
believe that the
Bronze Age is really

00:19:55.140 --> 00:19:57.920
kind of the
beginning of science,

00:19:57.920 --> 00:19:59.670
if you will, of the
beginning of some kind

00:19:59.670 --> 00:20:02.760
of historical science, in
that bronze can't be taken out

00:20:02.760 --> 00:20:03.360
of the ground.

00:20:03.360 --> 00:20:05.760
It has to be smelted,
there's a process involved.

00:20:05.760 --> 00:20:09.180
But the Bronze Age also
lasted for about 2000 years,

00:20:09.180 --> 00:20:11.080
or some 50 generations.

00:20:11.080 --> 00:20:14.340
So for 50 generations,
people just like you

00:20:14.340 --> 00:20:17.110
and me, with the same
brain inside their head,

00:20:17.110 --> 00:20:21.290
were born, grew up, and died in
precisely the same technology.

00:20:21.290 --> 00:20:24.090
Now you know today, if you
take a two week vacation,

00:20:24.090 --> 00:20:25.500
you're like two
operating systems

00:20:25.500 --> 00:20:28.260
behind and hopelessly
out of date.

00:20:28.260 --> 00:20:30.402
So clearly, things are
moving a little faster,

00:20:30.402 --> 00:20:32.610
and that's primarily happened
since what we typically

00:20:32.610 --> 00:20:35.429
call the Scientific Revolution,
about which there's some debate

00:20:35.429 --> 00:20:35.970
and all that.

00:20:35.970 --> 00:20:38.460
But I'm going to call it
the early 17th century,

00:20:38.460 --> 00:20:40.920
beginning with people like
Bacon, Descartes, Galileo,

00:20:40.920 --> 00:20:42.120
and so forth.

00:20:42.120 --> 00:20:45.930
And now for the last 10 or so
generations, a mere 400 years,

00:20:45.930 --> 00:20:49.752
we have these iconic
equations, just some of many.

00:20:49.752 --> 00:20:51.210
But what's particularly
interesting

00:20:51.210 --> 00:20:52.830
about these equations
is they not only

00:20:52.830 --> 00:20:54.288
work here on the
earth, but they're

00:20:54.288 --> 00:20:56.800
true throughout the
entire universe.

00:20:56.800 --> 00:20:57.790
And that's a big step.

00:20:57.790 --> 00:21:00.102
That's a big intellectual
leap forward.

00:21:00.102 --> 00:21:01.560
We also know, of
course, that there

00:21:01.560 --> 00:21:04.470
are huge advances in
technology, in transportation,

00:21:04.470 --> 00:21:07.650
and communications, in
flight, and so forth.

00:21:07.650 --> 00:21:09.270
My own particular
favorite, because I

00:21:09.270 --> 00:21:13.230
was trained as a pharmacologist,
as in pharmaceuticals--

00:21:13.230 --> 00:21:15.640
so for example, we
have this stuff here--

00:21:15.640 --> 00:21:17.400
I don't know how well you'll
be able to see it from the back

00:21:17.400 --> 00:21:19.483
there-- it was One Night
Cough Syrup, it's called.

00:21:19.483 --> 00:21:23.820
It has in it alcohol, cannabis,
chloroform, and morphine.

00:21:27.430 --> 00:21:32.820
Thus, I believe the name One
Night, where that comes from.

00:21:32.820 --> 00:21:37.650
There is also Dr. Body's
asthma cigarettes,

00:21:37.650 --> 00:21:40.820
for the treatment of
various bronchial disorders,

00:21:40.820 --> 00:21:41.372
and so forth.

00:21:41.372 --> 00:21:42.580
The big advance here, which--

00:21:42.580 --> 00:21:43.990
I don't know if you can see at
the bottoms-- is that there's

00:21:43.990 --> 00:21:45.910
a warning label here, actually.

00:21:45.910 --> 00:21:49.846
These are not recommended
for children under 6.

00:21:49.846 --> 00:21:51.970
So you can see that we've
moved forward in science.

00:21:51.970 --> 00:21:54.310
Progress is the key to science.

00:21:54.310 --> 00:21:55.622
How do we make this progress?

00:21:55.622 --> 00:21:56.830
How does this all come about?

00:21:56.830 --> 00:21:57.970
What's the actual method?

00:21:57.970 --> 00:22:02.080
Well, Dean Brown-Nagin
has told you a little bit

00:22:02.080 --> 00:22:03.310
about my idea about this.

00:22:03.310 --> 00:22:06.040
This is an ancient
aphorism, synonymous,

00:22:06.040 --> 00:22:07.630
and it says, "very
difficult to find

00:22:07.630 --> 00:22:10.240
a black cat in a dark
room, especially when there

00:22:10.240 --> 00:22:10.920
is no cat."

00:22:10.920 --> 00:22:13.210
But I just find this
a very apt description

00:22:13.210 --> 00:22:15.010
of what we do in science.

00:22:15.010 --> 00:22:17.860
We fumble around in dark
rooms, we bump into things,

00:22:17.860 --> 00:22:19.690
we feel around,
we imagine what it

00:22:19.690 --> 00:22:21.830
might look like,
where things are,

00:22:21.830 --> 00:22:23.860
where the cat might be hiding.

00:22:23.860 --> 00:22:25.510
And whether we find
the cat or not,

00:22:25.510 --> 00:22:27.250
we move into another black room.

00:22:27.250 --> 00:22:28.614
So we find the cat, that's fine.

00:22:28.614 --> 00:22:30.280
And then we just find
another dark room,

00:22:30.280 --> 00:22:31.720
and if we don't find
the cat, well, we

00:22:31.720 --> 00:22:33.220
move into another
dark room and look

00:22:33.220 --> 00:22:35.620
for another black cat, which
is I think why scientists

00:22:35.620 --> 00:22:36.610
tend to be so pale.

00:22:39.720 --> 00:22:42.600
One idea, anyway.

00:22:42.600 --> 00:22:45.120
But that's contrasted
with this notion

00:22:45.120 --> 00:22:47.460
of the scientific method,
which we're all sort of taught

00:22:47.460 --> 00:22:50.220
in school as how science works.

00:22:50.220 --> 00:22:52.440
And I have a whole rant
about the scientific method

00:22:52.440 --> 00:22:54.640
that I will try not to
get too deeply into,

00:22:54.640 --> 00:22:57.212
but I think it's
a very wrong idea.

00:22:57.212 --> 00:22:58.920
It's a wrong idea
because there's nothing

00:22:58.920 --> 00:23:01.080
particularly
methodical or recipe

00:23:01.080 --> 00:23:03.360
like about doing science.

00:23:03.360 --> 00:23:07.320
I mean, really, it's more like
this, to be honest with you,

00:23:07.320 --> 00:23:11.070
and kind of like that.

00:23:11.070 --> 00:23:15.480
So let's compare the scientific
method, for a moment, to what I

00:23:15.480 --> 00:23:17.191
think the process is more like.

00:23:17.191 --> 00:23:18.940
So here's the scientific
method, you know.

00:23:18.940 --> 00:23:21.990
You make an observation, come
up with a hypothesis about what

00:23:21.990 --> 00:23:24.240
might be causing
that observation,

00:23:24.240 --> 00:23:26.460
you do some test or
experiment you devise, make

00:23:26.460 --> 00:23:29.230
a new observation, you
revise the hypothesis,

00:23:29.230 --> 00:23:32.280
and so forth and so on,
in some iterative way.

00:23:32.280 --> 00:23:36.150
The trouble with this idea
is that the key thing, which

00:23:36.150 --> 00:23:39.200
is hypothesis, come
up with a hypothesis,

00:23:39.200 --> 00:23:40.960
it tells you nothing
about how to do that.

00:23:40.960 --> 00:23:42.110
Tells you nothing
about that process.

00:23:42.110 --> 00:23:42.870
What do you?

00:23:42.870 --> 00:23:45.290
Buy the book of hypotheses,
look a couple up?

00:23:45.290 --> 00:23:47.430
Oh, this one looks
good, we'll try that.

00:23:47.430 --> 00:23:49.539
So how do you come up
with this hypothesis?

00:23:49.539 --> 00:23:51.330
So instead of a scientific
method, I'd say,

00:23:51.330 --> 00:23:52.800
what we really
want to do is think

00:23:52.800 --> 00:23:55.000
about a scientific process.

00:23:55.000 --> 00:23:57.210
And that process
starts with ignorance,

00:23:57.210 --> 00:23:59.050
something we don't know.

00:23:59.050 --> 00:24:02.790
There's often some kind of
intuition about that thing.

00:24:02.790 --> 00:24:05.160
We do observations,
experiments, they almost

00:24:05.160 --> 00:24:07.690
invariably fail at a high rate.

00:24:07.690 --> 00:24:09.090
So now we have a new question.

00:24:09.090 --> 00:24:11.010
We make a question up.

00:24:11.010 --> 00:24:14.100
We try some inspiration on this
question, some imagination.

00:24:14.100 --> 00:24:17.970
Usually that fails,
so we revise.

00:24:17.970 --> 00:24:20.130
We have an interim explanation.

00:24:20.130 --> 00:24:21.630
That typically fails.

00:24:21.630 --> 00:24:24.840
And eventually, we wind up
with yet a better question.

00:24:24.840 --> 00:24:27.810
That's the scientific
process, and that's

00:24:27.810 --> 00:24:29.110
where we end up with.

00:24:29.110 --> 00:24:31.920
And I think this
is why we have made

00:24:31.920 --> 00:24:33.350
the kind of progress we have.

00:24:33.350 --> 00:24:35.597
So I want to try and prove
that to you, in a way.

00:24:35.597 --> 00:24:37.680
This is a favorite slide
of mine, a favorite quote

00:24:37.680 --> 00:24:41.280
of Marie Curie, who after
obtaining her second graduate

00:24:41.280 --> 00:24:42.040
degree--

00:24:42.040 --> 00:24:43.560
so she knew a lot
of stuff, right--

00:24:43.560 --> 00:24:46.680
but still says, "One never
notices what has been done.

00:24:46.680 --> 00:24:48.961
One can only see what
remains to be done."

00:24:48.961 --> 00:24:50.460
And I thought it's
what that remains

00:24:50.460 --> 00:24:53.670
to be done that's so lacking
in our education, our thinking

00:24:53.670 --> 00:24:55.200
about science,
because that's really

00:24:55.200 --> 00:24:56.760
what scientists think about.

00:24:56.760 --> 00:24:58.350
When I go to a
scientific conference,

00:24:58.350 --> 00:25:01.860
I sit through a long
day of boring talks,

00:25:01.860 --> 00:25:04.710
and then I head for the bar
where I learn the real stuff.

00:25:04.710 --> 00:25:06.780
And what I talk
about at the bar,

00:25:06.780 --> 00:25:08.954
over a couple of beers
with my colleagues,

00:25:08.954 --> 00:25:09.870
is not what they know.

00:25:09.870 --> 00:25:12.242
Nobody cares about what we
know, but what we don't know.

00:25:12.242 --> 00:25:13.200
What are the questions?

00:25:13.200 --> 00:25:14.937
What remains to be done?

00:25:14.937 --> 00:25:16.770
And I thought, well,
this is maybe something

00:25:16.770 --> 00:25:18.510
important to think about.

00:25:18.510 --> 00:25:20.220
Just in passing, I
have to note, again,

00:25:20.220 --> 00:25:23.160
that this is one of my favorite
pictures of Professor Curie,

00:25:23.160 --> 00:25:25.740
because I am convinced
that that glow behind her

00:25:25.740 --> 00:25:27.810
is not a photographic effect.

00:25:27.810 --> 00:25:32.490
I think that's actually
the real thing, you know.

00:25:32.490 --> 00:25:34.920
In fact, today, her
papers, her notebooks

00:25:34.920 --> 00:25:37.800
are so hot that they're
stored in a basement room

00:25:37.800 --> 00:25:40.850
in the Bibliotheque
Nationale Francais, in Paris.

00:25:40.850 --> 00:25:42.690
It's lead-lined, and
if you are a scholar

00:25:42.690 --> 00:25:44.190
and want to go work
with her papers,

00:25:44.190 --> 00:25:46.270
you have to wear radiation suit.

00:25:46.270 --> 00:25:48.780
And I say this not just
as a joke, actually,

00:25:48.780 --> 00:25:50.880
but because it's a
serious issue, here.

00:25:50.880 --> 00:25:53.520
I think one of the ideas that's
often left out of science, just

00:25:53.520 --> 00:25:55.500
as a side remark, is courage.

00:25:55.500 --> 00:25:58.630
And I think this is a
real case of courage.

00:25:58.630 --> 00:26:00.666
I mean, Marie Curie
knew what was going on,

00:26:00.666 --> 00:26:02.040
and knew what that
was all about,

00:26:02.040 --> 00:26:03.392
and what the dangers were.

00:26:03.392 --> 00:26:05.100
And I think there's
a lot of science that

00:26:05.100 --> 00:26:07.350
is dangerous in many ways,
whether it's intellectually

00:26:07.350 --> 00:26:10.140
or physically, and it requires
a certain kind of courage

00:26:10.140 --> 00:26:14.330
that we often discount
in its practice.

00:26:14.330 --> 00:26:16.480
So, as was also
pointed out, I think,

00:26:16.480 --> 00:26:22.170
by one of our introducers,
the thing about ignorance

00:26:22.170 --> 00:26:25.630
is that it grows with knowledge,
that the more you know,

00:26:25.630 --> 00:26:27.570
the more you know
you don't know.

00:26:27.570 --> 00:26:29.904
And I like this, sort of--
this is not original with me,

00:26:29.904 --> 00:26:32.111
several people have come up
with this kind of model--

00:26:32.111 --> 00:26:34.410
if you think of knowledge
as that bright white circle

00:26:34.410 --> 00:26:37.530
in the middle of this sea of
ignorance then, you know--

00:26:37.530 --> 00:26:41.820
this is the only formula
in the talk, I promise--

00:26:41.820 --> 00:26:43.309
but you know that
the circumference

00:26:43.309 --> 00:26:44.850
of that circle, the
part of it that's

00:26:44.850 --> 00:26:47.210
in touch with all
the vast ignorance,

00:26:47.210 --> 00:26:48.650
is described this way.

00:26:48.650 --> 00:26:52.510
And as that circle grows
as the amount of knowledge

00:26:52.510 --> 00:26:54.720
grows, so does
that circumference,

00:26:54.720 --> 00:26:57.990
by about six times
the radius also grows.

00:26:57.990 --> 00:27:02.944
And so we increase our ignorance
as we increase our knowledge.

00:27:02.944 --> 00:27:05.110
I think this is an important
process to think about.

00:27:05.110 --> 00:27:07.180
We typically think that
we begin with ignorance

00:27:07.180 --> 00:27:09.940
and we go to school, we read
a book, we do something,

00:27:09.940 --> 00:27:11.500
and we gain some knowledge.

00:27:11.500 --> 00:27:13.420
But then the crucial
question is, what do we

00:27:13.420 --> 00:27:15.090
want to do with that knowledge?

00:27:15.090 --> 00:27:17.284
I mean, it's useful,
knowledge is useful,

00:27:17.284 --> 00:27:18.700
but what do we
want to do with it?

00:27:18.700 --> 00:27:20.199
And I think the
thing we mostly want

00:27:20.199 --> 00:27:22.840
to do with it is
make more ignorance,

00:27:22.840 --> 00:27:24.070
but not just any ignorance.

00:27:24.070 --> 00:27:26.020
We want to make
better ignorance.

00:27:26.020 --> 00:27:28.900
We want to make higher quality
ignorance, if you will.

00:27:28.900 --> 00:27:31.060
Because, you know, there's
low quality ignorance

00:27:31.060 --> 00:27:32.518
and there's high
quality ignorance.

00:27:32.518 --> 00:27:34.270
It's not all the same, right?

00:27:34.270 --> 00:27:35.610
I mean, we argue about this.

00:27:35.610 --> 00:27:38.800
This is what
scientists argue about.

00:27:38.800 --> 00:27:40.370
Sometimes they're
just bull sessions,

00:27:40.370 --> 00:27:42.610
and sometimes they're
grant proposals.

00:27:42.610 --> 00:27:45.740
I'm just not clear
which they might be,

00:27:45.740 --> 00:27:47.260
but nonetheless
it's what we argue

00:27:47.260 --> 00:27:49.570
about, the quality of the
ignorance or, if you will,

00:27:49.570 --> 00:27:50.740
the questions.

00:27:50.740 --> 00:27:53.140
So the idea of
knowledge is to pose

00:27:53.140 --> 00:27:55.990
a better question, a more
sophisticated question,

00:27:55.990 --> 00:27:58.330
a deeper kind of question.

00:27:58.330 --> 00:28:00.170
I'm going to use a
story here about I. I.

00:28:00.170 --> 00:28:04.450
Rabi, a famous physicist who
won the Nobel Prize in 1944,

00:28:04.450 --> 00:28:07.010
was it, for the development
of nuclear magnetic resonance,

00:28:07.010 --> 00:28:09.520
a technique that's still
very important in chemistry

00:28:09.520 --> 00:28:12.160
laboratories, especially
today, and gave rise

00:28:12.160 --> 00:28:15.970
to the medical diagnostic tool,
magnetic resonance imaging.

00:28:15.970 --> 00:28:18.090
And Rabi, who was a
professor at Columbia--

00:28:18.090 --> 00:28:20.980
but I never knew him, he passed
away before I got there--

00:28:20.980 --> 00:28:22.720
used to tell this
story, apparently,

00:28:22.720 --> 00:28:25.690
that when he was growing up--

00:28:25.690 --> 00:28:27.220
I think it's important
to say today,

00:28:27.220 --> 00:28:31.600
that as a young immigrant
child on the Lower East

00:28:31.600 --> 00:28:34.051
Side of New York, that
he and his friends

00:28:34.051 --> 00:28:36.550
would come home from school and
their mothers would all say,

00:28:36.550 --> 00:28:38.320
so what did you learn
in school today?

00:28:38.320 --> 00:28:41.290
But Mrs. Rabi would
say, so, Isidore,

00:28:41.290 --> 00:28:43.615
did you ask any good
questions, today?

00:28:43.615 --> 00:28:45.820
Did you ask any good
questions, today, was

00:28:45.820 --> 00:28:47.680
what Mrs. Rabi wanted to know.

00:28:47.680 --> 00:28:49.291
And Izzy here won
the Nobel Prize.

00:28:49.291 --> 00:28:51.040
I don't know what
happened to his friends,

00:28:51.040 --> 00:28:52.840
I'm sure they did
OK, too, but I think

00:28:52.840 --> 00:28:54.910
Mrs. Rabi had the right idea.

00:28:57.369 --> 00:28:59.910
Yes, so one of the things that
happens when you write a book,

00:28:59.910 --> 00:29:01.951
I learned-- and I've never
written a book before,

00:29:01.951 --> 00:29:03.890
I write scientific papers
that nobody reads--

00:29:03.890 --> 00:29:06.210
and then I wrote a book
that people did read.

00:29:06.210 --> 00:29:09.240
And then they send you letters,
or in this case an email.

00:29:09.240 --> 00:29:11.180
This is from a woman
named Kathleen Erickson

00:29:11.180 --> 00:29:12.910
in Minneapolis, Minnesota.

00:29:12.910 --> 00:29:15.300
I don't know Kathleen,
we've never actually talked,

00:29:15.300 --> 00:29:19.430
but she read my book and wrote
me this interesting letter.

00:29:19.430 --> 00:29:21.530
"One of my grade school
arithmetic teachers began

00:29:21.530 --> 00:29:23.240
the first day of class
with a statement.

00:29:23.240 --> 00:29:25.550
'I assume all of you learned
your multiplication tables

00:29:25.550 --> 00:29:26.870
through 12.'

00:29:26.870 --> 00:29:29.300
He waited while all of us
sat frozen, because we'd all

00:29:29.300 --> 00:29:31.895
learned our tables through 10.

00:29:31.895 --> 00:29:33.770
Terrified that he'd spin
around, point at me,

00:29:33.770 --> 00:29:36.770
and say, quick, 7 times
12, I raised my hand

00:29:36.770 --> 00:29:39.632
and admitted that I'd only
learned my tables through 10.

00:29:39.632 --> 00:29:41.090
He then asked the
rest of the class

00:29:41.090 --> 00:29:42.464
how many had
learned their tables

00:29:42.464 --> 00:29:46.189
through 10, and of course
everybody raised their hands.

00:29:46.189 --> 00:29:48.230
'All right, he said,
looking at the raised hands.

00:29:48.230 --> 00:29:51.170
Kathy gets an A from me this
year because she's just learned

00:29:51.170 --> 00:29:54.770
the one thing that is essential
to learn, when to say,

00:29:54.770 --> 00:29:56.130
I don't know.'"

00:29:56.130 --> 00:29:58.880
And Miss Erickson
says, "This lesson

00:29:58.880 --> 00:30:01.460
remains the single
most useful experience

00:30:01.460 --> 00:30:03.450
in my educational history."

00:30:03.450 --> 00:30:08.600
So a word to the wise, from
Mrs. Rabi and Kathleen Erickson.

00:30:08.600 --> 00:30:10.340
So when I say
ignorance, of course,

00:30:10.340 --> 00:30:13.070
I don't mean just garden
variety ignorance.

00:30:13.070 --> 00:30:16.580
I don't mean stupidity, or a
callow indifference to facts,

00:30:16.580 --> 00:30:17.720
or things like that.

00:30:17.720 --> 00:30:20.690
I mean something-- this is
a quote from James Clerk

00:30:20.690 --> 00:30:25.100
Maxwell, possibly the greatest
physicist between Newton

00:30:25.100 --> 00:30:27.260
and Einstein, who
said, Thoroughly"

00:30:27.260 --> 00:30:30.290
conscious ignorance is the
prelude to every real advance

00:30:30.290 --> 00:30:31.460
in science."

00:30:31.460 --> 00:30:33.900
This notion of thoroughly
conscious ignorance,

00:30:33.900 --> 00:30:36.260
not just, I don't
know, not just,

00:30:36.260 --> 00:30:39.860
I wish I knew that, but rather
this thoroughly conscious

00:30:39.860 --> 00:30:41.429
ignorance-- how do
you get to that?

00:30:41.429 --> 00:30:42.970
Well, I found an
interesting phrase--

00:30:42.970 --> 00:30:45.320
it was pointed out to me
by somebody in this search

00:30:45.320 --> 00:30:47.140
for better ignorance--

00:30:47.140 --> 00:30:49.220
the phrase is called
"negative capability,"

00:30:49.220 --> 00:30:51.620
which at first sounds
like a bit of an odd idea.

00:30:51.620 --> 00:30:54.590
This word was coined
by the dreamy eyed poet

00:30:54.590 --> 00:30:57.830
John Keats, in fact, also in
a letter to his brother, where

00:30:57.830 --> 00:31:00.985
he identified the word as
meaning "that is when a man--"

00:31:00.985 --> 00:31:02.360
maybe we we should
say "person--"

00:31:02.360 --> 00:31:05.150
"is capable of being in
uncertainties, mysteries,

00:31:05.150 --> 00:31:09.050
and doubts without any irritable
reaching after fact and reason.

00:31:09.050 --> 00:31:11.900
And it's this notion of
being patient with mystery,

00:31:11.900 --> 00:31:13.530
with uncertainty, and doubt.

00:31:13.530 --> 00:31:15.800
And Keats considered this
the ideal creative state

00:31:15.800 --> 00:31:16.920
for the literary mind.

00:31:16.920 --> 00:31:19.370
But I would say it's just
the ideal creative state

00:31:19.370 --> 00:31:21.560
for any mind, that
when mystery, doubt,

00:31:21.560 --> 00:31:23.780
and uncertainty
surrounds us, this is

00:31:23.780 --> 00:31:25.350
when we become most creative.

00:31:25.350 --> 00:31:28.220
This is when we think the
deepest and the hardest.

00:31:28.220 --> 00:31:30.800
And to learn to be patient
with this, to develop

00:31:30.800 --> 00:31:35.150
negative capability, I think,
is one of the critical things

00:31:35.150 --> 00:31:39.446
that we would like to develop
in students, in ourselves.

00:31:39.446 --> 00:31:40.820
This was sort of
said, similarly,

00:31:40.820 --> 00:31:43.850
by a scientist in fact,
Erwin Schrodinger, who

00:31:43.850 --> 00:31:47.900
I guess knows something about
cats, or doesn't, I guess,

00:31:47.900 --> 00:31:51.207
as the case may be, right,
now that I think about it.

00:31:51.207 --> 00:31:53.540
So Schrodinger said, "In an
honest search for knowledge,

00:31:53.540 --> 00:31:56.090
you quite often have
to abide by ignorance

00:31:56.090 --> 00:31:59.390
for an indefinite
period," again,

00:31:59.390 --> 00:32:02.850
this notion of being
patient with ignorance.

00:32:02.850 --> 00:32:05.350
All right, so I've taken you a
little bit through ignorance.

00:32:05.350 --> 00:32:08.310
I hope you believe that the
unknown is very important.

00:32:08.310 --> 00:32:10.690
But what about a deeper
kind of ignorance?

00:32:10.690 --> 00:32:13.060
What about a really
deep kind of ignorance?

00:32:13.060 --> 00:32:15.700
What about the unknown unknown?

00:32:15.700 --> 00:32:19.090
What about the stuff we
don't know we don't know?

00:32:19.090 --> 00:32:23.980
So kind of ignorance
squared, as it were, right?

00:32:23.980 --> 00:32:26.650
This most recently,
unfortunately,

00:32:26.650 --> 00:32:27.695
was said by this guy.

00:32:27.695 --> 00:32:29.320
There are enough
people in the audience

00:32:29.320 --> 00:32:31.610
who recognize this character.

00:32:31.610 --> 00:32:34.450
For those lucky group of
you that are much younger,

00:32:34.450 --> 00:32:37.270
this is Donald Rumsfeld who
was the Secretary of Defense

00:32:37.270 --> 00:32:39.490
and the architect of our
misbegotten adventures

00:32:39.490 --> 00:32:41.170
in Afghanistan and Iraq.

00:32:41.170 --> 00:32:43.450
And he was called to
testify at the Senate

00:32:43.450 --> 00:32:44.840
as to what had gone so wrong.

00:32:44.840 --> 00:32:46.480
And he said, well there were a
lot of things we didn't know.

00:32:46.480 --> 00:32:47.854
We knew that we
didn't know them,

00:32:47.854 --> 00:32:49.480
but we tried to
deal with all that.

00:32:49.480 --> 00:32:53.020
But what really got us were
these unknown unknowns,

00:32:53.020 --> 00:32:55.910
the ones we don't
know we don't know.

00:32:55.910 --> 00:32:57.599
And he was roundly
ridiculed for this,

00:32:57.599 --> 00:32:59.140
but it's actually
a clever statement.

00:32:59.140 --> 00:33:01.570
Unfortunately, he's not the
first person to have said it,

00:33:01.570 --> 00:33:02.070
I learned.

00:33:02.070 --> 00:33:04.150
And it actually appears,
to my knowledge,

00:33:04.150 --> 00:33:07.510
earliest in a long epic poem
by D. H. Lawrence called

00:33:07.510 --> 00:33:08.800
"New Heaven and Earth."

00:33:08.800 --> 00:33:10.790
I don't actually care for the
poem, to tell you the truth.

00:33:10.790 --> 00:33:12.748
It's kind of long, it
goes on, but in any case,

00:33:12.748 --> 00:33:15.080
it's about the transition
from this life to the next,

00:33:15.080 --> 00:33:15.580
if you will.

00:33:15.580 --> 00:33:17.080
And towards the
end, there's a verse

00:33:17.080 --> 00:33:19.720
that goes, "now here
was I, new awakened,

00:33:19.720 --> 00:33:22.420
with my hand stretching
out--" into the unknown--

00:33:22.420 --> 00:33:25.150
"and touching the
unknown, the real unknown,

00:33:25.150 --> 00:33:27.370
the unknown unknown."

00:33:27.370 --> 00:33:29.200
So how do we get to
this unknown unknown?

00:33:29.200 --> 00:33:31.810
How do we get to this really
deep kind of ignorance?

00:33:31.810 --> 00:33:33.250
And I would say one way--

00:33:33.250 --> 00:33:36.310
maybe not the only way--
but one very successful way

00:33:36.310 --> 00:33:38.170
is through failure.

00:33:38.170 --> 00:33:40.270
You go to do an experiment
because you don't

00:33:40.270 --> 00:33:42.280
know something, you think
you'll know something

00:33:42.280 --> 00:33:42.930
at the end of the experiment.

00:33:42.930 --> 00:33:45.350
Instead, the experiment
fails, it doesn't work.

00:33:45.350 --> 00:33:47.440
So now you know that
there was something

00:33:47.440 --> 00:33:50.830
you didn't know you
didn't know, before you

00:33:50.830 --> 00:33:51.850
started the experiment.

00:33:51.850 --> 00:33:53.875
Right, you understand?

00:33:53.875 --> 00:33:56.350
I think I got that right.

00:33:56.350 --> 00:33:57.830
And so what about this failure?

00:33:57.830 --> 00:33:58.870
How can we use it?

00:33:58.870 --> 00:34:01.210
This is a quote from
Benjamin Franklin, arguably

00:34:01.210 --> 00:34:02.830
America's first
scientist, who says,

00:34:02.830 --> 00:34:04.870
"Perhaps the history
of errors of mankind,

00:34:04.870 --> 00:34:07.767
all things considered, is
more valuable and interesting

00:34:07.767 --> 00:34:09.100
than that of their discoveries."

00:34:09.100 --> 00:34:12.489
After all, the truth is uniform
and narrow, but screwing up,

00:34:12.489 --> 00:34:15.010
I mean, there are just endless
ways of doing that, right?

00:34:15.010 --> 00:34:17.560
And so it's far more
interesting, of course,

00:34:17.560 --> 00:34:22.100
than just truth and success.

00:34:22.100 --> 00:34:24.310
So there are a lot of
ideas about failure,

00:34:24.310 --> 00:34:26.440
and I'd like to say none
of them are the ones I

00:34:26.440 --> 00:34:27.530
want to talk about today.

00:34:27.530 --> 00:34:28.690
I want to put them
up very quickly,

00:34:28.690 --> 00:34:29.815
just so we get rid of them.

00:34:29.815 --> 00:34:32.860
They're useful things if you
have someone on the phone who

00:34:32.860 --> 00:34:35.949
has just had a terrible failure
in love, or sport, or business,

00:34:35.949 --> 00:34:38.280
or something, and you
want to pep them up.

00:34:38.280 --> 00:34:39.547
So here a couple of those.

00:34:39.547 --> 00:34:41.380
"Success is learning
to fail again and again

00:34:41.380 --> 00:34:44.080
with no lack of enthusiasm,"
often attributed to Winston

00:34:44.080 --> 00:34:45.850
Churchill, who in
fact never said it.

00:34:45.850 --> 00:34:48.460
But he gets lots of credits
for things he never said.

00:34:48.460 --> 00:34:51.920
"Fail hard, fail fast," is a
favorite in the tech industry.

00:34:51.920 --> 00:34:54.639
But this notion of, just get rid
of failure, just get rid of it

00:34:54.639 --> 00:34:56.989
and get on with your success.

00:34:56.989 --> 00:34:59.722
This was said by Thomas Edison
upon inventing the light bulb.

00:34:59.722 --> 00:35:02.180
He claimed to have discovered
10,000 ways that didn't work.

00:35:02.180 --> 00:35:05.080
I think he's exaggerating a bit.

00:35:05.080 --> 00:35:08.340
Like, the light bulb going
off, oh, that's a good idea,

00:35:08.340 --> 00:35:11.530
but he failed at that
like 10,000 times.

00:35:11.530 --> 00:35:14.500
You know WD-40, the
lubricant that everybody uses

00:35:14.500 --> 00:35:17.290
to fix everything, apparently?

00:35:17.290 --> 00:35:19.690
The reason it's called
WD-40 is that there

00:35:19.690 --> 00:35:24.894
were 39 earlier versions that
were no good, didn't work.

00:35:24.894 --> 00:35:26.810
"Failure is an opportunity
to begin again more

00:35:26.810 --> 00:35:28.130
intelligently."

00:35:28.130 --> 00:35:30.260
Oh this, I actually
got in a fortune cookie

00:35:30.260 --> 00:35:31.407
in a Chinese restaurant.

00:35:31.407 --> 00:35:32.990
So I figured I'd
take a picture of it.

00:35:32.990 --> 00:35:35.257
"Failure is an
opportunity in disguise."

00:35:35.257 --> 00:35:36.590
And this is one of my favorites.

00:35:36.590 --> 00:35:38.630
"If you're 40 years old
and never had a failure,

00:35:38.630 --> 00:35:39.650
you've been deprived."

00:35:39.650 --> 00:35:41.870
That was said by the
actress Gloria Swanson.

00:35:41.870 --> 00:35:43.910
I'm not really sure
what she means there,

00:35:43.910 --> 00:35:45.350
but it's interesting.

00:35:45.350 --> 00:35:48.140
Nonetheless, I don't mean any
of these kinds of failures.

00:35:48.140 --> 00:35:50.840
I don't mean the kind of failure
that just promotes resilience,

00:35:50.840 --> 00:35:54.470
or from which you learn
something, from which you gain

00:35:54.470 --> 00:35:57.860
some good personality trait,
eventually, or something

00:35:57.860 --> 00:35:59.180
like that.

00:35:59.180 --> 00:36:02.810
I'd rather take a somewhat
more enigmatic statement

00:36:02.810 --> 00:36:05.660
from Gertrude Stein, the poet,
who said, "A real failure does

00:36:05.660 --> 00:36:07.190
not need an excuse.

00:36:07.190 --> 00:36:09.480
It is an end in itself."

00:36:09.480 --> 00:36:12.960
So imagine values that are
just ends in themselves,

00:36:12.960 --> 00:36:14.890
not because, oh, I didn't
think this through,

00:36:14.890 --> 00:36:16.830
or oh, I'm sorry, I
a terrible mistake,

00:36:16.830 --> 00:36:18.770
or this is a screw
up, or this or that.

00:36:18.770 --> 00:36:22.060
No, this is just
an end in itself.

00:36:22.060 --> 00:36:24.080
It's worth thinking
about that, I think.

00:36:24.080 --> 00:36:27.050
Also, from the ever enigmatic
playwright Samuel Beckett,

00:36:27.050 --> 00:36:27.860
"Ever tried.

00:36:27.860 --> 00:36:28.800
Ever failed.

00:36:28.800 --> 00:36:29.300
No matter.

00:36:29.300 --> 00:36:29.900
Try again.

00:36:29.900 --> 00:36:30.989
Fail again.

00:36:30.989 --> 00:36:31.530
Fail better."

00:36:31.530 --> 00:36:34.790
And this sounds so much like
the regular old failure trope,

00:36:34.790 --> 00:36:36.290
I tried, I failed, tried again.

00:36:36.290 --> 00:36:39.110
But then he says at
the end, "fail better."

00:36:39.110 --> 00:36:41.560
How does one fail better?

00:36:41.560 --> 00:36:43.390
So failures are an
end in themselves,

00:36:43.390 --> 00:36:46.240
and the idea of failing
better are crucial things

00:36:46.240 --> 00:36:47.980
to try and wrap
our minds around.

00:36:47.980 --> 00:36:51.370
So what I'd like to say is that
failure is not only valuable

00:36:51.370 --> 00:36:53.230
retrospectively,
because it eventually

00:36:53.230 --> 00:36:56.740
lead to success or some
serendipitous discovery.

00:36:56.740 --> 00:36:58.300
I mean, I think
those are all fine,

00:36:58.300 --> 00:37:00.940
but they're not a requirement
for failure to be valuable.

00:37:00.940 --> 00:37:04.210
Failure is an integral part
of the fabric, especially

00:37:04.210 --> 00:37:04.870
in science.

00:37:04.870 --> 00:37:06.560
It's integral to the process.

00:37:06.560 --> 00:37:09.850
You can't leave it out or avoid
it, but you can utilize it

00:37:09.850 --> 00:37:11.420
and you can improve it.

00:37:11.420 --> 00:37:12.670
You can get better at it.

00:37:12.670 --> 00:37:14.680
You can make it better.

00:37:14.680 --> 00:37:16.840
So we could ask a couple
of reasonable questions

00:37:16.840 --> 00:37:17.890
about failure.

00:37:17.890 --> 00:37:20.140
One would be, how much failure?

00:37:20.140 --> 00:37:22.570
I mean, probably
not 100%, but I do

00:37:22.570 --> 00:37:25.330
believe we regularly
underestimate, significantly

00:37:25.330 --> 00:37:27.160
underestimate, the
amount of failure

00:37:27.160 --> 00:37:28.700
that would be acceptable.

00:37:28.700 --> 00:37:31.600
So I use as, an example
from the natural world--

00:37:31.600 --> 00:37:33.610
since I'm in the Earth
part of this thing,

00:37:33.610 --> 00:37:36.160
or the Life part of
this thing anyway--

00:37:36.160 --> 00:37:38.540
these guys are all the
top of the food chain,

00:37:38.540 --> 00:37:42.350
they're evolution's
winners, as it were, right?

00:37:42.350 --> 00:37:44.230
There are the kings,
or queens, if you

00:37:44.230 --> 00:37:46.840
will, of their particular
niches, the air, the sea,

00:37:46.840 --> 00:37:48.310
the land, et cetera.

00:37:48.310 --> 00:37:50.740
And I'm sure you believe,
as I did for a long time,

00:37:50.740 --> 00:37:52.364
that any time they
get a little hungry,

00:37:52.364 --> 00:37:54.716
they just go out and
bag a snack, right?

00:37:54.716 --> 00:37:56.090
But in fact, that's
not the case.

00:37:56.090 --> 00:37:57.506
There's a vast
literature on this,

00:37:57.506 --> 00:37:59.320
the predator prey literature.

00:37:59.320 --> 00:38:01.810
And in the literature, you
will find that these guys here

00:38:01.810 --> 00:38:06.010
are successful fewer, fewer
than 25% of their attempts.

00:38:06.010 --> 00:38:08.890
75%, of the time, they fail.

00:38:08.890 --> 00:38:10.720
That's why all those
prey animals are still

00:38:10.720 --> 00:38:12.700
out there roaming around, right?

00:38:12.700 --> 00:38:15.970
So apparently, with
a 75% failure rate,

00:38:15.970 --> 00:38:19.900
you can still be the top of
the food chain, if you will.

00:38:19.900 --> 00:38:22.012
Since we're at World Series--

00:38:22.012 --> 00:38:23.560
is the World Series is going on?

00:38:23.560 --> 00:38:25.710
There is one, right?

00:38:25.710 --> 00:38:29.014
I'm from New York, I lost track.

00:38:29.014 --> 00:38:29.830
I'm sorry.

00:38:32.380 --> 00:38:34.546
So you know, our
two sisters cities

00:38:34.546 --> 00:38:35.920
sport two of the
greatest hitters

00:38:35.920 --> 00:38:39.250
of all time, in baseball sport,
two of the highest lifetime

00:38:39.250 --> 00:38:40.540
batting averages.

00:38:40.540 --> 00:38:45.070
But of course, they also both
failed about 65% of the time.

00:38:45.070 --> 00:38:47.170
And as most of you
know, baseball today

00:38:47.170 --> 00:38:50.170
will know that any hitter
who hits 300 or above

00:38:50.170 --> 00:38:54.400
is likely to be sporting a $14
million plus yearly contract.

00:38:54.400 --> 00:38:58.780
So with a 2/3 failure rate, you
can do pretty well, apparently.

00:38:58.780 --> 00:39:01.690
So I think we, as I say,
significantly underestimate

00:39:01.690 --> 00:39:03.910
the amount of failure
that's acceptable,

00:39:03.910 --> 00:39:06.430
and that's important, because
this failure is valuable.

00:39:06.430 --> 00:39:08.870
These failures are valuable.

00:39:08.870 --> 00:39:11.980
And so we shouldn't--

00:39:11.980 --> 00:39:14.760
we don't want to try
and exclude them.

00:39:14.760 --> 00:39:16.850
And there's the obligatory
New Yorker cartoon.

00:39:16.850 --> 00:39:21.640
But it is true that one
of the things that--

00:39:21.640 --> 00:39:24.702
sorry, would be more fun, but
I don't think golf is fun,

00:39:24.702 --> 00:39:26.660
anyway, frankly, I don't
think there's anything

00:39:26.660 --> 00:39:29.930
you can do to golf
to make it more fun,

00:39:29.930 --> 00:39:34.310
but it certainly would
be improved, yes--

00:39:34.310 --> 00:39:37.470
so we do this regularly, and
the important thing here,

00:39:37.470 --> 00:39:39.790
of course, is that failure--

00:39:39.790 --> 00:39:42.170
in this, perhaps, slightly
counterintuitive way,

00:39:42.170 --> 00:39:44.330
also gives us a
certain confidence

00:39:44.330 --> 00:39:46.187
in the occasional success.

00:39:46.187 --> 00:39:48.770
So if you fail quite a bit, or
failure is part of the process,

00:39:48.770 --> 00:39:51.500
then you don't have an
infallible process, as it were.

00:39:51.500 --> 00:39:53.090
You have a very fallible one.

00:39:53.090 --> 00:39:56.000
And that gives us confidence
that when we do succeed,

00:39:56.000 --> 00:39:58.660
we have actually made some
sort of an important step.

00:39:58.660 --> 00:40:01.310
So failure and
struggle is actually

00:40:01.310 --> 00:40:03.580
quite critical to the process.

00:40:03.580 --> 00:40:05.990
Another question we could
ask is, how big a failure?

00:40:05.990 --> 00:40:08.600
So I'd say let's go
for the moon here.

00:40:08.600 --> 00:40:09.890
How about a debacle, right?

00:40:09.890 --> 00:40:12.020
So a debacle is
currently defined

00:40:12.020 --> 00:40:15.650
as an unmitigated
disaster, total failure.

00:40:15.650 --> 00:40:17.600
But the word has an
interesting etymology.

00:40:17.600 --> 00:40:20.060
It comes from a French word
that's not really in common use

00:40:20.060 --> 00:40:23.480
anymore, dbcler, which
means to free to, to unbar,

00:40:23.480 --> 00:40:24.310
or to unleash.

00:40:24.310 --> 00:40:27.860
And its original meaning was in
a nautical term, ice breaking.

00:40:27.860 --> 00:40:29.480
So the notion of
breaking up something

00:40:29.480 --> 00:40:32.260
solid to provide new pathways.

00:40:32.260 --> 00:40:34.390
Oh, that doesn't
sound so bad, does it?

00:40:34.390 --> 00:40:36.080
That begins to
sound interesting.

00:40:36.080 --> 00:40:38.930
And so we often think that
creativity, or innovation,

00:40:38.930 --> 00:40:42.230
or things like this arise
from associating new ideas,

00:40:42.230 --> 00:40:46.160
but I think, quite often, they
also, maybe more powerfully,

00:40:46.160 --> 00:40:48.260
arise from
dissociating ideas that

00:40:48.260 --> 00:40:51.380
have been too long associated,
which we no longer think

00:40:51.380 --> 00:40:55.350
about having been associated but
which need to be broken apart.

00:40:55.350 --> 00:40:57.740
The famous philosopher,
Spanish philosopher,

00:40:57.740 --> 00:40:59.210
of the last century
Ortega y Gasset

00:40:59.210 --> 00:41:01.910
said that it costs more
to dissociate ideas

00:41:01.910 --> 00:41:03.570
than to associate them.

00:41:03.570 --> 00:41:06.440
So I'd say, have a
breakthrough, right?

00:41:06.440 --> 00:41:08.810
I mean, we still use this
word for a big discovery,

00:41:08.810 --> 00:41:11.270
and yet it has the word
"break" in it, right?

00:41:11.270 --> 00:41:14.180
And so I think this notion
of breaking things up a bit

00:41:14.180 --> 00:41:15.970
is also very valuable.

00:41:15.970 --> 00:41:17.780
So you can have a
fairly big failure,

00:41:17.780 --> 00:41:19.400
and it can be quite useful.

00:41:19.400 --> 00:41:22.320
All right, so I'm
going to leave you--

00:41:22.320 --> 00:41:23.820
I'm not finished
yet-- but I'm going

00:41:23.820 --> 00:41:26.319
to leave you with two key ideas
about ignorance and failure.

00:41:26.319 --> 00:41:29.030
Negative capability,
this notion of remaining

00:41:29.030 --> 00:41:31.970
in doubt and uncertainty but
having patience with mystery

00:41:31.970 --> 00:41:34.970
and ignorance, and that
failure is an end in itself,

00:41:34.970 --> 00:41:39.000
and one can learn to
fail better, as it were.

00:41:39.000 --> 00:41:43.400
I think those are two key ideas,
and I see them as related.

00:41:43.400 --> 00:41:45.950
So along with failure
and ignorance,

00:41:45.950 --> 00:41:47.575
of course, comes
uncertainty and doubt.

00:41:47.575 --> 00:41:49.533
And we've sort of mentioned
these a little bit,

00:41:49.533 --> 00:41:52.210
so I just want to talk about
them for a quick moment, here.

00:41:52.210 --> 00:41:54.590
To put pull aside the problem
of certainty and the value

00:41:54.590 --> 00:41:57.400
of uncertainty-- because I think
we often reverse that idea,

00:41:57.400 --> 00:41:59.570
and I'd say we're
wrong about that--

00:41:59.570 --> 00:42:02.330
so uncertainty is something
that, in many areas

00:42:02.330 --> 00:42:03.250
of our life, we like.

00:42:03.250 --> 00:42:05.690
If you're playing poker
or you're at the casino,

00:42:05.690 --> 00:42:08.370
or you want to watch the
baseball game tomorrow night,

00:42:08.370 --> 00:42:10.370
you'd rather not
know the outcome

00:42:10.370 --> 00:42:13.010
before you watch the game, where
it's kind of less interesting.

00:42:13.010 --> 00:42:14.360
We have these spoiler alerts.

00:42:14.360 --> 00:42:15.770
I'm guessing nobody
in this room,

00:42:15.770 --> 00:42:19.220
probably, wants to know the
exact time of their death.

00:42:19.220 --> 00:42:24.370
Who wants to know that, kind
of ruin the party, I think.

00:42:24.370 --> 00:42:25.790
But these kinds
of uncertainties,

00:42:25.790 --> 00:42:27.748
I would also say, have
a fundamental difference

00:42:27.748 --> 00:42:29.120
with scientific uncertainty.

00:42:29.120 --> 00:42:33.080
Because they will, I guarantee
you, they will all resolve.

00:42:33.080 --> 00:42:35.450
The hand will be shown,
the ball will fall,

00:42:35.450 --> 00:42:38.400
the game score will be posted.

00:42:38.400 --> 00:42:41.210
And I'm sorry to say that
some digital place or another,

00:42:41.210 --> 00:42:43.400
the exact time and date
of all of our deaths

00:42:43.400 --> 00:42:45.860
will, indeed, be recorded.

00:42:45.860 --> 00:42:48.710
I find this a, kind of a
grander uncertainty in science,

00:42:48.710 --> 00:42:51.860
where there may be no ultimate
solution, no final resolution,

00:42:51.860 --> 00:42:54.410
no guaranteed complete
answer, that this

00:42:54.410 --> 00:42:58.220
is a kind of, if you
will, endless frontier,

00:42:58.220 --> 00:43:00.770
that indeed the
purpose in science,

00:43:00.770 --> 00:43:03.932
the purpose of science,
is not to get to 0 or 1

00:43:03.932 --> 00:43:05.390
by doing more and
more experiments,

00:43:05.390 --> 00:43:08.090
but to develop what I would
call stable probabilities,

00:43:08.090 --> 00:43:10.550
a stable kind of
uncertainty that we can then

00:43:10.550 --> 00:43:13.740
work with, and do work with,
in quite important ways.

00:43:13.740 --> 00:43:16.220
So the question to me is
not how we become certain,

00:43:16.220 --> 00:43:19.220
but how we get on so
successfully while accepting

00:43:19.220 --> 00:43:21.710
uncertainty, which is
what science traffics in,

00:43:21.710 --> 00:43:22.970
to a large extent.

00:43:22.970 --> 00:43:25.595
And certainty, if we
reached it, would kind of

00:43:25.595 --> 00:43:32.010
be the end of inquiry, which
doesn't sound very good to me.

00:43:32.010 --> 00:43:33.840
Yes, so I included
this the last minute

00:43:33.840 --> 00:43:35.170
because it's a favorite of
mine and I'm always looking

00:43:35.170 --> 00:43:36.211
for some place to put it.

00:43:36.211 --> 00:43:38.610
This is a haiku by the
famous Japanese haiku

00:43:38.610 --> 00:43:42.450
artist Basho, "Too much
mist, can't see Fuji,

00:43:42.450 --> 00:43:44.630
makes it more interesting."

00:43:44.630 --> 00:43:48.420
Yes, often it does, because you
can think about where it is.

00:43:48.420 --> 00:43:52.585
So I'm just going to make two
quick remarks about education,

00:43:52.585 --> 00:43:54.710
here, because we're going
to talk about this later,

00:43:54.710 --> 00:43:56.430
so I threw these in
at the last minute.

00:43:56.430 --> 00:43:58.400
But I think one of the
things we mistake, then,

00:43:58.400 --> 00:44:01.200
is we leave out that mist
in our educational process.

00:44:01.200 --> 00:44:03.800
We develop these heroic
narratives about science.

00:44:03.800 --> 00:44:06.730
My favorite is a sort of arc
of discovery in physics--

00:44:06.730 --> 00:44:09.980
you go from Copernicus to
Kepler, Galileo, Newton,

00:44:09.980 --> 00:44:12.080
Herschel, blah blah blah,
all the way to Einstein,

00:44:12.080 --> 00:44:14.750
and kaboom, physics, there
it is, a very smooth arc,

00:44:14.750 --> 00:44:16.070
and that's all there was to it.

00:44:16.070 --> 00:44:17.570
But of course, this
wasn't the path,

00:44:17.570 --> 00:44:18.903
this wasn't the way it happened.

00:44:18.903 --> 00:44:22.100
Actually, there was
this rambling, confused,

00:44:22.100 --> 00:44:25.490
often failed, wrong,
occasionally successful path

00:44:25.490 --> 00:44:28.417
of discovery that might have
included these same people

00:44:28.417 --> 00:44:30.500
but, you know, it wasn't
some nice straight arrow.

00:44:30.500 --> 00:44:32.750
They went off cock-eyed
directions and things

00:44:32.750 --> 00:44:33.290
like this.

00:44:33.290 --> 00:44:35.810
There were long periods when,
kind of, nobody could figure

00:44:35.810 --> 00:44:37.340
out what the next step was.

00:44:37.340 --> 00:44:38.889
There are a lot of
forgotten names.

00:44:38.889 --> 00:44:40.430
I should say a lot
of those forgotten

00:44:40.430 --> 00:44:45.270
names are the names of women,
so Caroline Herschel, Marie le

00:44:45.270 --> 00:44:49.910
Voicier, not just Marie
Curie, but her daughter Irene,

00:44:49.910 --> 00:44:52.820
and Mileva Maric,
Einstein's wife,

00:44:52.820 --> 00:44:55.760
and probably the better
mathematician of the two.

00:44:55.760 --> 00:44:57.860
And so I think these
are the kinds of stories

00:44:57.860 --> 00:45:01.550
that need to be told in
our classroom settings,

00:45:01.550 --> 00:45:04.430
and in general to the public.

00:45:04.430 --> 00:45:07.190
Oh, yeah, I know this
is a little weird,

00:45:07.190 --> 00:45:10.430
but I thought I would give
you at least something useful

00:45:10.430 --> 00:45:13.890
to take home with you, today.

00:45:13.890 --> 00:45:18.760
So I'm going to conclude this,
here, how to hide a dead body.

00:45:18.760 --> 00:45:21.084
So here's what you
do, just in case.

00:45:21.084 --> 00:45:23.250
You have a dead body, you
go out to the local park--

00:45:23.250 --> 00:45:26.010
you can go out to Cambridge
Green, here, if you want--

00:45:26.010 --> 00:45:29.180
and you dig a nice hole
about eight feet deep,

00:45:29.180 --> 00:45:32.250
and you throw the body
in the hole, of course.

00:45:32.250 --> 00:45:35.599
Then you fill the hole up,
but you leave it, just dirt

00:45:35.599 --> 00:45:36.640
and all the rest of that.

00:45:36.640 --> 00:45:38.880
Now the police
come along and they

00:45:38.880 --> 00:45:41.580
see this recently
disturbed patch of ground

00:45:41.580 --> 00:45:43.140
that looks a bit like a grave.

00:45:43.140 --> 00:45:44.820
Oh, let's go get
the cadaver dogs.

00:45:44.820 --> 00:45:46.860
They get the cadaver
dogs and the cadaver dogs

00:45:46.860 --> 00:45:48.690
go wild over it.

00:45:48.690 --> 00:45:51.000
What they don't know is
that you, cleverly, have--

00:45:51.000 --> 00:45:53.960
while filling this hole
up-- have buried a dead dog

00:45:53.960 --> 00:45:56.090
at 4 feet.

00:45:56.090 --> 00:45:59.140
So the police begin digging in
expectation of finding a body,

00:45:59.140 --> 00:46:02.860
and indeed they do find the
body of a dead dog at 4 feet.

00:46:02.860 --> 00:46:05.600
And off they go, right?

00:46:05.600 --> 00:46:07.940
So the question,
though, is how long

00:46:07.940 --> 00:46:10.670
will this body
remain undiscovered,

00:46:10.670 --> 00:46:11.990
and how many of these bodies?

00:46:11.990 --> 00:46:14.240
How many of these cadavers
are there, in science?

00:46:14.240 --> 00:46:16.850
How many times do we,
in our laboratories,

00:46:16.850 --> 00:46:19.850
do an experiment, get
the expected result,

00:46:19.850 --> 00:46:21.950
say, oh, that's great,
and toodle right along,

00:46:21.950 --> 00:46:24.950
not realizing there's yet
an undiscovered result

00:46:24.950 --> 00:46:29.296
below that fabulous
discovery we just made?

00:46:29.296 --> 00:46:30.920
So you could hide a
dead body this way,

00:46:30.920 --> 00:46:34.176
but it's not a good idea
to do this in science.

00:46:34.176 --> 00:46:35.550
What's the answer
to any of this?

00:46:35.550 --> 00:46:36.740
I don't have an
answer any of it,

00:46:36.740 --> 00:46:38.531
but I would like to
put in a pitch for what

00:46:38.531 --> 00:46:39.770
I call pluralism in science.

00:46:39.770 --> 00:46:43.550
So pluralism is an idea
in political theory

00:46:43.550 --> 00:46:46.310
and in history and many other
areas developed, I think,

00:46:46.310 --> 00:46:48.200
largely by Isaiah Berlin
in the last century,

00:46:48.200 --> 00:46:51.290
a great philosopher at Oxford.

00:46:51.290 --> 00:46:53.040
But I'd like to see
it applied to science.

00:46:53.040 --> 00:46:54.470
And I don't think we
do a good job of that.

00:46:54.470 --> 00:46:56.309
I'll use a quote
here from Niels Bohr.

00:46:56.309 --> 00:46:58.100
I know I have a lot of
quotes in this talk,

00:46:58.100 --> 00:47:00.380
but I don't do this for
the purpose of authority.

00:47:00.380 --> 00:47:02.930
I just think people who said
something important shouldn't

00:47:02.930 --> 00:47:07.180
be left out of the conversation
just because they're dead.

00:47:07.180 --> 00:47:10.394
And I also think it's
important to recognize

00:47:10.394 --> 00:47:11.810
that the conversation
has actually

00:47:11.810 --> 00:47:15.770
been going on for a long time,
and it will continue to go on.

00:47:15.770 --> 00:47:18.290
And our job is to jump
in, say something.

00:47:18.290 --> 00:47:23.000
So Boris said, "The opposite
of a fact is a falsehood,

00:47:23.000 --> 00:47:25.580
but the opposite
of a profound truth

00:47:25.580 --> 00:47:28.460
is often another
profound truth."

00:47:28.460 --> 00:47:30.800
That's a hard one to wrap
your head around as well,

00:47:30.800 --> 00:47:32.600
but it happens quite regularly.

00:47:32.600 --> 00:47:35.630
And we often don't let
this happen in science.

00:47:35.630 --> 00:47:39.350
So Charles Pierce, a
Cambridge born philosopher,

00:47:39.350 --> 00:47:43.950
a logician, mathematician, and
scientist of the late 19th,

00:47:43.950 --> 00:47:47.540
early 20th century, considered
one of America's finest

00:47:47.540 --> 00:47:48.450
in those areas--

00:47:48.450 --> 00:47:51.800
although a little bit
of a strange character--

00:47:51.800 --> 00:47:53.400
he said, science
is not like a chain

00:47:53.400 --> 00:47:55.310
only as strong as the
proverbial weakest

00:47:55.310 --> 00:47:57.150
link, that it is
not a chain of facts

00:47:57.150 --> 00:47:59.720
where the weakest
fact, the chain breaks.

00:47:59.720 --> 00:48:01.910
Rather, it's more
like a cable, made up

00:48:01.910 --> 00:48:05.210
of many delicate strands,
each one quite fragile,

00:48:05.210 --> 00:48:08.300
but when bundled together
of considerable strength,

00:48:08.300 --> 00:48:10.760
and that the loss of any
one of these few strands

00:48:10.760 --> 00:48:13.970
here and there will not
reduce, appreciably,

00:48:13.970 --> 00:48:15.470
the strength of the cable.

00:48:15.470 --> 00:48:17.720
And so the idea is to
keep the strands going on,

00:48:17.720 --> 00:48:19.580
and not worry about
the few that--

00:48:19.580 --> 00:48:23.070
or even the many--
that don't work.

00:48:23.070 --> 00:48:25.790
So let me end this by telling
you the story of my dog.

00:48:25.790 --> 00:48:26.867
This is my dog, in fact.

00:48:26.867 --> 00:48:28.700
But that's not what the
story is about this.

00:48:28.700 --> 00:48:31.370
This is a Newfoundland
named Orson,

00:48:31.370 --> 00:48:35.510
out in his favorite environment,
the snow of Riverside Park.

00:48:35.510 --> 00:48:38.150
But the story of my dog is
about young Tom, a seventh grade

00:48:38.150 --> 00:48:40.760
student who's given an
assignment to write an essay.

00:48:40.760 --> 00:48:43.910
Young Tom writes an
essay called, My Dog.

00:48:43.910 --> 00:48:44.960
He hands it in.

00:48:44.960 --> 00:48:48.470
Two days later, the teacher
comes back and says, but Tom,

00:48:48.470 --> 00:48:53.210
your essay on My Dog is exactly
the same as your brother's.

00:48:53.210 --> 00:48:54.610
Did you copy it?

00:48:54.610 --> 00:48:57.810
And Tom says, no ma'am.

00:48:57.810 --> 00:48:58.695
It's the same dog.

00:49:02.640 --> 00:49:06.860
Yeah, so we all think
that's ridiculous, right?

00:49:06.860 --> 00:49:08.930
But that's not what
we do in science.

00:49:08.930 --> 00:49:12.840
We don't recognize that
there are a large number--

00:49:12.840 --> 00:49:15.170
not an infinite number--
but many, many diverse ways

00:49:15.170 --> 00:49:17.630
of describing the same dog.

00:49:17.630 --> 00:49:20.240
And every one of
them has some value.

00:49:20.240 --> 00:49:22.160
Some have more value,
some have less value,

00:49:22.160 --> 00:49:24.890
but everyone has
some value, at least.

00:49:24.890 --> 00:49:27.320
So let me just end with
these two last statements.

00:49:27.320 --> 00:49:30.050
This is from Rita Dove,
one time a poet laureate,

00:49:30.050 --> 00:49:33.080
"Failure is a favor
to the future."

00:49:33.080 --> 00:49:35.180
And this is from the
poet E. E. Cummings,

00:49:35.180 --> 00:49:37.400
"Always the beautiful
answer who asks

00:49:37.400 --> 00:49:38.810
a more beautiful question."

00:49:38.810 --> 00:49:41.680
And with that, let me ask
you what your questions are.

00:49:41.680 --> 00:49:43.171
Thank you very much.

00:49:43.171 --> 00:49:47.147
[APPLAUSE]

00:49:54.110 --> 00:49:57.620
- So that was wonderful, and I'm
sure you have many questions.

00:49:57.620 --> 00:50:00.260
And so let me just tell you
how we're going to do that.

00:50:00.260 --> 00:50:02.030
You see that there's
a microphone here,

00:50:02.030 --> 00:50:04.580
in the center aisle,
so please just

00:50:04.580 --> 00:50:06.770
come to that microphone
to ask your question.

00:50:06.770 --> 00:50:09.080
We'll be patient while
people make their way there.

00:50:09.080 --> 00:50:11.600
And then, just as
you ask the question,

00:50:11.600 --> 00:50:14.210
people love to talk, so
just try to be careful

00:50:14.210 --> 00:50:17.870
and ask a question
pretty quickly.

00:50:17.870 --> 00:50:20.780
And we'll take as many
as we can, so thank you.

00:50:20.780 --> 00:50:23.690
- You know, the worst thing
is that I also love to talk,

00:50:23.690 --> 00:50:27.811
so I'll try and make it
a brief answer, as well.

00:50:27.811 --> 00:50:28.310
Yes.

00:50:28.310 --> 00:50:31.820
- Could you comment on the fact
that so many of your references

00:50:31.820 --> 00:50:38.160
were from the humanities,
an area we tend to think

00:50:38.160 --> 00:50:40.320
is separate from science?

00:50:40.320 --> 00:50:43.410
- Well I don't think
it is, obviously,

00:50:43.410 --> 00:50:46.395
and I'm quite pleased to be
able to put so many references

00:50:46.395 --> 00:50:48.090
to the humanities in there.

00:50:48.090 --> 00:50:50.130
I claim that this is
a talk about science,

00:50:50.130 --> 00:50:51.487
and I think it is--

00:50:51.487 --> 00:50:53.820
and I talk about science
because science is what I know,

00:50:53.820 --> 00:50:54.990
it's what I do--

00:50:54.990 --> 00:50:56.610
but I don't believe
that it exists

00:50:56.610 --> 00:50:59.370
isolated from the rest of our
culture in any way, shape,

00:50:59.370 --> 00:51:00.300
or form.

00:51:00.300 --> 00:51:02.280
And almost everything
I've said today

00:51:02.280 --> 00:51:05.100
could just as easily be applied
to the arts, to the humanities,

00:51:05.100 --> 00:51:08.760
to any of them, and that
many people in the humanities

00:51:08.760 --> 00:51:11.586
have thought about these
questions very seriously.

00:51:11.586 --> 00:51:12.960
I have a number
of friends-- see,

00:51:12.960 --> 00:51:14.670
I'm going to go on too
long, but real quickly--

00:51:14.670 --> 00:51:16.990
I have a number of friends who
are philosophers of science.

00:51:16.990 --> 00:51:19.680
And one of the things they tend
to worry about is, do we care?

00:51:19.680 --> 00:51:22.770
Do scientists care about what
philosophers of science think?

00:51:22.770 --> 00:51:25.890
And I like to tell
them, it doesn't matter.

00:51:25.890 --> 00:51:28.525
It doesn't matter what we think
about philosophy of science.

00:51:28.525 --> 00:51:30.900
I mean, it would be nice if
more of my science colleagues

00:51:30.900 --> 00:51:32.650
thought philosophy of
science was important.

00:51:32.650 --> 00:51:35.066
But I think science is one of
the most important things we

00:51:35.066 --> 00:51:36.220
have in our culture.

00:51:36.220 --> 00:51:37.510
We are a scientific culture.

00:51:37.510 --> 00:51:39.420
If you think the
Renaissance was important,

00:51:39.420 --> 00:51:41.010
or the Reformation
was important,

00:51:41.010 --> 00:51:43.950
the scientific revolution has
had more effect on our lives

00:51:43.950 --> 00:51:45.690
than either of those
things, really.

00:51:45.690 --> 00:51:48.870
And so why shouldn't there
be a philosophy and a history

00:51:48.870 --> 00:51:50.970
of science for the culture?

00:51:50.970 --> 00:51:54.080
Not for scientists-- who cares
about them, really, you know?

00:51:54.080 --> 00:51:56.650
So this is what I try and tell
my philosopher and historian

00:51:56.650 --> 00:51:57.150
friends.

00:51:57.150 --> 00:51:58.983
Do it for the culture,
don't worry about us.

00:52:02.880 --> 00:52:06.110
- There's a paper
out on the internet--

00:52:06.110 --> 00:52:08.292
which might have
been published--

00:52:08.292 --> 00:52:09.500
- It sounds pretty dangerous.

00:52:09.500 --> 00:52:14.860
- --in a reputable journal
that had a title, I paraphrase,

00:52:14.860 --> 00:52:19.610
the majority of scientific
findings are false.

00:52:19.610 --> 00:52:24.130
And it was a paper about,
I guess, statistics,

00:52:24.130 --> 00:52:30.250
and it goes to the heart of,
have we failed or succeeded,

00:52:30.250 --> 00:52:33.240
or how do we define
that, particularly

00:52:33.240 --> 00:52:37.660
in fields where the evidence
is in the form of numbers?

00:52:37.660 --> 00:52:43.390
And I'm just curious
where this issue of--

00:52:43.390 --> 00:52:47.020
maybe people agree that the
supernova had this brightness,

00:52:47.020 --> 00:52:49.580
but not on whether the
universe is accelerating.

00:52:49.580 --> 00:52:53.200
Maybe they agree on this
pattern of epidemiological data,

00:52:53.200 --> 00:52:54.970
but not on the
[INAUDIBLE] or approach.

00:52:54.970 --> 00:52:58.180
- Right, so this
paper was about what's

00:52:58.180 --> 00:53:00.910
come to be called the
replication crisis in science,

00:53:00.910 --> 00:53:03.922
the inability of a
certain number of papers--

00:53:03.922 --> 00:53:05.380
and we can argue
about whether it's

00:53:05.380 --> 00:53:06.660
a large number or
a small number--

00:53:06.660 --> 00:53:08.118
but a certain number
of papers that

00:53:08.118 --> 00:53:10.970
are published in scientific
journals, legitimate,

00:53:10.970 --> 00:53:15.780
which can then not be replicated
by another laboratory later on.

00:53:15.780 --> 00:53:17.590
And this is considered
to be indicative

00:53:17.590 --> 00:53:20.080
of poor statistical
power and a variety

00:53:20.080 --> 00:53:22.840
of other sorts of things.

00:53:22.840 --> 00:53:24.930
I gave a talk last weekend
on this whole issue,

00:53:24.930 --> 00:53:26.740
so unless you want
to reset the clock

00:53:26.740 --> 00:53:29.059
I can't give you the
whole answer to this.

00:53:29.059 --> 00:53:31.100
Except to say that I don't
believe it's a crisis.

00:53:31.100 --> 00:53:33.220
I believe that
replication failure

00:53:33.220 --> 00:53:36.790
is a kind of scientific
failure that's very valuable.

00:53:36.790 --> 00:53:38.860
I think when-- I'm not
talking about fraud, no,

00:53:38.860 --> 00:53:41.800
fraud is another story, fraud
in science is the only thing I

00:53:41.800 --> 00:53:46.270
believe the death penalty should
be used for because, really,

00:53:46.270 --> 00:53:48.250
it won't work if people lie--

00:53:48.250 --> 00:53:51.665
but I think many
laboratories publish--

00:53:51.665 --> 00:53:53.290
all sorts of subtleties
in here-- but I

00:53:53.290 --> 00:53:55.900
think laboratories will publish
the result that they generally

00:53:55.900 --> 00:53:58.030
believe in it, they have gotten.

00:53:58.030 --> 00:54:00.670
If it can't be replicated by
another laboratory, that often

00:54:00.670 --> 00:54:02.272
means that there
was something they

00:54:02.272 --> 00:54:03.730
did they didn't
even know they did.

00:54:03.730 --> 00:54:06.280
It was one of those, we didn't
know what we didn't know.

00:54:06.280 --> 00:54:09.100
And now we know that we have to
look a little deeper into this.

00:54:09.100 --> 00:54:12.130
The original data is
probably reasonable evidence.

00:54:12.130 --> 00:54:13.420
It just needs more evidence.

00:54:13.420 --> 00:54:15.100
It needs a better
look, a deeper look.

00:54:15.100 --> 00:54:17.090
Sometimes it will
turn out to be wrong.

00:54:17.090 --> 00:54:19.390
But I have a phrase from
Charles Colson Gillespie,

00:54:19.390 --> 00:54:20.890
a great historian
of science, who

00:54:20.890 --> 00:54:24.470
said that in science,
revision is a victory.

00:54:24.470 --> 00:54:28.570
And I think that should hang on
the wall of every laboratory.

00:54:28.570 --> 00:54:31.720
So that's how we
get to these things.

00:54:35.480 --> 00:54:39.530
- You indicated that ignorance
grows with knowledge.

00:54:39.530 --> 00:54:42.360
Is there any
explanation as to why

00:54:42.360 --> 00:54:48.080
ignorance, regardless
of knowledge or facts,

00:54:48.080 --> 00:54:53.560
consistently remains in
the 38% and never changes?

00:54:53.560 --> 00:54:54.862
- In the 38%?

00:54:54.862 --> 00:54:56.320
I'm not sure what
you mean by that.

00:54:56.320 --> 00:55:02.330
- In other words, ignorance
seems that it doesn't change,

00:55:02.330 --> 00:55:05.860
even when there is new
fact, the new additions.

00:55:05.860 --> 00:55:09.810
It still remains very
within that range.

00:55:09.810 --> 00:55:11.330
It doesn't really--

00:55:11.330 --> 00:55:15.060
- Yes, so again, I think this
is a different kind of ignorance

00:55:15.060 --> 00:55:18.650
than the one that I'm trying
to talk about, which is

00:55:18.650 --> 00:55:20.090
more of a communal ignorance.

00:55:20.090 --> 00:55:22.490
It's not so much
personal ignorance,

00:55:22.490 --> 00:55:25.760
people who prefer to disregard
facts or see facts only

00:55:25.760 --> 00:55:29.150
in the particular way
that makes sense to them.

00:55:29.150 --> 00:55:32.090
And I want to point out, I'm
not making a political statement

00:55:32.090 --> 00:55:33.230
here.

00:55:33.230 --> 00:55:35.120
I know it sounds
like one, but I'm not

00:55:35.120 --> 00:55:36.350
making a political statement.

00:55:36.350 --> 00:55:39.390
Or at least, I'm not making a
political statement that says,

00:55:39.390 --> 00:55:42.260
this is more true of those
people on the right of center

00:55:42.260 --> 00:55:44.570
than those people on
the left of center.

00:55:44.570 --> 00:55:47.870
Marin County is full of
well-educated liberals who

00:55:47.870 --> 00:55:50.160
believe they should not
vaccinate their children,

00:55:50.160 --> 00:55:51.570
and they're out of their minds.

00:55:51.570 --> 00:55:54.720
I mean, they're just as
ignorant as all the rest of it.

00:55:54.720 --> 00:55:57.830
And so, you know,
nobody has nobody

00:55:57.830 --> 00:56:00.472
has a hold on
ignorance in that way,

00:56:00.472 --> 00:56:02.180
but that's a different
kind of ignorance,

00:56:02.180 --> 00:56:03.846
I think, than the one
I'm talking about.

00:56:03.846 --> 00:56:06.080
That's the low
quality ignorance.

00:56:06.080 --> 00:56:08.740
And that, I'm afraid, we may
have to learn to live with.

00:56:08.740 --> 00:56:11.540
Yeah, I don't know.

00:56:11.540 --> 00:56:15.000
- So many of the quotations,
the wonderful quotations

00:56:15.000 --> 00:56:17.150
you showed us today
are historical.

00:56:17.150 --> 00:56:19.220
And you made, already,
the point that you

00:56:19.220 --> 00:56:21.496
wanted to show that
it's a [INAUDIBLE],,

00:56:21.496 --> 00:56:23.870
because I've been thinking
about that for a while, right?

00:56:23.870 --> 00:56:25.610
So if that's the case, why--

00:56:25.610 --> 00:56:27.510
I mean, this is not
a new realization--

00:56:27.510 --> 00:56:31.920
so why do you think
it hasn't been taught?

00:56:31.920 --> 00:56:35.210
It hasn't changed the
way to teach science,

00:56:35.210 --> 00:56:40.140
given that, again, we have been
talking about that for a while.

00:56:40.140 --> 00:56:42.020
And I just was
wondering, could it

00:56:42.020 --> 00:56:44.440
be that a more
constrictive way to teach

00:56:44.440 --> 00:56:47.840
it is actually more efficient,
or that you would figure out

00:56:47.840 --> 00:56:50.430
that on your own, at
some point, maybe it's

00:56:50.430 --> 00:56:52.560
a better way than
telling you that you're

00:56:52.560 --> 00:56:54.760
going to fail many times?

00:56:54.760 --> 00:56:57.080
- Yes, everybody
has big questions,

00:56:57.080 --> 00:57:00.880
and there's this clock
ticking away over here.

00:57:00.880 --> 00:57:02.630
Let me try to make a
quick answer to that,

00:57:02.630 --> 00:57:05.090
and then I'd like to say that
I will be around all day,

00:57:05.090 --> 00:57:06.870
so I'd be very happy
to have discussions,

00:57:06.870 --> 00:57:08.840
especially at the
poster session, which

00:57:08.840 --> 00:57:09.620
I intend to go to.

00:57:09.620 --> 00:57:11.870
Because I think education
is, in many ways,

00:57:11.870 --> 00:57:14.610
the key to this issue.

00:57:14.610 --> 00:57:17.630
Let me just say that I
think educational reforms

00:57:17.630 --> 00:57:19.316
and ideas for
educational reforms

00:57:19.316 --> 00:57:20.690
have been around
for a long time.

00:57:20.690 --> 00:57:23.270
Most of what I said today,
I think, is not new.

00:57:23.270 --> 00:57:26.150
As I said, John Dewey,
in my opinion kind of

00:57:26.150 --> 00:57:28.844
had this all figured
out 100 years ago.

00:57:28.844 --> 00:57:31.260
To me, the question is, what's
the obstacle to doing this?

00:57:31.260 --> 00:57:33.260
What's the obstacle to
making these changes

00:57:33.260 --> 00:57:36.430
that we almost all see as
obvious, once you say them?

00:57:36.430 --> 00:57:40.790
And I think the main obstacles
are evaluation and assessment.

00:57:40.790 --> 00:57:43.340
We need to evaluate, we
need to assess students

00:57:43.340 --> 00:57:45.770
and how they do,
ourselves, and how we do.

00:57:45.770 --> 00:57:49.760
And the tools we use are
old, and decrepit, and blunt,

00:57:49.760 --> 00:57:51.350
and not very good.

00:57:51.350 --> 00:57:54.620
We need new tools for
evaluating and assessing

00:57:54.620 --> 00:57:57.080
that include things like
ignorance, and failure,

00:57:57.080 --> 00:57:59.570
and uncertainty, and
measurements of that,

00:57:59.570 --> 00:58:04.470
and ways that students can
develop in those areas.

00:58:04.470 --> 00:58:06.770
But we can still
evaluate and measure.

00:58:06.770 --> 00:58:08.840
The only thing I will say
positive about all that

00:58:08.840 --> 00:58:10.923
is that I think that's a
scientific problem that's

00:58:10.923 --> 00:58:11.870
solvable.

00:58:11.870 --> 00:58:14.300
I think with computer
science, with statistics,

00:58:14.300 --> 00:58:17.710
with probability,
with game theory,

00:58:17.710 --> 00:58:20.330
and even including
things like art auctions,

00:58:20.330 --> 00:58:23.060
and economics, and
business evaluation,

00:58:23.060 --> 00:58:26.510
we can learn to develop
new methods of evaluation

00:58:26.510 --> 00:58:27.450
and assessment.

00:58:27.450 --> 00:58:29.210
So this is a problem
that's solvable.

00:58:29.210 --> 00:58:30.530
We just have to get to it.

00:58:33.344 --> 00:58:35.220
Yes.

00:58:35.220 --> 00:58:37.170
- Hi, there.

00:58:37.170 --> 00:58:43.360
So my question, as a
lawyer, is when we're

00:58:43.360 --> 00:58:45.660
developing public policy--

00:58:45.660 --> 00:58:51.290
so what are the implications for
both the development of policy,

00:58:51.290 --> 00:58:53.880
of uncertainty as
to scientific facts,

00:58:53.880 --> 00:58:57.120
whether it's approving
medicines or coming

00:58:57.120 --> 00:59:00.150
up with environmental
policy, in terms

00:59:00.150 --> 00:59:03.270
of the substance of
those policies and also,

00:59:03.270 --> 00:59:09.710
what should we be
embedding in our policies

00:59:09.710 --> 00:59:14.640
to account for the possibility
that the initial facts

00:59:14.640 --> 00:59:17.772
on which the policy is
based turn out to be wrong?

00:59:17.772 --> 00:59:19.230
Do you see something
that we should

00:59:19.230 --> 00:59:20.887
be doing to address that?

00:59:20.887 --> 00:59:23.220
- You know, of course, if I
had a prescription for that,

00:59:23.220 --> 00:59:26.117
I would have told
you during the talk.

00:59:26.117 --> 00:59:27.450
And I don't have a prescription.

00:59:27.450 --> 00:59:29.250
And I think what we
have to recognize

00:59:29.250 --> 00:59:33.420
is that it's hard work,
that you do the best you can

00:59:33.420 --> 00:59:37.470
with what you have, that
unsettled science, as I like

00:59:37.470 --> 00:59:39.240
to say, is not unsound science.

00:59:39.240 --> 00:59:40.940
It's simply unsettled.

00:59:40.940 --> 00:59:44.550
And as we improve it,
we improve policy.

00:59:44.550 --> 00:59:47.370
But you do what you
can with what you have.

00:59:47.370 --> 00:59:49.600
And that's been
surprisingly successful,

00:59:49.600 --> 00:59:51.581
so why not continue doing that?

00:59:51.581 --> 00:59:53.580
There's a philosopher of
science here at Harvard

00:59:53.580 --> 00:59:55.770
named Catherine Elgin,
who wrote a book called

00:59:55.770 --> 00:59:59.340
True Enough, in which she talks
about felicitous falsehoods,

00:59:59.340 --> 01:00:01.810
and that science is
never completely true.

01:00:01.810 --> 01:00:04.530
It's never always correct,
it's just true enough,

01:00:04.530 --> 01:00:06.990
is the important
judgment to make.

01:00:06.990 --> 01:00:09.120
Longtime editor of
nature of a big science

01:00:09.120 --> 01:00:11.880
journal, John Maddox-- he was
an editor for some 20 years--

01:00:11.880 --> 01:00:13.980
was once asked by a
reporter, so how many

01:00:13.980 --> 01:00:16.200
papers do you think Nature
publishes that turn out

01:00:16.200 --> 01:00:17.240
to be wrong?

01:00:17.240 --> 01:00:18.490
And Maddox answered like that.

01:00:18.490 --> 01:00:20.790
He said, oh, that's
easy, all of them.

01:00:20.790 --> 01:00:22.350
Because that's
the case, they all

01:00:22.350 --> 01:00:24.690
should turn out to be
wrong at some point.

01:00:24.690 --> 01:00:27.420
And so it's hard, I
understand, to make policy

01:00:27.420 --> 01:00:29.826
on what you don't know
is absolutely certain.

01:00:29.826 --> 01:00:31.200
But as I say,
science has learned

01:00:31.200 --> 01:00:32.680
to work with uncertainty.

01:00:32.680 --> 01:00:35.100
And I think politics can learn
to work with uncertainty as

01:00:35.100 --> 01:00:35.600
well.

01:00:44.380 --> 01:00:46.090
- I find your talk
very interesting

01:00:46.090 --> 01:00:49.780
because you have a focus
on ignorance and failure

01:00:49.780 --> 01:00:53.540
as fundamental to science.

01:00:53.540 --> 01:00:55.420
And it was very
interesting to me,

01:00:55.420 --> 01:00:58.840
because I disagree with that.

01:00:58.840 --> 01:01:01.890
And for me, the most
important aspects of science

01:01:01.890 --> 01:01:06.120
are curiosity and
discovery, and sometimes you

01:01:06.120 --> 01:01:08.316
don't discover what
you thought you would,

01:01:08.316 --> 01:01:09.954
but it's still very exciting.

01:01:09.954 --> 01:01:11.370
And so I was
wondering, why do you

01:01:11.370 --> 01:01:15.990
choose to focus on
ignorance and failure,

01:01:15.990 --> 01:01:19.920
as opposed to curiosity?

01:01:19.920 --> 01:01:22.500
- I would say curiosity
comes out of ignorance

01:01:22.500 --> 01:01:30.280
and leads to failure,
most typically.

01:01:30.280 --> 01:01:32.310
I don't want to leave
you, then, with the idea

01:01:32.310 --> 01:01:34.851
that I don't think, for example,
that knowledge is important.

01:01:34.851 --> 01:01:37.170
You need to know some things
in order to get anywhere.

01:01:37.170 --> 01:01:38.711
As was pointed out,
I think earlier--

01:01:38.711 --> 01:01:41.862
I think it was Alyssa who
said, you know, lawyers--

01:01:41.862 --> 01:01:43.320
sorry, for the
lawyer-- but lawyers

01:01:43.320 --> 01:01:45.930
don't make serendipitous
scientific discoveries.

01:01:45.930 --> 01:01:48.120
Scientists do, and
biologists don't

01:01:48.120 --> 01:01:50.079
make serendipitous
physics discoveries.

01:01:50.079 --> 01:01:51.370
You have to be working on them.

01:01:51.370 --> 01:01:52.495
You have to know something.

01:01:52.495 --> 01:01:54.570
So oddly enough,
the higher the level

01:01:54.570 --> 01:01:56.610
of expertise, in my
opinion, the higher

01:01:56.610 --> 01:01:59.994
the level of ignorance
and failure, in fact.

01:01:59.994 --> 01:02:01.410
It's the experts
who fail the most

01:02:01.410 --> 01:02:06.010
and recognize how
to fail the best.

01:02:06.010 --> 01:02:07.570
I don't want to
dismiss curiosity.

01:02:07.570 --> 01:02:09.390
I'm really trying to kind
of re-balance the thing,

01:02:09.390 --> 01:02:11.400
because so much of what
we think about science

01:02:11.400 --> 01:02:15.270
seems to be based on facts,
big textbooks full of facts,

01:02:15.270 --> 01:02:20.940
potted histories of discoveries,
and the idea that we

01:02:20.940 --> 01:02:25.344
don't fail, that we just go from
great success to great success.

01:02:25.344 --> 01:02:26.760
And just to balance
that, I'd like

01:02:26.760 --> 01:02:29.490
to simply suggest that
if you want curiosity,

01:02:29.490 --> 01:02:32.100
curiosity does not, in
my opinion, come out

01:02:32.100 --> 01:02:35.820
of textbooks and
arcs of discovery,

01:02:35.820 --> 01:02:38.400
genius-made
discoveries, as it were.

01:02:38.400 --> 01:02:41.490
But curiosity,
imagination, intuition,

01:02:41.490 --> 01:02:43.140
inspiration, this
comes out of, I

01:02:43.140 --> 01:02:47.410
think, a willingness to
be ignorant, if you will,

01:02:47.410 --> 01:02:50.760
and a willingness to fail.

01:02:50.760 --> 01:02:53.204
I think we're talking
about the same thing.

01:02:57.100 --> 01:02:59.190
- Stuart, that was fantastic.

01:02:59.190 --> 01:03:03.350
So as a scientist,
I've had my many years

01:03:03.350 --> 01:03:05.490
of ignorance and failure.

01:03:05.490 --> 01:03:08.600
So I had a more
general question.

01:03:08.600 --> 01:03:12.260
So for young researchers
coming up in the field,

01:03:12.260 --> 01:03:17.180
they're not allowed to admit to
ignorance and failure because

01:03:17.180 --> 01:03:19.340
of the pressures
of universities,

01:03:19.340 --> 01:03:24.270
and tenure, and academic
success, is what is valued.

01:03:24.270 --> 01:03:27.740
So as a seasoned
researcher as yourself--

01:03:27.740 --> 01:03:30.222
and I say that in the best way--

01:03:30.222 --> 01:03:31.814
[LAUGHTER]

01:03:31.814 --> 01:03:33.230
- Thank you for
making that clear.

01:03:36.920 --> 01:03:40.880
- How do we instill
this idea that you

01:03:40.880 --> 01:03:45.140
can fail, and be ignorant, and
still get tenure at Columbia?

01:03:45.140 --> 01:03:45.860
- Well, I did.

01:03:50.107 --> 01:03:51.440
Yes, it's an important question.

01:03:51.440 --> 01:03:52.148
I think this is--

01:03:52.148 --> 01:03:54.004
I really didn't have
the time to develop it,

01:03:54.004 --> 01:03:55.420
but I think it
could be developed,

01:03:55.420 --> 01:03:56.870
and I think there are lot
of people working on this--

01:03:56.870 --> 01:03:59.170
I think this is where
ideas of pluralism

01:03:59.170 --> 01:04:02.560
become so important,
that there are so

01:04:02.560 --> 01:04:05.350
many ways to contribute that--

01:04:05.350 --> 01:04:07.660
and again, it's kind of an
assessment and evaluation

01:04:07.660 --> 01:04:08.440
problem.

01:04:08.440 --> 01:04:11.410
So I don't think pluralism is
actually a very useful thing

01:04:11.410 --> 01:04:12.494
at the bench, if you will.

01:04:12.494 --> 01:04:14.410
I mean, if I'm in the
middle of an experiment,

01:04:14.410 --> 01:04:16.720
I don't want to be thinking
of 20 other possible ways

01:04:16.720 --> 01:04:18.178
that this experiment
could be done.

01:04:18.178 --> 01:04:21.500
I need to be dedicated and
focused on that experiment.

01:04:21.500 --> 01:04:24.880
But in so much else that we
do as scientists to support

01:04:24.880 --> 01:04:27.235
the scientific structure
such as promotion

01:04:27.235 --> 01:04:31.417
and hiring, curriculum,
or reviewing papers,

01:04:31.417 --> 01:04:33.250
reviewing grants, all
of these other things,

01:04:33.250 --> 01:04:38.740
I think a more serious approach
to pluralism in those areas

01:04:38.740 --> 01:04:41.440
would benefit the whole
structure, and all the people

01:04:41.440 --> 01:04:43.102
in it, tremendously.

01:04:43.102 --> 01:04:44.560
Because they would
allow for things

01:04:44.560 --> 01:04:45.700
like ignorance and failure.

01:04:45.700 --> 01:04:47.290
If you have really
good ignorance,

01:04:47.290 --> 01:04:50.120
if your questions are good, then
I want you in my department.

01:04:50.120 --> 01:04:51.820
I don't care if you
know the answers.

01:04:51.820 --> 01:04:54.160
I just want you in my department
if your questions are good.

01:04:54.160 --> 01:04:56.076
And the better your
questions, the more likely

01:04:56.076 --> 01:04:57.340
you are to fail.

01:04:57.340 --> 01:05:00.440
But you're likely to
fail in creative ways.

01:05:00.440 --> 01:05:02.880
And some of those failures
will be really useful to me,

01:05:02.880 --> 01:05:03.670
as well.

01:05:03.670 --> 01:05:04.870
But I appreciate it.

01:05:04.870 --> 01:05:06.750
It's a very difficult
problem because we

01:05:06.750 --> 01:05:09.420
have students who we want
to promote along the way,

01:05:09.420 --> 01:05:10.720
and all the rest of that.

01:05:10.720 --> 01:05:12.292
But somewhere along
the line, they're

01:05:12.292 --> 01:05:14.250
going to have to learn
that it's mostly failure

01:05:14.250 --> 01:05:15.931
and an awful lot of ignorance.

01:05:20.080 --> 01:05:22.240
Thank you very much, thank
you all very much, yes.

01:05:22.240 --> 01:05:26.790
[APPLAUSE]

