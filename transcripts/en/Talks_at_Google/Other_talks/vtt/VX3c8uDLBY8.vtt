WEBVTT
Kind: captions
Language: en

00:00:00.130 --> 00:00:02.880
&gt;&gt;commentator: Good afternoon everyone, thank
you all for coming.

00:00:02.880 --> 00:00:05.620
Today we are honored to have Joshua Foer with
us.

00:00:05.620 --> 00:00:11.040
Josh is a science journalist whose work has
appeared in National Geographic, Esquire,

00:00:11.040 --> 00:00:15.769
Slate, Outside, The New York Times, and many
other publications.

00:00:15.769 --> 00:00:20.390
His first book Moonwalking with Einstein:
The Art and Science of Remembering Everything

00:00:20.390 --> 00:00:24.849
chronicles his journey of going from being
a guy with just an average memory to becoming

00:00:24.849 --> 00:00:31.079
the 2006 U.S. Memory Champion capable of memorizing
a deck of cards in a minute and forty seconds.

00:00:31.079 --> 00:00:37.110
Joshua is co-founder of Atlas Obscura an online
guide to the world's wonders and curiosities

00:00:37.110 --> 00:00:40.990
and is also co-founder of the design competition,
Sukkah City.

00:00:40.990 --> 00:00:42.820
Please join me in welcoming Joshua.

00:00:42.820 --> 00:00:43.820
[applause]

00:00:43.820 --> 00:00:45.760
&gt;&gt;Joshua Foer: Thanks.

00:00:45.760 --> 00:00:50.180
It's so nice to be here.

00:00:50.180 --> 00:00:56.610
I guess given that this is such an intimate
setting I think I would like to maybe chat

00:00:56.610 --> 00:01:03.390
briefly and then have a kind of conversation
with you guys about a theme, a subject, that

00:01:03.390 --> 00:01:08.590
is almost like this thread that goes through
my book, Moonwalking With Einstein which is

00:01:08.590 --> 00:01:15.970
the relationship between knowledge and wisdom,
between memory and intelligence.

00:01:15.970 --> 00:01:23.450
And I think it's a pertinent subject to talk
about at this moment in time here at Google.

00:01:23.450 --> 00:01:31.329
In Steven Levy's book In the Plex about the
history and culture of Google he has your

00:01:31.329 --> 00:01:37.179
CEO, Larry Page, on the record saying that
he looks forward to the day when ultimately

00:01:37.179 --> 00:01:44.219
his products, Google products, will be channeled
straight into your brain, where you will merely

00:01:44.219 --> 00:01:49.720
think of a question and the answer will come
straight to you.

00:01:49.720 --> 00:01:55.200
In fact someday maybe you'll have a Google
implant that will connect you directly to

00:01:55.200 --> 00:01:57.229
Google services.

00:01:57.229 --> 00:02:05.749
Sergey Brin has said that ultimately Google
is about making, augmenting your brain with

00:02:05.749 --> 00:02:08.920
sort of all of the world's knowledge.

00:02:08.920 --> 00:02:15.610
And that my sound kinda like science fiction,
but I'm enough of a technological determinist

00:02:15.610 --> 00:02:21.850
and I guess have enough faith in Google [chuckles]
to believe that that is something that may

00:02:21.850 --> 00:02:24.960
ultimately come about.

00:02:24.960 --> 00:02:27.510
And I think if you look around at sort of
what's going on in the world there are enough

00:02:27.510 --> 00:02:30.770
indicators that suggest that this is a future
that's not that impossible.

00:02:30.770 --> 00:02:37.720
So already you know cochlear implants have
been installed in something like over 200,000

00:02:37.720 --> 00:02:42.090
human brains; take sound waves, turns them
into electrical impulses, channels them into

00:02:42.090 --> 00:02:45.680
you; the brain stem allows deaf people to
hear.

00:02:45.680 --> 00:02:50.630
And you've got a number of sort of research
firms all over the world, research groups

00:02:50.630 --> 00:02:55.220
I should say, working on developing sort of
primitive neuroprosthetics.

00:02:55.220 --> 00:03:00.650
I did a story for Esquire a few years back
about a guy called Erik Ramsey who when he

00:03:00.650 --> 00:03:07.710
was 16 years old was in this absolutely tragic
car accident that left him locked in, totally

00:03:07.710 --> 00:03:12.500
took away his ability to control any part
of his body beyond his eyes.

00:03:12.500 --> 00:03:20.280
But cognitively he was totally there and working
with a scientist, a neuroscientist in Georgia,

00:03:20.280 --> 00:03:28.300
he had a set of electrodes implanted into
the part of the pre-motor cortex that controls

00:03:28.300 --> 00:03:31.210
sort of movement of the mouth, the tongue,
the lips.

00:03:31.210 --> 00:03:38.060
And the notion is that at some point they're
training him to control the prosthetic voice

00:03:38.060 --> 00:03:41.490
using his thoughts.

00:03:41.490 --> 00:03:47.760
So that's sort of like one way communication,
I think the ultimate vision is some sort of

00:03:47.760 --> 00:03:53.160
two way communication where it's not just
data coming but data coming into the brain.

00:03:53.160 --> 00:03:58.180
And I don't know if it's gonna be Google who
does this or I don't know if it's gonna happen

00:03:58.180 --> 00:04:03.210
in my lifetime, but if you look at sort of
the broad trajectory of where technology is

00:04:03.210 --> 00:04:12.490
going in terms of creating an ever more seamless
connection, interface, between the minds that

00:04:12.490 --> 00:04:19.709
are embodied in our brains and the memories
that are embodied in our technology, in our

00:04:19.709 --> 00:04:24.440
devices like our Smart Phones, I think it's
fair to say that Google has got a nice head

00:04:24.440 --> 00:04:25.440
start.

00:04:25.440 --> 00:04:30.500
And there was some reporting in The New York
Times earlier this year by Nick Bilton who

00:04:30.500 --> 00:04:37.620
suggested that you guys are working on a heads
up display that he says is gonna be out by

00:04:37.620 --> 00:04:38.620
Christmas.

00:04:38.620 --> 00:04:46.010
And that the notion is we'll be walking around
with sort of all of this information sort

00:04:46.010 --> 00:04:53.490
of projected straight on to our retinas which
is a much less clumsy and clunky way of tapping

00:04:53.490 --> 00:05:00.400
into the collective knowledge of mankind than
using my thumbs or even talking to my phone.

00:05:00.400 --> 00:05:09.810
And I think this is poised to be like the
big story of my lifetime, of the next several

00:05:09.810 --> 00:05:18.660
decades is how life is going to change as
we really merge in a more seamless way our

00:05:18.660 --> 00:05:22.120
internal and our external minds.

00:05:22.120 --> 00:05:23.660
And—

00:05:23.660 --> 00:05:32.300
I think this is actually an old story; we've
been figuring out better and better ways to

00:05:32.300 --> 00:05:39.150
externalize our memories and to recall them,
activate them with better and better technologies

00:05:39.150 --> 00:05:44.990
basically since the first caveman splashed
paint on the wall of a cave.

00:05:44.990 --> 00:05:50.550
Once upon a time anything that was going to
be passed on had to be remembered, there was

00:05:50.550 --> 00:05:52.620
nothing to do with a thought except remember
it.

00:05:52.620 --> 00:05:58.460
There was no alphabet to transcribe thoughts
in, no paper to put them down upon, and anything

00:05:58.460 --> 00:06:02.760
that was gonna be conveyed first has to be
memorized.

00:06:02.760 --> 00:06:06.449
And then there was of course this massive
technological shift, the invention of writing,

00:06:06.449 --> 00:06:12.490
and you had people who were objecting to that;
2500 years ago Socrates was at the very least

00:06:12.490 --> 00:06:18.580
ambivalent and maybe even up in arms about
this new invention called writing and he said,

00:06:18.580 --> 00:06:20.740
"Writing is gonna make people dumb.

00:06:20.740 --> 00:06:25.240
People are gonna start taking ideas out of
their minds, putting them down on papyrus

00:06:25.240 --> 00:06:36.240
and thinking that they're still smart when
in fact they're just gonna be like empty vessels.

00:06:36.240 --> 00:06:43.210
Information memory stored on a external source,
they can't inquire of you, they can't challenge

00:06:43.210 --> 00:06:45.510
you, they're static.

00:06:45.510 --> 00:06:52.110
Real knowledge has to be sort of deeply embedded
in your consciousness."

00:06:52.110 --> 00:06:55.570
And Socrates thought the culture was headed
down this terrible, treacherous path that

00:06:55.570 --> 00:06:58.280
was gonna end no place good.

00:06:58.280 --> 00:07:03.590
Fortunately somebody had the good sense to
write down Socrates' disdain for the written

00:07:03.590 --> 00:07:07.600
word otherwise we wouldn't remember it; thank
you very much Plato.

00:07:07.600 --> 00:07:11.500
And well I think we would all agree that he
was overstating the case, we've had writing

00:07:11.500 --> 00:07:15.830
for a couple of millennia, we're more inclined
to see its benefits than its pitfalls.

00:07:15.830 --> 00:07:21.431
I think there's also something we can recognize
in what Socrates was concerned about, some

00:07:21.431 --> 00:07:28.720
nugget of wisdom that is especially pertinent
today and I think it has to do with the operating

00:07:28.720 --> 00:07:33.570
metaphor in how we think about memory, how
we talk about memory colloquially.

00:07:33.570 --> 00:07:39.150
I think it's the operating metaphor that's
embedded in the idea of these Google goggles

00:07:39.150 --> 00:07:44.540
and in so much else that we're doing with
technology right now, which is this notion

00:07:44.540 --> 00:07:51.729
that our memories are like a bank; we deposit
information into this bank when we encode

00:07:51.729 --> 00:07:56.540
it and we pull it back out at some later date.

00:07:56.540 --> 00:08:02.570
And that implies a kind of equivalence between
an internal memory and an external memory.

00:08:02.570 --> 00:08:10.030
Actually if I've got a bank up here and a
bank here, the bank that's hardware is a whole

00:08:10.030 --> 00:08:18.770
lot less likely to make mistakes, it's a whole
lot more durable, it is in almost every way

00:08:18.770 --> 00:08:23.220
superior to the wetware that I've got up here.

00:08:23.220 --> 00:08:29.250
And I think you find, I found this idea, this
metaphor the memory as a bank is really sort

00:08:29.250 --> 00:08:32.419
of seeped into a lot of aspects of our life.

00:08:32.419 --> 00:08:39.270
Even in school you find now kids saying, "Well
why should I learn that piece of information

00:08:39.270 --> 00:08:41.950
I can always just Google it?"

00:08:41.950 --> 00:08:46.230
And you can find teachers who seem to be agreeing
with them, "Yeah why should we teach kids

00:08:46.230 --> 00:08:52.680
facts, why should we teach kids content, we
wanna make kids into creative thinkers and

00:08:52.680 --> 00:08:57.400
to innovative thinkers, into people who can
process the world and so why should we waste

00:08:57.400 --> 00:09:02.680
our time on content, it's just gonna get forgotten
about anyways?"

00:09:02.680 --> 00:09:08.450
And I think what we're seeing is a kind of
evolution in our notion of what it means to

00:09:08.450 --> 00:09:09.790
be erudite.

00:09:09.790 --> 00:09:18.320
So for Socrates erudition meant having all
of these internally stored memories that were

00:09:18.320 --> 00:09:23.270
sort of always there at the forefront of his
mind.

00:09:23.270 --> 00:09:28.600
And I mean all the way through the late Middle
Ages you had people thinking about writing

00:09:28.600 --> 00:09:31.810
in very different terms than we do today.

00:09:31.810 --> 00:09:36.770
People wrote things down not as we do today
to sort of offload them so we don't have to

00:09:36.770 --> 00:09:40.110
remember things, people wrote things down
to aid their memories, writing was thought

00:09:40.110 --> 00:09:42.490
of as an aide memoir.

00:09:42.490 --> 00:09:52.050
We had, there's a wonderful quote by Petrarch,
he says, "I ate in the morning what I digested

00:09:52.050 --> 00:09:55.380
in the afternoon.

00:09:55.380 --> 00:09:59.430
What I swallowed as a boy I've ruminated upon
as an old man.

00:09:59.430 --> 00:10:02.120
These writings were implanted not just in
my memory but in my marrow."

00:10:02.120 --> 00:10:08.260
There was this notion that to really fully
engage with information deeply it had to be

00:10:08.260 --> 00:10:12.000
sort of integrated into your soul.

00:10:12.000 --> 00:10:18.860
It's a very different sort of notion of reading
than we have today.

00:10:18.860 --> 00:10:24.070
After Gutenberg, after books become mass produced
commodities, erudition evolves from having

00:10:24.070 --> 00:10:28.160
all this stuff stored internally to knowing
how and where to find information in this

00:10:28.160 --> 00:10:32.480
labyrinthine world of external memories, there
are now books everywhere.

00:10:32.480 --> 00:10:38.730
I'd argue that there is sort of a new kind
of, new stage in this evolution of erudition

00:10:38.730 --> 00:10:42.120
which is that we no longer have to even know
how and where to find stuff we just need to

00:10:42.120 --> 00:10:48.090
know the right set of search terms and then
Google can take care of the rest.

00:10:48.090 --> 00:10:52.810
And what I guess is problematic about this
metaphor of memory as a bank is that it's

00:10:52.810 --> 00:10:55.459
not really how our memories work.

00:10:55.459 --> 00:10:59.940
Our memories are not sequestered in some vault
in our brain they're actually always there,

00:10:59.940 --> 00:11:06.230
they are always shaping how we perceive the
world, how we make decisions in the world,

00:11:06.230 --> 00:11:11.899
how we move through the world, our judgment,
and there's this kind of continuous feedback

00:11:11.899 --> 00:11:15.040
process between our perception and our memory.

00:11:15.040 --> 00:11:19.330
Our memories are actually much less like a
bank and much more like a lens; a lens that

00:11:19.330 --> 00:11:24.980
is constantly filtering the world for us and
helping us to make sense of it.

00:11:24.980 --> 00:11:28.920
And I think this is something that we all
kind of intuitively get.

00:11:28.920 --> 00:11:35.370
I mean if I was to sit down next to a Google
engineer and look at a website we would see

00:11:35.370 --> 00:11:40.290
two very different things; we actually would
look at the world differently because of the

00:11:40.290 --> 00:11:42.830
memories that we've got floating around in
our skulls.

00:11:42.830 --> 00:11:47.560
The Google engineer would see all sorts of
things that just don't have meaning to me,

00:11:47.560 --> 00:11:50.700
that aren't relevant to me, that I don't even
understand.

00:11:50.700 --> 00:11:56.390
And likewise if we took a walk in a park because
I studied evolutionary biology in college

00:11:56.390 --> 00:12:02.060
and know a little bit about the life history
of trees, there are things that I pay attention

00:12:02.060 --> 00:12:08.260
to, things that direct sort of my attention
that might not otherwise catch another person's.

00:12:08.260 --> 00:12:12.399
And my experience of that walk in the park
is going to be qualitatively different from

00:12:12.399 --> 00:12:14.610
somebody else's.

00:12:14.610 --> 00:12:20.141
And I guess that's what is sort of the notion
behind what Petrarch was saying is look, our

00:12:20.141 --> 00:12:27.480
memories make us who we are, they're at the
root of not just our self identity but our

00:12:27.480 --> 00:12:34.610
values, our character, our judgments, our
sense of appreciation of the world.

00:12:34.610 --> 00:12:44.390
And it's not just about information as sort
of a-- well I'll tell you a story which is

00:12:44.390 --> 00:12:51.649
that not long ago I was in Shanghai doing
an assignment for National Geographic, and

00:12:51.649 --> 00:12:57.070
I went through high school not having received
even the smallest bit of education about Chinese

00:12:57.070 --> 00:13:05.149
history; I didn't know that Kublai Khan was
a real person, which in retrospect is kind

00:13:05.149 --> 00:13:06.940
of amazing.

00:13:06.940 --> 00:13:11.230
And I tried to make the best of this three
days that I had in Shanghai and I tried to

00:13:11.230 --> 00:13:16.690
go to all the museums and interpret the culture
as best I could and make sense of the history.

00:13:16.690 --> 00:13:21.830
And what I found was that not just that I
didn't know this stuff it was I didn't even

00:13:21.830 --> 00:13:27.610
have the ability to learn it; I didn't have
the basic facts to fasten other facts to.

00:13:27.610 --> 00:13:37.140
And what that suggests is the extent to which
our memories, my experience was impoverished

00:13:37.140 --> 00:13:40.089
is what it points to, my experience was impoverished.

00:13:40.089 --> 00:13:43.800
And it kinda sucked and it made me regret
the fact that I didn't know anything about

00:13:43.800 --> 00:13:45.910
Chinese history.

00:13:45.910 --> 00:13:51.380
And I guess part of what makes me nervous
about sort of this direction that technology,

00:13:51.380 --> 00:13:59.470
our culture seems to be going in, is that
in the process of privileging this kind of

00:13:59.470 --> 00:14:04.519
memory that we are devaluing the other kind
of memory, the kind of memory that actually

00:14:04.519 --> 00:14:09.050
really matters to living a rich life, to living
a good life.

00:14:09.050 --> 00:14:16.360
And there was this study that I'm sure many
of you are aware of in the Journal of Science

00:14:16.360 --> 00:14:21.279
last year that suggested that when people
know their piece of information is stored

00:14:21.279 --> 00:14:28.460
on the Internet in a computer that they invest
less of themselves in remembering it and tend

00:14:28.460 --> 00:14:32.209
to have a worse memory for that information
just because they know that it exists online.

00:14:32.209 --> 00:14:38.100
It's not that Google's making us dumb, it's
that Google is making us lazy, that's what

00:14:38.100 --> 00:14:40.930
that study really suggested.

00:14:40.930 --> 00:14:51.050
When we, when I think about this vision of
the future that Larry Page is pre-visioning

00:14:51.050 --> 00:14:57.580
of a world in which we are constantly plugged
in and constantly have the entire collective

00:14:57.580 --> 00:15:03.410
knowledge of humanity, the greater human consciousness
all sort of immediately accessible, always

00:15:03.410 --> 00:15:09.579
there, always on, I think there are gonna
be ways in which it's gonna be truly wonderful,

00:15:09.579 --> 00:15:15.350
truly glorious having access to all of the
world's information is incredible.

00:15:15.350 --> 00:15:19.880
But the thing that I hope we will keep in
mind is that infinite knowledge is not the

00:15:19.880 --> 00:15:25.670
same thing as wisdom and that I hope Google
will keep in mind as it develops all of this

00:15:25.670 --> 00:15:31.040
technology because over the next couple of
decades you guys are gonna have a power to

00:15:31.040 --> 00:15:38.040
shape our culture and shape how humans live
at a very intimate level in a way that I don't

00:15:38.040 --> 00:15:43.410
know that any institution outside of organized
religion has ever had before.

00:15:43.410 --> 00:15:52.300
And I guess my hope that what will guide you
guys is a kind of humanism.

00:15:52.300 --> 00:15:58.310
I mean think this trajectory may be inevitable
but Google and maybe a few of your competitors

00:15:58.310 --> 00:16:04.860
have the power to actually guide us in some
ways and to help shape the culture that we're

00:16:04.860 --> 00:16:06.459
creating together.

00:16:06.459 --> 00:16:13.019
And what would be a shame is if it is the
value of technologists, of how do we make

00:16:13.019 --> 00:16:19.880
life easier, how to do we make life more efficient,
how do we get that extra marginal utility

00:16:19.880 --> 00:16:22.120
which doesn't necessarily equate to the good
life.

00:16:22.120 --> 00:16:30.490
If that's what's driving us, or much worse,
the bottom line in maximizing shareholder

00:16:30.490 --> 00:16:36.700
profits, I hope that what will guide Google
is a sense of humanism, of people asking really

00:16:36.700 --> 00:16:43.240
big questions, really old questions that what
the good life really means and what are the

00:16:43.240 --> 00:16:48.079
values that we want to perpetuate in ourselves
and in humanity at large.

00:16:48.079 --> 00:16:53.079
And if you guys don't ask those questions,
if Google's not asking those questions, if

00:16:53.079 --> 00:16:56.080
Apple's not asking those questions, if Facebook's
not asking those questions, I fear we're gonna

00:16:56.080 --> 00:17:02.860
wake up in 25 years wearing our Google goggles
and having our thoughts Tweeted straight into

00:17:02.860 --> 00:17:10.280
the ether and we're gonna be like that proverbial
lobster that doesn't even realize that it's

00:17:10.280 --> 00:17:13.310
boiling itself to death; that we're gonna
wake up and we're gonna say, "Is this really

00:17:13.310 --> 00:17:14.310
good?

00:17:14.310 --> 00:17:20.089
I know my life is more efficient, more productive,
I'm more connected, I'm more, my Internet

00:17:20.089 --> 00:17:26.150
connection is faster, but am I really living
a good life and are my basic human needs in

00:17:26.150 --> 00:17:28.799
the biggest possible sense being met?

00:17:28.799 --> 00:17:32.460
And is this really the future that we wanted?"

00:17:32.460 --> 00:17:33.460
So –

00:17:33.460 --> 00:17:39.350
I guess maybe we should have a conversation
about that.

00:17:39.350 --> 00:17:43.650
I'm curious to hear what you guys think since
you all are shaping that future.

00:17:43.650 --> 00:17:47.360
Hey man, thanks for [inaudible].

00:17:47.360 --> 00:17:50.330
&gt;&gt;male #1: Hi Josh.

00:17:50.330 --> 00:17:54.049
&gt;&gt;Joshua Foer: How are ya?

00:17:54.049 --> 00:17:57.620
&gt;&gt;male #1: [chuckles] I'm good, how are you.

00:17:57.620 --> 00:18:03.150
So I mean I think the way that you're putting
this story is really kind of a story of escalating

00:18:03.150 --> 00:18:08.830
complexity; computers give us the power to
handle more complex interactions every single

00:18:08.830 --> 00:18:13.419
day; there's just more stuff that we have
to do.

00:18:13.419 --> 00:18:17.820
And of course as soon as we get the capability
to handle this we also have the capability

00:18:17.820 --> 00:18:22.080
to add more of it, right?

00:18:22.080 --> 00:18:27.990
So in this world how can we come to a situation
where we get the power to deal with complexity

00:18:27.990 --> 00:18:30.140
but we don't use that power to add more complexity?

00:18:30.140 --> 00:18:35.900
&gt;&gt;Joshua Foer: I don't know if more complexity
is necessarily bad, it's the question it's

00:18:35.900 --> 00:18:38.480
superficial complexity.

00:18:38.480 --> 00:18:47.460
So just to go back to that notion of like
the changing notion of how we read.

00:18:47.460 --> 00:18:52.530
People use to read a lot less, they read a
lot less, a lot deeper, and they really etched

00:18:52.530 --> 00:18:59.040
these ideas onto their consciousness in a
way that would seem totally alien to us today.

00:18:59.040 --> 00:19:03.080
Today you just can't do that, you can't do
that and keep up because the world is more

00:19:03.080 --> 00:19:07.090
complex; you have to read widely and that
means reading superficially.

00:19:07.090 --> 00:19:11.480
So there's always gonna be that balance.

00:19:11.480 --> 00:19:17.220
The question is we have to be like conscious
of when we've swung too far, when the pendulum

00:19:17.220 --> 00:19:20.840
has swung too far.

00:19:20.840 --> 00:19:26.830
So I don't know maybe this is just something
that like is unstoppable and that we're all

00:19:26.830 --> 00:19:34.270
kind of destined to be living in the matrix
in 250 years because that's just where technology

00:19:34.270 --> 00:19:36.040
is gonna take us and we don't have any control
over it.

00:19:36.040 --> 00:19:40.500
But I think actually we do have some control.

00:19:40.500 --> 00:19:45.700
&gt;&gt;male #1: Well but how would we exercise
that control, would we exercise that control

00:19:45.700 --> 00:19:49.600
by essentially sort of constraining choice?

00:19:49.600 --> 00:19:53.320
Is the idea saying, "Well you may think that
you want option B more than option A where

00:19:53.320 --> 00:19:59.130
option B is a more technologized, less humanized
world, but actually we know that you don't?"

00:19:59.130 --> 00:20:01.020
&gt;&gt;Joshua Foer: Yeah, maybe.

00:20:01.020 --> 00:20:11.660
Yeah because so a lot of what we're, is being
sort of created in the world and by Google

00:20:11.660 --> 00:20:16.360
is like how do we flip a little pleasure switch
in your brain or flip a little switch that

00:20:16.360 --> 00:20:20.220
gives you some sort of immediate reward?

00:20:20.220 --> 00:20:25.919
I actually get some immediate amount of pleasure
every time I check my email that is, I don't

00:20:25.919 --> 00:20:30.710
know why that is setting something off in
me that is like I wanna constantly check it,

00:20:30.710 --> 00:20:34.580
but I suspect in the big picture this is not
a good thing that I'm constantly checking

00:20:34.580 --> 00:20:37.809
my Smartphone.

00:20:37.809 --> 00:20:43.940
And so maybe for the people who are developing
Smartphones they should think about that like,

00:20:43.940 --> 00:20:49.700
"Okay so how do we create a system in which
you're not incentivized to wanna be looking

00:20:49.700 --> 00:20:52.020
at this thing every second?"

00:20:52.020 --> 00:20:56.730
I don't know how you do that but you need
to be asking that question at the very least.

00:20:56.730 --> 00:21:00.770
&gt;&gt;male #1: It seems like an odd position for
a technological determinist to take though,

00:21:00.770 --> 00:21:01.770
saying that.

00:21:01.770 --> 00:21:07.929
&gt;&gt;Joshua Foer: Well, so I think this stuff,
I think there is still some degree of control

00:21:07.929 --> 00:21:14.020
that we have over like the conditions in which
this stuff is deployed.

00:21:14.020 --> 00:21:23.799
So it may be inevitable that we'll all have
these chips plugged in whatever, but I think

00:21:23.799 --> 00:21:28.980
there are choices that are gonna be made along
the way that will shape the extent to which

00:21:28.980 --> 00:21:30.600
that is for good or for ill.

00:21:30.600 --> 00:21:34.429
&gt;&gt;male #1: Okay, I'm gonna let other people.

00:21:34.429 --> 00:21:35.860
&gt;&gt;Joshua Foer: Alright.

00:21:35.860 --> 00:21:38.730
&gt;&gt;male #1: You might wanna, oh.

00:21:38.730 --> 00:21:47.400
&gt;&gt;male #2: I find what you say very compelling
and very interesting but I always find this

00:21:47.400 --> 00:21:52.789
an odd conflict for the following reason:
you give the example kids today are saying,

00:21:52.789 --> 00:21:55.740
"Why should I learn facts, I can always go
Google 'em."

00:21:55.740 --> 00:22:02.809
Well I remember being in high school which
was a very long time ago and I remember making

00:22:02.809 --> 00:22:07.430
the same statement myself and all my friends
agreeing, "Why should we memorize this stuff,

00:22:07.430 --> 00:22:09.490
it's all in the library?"

00:22:09.490 --> 00:22:14.700
And it was sometime during college that I
came to the realization that the answer to

00:22:14.700 --> 00:22:20.410
that was, "Well if that's true then that library
down the block is the most intelligent being

00:22:20.410 --> 00:22:21.410
on the planet.

00:22:21.410 --> 00:22:25.360
If you don't believe that then you shouldn't
be making that statement."

00:22:25.360 --> 00:22:28.299
So –-

00:22:28.299 --> 00:22:34.210
it's always so easy to look at the current
state and say, "Well this is unprecedented,

00:22:34.210 --> 00:22:38.140
this hasn't happened before, we need to do
something different because we're going in

00:22:38.140 --> 00:22:40.460
the wrong direction."

00:22:40.460 --> 00:22:43.470
But it's not like this question was new when
I was in high school --

00:22:43.470 --> 00:22:45.890
&gt;&gt;Joshua Foer: Or when Socrates was in academy.

00:22:45.890 --> 00:22:46.890
[chuckles]

00:22:46.890 --> 00:22:47.890
[laughter]

00:22:47.890 --> 00:22:55.610
&gt;&gt;male #2: Yeah, and somehow we've managed
to muddle through which suggests that maybe

00:22:55.610 --> 00:22:57.510
we're asking the wrong question here.

00:22:57.510 --> 00:23:03.500
&gt;&gt;Joshua Foer: Well first of all I would say,
I mean I agree with you this is an old story,

00:23:03.500 --> 00:23:09.539
this is only sort of the latest chapter in
a conversation that we've been having truly

00:23:09.539 --> 00:23:15.160
for millennia although things seem to be accelerating
at a rate today --

00:23:15.160 --> 00:23:16.220
&gt;&gt;male #2: Um-hum.

00:23:16.220 --> 00:23:19.030
&gt;&gt;Joshua Foer: that they weren't maybe when
you were in high school.

00:23:19.030 --> 00:23:24.130
The thing I would say is look, it's true.

00:23:24.130 --> 00:23:32.260
I have all the world's information a thumb
click away right now and in a sense I know

00:23:32.260 --> 00:23:36.450
that information, there's a sense in which
that is all sort of immediately accessible

00:23:36.450 --> 00:23:43.610
to me in which if you wanna take this sort
of idea of like a self that spills –

00:23:43.610 --> 00:23:44.610
&gt;&gt;male #2: Um-hum.

00:23:44.610 --> 00:23:48.679
&gt;&gt;Joshua Foer: across the boundaries of my
epidermis and this is actually part of me,

00:23:48.679 --> 00:23:50.929
okay.

00:23:50.929 --> 00:23:56.250
But your library that is the greatest living,
smartest organism on the planet actually can't

00:23:56.250 --> 00:24:02.330
take two ideas that didn't previously go together
and put them together, can't make an insight,

00:24:02.330 --> 00:24:03.870
can't have a creative thought --

00:24:03.870 --> 00:24:04.870
&gt;&gt;male #2: Right.

00:24:04.870 --> 00:24:08.080
&gt;&gt;Joshua Foer: can't invent anything; that
still takes a human mind.

00:24:08.080 --> 00:24:13.940
And to the extent that we are impoverishing
our memories because we're saying, "Well I

00:24:13.940 --> 00:24:17.320
can always go look it up in the library, I
don't need to fill my mind with stuff, I don't

00:24:17.320 --> 00:24:21.950
need to have a furnished brain, a furnished
mind," I suspect that there are consequences

00:24:21.950 --> 00:24:25.720
to that that are very difficult to calculate.

00:24:25.720 --> 00:24:32.780
&gt;&gt;male #2: And again I agree with you a hundred
percent and yet I'm concerned that we, in

00:24:32.780 --> 00:24:37.730
every generation we look back and say, "Oh
the way we knew it when we were growing up

00:24:37.730 --> 00:24:41.700
or the way our father's knew it when we were
growing up were better, things are falling

00:24:41.700 --> 00:24:45.980
apart now."

00:24:45.980 --> 00:24:51.100
When you have such a long history of such
statements you have to ask, "Are my intuitions

00:24:51.100 --> 00:24:52.150
here really right?

00:24:52.150 --> 00:24:54.490
Am I approaching this problem the right way?"

00:24:54.490 --> 00:24:58.549
&gt;&gt;Joshua Foer: Or, "Am I actually right?"

00:24:58.549 --> 00:24:59.549
Maybe actually --

00:24:59.549 --> 00:25:00.549
&gt;&gt;male #2: Finally after all these warnings?

00:25:00.549 --> 00:25:01.549
&gt;&gt;Joshua Foer: What's that?

00:25:01.549 --> 00:25:02.549
&gt;&gt;male #2: Maybe.

00:25:02.549 --> 00:25:03.549
[chuckles]

00:25:03.549 --> 00:25:10.490
&gt;&gt;Joshua Foer: Maybe life was actually better
in some qualitatively meaningful ways for

00:25:10.490 --> 00:25:13.590
my father's generation than it is for my generation
in terms of --

00:25:13.590 --> 00:25:14.590
&gt;&gt;male #2: Could be.

00:25:14.590 --> 00:25:18.380
&gt;&gt;Joshua Foer: I think if you're a kid growing
up I think there are really like reasonable

00:25:18.380 --> 00:25:24.490
arguments to be made that my nephews who are
going to grow up absolutely glued to their

00:25:24.490 --> 00:25:30.090
computers are maybe not having as good of
a childhood as I did.

00:25:30.090 --> 00:25:35.429
&gt;&gt;male #2: We had TV before that and comic
books before that [laughs] so but I'll leave

00:25:35.429 --> 00:25:36.429
it at that.

00:25:36.429 --> 00:25:38.130
&gt;&gt;male #3: Hi, thanks for coming.

00:25:38.130 --> 00:25:39.130
&gt;&gt;Joshua Foer: Thanks.

00:25:39.130 --> 00:25:40.130
&gt;&gt;male #3: I enjoyed your book, by the way,
--

00:25:40.130 --> 00:25:41.130
&gt;&gt;Joshua Foer: Thank you.

00:25:41.130 --> 00:25:42.130
&gt;&gt;male #3: it was really great.

00:25:42.130 --> 00:25:48.350
So I would say, I have basically, my response
to you is that here's why I think it's not

00:25:48.350 --> 00:25:50.000
a big deal.

00:25:50.000 --> 00:25:53.799
For me to look up something on my Smartphone,
for example, I have a lot of externalized

00:25:53.799 --> 00:25:58.860
memories on my Smartphone, it takes a long
time for me to look this up.

00:25:58.860 --> 00:26:04.630
I mean I could probably do it in like 10 seconds,
20 seconds, but that's huge; an average Google

00:26:04.630 --> 00:26:13.630
search is much smaller than one second it's
like a few hundred milliseconds, and even

00:26:13.630 --> 00:26:18.090
if it's 800 milliseconds that's qualitatively
worse for users.

00:26:18.090 --> 00:26:24.150
So I would say that the more latency there
is before you get your answer, like you have

00:26:24.150 --> 00:26:31.150
to overcome that latency and you have to really
want to know that information; in essence

00:26:31.150 --> 00:26:35.530
it's for information when you kind of accept
that latency, it's for information that's

00:26:35.530 --> 00:26:41.260
just not that important; if it was important
you'd memorize it basically.

00:26:41.260 --> 00:26:47.120
And I think this is kind of proven by when
we interview people we tend not to ask kind

00:26:47.120 --> 00:26:51.580
of little trivia questions that people could
look up with Google, but we do ask questions

00:26:51.580 --> 00:26:57.080
that are very basic and maybe the people could
also look them up with Google, but if they

00:26:57.080 --> 00:27:00.980
were interested in the subject they would
have memorized it at this point.

00:27:00.980 --> 00:27:10.450
And so it's sort of a, I think what's in your,
there's no chance of not having a lot of memorization

00:27:10.450 --> 00:27:15.610
happen because you'll memorize stuff that
you're gonna be interested in and what you're

00:27:15.610 --> 00:27:19.010
interested in is growing more complex anyway
so it's like that is just crowding up the

00:27:19.010 --> 00:27:24.190
space of the brain, everything else goes on
to Smartphones and I think we could all live

00:27:24.190 --> 00:27:26.250
with that trade off because it's pretty efficient
actually.

00:27:26.250 --> 00:27:29.440
&gt;&gt;Joshua Foer: Isn't that exactly the case
that I'm making though that, I mean so once

00:27:29.440 --> 00:27:34.230
we've got the Google goggles that our, I mean
I know actually Google goggles is actually

00:27:34.230 --> 00:27:35.230
the name of one of your --

00:27:35.230 --> 00:27:36.230
&gt;&gt;male #3: It is.

00:27:36.230 --> 00:27:39.400
&gt;&gt;Joshua Foer: lab products which is image
search --

00:27:39.400 --> 00:27:40.400
&gt;&gt;male #3: Yes.

00:27:40.400 --> 00:27:44.360
&gt;&gt;Joshua Foer: which I presume is a stalking
horse for when that camera's gonna be sort

00:27:44.360 --> 00:27:45.760
of in my glasses and I'll immediately --

00:27:45.760 --> 00:27:47.390
&gt;&gt;male #3: Maybe, I don't know.

00:27:47.390 --> 00:27:52.169
&gt;&gt;Joshua Foer: be able to search whatever
I'm looking at and I'll have met you and I'll

00:27:52.169 --> 00:27:56.280
actually already know your name and your Facebook
profile and --

00:27:56.280 --> 00:27:57.490
&gt;&gt;male #3: That's true but that's not that
important.

00:27:57.490 --> 00:28:03.980
&gt;&gt;Joshua Foer: No but the thing is, the question
is as we sort of move towards that future

00:28:03.980 --> 00:28:08.309
where all of this information, there is no
latency, in fact it'll be calling up stuff

00:28:08.309 --> 00:28:10.980
that maybe I don't even need.

00:28:10.980 --> 00:28:16.900
How is that going to change the extent to
which we invest in bothering to learn information

00:28:16.900 --> 00:28:17.900
at all?

00:28:17.900 --> 00:28:21.049
&gt;&gt;male #3: Well I would say, first of all
I'd say there's always gonna be latency even

00:28:21.049 --> 00:28:25.500
if like in, if you're envisioning in 20 years
where we're gonna have Google goggles planted

00:28:25.500 --> 00:28:30.230
on our face at all times, even then there'll
still be latency even if it's only like a

00:28:30.230 --> 00:28:32.510
few hundred milliseconds to get answers.

00:28:32.510 --> 00:28:38.159
I think it's just inevitable that thinking
is always gonna be faster than whatever else,

00:28:38.159 --> 00:28:40.940
getting information some way and then thinking
about it.

00:28:40.940 --> 00:28:46.500
And also for stuff that you're interested
in and you want to think about it and that

00:28:46.500 --> 00:28:50.470
involves memorization as a byproduct even
if you're not even set out to memorize it.

00:28:50.470 --> 00:28:55.260
So I think it's gonna happen anyway, that
is you will memorize lots of things throughout

00:28:55.260 --> 00:28:56.260
your life.

00:28:56.260 --> 00:29:00.179
&gt;&gt;Joshua Foer: Yeah except people don't seem
to be doing that.

00:29:00.179 --> 00:29:01.179
I mean --

00:29:01.179 --> 00:29:03.120
&gt;&gt;male #3: I think it happens, I mean I think
it does happen like you --

00:29:03.120 --> 00:29:06.100
&gt;&gt;Joshua Foer: You look at like, maybe this
is another issue altogether, but you look

00:29:06.100 --> 00:29:12.520
at these statistics of kids coming out of
high school in America who don't know jack

00:29:12.520 --> 00:29:16.429
squat, 20 percent of American high school
students can't tell you who America fought

00:29:16.429 --> 00:29:17.429
in World War II.

00:29:17.429 --> 00:29:19.150
&gt;&gt;male #3: Yeah but, okay but they're probably
not interested in it.

00:29:19.150 --> 00:29:23.929
Let me give you an example that you just earlier
in this when you were talking you kind of

00:29:23.929 --> 00:29:26.750
mentioned, "Oh there was an article, there's
an article in The New York Times," and you

00:29:26.750 --> 00:29:29.130
mentioned the person who wrote it.

00:29:29.130 --> 00:29:30.130
&gt;&gt;Joshua Foer: Um-hum.

00:29:30.130 --> 00:29:33.179
&gt;&gt;male #3: You memorized that, that is all
in your memory 'cause it's really interesting

00:29:33.179 --> 00:29:36.250
to you as a writer who wrote one piece for
The New York Times.

00:29:36.250 --> 00:29:41.809
Now I heard it, it's not interesting, I mean
it is interesting but I didn't take the time

00:29:41.809 --> 00:29:42.900
to memorize that name.

00:29:42.900 --> 00:29:46.470
&gt;&gt;Joshua Foer: So I guess one response to
that is are you going to be interested in

00:29:46.470 --> 00:29:52.330
learning information when it is so immediately,
shallowly available to you?

00:29:52.330 --> 00:29:58.930
So for example, I'm walking through a park
--

00:29:58.930 --> 00:29:59.930
&gt;&gt;male #3: Um-hum.

00:29:59.930 --> 00:30:07.940
&gt;&gt;Joshua Foer: and if I want to, I take that
extra moment to learn what kind of, to identify

00:30:07.940 --> 00:30:12.690
what kind of tree this is, that kind of depth
of engagement of taking that extra moment

00:30:12.690 --> 00:30:17.730
to try and figure it out and look at the leaves
and see if I can tell what the shape is and

00:30:17.730 --> 00:30:22.659
can I make sense of this, that extra engagement
is what makes it memorable, that depth of

00:30:22.659 --> 00:30:23.700
processing.

00:30:23.700 --> 00:30:30.390
But if I can just walk up to it, take a picture
of it, and I have the answer sent right to

00:30:30.390 --> 00:30:36.210
my brain, right to my retina, then I'm not
engaging with it very deeply.

00:30:36.210 --> 00:30:38.770
I'm engaging with it superficially and it's
not gonna be memorable.

00:30:38.770 --> 00:30:39.770
&gt;&gt;male #3: Yeah but I --

00:30:39.770 --> 00:30:44.880
&gt;&gt;Joshua Foer: We're creating a culture in
which everything is kind of, you're just skimming

00:30:44.880 --> 00:30:48.419
over the surface of the world because it's
all coming at you and you're getting the pleasure

00:30:48.419 --> 00:30:55.370
of knowing that answer without actually investing
any of yourself in learning it, then are we

00:30:55.370 --> 00:31:00.070
actually going to truly have real memories
or are we just gonna have this kind of superstructure

00:31:00.070 --> 00:31:01.160
of external memories?

00:31:01.160 --> 00:31:07.029
&gt;&gt;male #3: Yeah, well I think it's all based
on interests and if you're interested the

00:31:07.029 --> 00:31:08.029
memorization will happen.

00:31:08.029 --> 00:31:09.029
But I'll let other people talk now.

00:31:09.029 --> 00:31:10.029
Thank you.

00:31:10.029 --> 00:31:11.029
&gt;&gt;Joshua Foer: Thanks.

00:31:11.029 --> 00:31:14.770
&gt;&gt;male #4: Hi, couple of quick points: thank
goodness for the bell shaped curve because

00:31:14.770 --> 00:31:19.320
you'll always have some of one and some of
the other.

00:31:19.320 --> 00:31:27.820
If you think you have the world knowledge
at your fingertips you're sadly deluded.

00:31:27.820 --> 00:31:35.779
I have done research using Google where I've
had to go to page 27 to get the correct result

00:31:35.779 --> 00:31:37.500
because the noise drowned out the signal.

00:31:37.500 --> 00:31:45.350
If you don't have the ability to think critically
like that you're just going to delude yourself

00:31:45.350 --> 00:31:51.620
and that may be a danger and one that I am
particularly concerned about.

00:31:51.620 --> 00:31:59.230
I've raised a son who's now employed full
time about almost a year which is quite an

00:31:59.230 --> 00:32:01.620
achievement for a college grad these days.

00:32:01.620 --> 00:32:07.220
And I was always asking him, "Okay now that
you've figured it out tell me what it means."

00:32:07.220 --> 00:32:11.159
Well the poor rascal ended up studying philosophy
and it's all my fault.

00:32:11.159 --> 00:32:12.159
[laughter]

00:32:12.159 --> 00:32:13.530
&gt;&gt;Joshua Foer: But he still got a job.

00:32:13.530 --> 00:32:17.590
&gt;&gt;male #4: [chuckles] He did indeed, he did
indeed and what your learn in philosophy is

00:32:17.590 --> 00:32:22.570
how to size up an argument quickly, size up
a bunch of information quickly and that is

00:32:22.570 --> 00:32:24.779
something Google can't do and I doubt Google
--

00:32:24.779 --> 00:32:25.779
&gt;&gt;Joshua Foer: Isn't that your mission?

00:32:25.779 --> 00:32:30.110
I mean isn't your mission, isn't the Google
mission to get, if the piece of information

00:32:30.110 --> 00:32:35.620
I actually want is on page 27 and that is
Google saying, "We're actually not doing a

00:32:35.620 --> 00:32:38.360
good enough job and our goal is to get it
to number one?"

00:32:38.360 --> 00:32:41.850
&gt;&gt;male #4: Right on the money.

00:32:41.850 --> 00:32:50.029
But the way we do it it's a popularity contest
and people have freedom of opinion, but I

00:32:50.029 --> 00:32:55.440
don't think people have freedom of truth and
that's where we fail.

00:32:55.440 --> 00:33:02.970
And what it takes to survive in an information
rich society is the ability to distinguish

00:33:02.970 --> 00:33:05.200
signal from noise.

00:33:05.200 --> 00:33:10.610
Socrates was right, you can have an information
dystopia and we have had it in history, it's

00:33:10.610 --> 00:33:17.720
called scholasticism where the written word
superseded observables.

00:33:17.720 --> 00:33:19.330
Okay?

00:33:19.330 --> 00:33:30.530
The danger lies in the lack of critical thinking
to where it's truly becomes if it's on the

00:33:30.530 --> 00:33:33.470
Internet it must be true.

00:33:33.470 --> 00:33:39.730
And we have to work to prevent that and I
think that's what you're trying to say if

00:33:39.730 --> 00:33:40.990
I understand you correctly.

00:33:40.990 --> 00:33:42.370
&gt;&gt;Joshua Foer: I think it's a piece of it.

00:33:42.370 --> 00:33:44.710
&gt;&gt;male #4: Yeah, a good piece of it.

00:33:44.710 --> 00:33:46.690
Anyway I could go on forever but I better
not.

00:33:46.690 --> 00:33:47.690
&gt;&gt;Joshua Foer: Thank you.

00:33:47.690 --> 00:33:48.900
&gt;&gt;male #4: Thank you.

00:33:48.900 --> 00:33:51.179
&gt;&gt;male #5: Hi, thanks for coming.

00:33:51.179 --> 00:33:52.179
I have a quick comment.

00:33:52.179 --> 00:33:55.090
I mean a lot of what you're saying here is
it's really interesting, there's a lot of

00:33:55.090 --> 00:33:58.110
tricky questions, it all kinda sounds like
a bummer too.

00:33:58.110 --> 00:33:59.110
[chuckles]

00:33:59.110 --> 00:34:03.630
One thing that occurred to me when the first
questioner was up here talking about the restriction

00:34:03.630 --> 00:34:11.069
of choice in order to I guess guide people
towards a more enriched life, it sounds like

00:34:11.069 --> 00:34:16.809
there's an analogy with nutrition and physical
health and that what we're kind of talking

00:34:16.809 --> 00:34:22.149
about is the information and experience equivalent
of junk food.

00:34:22.149 --> 00:34:28.609
That in agriculture and in food production
in general we've found ways to feed a lot

00:34:28.609 --> 00:34:36.089
more people, in the meantime we've also created
a diabetes and obesity epidemic in this country.

00:34:36.089 --> 00:34:41.429
And I think a lot of what you're saying is
kinda that same thing like when food or information

00:34:41.429 --> 00:34:46.359
is so readily available that people may not
be making conscious healthy decisions.

00:34:46.359 --> 00:34:50.459
And I think to some degree we are seeing the
pendulum swing back a little bit more like

00:34:50.459 --> 00:34:56.229
people are choosing to pay more for organic
food even though there's plenty of cheap food

00:34:56.229 --> 00:35:00.220
available on the shelves, you can always feed
yourself with junk food.

00:35:00.220 --> 00:35:01.220
Um, but --

00:35:01.220 --> 00:35:03.810
&gt;&gt;Joshua Foer: Yeah, I think that's a really
wonderful analogy that I hadn't --

00:35:03.810 --> 00:35:04.810
&gt;&gt;male #5: Yeah.

00:35:04.810 --> 00:35:07.630
&gt;&gt;Joshua Foer: really thought of and may borrow
from you.

00:35:07.630 --> 00:35:09.670
&gt;&gt;male #5: [chuckles]

00:35:09.670 --> 00:35:10.670
[laughter]

00:35:10.670 --> 00:35:14.869
And instructive in a lot of ways because I
think you're actually just starting to see

00:35:14.869 --> 00:35:22.130
sort of some of that pendulum swinging back
the other way in relation to our engagement

00:35:22.130 --> 00:35:27.680
with the Web and with ubiquitous Smartphones
and stuff.

00:35:27.680 --> 00:35:28.680
I mean --

00:35:28.680 --> 00:35:31.989
&gt;&gt;male #5: Right, I mean I think the flip
side of that is we're also, we're kind of,

00:35:31.989 --> 00:35:34.630
we're feeding a lot more people than we ever
have and we're also educating more people

00:35:34.630 --> 00:35:35.630
than we ever have.

00:35:35.630 --> 00:35:39.769
I mean you're talking, you mentioned something
about high school students not being able

00:35:39.769 --> 00:35:40.769
to recall --

00:35:40.769 --> 00:35:41.769
&gt;&gt;Joshua Foer: Um-hum.

00:35:41.769 --> 00:35:42.769
&gt;&gt;male #5: facts when they graduate.

00:35:42.769 --> 00:35:47.009
There's also I think, I don't have any numbers
on this, more high school students are graduating

00:35:47.009 --> 00:35:48.019
with the knowledge of calculus --

00:35:48.019 --> 00:35:49.019
&gt;&gt;Joshua Foer: Um-hum.

00:35:49.019 --> 00:35:50.650
&gt;&gt;male #5: than ever did before.

00:35:50.650 --> 00:35:56.140
So maybe we're shifting more toward skills
rather than facts and like we're talking about

00:35:56.140 --> 00:35:57.140
creative synthesis.

00:35:57.140 --> 00:36:02.160
I think you're right though without a sort
of a basis of knowledge that there's nothing

00:36:02.160 --> 00:36:08.530
to synthesis and that your brain has to have
something to work in order to be able to generate

00:36:08.530 --> 00:36:09.530
those --

00:36:09.530 --> 00:36:10.530
&gt;&gt;Joshua Foer: Yeah, well I --

00:36:10.530 --> 00:36:11.530
&gt;&gt;male #5: experiences.

00:36:11.530 --> 00:36:13.150
&gt;&gt;Joshua Foer: so I think you're right.

00:36:13.150 --> 00:36:18.180
In everything we do there are costs and benefits
and the question is how do we think about

00:36:18.180 --> 00:36:19.480
them in relation to each other?

00:36:19.480 --> 00:36:25.789
And with respect to nutrition like people
started having a big conversation --

00:36:25.789 --> 00:36:26.789
&gt;&gt;male #5: Right.

00:36:26.789 --> 00:36:30.670
&gt;&gt;Joshua Foer: like a really epically big
conversation that involved scientists, involved

00:36:30.670 --> 00:36:37.009
the government, involved farmers, involved
consumers, McDonald's, K-Mart --

00:36:37.009 --> 00:36:42.160
&gt;&gt;male #5: And this really only seemed to
happen like after we discovered that we have

00:36:42.160 --> 00:36:43.160
big problems.

00:36:43.160 --> 00:36:44.160
&gt;&gt;Joshua Foer: Right.

00:36:44.160 --> 00:36:47.579
&gt;&gt;male #5: So we may be sort of on the way
up of the pendulum swing right now with this

00:36:47.579 --> 00:36:53.140
information problem and we may have to go
pretty far before, as you mentioned like some

00:36:53.140 --> 00:36:57.839
people start to say, "Well maybe this isn't
right, maybe this isn't what we want."

00:36:57.839 --> 00:37:04.980
And I think it's a small number of people
still who are swinging back in the realm of

00:37:04.980 --> 00:37:05.980
nutrition.

00:37:05.980 --> 00:37:10.930
I mean you have shows like The Biggest Loser
on TV, but people are becoming aware of this

00:37:10.930 --> 00:37:15.069
but it's still not, I mean a lot of people
are still eating really crappy food all the

00:37:15.069 --> 00:37:16.069
time, everyday.

00:37:16.069 --> 00:37:20.739
&gt;&gt;Joshua Foer: So my question is how does
Google like embed this kind, maybe it is,

00:37:20.739 --> 00:37:30.700
embed this kind of big think questioning into
how you guys direct your resources and think

00:37:30.700 --> 00:37:33.869
about shaping the culture in which we live.

00:37:33.869 --> 00:37:35.960
&gt;&gt;male #5: Yeah, I think that's a big question
for us.

00:37:35.960 --> 00:37:40.569
I mean how do we continue to use technology
to make our lives better rather than just

00:37:40.569 --> 00:37:41.569
easier --

00:37:41.569 --> 00:37:42.569
&gt;&gt;Joshua Foer: Right.

00:37:42.569 --> 00:37:43.569
&gt;&gt;male #5: or more [unintelligible].

00:37:43.569 --> 00:37:44.569
&gt;&gt;Joshua Foer: Right, what is better?

00:37:44.569 --> 00:37:45.569
&gt;&gt;male #5: Yeah.

00:37:45.569 --> 00:37:46.569
&gt;&gt;Joshua Foer: So, thanks.

00:37:46.569 --> 00:37:47.569
&gt;&gt;male #5: Yeah.

00:37:47.569 --> 00:37:48.569
&gt;&gt;male #2: You should probably take him first
--

00:37:48.569 --> 00:37:49.569
&gt;&gt;Joshua Foer: Yeah.

00:37:49.569 --> 00:37:50.569
&gt;&gt;male #2: 'cause I just came back up.

00:37:50.569 --> 00:37:51.569
Go ahead.

00:37:51.569 --> 00:37:52.569
&gt;&gt;male #6: Thank you for coming.

00:37:52.569 --> 00:37:58.040
I haven't read your book yet although I've
read one of the articles based on your book.

00:37:58.040 --> 00:38:02.460
I think you're sort of posing a false dichotomy
here.

00:38:02.460 --> 00:38:08.269
And you discussed that people know a lot of
things very shallowly whereas previously you

00:38:08.269 --> 00:38:13.660
would read one or two books and think about
them very deeply for a long time.

00:38:13.660 --> 00:38:20.809
And yet you still see people nowadays devoting
their entire lives to a single subject, a

00:38:20.809 --> 00:38:26.369
single train of thought sometimes and kids
right out of college, kids right out of high

00:38:26.369 --> 00:38:29.200
school do this.

00:38:29.200 --> 00:38:35.960
I don't know that it is so much a matter of
we are being trained to think about things

00:38:35.960 --> 00:38:42.630
shallowly, to remember things shallowly because
this information is so much at our fingertips

00:38:42.630 --> 00:38:50.690
as it is we know that we can develop the richer
context in a shorter time.

00:38:50.690 --> 00:38:53.019
You talked about your trip to Shanghai was
it?

00:38:53.019 --> 00:38:54.019
&gt;&gt;Joshua Foer: Um-hum.

00:38:54.019 --> 00:38:59.709
&gt;&gt;male #6: That basically you came in with
no preparation and you spent three days going

00:38:59.709 --> 00:39:06.280
to the museums and came away with nothing
'cause you had no context to attach it to.

00:39:06.280 --> 00:39:13.859
Whereas in 25 years from now with your Google
implant you could spend the plane ride over

00:39:13.859 --> 00:39:20.450
developing the sort of knowledge base that
20 years ago would have taken you three months

00:39:20.450 --> 00:39:23.459
and 14 trips to the library to develop.

00:39:23.459 --> 00:39:24.459
&gt;&gt;Joshua Foer: Um-hum.

00:39:24.459 --> 00:39:32.440
&gt;&gt;male #6: And yeah that context may not be
as fully textured as the one you would have

00:39:32.440 --> 00:39:37.279
had 20 years ago, but if you retain the interest
in the subject --

00:39:37.279 --> 00:39:38.279
&gt;&gt;Joshua Foer: Um-hum.

00:39:38.279 --> 00:39:41.200
&gt;&gt;male #6: I think you can develop the richer
context faster.

00:39:41.200 --> 00:39:42.240
&gt;&gt;Joshua Foer: Um-hum.

00:39:42.240 --> 00:39:47.829
&gt;&gt;male #6: And you can see this with if you've
ever met a six year old who's just developed

00:39:47.829 --> 00:39:50.170
an interest in dinosaurs.

00:39:50.170 --> 00:39:56.660
Within one month they can rattle off 50 to
100 species and they'll know the physical

00:39:56.660 --> 00:39:59.459
characteristics of these things.

00:39:59.459 --> 00:40:04.890
And if they retain the interest within three
months they'll know the names of the paleontologist

00:40:04.890 --> 00:40:09.509
who dug them up and like the techniques and
where they were discovered.

00:40:09.509 --> 00:40:16.719
It's more a matter of if you have the interest
the tools are becoming more available for

00:40:16.719 --> 00:40:17.989
you to develop the context –

00:40:17.989 --> 00:40:18.989
&gt;&gt;Joshua Foer: Um-hum.

00:40:18.989 --> 00:40:21.109
&gt;&gt;male #6: but it relies on you having the
interest.

00:40:21.109 --> 00:40:22.109
&gt;&gt;Joshua Foer: Yeah.

00:40:22.109 --> 00:40:28.829
So I really love that and I think maybe the
way to pose the question is like how do we

00:40:28.829 --> 00:40:37.329
use these tools to develop that kind of depth?

00:40:37.329 --> 00:40:42.609
I'm sure that, I'm very confident that the
same technology we're talking about can be

00:40:42.609 --> 00:40:49.030
used to make people have richer experiences,
deeper experiences, have like fuller mental

00:40:49.030 --> 00:40:50.030
lives.

00:40:50.030 --> 00:40:54.349
And the question is how do we design what
we're creating so that it does that and --

00:40:54.349 --> 00:40:56.329
&gt;&gt;male #6: Not an easy problem.

00:40:56.329 --> 00:40:57.329
No.

00:40:57.329 --> 00:40:59.089
&gt;&gt;Joshua Foer: Not an easy problem, but one
I hope you guys will think about.

00:40:59.089 --> 00:41:00.259
&gt;&gt;male #6: Okay.

00:41:00.259 --> 00:41:01.430
&gt;&gt;Joshua Foer: Yeah.

00:41:01.430 --> 00:41:06.440
&gt;&gt;male #2: Alright I asked earlier about are
we asking the wrong question and I found it

00:41:06.440 --> 00:41:11.029
fascinating 'cause the very next person came
up and asked a number of questions and as

00:41:11.029 --> 00:41:17.749
you two talked you fell into exactly the trap
you warned about earlier, which was that you

00:41:17.749 --> 00:41:25.599
talked about memory, human memory, as if it
were just like the external memory, it's just

00:41:25.599 --> 00:41:26.599
this data bank.

00:41:26.599 --> 00:41:30.089
You were talking about a series of facts;
do kids come out of high school knowing --

00:41:30.089 --> 00:41:31.089
&gt;&gt;Joshua Foer: Um-hum.

00:41:31.089 --> 00:41:34.819
&gt;&gt;male #2: a bunch of facts, which completely
misses the point.

00:41:34.819 --> 00:41:37.569
Facts are irrelevant, that's not what we really
learn.

00:41:37.569 --> 00:41:43.459
There are the classic studies I think it was
by Simon on expert chess players.

00:41:43.459 --> 00:41:44.459
&gt;&gt;Joshua Foer: Um-hum.

00:41:44.459 --> 00:41:47.890
&gt;&gt;male #2: Expert chess players have memorized
thousands upon thousands of games.

00:41:47.890 --> 00:41:53.869
They can look at a board position and memorize
it within seconds, but only if it's an actual

00:41:53.869 --> 00:41:55.160
board position that makes sense.

00:41:55.160 --> 00:41:58.230
If you give them a board position with just
pieces randomly [ inaudible ] around that

00:41:58.230 --> 00:42:04.140
they're no better than somebody who's never
seen a game of chess before.

00:42:04.140 --> 00:42:10.150
What we learn, I mean the reason that we learn,
that we are able to retain facts is because

00:42:10.150 --> 00:42:11.750
we learn certain ways of thinking --

00:42:11.750 --> 00:42:12.750
&gt;&gt;Joshua Foer: Right.

00:42:12.750 --> 00:42:14.779
&gt;&gt;male #2: within which the facts fit.

00:42:14.779 --> 00:42:18.839
If you know about evolutionary biology and
you look at trees it's not the fact that you

00:42:18.839 --> 00:42:23.359
know the names of the trees, anyone can memorize
a list of names of trees; that gives them

00:42:23.359 --> 00:42:28.789
no understanding of how the trees fit together
into the ecosystem, how they evolved, what's

00:42:28.789 --> 00:42:30.930
important, what's not.

00:42:30.930 --> 00:42:36.050
It doesn't seem to me that anything that you're
saying about the easy availability of facts

00:42:36.050 --> 00:42:46.749
has anything whatsoever to do with our ability
and need to develop understandings.

00:42:46.749 --> 00:42:53.959
It may tempt us to think that we can be experts
if we simply have access to a bunch of facts,

00:42:53.959 --> 00:42:56.390
it's not true, it never was true.

00:42:56.390 --> 00:42:59.709
The other final thing that's interesting there's
been a lot study on this about what it takes

00:42:59.709 --> 00:43:00.709
to become an expert.

00:43:00.709 --> 00:43:01.709
&gt;&gt;Joshua Foer: Yes.

00:43:01.709 --> 00:43:02.709
&gt;&gt;male #2: What expertise really takes.

00:43:02.709 --> 00:43:03.779
&gt;&gt;Joshua Foer: Have you read my book Moonwalking
With Einstein available in the back?

00:43:03.779 --> 00:43:04.779
[laughter]

00:43:04.779 --> 00:43:05.779
&gt;&gt;male #2: Okay.

00:43:05.779 --> 00:43:06.779
&gt;&gt;Joshua Foer: [chuckles] [inaudible]

00:43:06.779 --> 00:43:07.779
&gt;&gt;male #2: And one interesting thing about
it is it takes about 10 years.

00:43:07.779 --> 00:43:08.779
&gt;&gt;Joshua Foer: Right.

00:43:08.779 --> 00:43:13.079
&gt;&gt;male #2: And it's always taken about 10
years and nothing we've done has changed that.

00:43:13.079 --> 00:43:14.079
&gt;&gt;Joshua Foer: Right.

00:43:14.079 --> 00:43:17.049
&gt;&gt;male #2: So why are we so worried?

00:43:17.049 --> 00:43:23.310
What is it that you, if you look at it in
those terms, is there something about, even

00:43:23.310 --> 00:43:27.510
assume the technology trends goin' the direction
you're going is there something in there that

00:43:27.510 --> 00:43:30.369
would lead you to believe that people will
not become experts?

00:43:30.369 --> 00:43:36.539
&gt;&gt;Joshua Foer: Yeah, so this is, I think this
is actually the essence of it which is that,

00:43:36.539 --> 00:43:37.670
so with chess, right?

00:43:37.670 --> 00:43:38.809
&gt;&gt;male #2: Um-hum.

00:43:38.809 --> 00:43:42.959
&gt;&gt;Joshua Foer: It's not that people become
chess experts from memorizing lots and lots

00:43:42.959 --> 00:43:43.959
–

00:43:43.959 --> 00:43:44.959
&gt;&gt;male #2: Um-hum.

00:43:44.959 --> 00:43:46.279
&gt;&gt;Joshua Foer: of games, it's that, the causality
works in the other direction.

00:43:46.279 --> 00:43:47.279
It's that --

00:43:47.279 --> 00:43:48.279
&gt;&gt;male #2: Correct.

00:43:48.279 --> 00:43:51.479
&gt;&gt;Joshua Foer: by having played lots of games,
having been invested in the sport of chess

00:43:51.479 --> 00:43:52.479
for a long time –

00:43:52.479 --> 00:43:53.479
&gt;&gt;male #2: Um-hum.

00:43:53.479 --> 00:43:56.829
&gt;&gt;Joshua Foer: they develop terrific memories
for chess because they have this deeper way

00:43:56.829 --> 00:43:57.829
of thinking --

00:43:57.829 --> 00:43:58.829
&gt;&gt;male #2: Um-hum.

00:43:58.829 --> 00:44:01.699
&gt;&gt;Joshua Foer: more context, they see dynamics,
they see structure, they see all sorts of

00:44:01.699 --> 00:44:02.699
--

00:44:02.699 --> 00:44:03.699
&gt;&gt;male #2: Um-hum.

00:44:03.699 --> 00:44:04.699
&gt;&gt;Joshua Foer: all sorts of things that I
don't see when I look at a chess game.

00:44:04.699 --> 00:44:08.499
And this is true of experts in every possible
discipline that's ever been studied.

00:44:08.499 --> 00:44:13.349
Something about achieving expertise brings
with it a terrific memory for the details

00:44:13.349 --> 00:44:14.509
of that field.

00:44:14.509 --> 00:44:22.489
The question is when the details are easy
to come by, when they are, we don't have to,

00:44:22.489 --> 00:44:30.589
when they're just sort of fed to us does that
kind of superficial knowledge make us somehow

00:44:30.589 --> 00:44:37.670
less likely to invest in the kind of way that
it would take to be a real expert.

00:44:37.670 --> 00:44:41.650
So if you're a chess player and you've got
the answers constantly being funneled into

00:44:41.650 --> 00:44:44.519
your heads up display you're never gonna become
a good chess player.

00:44:44.519 --> 00:44:48.719
&gt;&gt;male #2: That's right and if your interest
was in chess you will quickly discover that

00:44:48.719 --> 00:44:50.229
that's the wrong way to go about it.

00:44:50.229 --> 00:44:51.229
&gt;&gt;Joshua Foer: Right.

00:44:51.229 --> 00:44:52.229
&gt;&gt;male #2: What's new here?

00:44:52.229 --> 00:44:58.270
I mean people have been experts on baseball
statistics for generations; they memorize

00:44:58.270 --> 00:45:03.809
huge numbers of baseball statistics, a completely
useless bit of mental --

00:45:03.809 --> 00:45:05.479
[laughter]

00:45:05.479 --> 00:45:08.329
stuff by any kind of outside measure.

00:45:08.329 --> 00:45:12.690
I mean if you're into that kind of thing,
you're into that kind of thing.

00:45:12.690 --> 00:45:13.690
So what?

00:45:13.690 --> 00:45:16.140
I mean that stuff has always been there for
anyone to look up.

00:45:16.140 --> 00:45:17.140
&gt;&gt;Joshua Foer: That's true.

00:45:17.140 --> 00:45:22.009
&gt;&gt;male #2: Has it made baseball any more or
less inter, well it's been more interesting,

00:45:22.009 --> 00:45:26.329
actually it's made it more interesting, the
statistics draw a lot of people into the game.

00:45:26.329 --> 00:45:28.599
How has it made it less interesting?

00:45:28.599 --> 00:45:32.970
How has it made people less interested in
playing the game, in watching the game?

00:45:32.970 --> 00:45:36.880
&gt;&gt;Joshua Foer: So that's trivia, when we're
talking about --

00:45:36.880 --> 00:45:41.160
&gt;&gt;male #2: Maybe to you, maybe to me [laughs]
no but some people --

00:45:41.160 --> 00:45:44.069
&gt;&gt;Joshua Foer: If we take that metaphor of
chess --

00:45:44.069 --> 00:45:45.069
&gt;&gt;male #2: Um-hum.

00:45:45.069 --> 00:45:49.180
&gt;&gt;Joshua Foer: which I think is a useful metaphor
that we can apply more broadly to sort of

00:45:49.180 --> 00:45:58.329
all areas in which people develop hard earned
expertise and a sort of a deeper way of thinking

00:45:58.329 --> 00:46:02.339
about the world, a deeper way of seeing.

00:46:02.339 --> 00:46:06.709
Truly an expert chess player looks at a board
differently, I mean activates different regions

00:46:06.709 --> 00:46:10.299
of the brain than I do when they look at the
board.

00:46:10.299 --> 00:46:16.190
It's, the question is --

00:46:16.190 --> 00:46:25.190
if the answers are always there and immediately
accessible how is that going to affect knowledge

00:46:25.190 --> 00:46:27.140
in the bigger picture in all sorts of disciplines?

00:46:27.140 --> 00:46:33.680
&gt;&gt;male #2: I will only suggest that in your
answer that well, chess, that the baseball

00:46:33.680 --> 00:46:40.390
statistics is just trivia: any field in which
simply having the recorded answers is sufficient

00:46:40.390 --> 00:46:42.509
is just trivia so why worry about it?

00:46:42.509 --> 00:46:46.069
&gt;&gt;Joshua Foer: That's, no don't think that's
right.

00:46:46.069 --> 00:46:51.930
I don't think that's right I think to go back
to our walk through the park --

00:46:51.930 --> 00:46:54.869
&gt;&gt;male #2: But that's not sufficient.

00:46:54.869 --> 00:46:58.690
You understand things at a deeper level than
someone who simply knows the names of all

00:46:58.690 --> 00:46:59.690
the trees.

00:46:59.690 --> 00:47:03.029
&gt;&gt;Joshua Foer: So one of the Google goggles
apps, I don't know if it's been developed

00:47:03.029 --> 00:47:06.400
or in development will take a picture of a
leaf and tell you what kind of tree it is.

00:47:06.400 --> 00:47:07.400
&gt;&gt;male #2: Yeah, and --

00:47:07.400 --> 00:47:08.400
&gt;&gt;Joshua Foer: So that is trivia --

00:47:08.400 --> 00:47:09.400
&gt;&gt;male #2: Yeah.

00:47:09.400 --> 00:47:10.400
&gt;&gt;Joshua Foer: but understanding why --

00:47:10.400 --> 00:47:11.400
&gt;&gt;male #2: [inaudible]

00:47:11.400 --> 00:47:12.400
&gt;&gt;Joshua Foer: this leaf is --

00:47:12.400 --> 00:47:20.119
&gt;&gt;male #2: Say again and what I'm suggesting
to you is if having such a perfect app which

00:47:20.119 --> 00:47:23.430
tells you everything about a leaf --

00:47:23.430 --> 00:47:24.430
&gt;&gt;Joshua Foer: Um-hum.

00:47:24.430 --> 00:47:28.240
&gt;&gt;male #2: just from taking a picture of it
defines everything there is about the field,

00:47:28.240 --> 00:47:29.240
then the field is trivia --

00:47:29.240 --> 00:47:30.240
&gt;&gt;Joshua Foer: Actually --

00:47:30.240 --> 00:47:31.240
&gt;&gt;male #2: and who cares?

00:47:31.240 --> 00:47:33.880
&gt;&gt;Joshua Foer: the question will people who
have all this --

00:47:33.880 --> 00:47:34.880
&gt;&gt;male #2: Hasn't stopped --

00:47:34.880 --> 00:47:36.910
&gt;&gt;Joshua Foer: stuff constantly channeled
into them, are they gonna bother?

00:47:36.910 --> 00:47:42.170
Are they gonna be like content to just get
that extra little kick that –

00:47:42.170 --> 00:47:43.170
&gt;&gt;male #2: Um-hum.

00:47:43.170 --> 00:47:44.420
&gt;&gt;Joshua Foer: they get from knowing that
piece of information and moving on?

00:47:44.420 --> 00:47:46.519
&gt;&gt;male #2: Do you see any evidence that they
are?

00:47:46.519 --> 00:47:49.369
&gt;&gt;Joshua Foer: I do, yeah

00:47:49.369 --> 00:47:50.369
&gt;&gt;male #2: Oh.

00:47:50.369 --> 00:47:51.369
&gt;&gt;Joshua Foer: Yeah I do.

00:47:51.369 --> 00:47:58.039
I see it in my own life in how I browse the
Internet, in how I like hopscotch around and

00:47:58.039 --> 00:47:59.710
in how I read.

00:47:59.710 --> 00:48:06.609
I mean I see it in my own, I don't know, do
people not see that in their own lives this

00:48:06.609 --> 00:48:10.861
sort of sense of, "I'm not really engaging
as deeply as I used to or that could be?"

00:48:10.861 --> 00:48:12.020
I see --

00:48:12.020 --> 00:48:15.119
&gt;&gt;male #2: I can answer for myself.

00:48:15.119 --> 00:48:20.410
&gt;&gt;Joshua Foer: I see it in personal interactions
with people that I'm tempted to constantly

00:48:20.410 --> 00:48:26.589
be picking up my phone and looking at it which
is a form of like ADD, I mean it's like I'm

00:48:26.589 --> 00:48:33.910
not paying attention, my mind is elsewhere,
I'm doing something else and not engaging

00:48:33.910 --> 00:48:36.709
in the way that will make my life richer,
make my life better.

00:48:36.709 --> 00:48:38.180
I don't know.

00:48:38.180 --> 00:48:40.160
Yeah, thank you though.

00:48:40.160 --> 00:48:45.339
&gt;&gt;male #7: Hi, thanks for coming to speak
to us today, really enjoyed the topic and

00:48:45.339 --> 00:48:51.819
I appreciate the dilemma that you're bringing
up of super intelligence versus wisdom and

00:48:51.819 --> 00:48:55.729
I just sort of belated thoughts: one is on
the analogy of like the library being the

00:48:55.729 --> 00:49:01.269
most intelligent being if that those were
the same idea.

00:49:01.269 --> 00:49:05.480
So I think the idea of, the challenge that
you're bringing to us is valuable and we should

00:49:05.480 --> 00:49:09.700
be thinking about it, but at the same time
maybe it's not proper that Google should be

00:49:09.700 --> 00:49:13.319
the place that sort of solves it, we're trying
to be the world's best librarian in a sense

00:49:13.319 --> 00:49:16.569
and what you're saying is that that's not
sufficient and I agree.

00:49:16.569 --> 00:49:20.660
I'm sure many of my colleagues agree, but
it's more of a cultural question: how do we

00:49:20.660 --> 00:49:23.319
make wisdom out of intelligence?

00:49:23.319 --> 00:49:27.759
And I thought, I personally grew up in a sort
of religious Jewish day school and we always

00:49:27.759 --> 00:49:33.430
were arguing about stories, ethics, morals
[clears throat] we read books over 2,000,

00:49:33.430 --> 00:49:37.349
3,000 years old and I think that's what the
distinction that you're bringing up is like

00:49:37.349 --> 00:49:39.269
stories versus facts.

00:49:39.269 --> 00:49:43.280
So I have my particular way of coming to that
and I'm sure everyone had their own and I

00:49:43.280 --> 00:49:49.809
guess the thought to me is, is there a way
of having this general discussion a valid

00:49:49.809 --> 00:49:54.410
question without a particular way of coming
to stories?

00:49:54.410 --> 00:50:00.079
I have my own particular background is there
a way of having a common way of doing that

00:50:00.079 --> 00:50:01.329
to the whole culture?

00:50:01.329 --> 00:50:04.349
&gt;&gt;Joshua Foer: See I think that is your responsibility.

00:50:04.349 --> 00:50:15.339
I think Google has become much more than just
a librarian and is becoming more and more

00:50:15.339 --> 00:50:23.619
intimately involved in what it means to think
and to, I mean when you talk about the goggles,

00:50:23.619 --> 00:50:28.109
by the way, [chuckles] maybe that's a myth,
maybe the goggles aren't even coming.

00:50:28.109 --> 00:50:29.390
But in any case --

00:50:29.390 --> 00:50:31.809
&gt;&gt;male #7: It could.

00:50:31.809 --> 00:50:38.700
&gt;&gt;Joshua Foer: if we're talking about a company,
a technology that is mediating our direct

00:50:38.700 --> 00:50:45.089
experience of reality on a moment by moment
basis that's like we're in the realm of like

00:50:45.089 --> 00:50:54.420
the spiritual here in terms of what kind of
power that technology can wield upon us.

00:50:54.420 --> 00:50:59.049
And I think it is Google, whoever creates
this whether it's Apple or you guys or both

00:50:59.049 --> 00:51:04.439
of you guys or you create it and they copy
you --

00:51:04.439 --> 00:51:07.230
that's incredible power and it brings with
it incredible –

00:51:07.230 --> 00:51:08.230
&gt;&gt;male #7: Um-hum.

00:51:08.230 --> 00:51:09.230
&gt;&gt;Joshua Foer: responsibility.

00:51:09.230 --> 00:51:10.230
&gt;&gt;male #7: I agree with that.

00:51:10.230 --> 00:51:11.619
I didn't mean it as a way of shrugging off
or we shouldn't have to worry about that,

00:51:11.619 --> 00:51:15.449
I meant more it's a bigger question, it shouldn't
be relegated to one company.

00:51:15.449 --> 00:51:21.170
In a sense those goggles would be the ultimate
reference librarian but that is to point out

00:51:21.170 --> 00:51:23.279
to your issue that that's not the same as
knowledge.

00:51:23.279 --> 00:51:31.249
We should be coming up with a culture as appreciation
that that's merely one side of a coin or multifaceted

00:51:31.249 --> 00:51:36.619
object that as a measure of humility we shouldn't
be thinking, "Oh we can come up with a way

00:51:36.619 --> 00:51:37.619
to solve that problem."

00:51:37.619 --> 00:51:40.859
Any one company I don't think should have
that expectation.

00:51:40.859 --> 00:51:46.630
We can become the best, fulfill our company's
mission making information universally accessible,

00:51:46.630 --> 00:51:50.440
that's different than trying to push wisdom
onto everyone in the world and I think it

00:51:50.440 --> 00:51:51.950
should remain that way.

00:51:51.950 --> 00:51:54.519
&gt;&gt;Joshua Foer: I'm not sure that they're so
separable.

00:51:54.519 --> 00:51:57.339
That's I guess my response.

00:51:57.339 --> 00:52:00.869
&gt;&gt;male #7: Okay, thanks.

00:52:00.869 --> 00:52:03.509
&gt;&gt;Joshua Foer: Thanks.

00:52:03.509 --> 00:52:05.910
A couple more minutes.

00:52:05.910 --> 00:52:09.150
Does anyone have any other questions?

00:52:09.150 --> 00:52:10.150
Okay.

00:52:10.150 --> 00:52:11.349
Maybe we'll call it a day then.

00:52:11.349 --> 00:52:12.349
[applause]

00:52:12.349 --> 00:52:13.349
Thank you.

00:52:13.349 --> 00:52:13.350
[applause]

