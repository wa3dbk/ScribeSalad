WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.690
&gt;&gt; Welcome everyone to an Authors at Google
talk.

00:00:03.690 --> 00:00:07.380
We are very pleased to have Sam Harris here.

00:00:07.380 --> 00:00:12.990
And to introduce him, we have Jed Salazar.

00:00:12.990 --> 00:00:13.990
Thank you.

00:00:13.990 --> 00:00:17.381
&gt;&gt;Jed Salazar: Hi everyone.

00:00:17.381 --> 00:00:21.619
I'd like to welcome Sam Harris to Google Santa
Monica.

00:00:21.619 --> 00:00:24.170
And to give you a little bit of background
about Sam Harris.

00:00:24.170 --> 00:00:28.789
Sam Harris has written two bestselling books
 -- "The End of Faith" and "A Letter to a

00:00:28.789 --> 00:00:30.269
Christian Nation".

00:00:30.269 --> 00:00:36.159
Sam has appeared on, has appeared on countless
shows and has written many publications.

00:00:36.159 --> 00:00:42.690
He received his degree from Stanford in philosophy,
has studied religion for many years, and most

00:00:42.690 --> 00:00:50.600
recently has received his PH.D in neuroscience
from UCLA.

00:00:50.600 --> 00:00:56.399
Sam is also a co-founder and CEO of the Reason
Project which is a non-profit foundation devoted

00:00:56.399 --> 00:00:59.969
to spreading scientific knowledge and secular
values in society.

00:00:59.969 --> 00:01:03.761
And without further ado, I'd like to welcome
Sam.

00:01:03.761 --> 00:01:05.040
[Applause]

00:01:05.040 --> 00:01:13.109
&gt;&gt;Sam Harris: Well thank you Jed, and thank
you for the invitation to speak here.

00:01:13.109 --> 00:01:15.340
It's an honor to speak here.

00:01:15.340 --> 00:01:17.920
I'm gonna be giving a talk I've never given
before.

00:01:17.920 --> 00:01:22.899
So you will have the luxury of telling me
whether I made any sense at the end.

00:01:22.899 --> 00:01:25.969
Hopefully I'll leave a good chunk of time
for a conversation.

00:01:25.969 --> 00:01:34.829
I'm gonna speak about human values and about
morality and how we can understand these scientifically

00:01:34.829 --> 00:01:41.030
and in fact not only understand descriptively
what people are doing in the name of morality

00:01:41.030 --> 00:01:47.289
and human values, but actually come up with
scientific answers to moral questions.

00:01:47.289 --> 00:01:50.630
It's widely believed that there is no way
of doing this.

00:01:50.630 --> 00:01:56.939
That the most important questions in human
life -- like what to live for and what to

00:01:56.939 --> 00:02:04.170
die for and what constitutes a good life -- are
by definition outside the purview of scientific

00:02:04.170 --> 00:02:05.170
objectivity.

00:02:05.170 --> 00:02:12.019
And so I'm gonna try to give you a framework
for seeing that that's not so.

00:02:12.019 --> 00:02:18.780
But it's believed that, that facts and values
are distinct and dissimilar kinds of things

00:02:18.780 --> 00:02:23.150
 -- that our talk about one does not translate
into talk about the other.

00:02:23.150 --> 00:02:30.239
There's no description of the way the world
is that can get you to a description of the

00:02:30.239 --> 00:02:31.920
way the world ought to be.

00:02:31.920 --> 00:02:39.659
And that's, we have David Hume and G. E. Moore
and Karl Popper in philosophy telling us that

00:02:39.659 --> 00:02:40.750
that's so.

00:02:40.750 --> 00:02:45.170
And most scientists have simply swallowed
that philosophy whole.

00:02:45.170 --> 00:02:52.290
I'm gonna argue that that's not true and that
it's crucial that we see that it's not true.

00:02:52.290 --> 00:02:57.180
Because it seems to me the only way we can
get to a world in which we converge on the

00:02:57.180 --> 00:03:08.330
same kinds of moral, environmental, political,
social solutions to global problems -- the

00:03:08.330 --> 00:03:12.049
only way we can get there is to have some
kind of universal framework for talking about

00:03:12.049 --> 00:03:16.060
right and wrong and good and evil.

00:03:16.060 --> 00:03:22.159
And what we've been left with, what this fragmentation
of our discourse has given us, is that it

00:03:22.159 --> 00:03:27.159
has delivered us into a world where the only
people who claim to be moral experts -- indeed

00:03:27.159 --> 00:03:33.030
the only people who claim that there's such
a thing as moral expertise are religious demagogues

00:03:33.030 --> 00:03:35.099
of one or another flavor.

00:03:35.099 --> 00:03:40.409
And this has shattered our world into these
separate moral communities where there is

00:03:40.409 --> 00:03:50.450
just no, there's nothing for a fundamentalist
Christian to say to a Islamist to bridge their

00:03:50.450 --> 00:03:52.090
mutually incompatible world views.

00:03:52.090 --> 00:03:59.170
And so I wanted -- I'll talk for a minute
about why religion can't be the repository

00:03:59.170 --> 00:04:03.930
of our moral wisdom and our notion of the
good life.

00:04:03.930 --> 00:04:10.049
But, the crucial bit to take on board at this
point is that, it's only religion that is

00:04:10.049 --> 00:04:13.310
saying that there are right and wrong answers
to moral questions.

00:04:13.310 --> 00:04:17.040
And the scientific community has more or less
said, "You're right.

00:04:17.040 --> 00:04:23.671
Science and reason can never give you a universal
framework for moral questions."

00:04:23.671 --> 00:04:30.981
Now we should have been able to see that religion
wasn't gonna give us a universal framework.

00:04:30.981 --> 00:04:35.500
Because as Bertrand Russell pointed out over
a century ago, there's such a bewildering

00:04:35.500 --> 00:04:42.171
number of religions on offer, making mutually
incompatible claims about the nature of reality

00:04:42.171 --> 00:04:47.980
and how to live within it that even if we
knew one of our religions was perfectly true,

00:04:47.980 --> 00:04:54.350
even if we knew this was God's multiple choice
exam, is it A) Hinduism B) Buddhism C) Shamanism.

00:04:54.350 --> 00:05:01.220
There are so many religions that every believer
should expect damnation purely as a matter

00:05:01.220 --> 00:05:03.890
of probability.

00:05:03.890 --> 00:05:06.050
So it seems to me that should end the argument.

00:05:06.050 --> 00:05:10.630
It hasn't, but in any case, Russell had that
right.

00:05:10.630 --> 00:05:16.200
Another way to see that religion isn't tracking
reality as it is, is this is a world map of

00:05:16.200 --> 00:05:18.030
religious denominations.

00:05:18.030 --> 00:05:24.410
You can see that this is not the way genuine
knowledge should be partitioned in our world.

00:05:24.410 --> 00:05:28.170
It shouldn't follow national or political
boundaries.

00:05:28.170 --> 00:05:29.480
Take India as an example.

00:05:29.480 --> 00:05:37.490
India, Nepal, the main places on earth where
they seem to have discovered that there's

00:05:37.490 --> 00:05:41.950
not just one god of Abraham to worry about,
but there's a multiplicity of god.

00:05:41.950 --> 00:05:44.830
There's thousands and thousands of Gods.

00:05:44.830 --> 00:05:49.780
What are the chances that they, among all
the earth's people, have discovered that the

00:05:49.780 --> 00:05:54.780
elephant headed God Ganesh really exists and
needs to be propitiated?

00:05:54.780 --> 00:06:00.880
Does anyone think this is the way human knowledge
is developing?

00:06:00.880 --> 00:06:01.880
I don't think so.

00:06:01.880 --> 00:06:07.060
In any case, the contradictions between faiths
are only one of the problems.

00:06:07.060 --> 00:06:10.450
And within any faith, you have impressive
patterns of contradictions.

00:06:10.450 --> 00:06:15.940
So this is an image of contradictions within
the Bible – both the Old and New Testament.

00:06:15.940 --> 00:06:24.410
And every arc is a verse that contradicts
another verse and the grey bars, or the depth

00:06:24.410 --> 00:06:29.520
of the grey bars indicate the number of verses
in each chapter of each book.

00:06:29.520 --> 00:06:32.320
And these are real, these are deal breaking
contradictions.

00:06:32.320 --> 00:06:38.350
These are John the Baptist was in prison when
Jesus went into Galilee, John the Baptist

00:06:38.350 --> 00:06:41.230
was not in prison when Jesus went to Galilee.

00:06:41.230 --> 00:06:46.430
These are moments when the text refutes itself.

00:06:46.430 --> 00:06:50.340
And then there's the inconvenient fact that
some of the easiest moral questions that we

00:06:50.340 --> 00:06:53.920
have ever had to solve religion gets wrong.

00:06:53.920 --> 00:06:56.750
The Bible and the Koran both support slavery.

00:06:56.750 --> 00:07:04.690
There's absolutely no question that theology
was on the side of the slave holders during

00:07:04.690 --> 00:07:10.150
our long effort to get rid of slavery as Jefferson
Davis, the President of the Confederacy pointed

00:07:10.150 --> 00:07:12.140
out.
Slavery was established by the decree of Almighty

00:07:12.140 --> 00:07:16.040
God -- it's sanctioned in the bible in both
testaments from Genesis to Revelation.

00:07:16.040 --> 00:07:17.730
This is true.

00:07:17.730 --> 00:07:27.200
There's no one of any flavor of Christian,
Muslim or Jew who can deny that fact intelligibly.

00:07:27.200 --> 00:07:34.040
And so it seems to me that if the easiest
and most significant moral questions are not

00:07:34.040 --> 00:07:41.130
solved by these scriptural traditions, in
fact are where we get the wrong answer, from

00:07:41.130 --> 00:07:42.130
these traditions.

00:07:42.130 --> 00:07:48.100
We have to recognize that our moral wisdom
is not coming from these texts and when you

00:07:48.100 --> 00:07:54.770
go to the texts and pick and choose the wise
bits, as you have to, given what's in them,

00:07:54.770 --> 00:07:59.420
when you notice for instance that the Golden
Rule is a very wise moral precept and we should

00:07:59.420 --> 00:08:04.470
take that on board, and then you notice that
there are other rules, like if a woman is

00:08:04.470 --> 00:08:09.500
not a virgin on her wedding night, she should
be stoned to death on her father's doorstep.

00:08:09.500 --> 00:08:12.660
That rule hasn't aged very well.

00:08:12.660 --> 00:08:16.780
That process of picking and choosing is clearly
something that we bring to the text.

00:08:16.780 --> 00:08:22.650
This is not -- we're not getting it from the
text, we are having to bowdlerize the text

00:08:22.650 --> 00:08:27.470
based on our own moral intuitions and based
on a larger conversation about the nature

00:08:27.470 --> 00:08:33.979
of human flourishing and human well being.

00:08:33.979 --> 00:08:40.110
You can also see that this gap between facts
and values looks a little suspicious when

00:08:40.110 --> 00:08:43.219
you look at how we talk about facts and values.

00:08:43.219 --> 00:08:45.410
We talk in terms of belief.

00:08:45.410 --> 00:08:47.509
We believe things about the nature of reality.

00:08:47.509 --> 00:08:52.220
We make assertions about what is so in the
world.

00:08:52.220 --> 00:08:58.920
We make assertions about facts, we form scientific
beliefs and this includes history and journalism

00:08:58.920 --> 00:09:04.819
and any other type of conversation where we're
saying how the world is.

00:09:04.819 --> 00:09:06.700
But we also form beliefs about values.

00:09:06.700 --> 00:09:13.490
We talk about morality and meaning and spiritual
principles and it's often thought that these

00:09:13.490 --> 00:09:15.620
are radically different acts.

00:09:15.620 --> 00:09:22.089
But I have thought for a long time that belief
is in some sense content neutral.

00:09:22.089 --> 00:09:28.579
So that to make a claim about say chemistry,
water is two parts hydrogen and one part oxygen

00:09:28.579 --> 00:09:34.779
is very much like making a claim in ethics
 -- like it's good to be kind to children.

00:09:34.779 --> 00:09:39.680
This may not, this is certainly not intuitive
for most people, but this is the way it has

00:09:39.680 --> 00:09:41.089
seemed to me for quite some time.

00:09:41.089 --> 00:09:44.709
And we did some FMRI work which seems to have
borne this out.

00:09:44.709 --> 00:09:47.209
We've put people in the scanner.

00:09:47.209 --> 00:09:53.350
We gave them propositions to read to judge
either true or false and then we compared

00:09:53.350 --> 00:09:54.930
belief to disbelief.

00:09:54.930 --> 00:10:01.360
And on the left you have all stimuli which
gave us this very localized region of signal

00:10:01.360 --> 00:10:07.610
in the ventromedial pre-frontal cortex and
then we were able to break out some of our

00:10:07.610 --> 00:10:09.259
individual categories of belief.

00:10:09.259 --> 00:10:14.769
And here I break out mathematics and ethics
which are perhaps the most different kinds

00:10:14.769 --> 00:10:15.769
of stimuli.

00:10:15.769 --> 00:10:23.470
Mathematics was just mathematical equations
that were true or false: 2+2=4 versus 2+2=5.

00:10:23.470 --> 00:10:28.670
Ethics was statements like it's good to be
kind to children versus it's good to beat

00:10:28.670 --> 00:10:31.730
your children.

00:10:31.730 --> 00:10:38.930
And while the overlap isn't perfect, it's
by the standards of neuroimaging, it's quite

00:10:38.930 --> 00:10:39.930
close.

00:10:39.930 --> 00:10:45.209
And I'm reasonably confident that we can say
that the main reporter of belief in the brain,

00:10:45.209 --> 00:10:50.730
this region of the frontal lobe is content
independent.

00:10:50.730 --> 00:10:56.089
And this region's involved in self-representation
and reward.

00:10:56.089 --> 00:11:02.129
And so when you make judgments of self-relevance,
this is the region you get in other studies.

00:11:02.129 --> 00:11:09.120
And so I think of belief as a kind of extension
of the self.

00:11:09.120 --> 00:11:12.889
When you believe a proposition, when someone
says something and you think, "Yeah that's

00:11:12.889 --> 00:11:20.670
true", you are in some sense taking it in
hand as part of your cognitive emotional repertoire.

00:11:20.670 --> 00:11:26.269
You're saying, "Yes I can use this, this is
gonna inform my emotion and behavior."

00:11:26.269 --> 00:11:30.529
There was a question after we did this study
whether religious belief was distinct.

00:11:30.529 --> 00:11:32.850
And so we ran another study.

00:11:32.850 --> 00:11:38.579
We used religion in that first study, but
we weren't able to break out the data.

00:11:38.579 --> 00:11:45.620
So we did a study just on religious versus
ordinary belief with -- and this time we selected

00:11:45.620 --> 00:11:46.620
believers and non-believers.

00:11:46.620 --> 00:11:50.290
So we had two separate groups of subjects
and we gave them very simple statements to

00:11:50.290 --> 00:11:51.290
read.

00:11:51.290 --> 00:11:54.360
The biblical God really exists versus the
biblical god is a myth.

00:11:54.360 --> 00:12:01.309
And so the atheists in our study would answer
the factual question the same way as the Christians,

00:12:01.309 --> 00:12:02.309
and vice-versa.

00:12:02.309 --> 00:12:05.749
But they would be diametrically opposed on
religious statements.

00:12:05.749 --> 00:12:07.680
And we essentially got the same result.

00:12:07.680 --> 00:12:14.309
This region of the ventromedial pre-frontal
cortex is apparently the reporter of belief

00:12:14.309 --> 00:12:23.620
in both Christians and non-believers on both
religious and non-religious subjects, topics.

00:12:23.620 --> 00:12:30.529
So what I propose to you is that belief is
something -- is a way that we attempt to map

00:12:30.529 --> 00:12:34.899
our thoughts onto reality, whatever reality
is altogether.

00:12:34.899 --> 00:12:40.940
And where we seem to succeed in this process,
we call it knowledge, where our talk about

00:12:40.940 --> 00:12:45.949
reality functions in such a way that it's
reliable that it becomes a guide to the future,

00:12:45.949 --> 00:12:49.939
where we have significant consensus, that
we're making sense.

00:12:49.939 --> 00:12:52.579
We're calling this knowledge.

00:12:52.579 --> 00:12:57.029
There are other obviously a lot of our beliefs
don't map onto reality in any, with any kind

00:12:57.029 --> 00:12:58.029
of fluidity.

00:12:58.029 --> 00:12:59.769
And so we -- they're false.

00:12:59.769 --> 00:13:06.779
You can see there's a region where beliefs
are mapping on, but we don't call it knowledge,

00:13:06.779 --> 00:13:12.250
and that's all of the beliefs people have
about the world that are right essentially

00:13:12.250 --> 00:13:13.250
by accident.

00:13:13.250 --> 00:13:20.689
It's possible to believe things for bad reasons,
believe true things for bad reasons.

00:13:20.689 --> 00:13:28.579
In any case, that's just to say that religion
doesn't have some special corner on the market

00:13:28.579 --> 00:13:30.370
of value based talk.

00:13:30.370 --> 00:13:36.160
And there are many reasons to think that it
is not the best source of value talk.

00:13:36.160 --> 00:13:42.149
But the thing that religious people are right
about, even the bible thumpers and the jihadists

00:13:42.149 --> 00:13:49.910
of the world, people who we might be critical
of in all other respects, they're right to

00:13:49.910 --> 00:13:52.129
think that we need a universal morality.

00:13:52.129 --> 00:13:55.850
And it's long been obvious that we need a
universal morality.

00:13:55.850 --> 00:14:02.559
In the immediate aftermath of World War II,
the UN tried to put forward a universal declaration

00:14:02.559 --> 00:14:03.829
of human rights.

00:14:03.829 --> 00:14:08.569
And the American Anthropological association
in all its wisdom said, "This is a fool's

00:14:08.569 --> 00:14:13.970
errand. There is no universal declaration
of human rights because any effort to make

00:14:13.970 --> 00:14:24.550
a universal notion of human value is merely
to foist your provincial white colonial merely

00:14:24.550 --> 00:14:32.579
local version of the truth onto the rest of
humanity. It has no intellectual legitimacy,

00:14:32.579 --> 00:14:34.959
this project."

00:14:34.959 --> 00:14:38.839
So, but please notice this is the best our
social sciences could do.

00:14:38.839 --> 00:14:44.310
Essentially with the crematory of Auschwitz
still smoking and this was in 1947.

00:14:44.310 --> 00:14:47.000
So how have we gotten here?

00:14:47.000 --> 00:14:53.330
Well, it seems to me we have a double standard
in how we treat differences of opinion in

00:14:53.330 --> 00:14:54.330
the moral sphere.

00:14:54.330 --> 00:15:00.360
So you confront moral difference.

00:15:00.360 --> 00:15:03.959
For instance, a difference of opinion between
someone like the Dalai Lama and someone like

00:15:03.959 --> 00:15:10.529
Ted Bundy, the Dalai Lama wakes up every morning
thinking that maximizing compassion and helping

00:15:10.529 --> 00:15:17.059
other people is an integral part of human
happiness and this is what his attention is

00:15:17.059 --> 00:15:19.730
purposed toward for the most part.

00:15:19.730 --> 00:15:24.809
Then you have someone like Ted Bundy who woke
up every morning trying to think of which

00:15:24.809 --> 00:15:30.110
young woman he was gonna abduct and rape and
torture and kill -- and I think he killed

00:15:30.110 --> 00:15:33.129
something like 28 of them.

00:15:33.129 --> 00:15:34.161
A difference of opinion.

00:15:34.161 --> 00:15:38.170
I mean these are irreconcilable moral views.

00:15:38.170 --> 00:15:42.809
Many people take this disparity to suggest
that there is no ground truth.

00:15:42.809 --> 00:15:49.249
There's nothing Ted Bundy can be wrong about
and that the Dalai Lama can be right about.

00:15:49.249 --> 00:15:53.059
That is -- that gives us any kind of moral
bedrock.

00:15:53.059 --> 00:15:56.209
They have a difference of opinion obviously.

00:15:56.209 --> 00:16:02.050
He likes chocolate, he likes vanilla but no
one is wrong in any deep sense that cuts to

00:16:02.050 --> 00:16:03.181
the nature or reality.

00:16:03.181 --> 00:16:07.649
Now notice that we don't do this in Science.

00:16:07.649 --> 00:16:09.119
You take Physics, for example.

00:16:09.119 --> 00:16:13.740
On the left you have Edward Witten -- he's
a real physicist's physicist.

00:16:13.740 --> 00:16:19.230
He's -- if you ask the smartest physicist's
around, who's the smartest physicist around?

00:16:19.230 --> 00:16:23.579
Half of them in my experience will tell you
it's Ed Witten.

00:16:23.579 --> 00:16:27.540
The other half will tell you they don't like
the question.

00:16:27.540 --> 00:16:31.790
In any case, Ed Witten's one of the patriarchs
of string theory.

00:16:31.790 --> 00:16:35.189
He thinks it's the greatest thing since sliced
bread.

00:16:35.189 --> 00:16:41.509
What would happen if I showed up at a physics
conference and said string theory is bogus?

00:16:41.509 --> 00:16:43.119
It's not my cup of tea.

00:16:43.119 --> 00:16:46.980
It doesn't resonate with me, it's not how
I choose to view the universe at the smallest

00:16:46.980 --> 00:16:47.980
scale.

00:16:47.980 --> 00:16:53.040
Well nothing would happen because no one would
care and that's just the point.

00:16:53.040 --> 00:16:55.439
My opinion does not count.

00:16:55.439 --> 00:16:58.209
I'm not adequate to the conversation about
string theory.

00:16:58.209 --> 00:17:00.800
I don't have the mathematical expertise.

00:17:00.800 --> 00:17:03.910
I don't understand string theory.

00:17:03.910 --> 00:17:07.300
And this is what it is to have a domain of
expertise.

00:17:07.300 --> 00:17:11.410
Certain opinions can't count.

00:17:11.410 --> 00:17:17.250
We have convinced ourselves somehow that in
the moral domain, everyone gets a vote, that

00:17:17.250 --> 00:17:22.110
Epistemology has to run by democratic principles.

00:17:22.110 --> 00:17:23.339
Every opinion counts equally.

00:17:23.339 --> 00:17:25.500
There's no such thing as moral expertise.

00:17:25.500 --> 00:17:26.990
There's no such thing as moral talent.

00:17:26.990 --> 00:17:31.410
There's no such thing as moral genius.

00:17:31.410 --> 00:17:35.360
So I would argue that that's almost certainly
untrue.

00:17:35.360 --> 00:17:39.390
Another way we've gotten here is we look at
certain moral dilemmas.

00:17:39.390 --> 00:17:41.530
How many of you have seen the trolley problem?

00:17:41.530 --> 00:17:47.250
This is kind of ubiquitous in philosophy and
psychology at the moment.

00:17:47.250 --> 00:17:51.960
So there's a trolley, a runaway car coming
down the track.

00:17:51.960 --> 00:17:55.490
If you do nothing it's going to hit 5 workmen
on the track.

00:17:55.490 --> 00:18:00.400
But you stand at the switch, and you can throw
the switch diverting it so that it will only

00:18:00.400 --> 00:18:04.950
hit one workman, saving a net 4 lives.

00:18:04.950 --> 00:18:08.391
How many of you think it would be a good thing
to do to throw this switch?

00:18:08.391 --> 00:18:14.549
You're gonna save -- it's either 5 or 1, someone's
gonna die.

00:18:14.549 --> 00:18:18.770
Well, most people when you test this, something
like 90% of people think that yes, you have

00:18:18.770 --> 00:18:21.350
a moral obligation to throw the switch.

00:18:21.350 --> 00:18:28.480
But when you describe it under another guise,
now you stand at a -- on a foot bridge.

00:18:28.480 --> 00:18:31.500
The same car is coming down the track destined
to hit 5 people.

00:18:31.500 --> 00:18:37.120
But you are beside a suitably large person
whom you can physically push into the path

00:18:37.120 --> 00:18:39.590
of the oncoming trolley.

00:18:39.590 --> 00:18:42.270
And he will die, but he will stop the trolley.

00:18:42.270 --> 00:18:45.190
Now I happen to think this is not so well
posed.

00:18:45.190 --> 00:18:49.640
We all have an intuitive physics which causes
us to burn a lot of fuel wondering whether

00:18:49.640 --> 00:18:51.060
he's really gonna stop the trolley.

00:18:51.060 --> 00:18:58.020
But if you stipulate that he will stop the
trolley, it still feels like a different problem.

00:18:58.020 --> 00:19:02.120
This pushes our intuitions around.

00:19:02.120 --> 00:19:08.000
People come away from this dilemma thinking
there's no there there.

00:19:08.000 --> 00:19:13.230
There's no way, you frame it one way, 90 people,
90% of people say yes.

00:19:13.230 --> 00:19:17.190
IF you frame it another way, 90% of people
say no.

00:19:17.190 --> 00:19:18.530
There's no ground truth.

00:19:18.530 --> 00:19:23.880
Now notice that we don't do this when we confront
logical dilemmas.

00:19:23.880 --> 00:19:25.790
How many of you know the Monty Hall problem?

00:19:25.790 --> 00:19:30.630
How many of you know that you know the right
answer to the Monty Hall problem?

00:19:30.630 --> 00:19:32.160
OK, there's a few.

00:19:32.160 --> 00:19:36.340
You're on a game show, you've got three doors.

00:19:36.340 --> 00:19:40.460
Behind one is a new car, behind the other
two are goats.

00:19:40.460 --> 00:19:46.090
You pick door number one, and your host opens
door number 2 revealing a goat.

00:19:46.090 --> 00:19:50.870
He now gives you a choice to switch to door
number 3.

00:19:50.870 --> 00:19:55.280
So you pick door number 1, you can switch
to door number 3.

00:19:55.280 --> 00:20:00.520
How many of you think you should switch, that
it's wise to switch?

00:20:00.520 --> 00:20:05.150
How many of you think it's 50/50 and there's
no reason to switch?

00:20:05.150 --> 00:20:12.030
OK, well you should switch, and many people
don't see that you should switch and even

00:20:12.030 --> 00:20:14.350
when it's explained to them over and over
again.

00:20:14.350 --> 00:20:19.100
Do you have an answer to this?

00:20:19.100 --> 00:20:20.100
&gt;&gt; [Inaudible]

00:20:20.100 --> 00:20:21.461
&gt;&gt;Sam: What was that?

00:20:21.461 --> 00:20:24.500
&gt;&gt; [Inaudible]

00:20:24.500 --> 00:20:27.531
&gt;&gt;Sam: Right.

00:20:27.531 --> 00:20:30.070
&gt;&gt;[Inaudible]

00:20:30.070 --> 00:20:40.780
Sam: Well this is, in this case he's clearly
not going to reveal the car with three doors,

00:20:40.780 --> 00:20:42.120
and he's only revealed a goat.

00:20:42.120 --> 00:20:43.740
&gt;&gt; [Inaudible]

00:20:43.740 --> 00:20:48.070
&gt;&gt;Sam: OK, but he hasn't [Inaudible]

00:20:48.070 --> 00:20:49.220
&gt;&gt; [Inaudible]

00:20:49.220 --> 00:20:50.370
[Laughter]

00:20:50.370 --> 00:21:02.450
&gt;&gt;Sam: With those stipulations, in this case,
let's assume those are valid.

00:21:02.450 --> 00:21:06.830
People -- when you explain this problem to
people, people are logically dumbfounded.

00:21:06.830 --> 00:21:12.640
We have a very strong intuition that with
two doors remaining, why would you switch?

00:21:12.640 --> 00:21:16.920
There's a car behind one, there's a goat behind
another -- we know this.

00:21:16.920 --> 00:21:18.130
Two doors are closed.

00:21:18.130 --> 00:21:21.410
You have a 50/50 chance that your first pick
was right.

00:21:21.410 --> 00:21:24.390
Well you don't you have a one in three chance.

00:21:24.390 --> 00:21:25.590
And switching gets you to 2/3.

00:21:25.590 --> 00:21:29.560
This is actually easier to see if you imagine
1,000 doors.

00:21:29.560 --> 00:21:36.490
And you pick door number 1 and then Monty
Hell invalidates 998 doors leaving door 576

00:21:36.490 --> 00:21:38.010
that you have never thought of.

00:21:38.010 --> 00:21:40.160
Should you switch to door 576?

00:21:40.160 --> 00:21:46.310
Well, you had significant uncertainty when
you made your initial choice.

00:21:46.310 --> 00:21:49.230
The chance was 1/1000 that you pick the right
door.

00:21:49.230 --> 00:21:55.520
Here that remaining probability of 999 out
of 1000, that collapses on the one remaining

00:21:55.520 --> 00:21:56.700
door.

00:21:56.700 --> 00:21:58.331
It's obvious that you should switch.

00:21:58.331 --> 00:22:03.480
But the point is for many people it's not
obvious, even when they've had it explained

00:22:03.480 --> 00:22:09.390
to them in terms of probability, they can
fall back into this intuition of why, why

00:22:09.390 --> 00:22:11.200
you switch.

00:22:11.200 --> 00:22:16.391
We don't leave this thinking -- well so there's
no right answer to the Monty Hall problem.

00:22:16.391 --> 00:22:19.350
There's no such thing as logical high ground.

00:22:19.350 --> 00:22:22.840
This is not a domain where we can have objective
knowledge.

00:22:22.840 --> 00:22:28.640
So to give you a framework for thinking about
how we can have objective knowledge about

00:22:28.640 --> 00:22:30.530
human values.

00:22:30.530 --> 00:22:38.030
It seems to me it arrives rather easily the
moment you realize that human values, or values

00:22:38.030 --> 00:22:41.600
of any kind reduce to a certain form of fact.

00:22:41.600 --> 00:22:48.210
They reduce to facts about the experience
of conscious beings, anything that can have

00:22:48.210 --> 00:22:52.800
happiness or suffering, anything that can
experience value on any level.

00:22:52.800 --> 00:22:59.310
So, why is it when you see a piece of broken
glass, you don't feel compassion, you don't

00:22:59.310 --> 00:23:02.840
worry that there's some terrible suffering
involved?

00:23:02.840 --> 00:23:05.490
Because you don't think there's anything we
can do to glass to make it suffer.

00:23:05.490 --> 00:23:08.300
You don't think that's a domain of experience.

00:23:08.300 --> 00:23:13.980
And if we care more about our fellow primates
than we care about insects, which we do, it's

00:23:13.980 --> 00:23:19.410
because we've drawn analogies, based on their
behavior and their underlying neurology such

00:23:19.410 --> 00:23:24.390
that we think they -- primates experience
a broader range of possible happiness and

00:23:24.390 --> 00:23:26.720
suffering than insects.

00:23:26.720 --> 00:23:30.470
Now the important point here is that this
is a factual claim.

00:23:30.470 --> 00:23:32.530
This is a claim about which we can be right
or wrong.

00:23:32.530 --> 00:23:39.030
It's possible that we have misconstrued the
neurology of ants, or we've misconstrued the

00:23:39.030 --> 00:23:44.030
relationship between physical complexity and
the possibilities of experience.

00:23:44.030 --> 00:23:49.340
And if we've misconstrued those things, then
maybe we'll have to revise our notion of possible

00:23:49.340 --> 00:23:51.870
ant value.

00:23:51.870 --> 00:24:00.310
But again, the cash value of value is in terms
of changes in conscious experience, actual

00:24:00.310 --> 00:24:03.070
or potential changes in conscious experience.

00:24:03.070 --> 00:24:08.730
And this is true, even if your values are
focused on another life.

00:24:08.730 --> 00:24:13.530
Even if you think that after death you're
either gonna be consigned to some kind of

00:24:13.530 --> 00:24:18.540
paradise for eternity or you're gonna wind
up in hell for eternity.

00:24:18.540 --> 00:24:23.770
Again, the thing you're worried about is the
experience of anything that can suffer an

00:24:23.770 --> 00:24:25.640
eternity of either kind.

00:24:25.640 --> 00:24:28.940
Obviously it wouldn't be realized at the level
of the brain in this case.

00:24:28.940 --> 00:24:34.910
But whatever is doing the knowing is the thing
you're worried about.

00:24:34.910 --> 00:24:41.230
And clearly there's a continuum of human experience
to speak exclusively about people now this

00:24:41.230 --> 00:24:42.230
side of the grave.

00:24:42.230 --> 00:24:48.400
There's a continuum of experience that we
recognize and movement on this continuum is

00:24:48.400 --> 00:24:49.990
fact based.

00:24:49.990 --> 00:24:52.450
There are right and wrong answers to how to
move.

00:24:52.450 --> 00:24:58.170
We know that you can live in a condition where
basically everything that can go wrong does

00:24:58.170 --> 00:24:59.170
go wrong.

00:24:59.170 --> 00:25:02.950
You can live in a failed state where it's
impossible to feed your children, where you

00:25:02.950 --> 00:25:10.260
can't reasonably form an expectation of collaborating
with a stranger because it's essentially a

00:25:10.260 --> 00:25:13.220
war of all against all.

00:25:13.220 --> 00:25:18.410
And we know it's possible to move rightward
in this -- on this continuum to something

00:25:18.410 --> 00:25:25.570
far more idyllic, something far more like
the kinds of lives we live where we have the

00:25:25.570 --> 00:25:33.270
freedom to have -- general freedom from violence,
freedom to use our time, to get educated,

00:25:33.270 --> 00:25:35.900
to pursue various interests, to enjoy our
lives.

00:25:35.900 --> 00:25:39.620
And no doubt this continuum extends further
in both directions.

00:25:39.620 --> 00:25:45.030
There are greater possibilities of human happiness,
and greater possibility of human misery than

00:25:45.030 --> 00:25:49.920
any of us have visualized, very likely.

00:25:49.920 --> 00:25:54.120
And there are many levels of analysis for
this continuum.

00:25:54.120 --> 00:25:59.430
There's a level certainly to talk about the
human genome and biochemistry and molecular

00:25:59.430 --> 00:26:06.590
biology, especially given that fact that we
are poised to meddle with our own genomes.

00:26:06.590 --> 00:26:13.500
Any changes we make relevant to the possibilities
of experiencing human well being are morally

00:26:13.500 --> 00:26:16.200
salient.

00:26:16.200 --> 00:26:22.140
And then in a much higher level of resolution,
we can talk about economic systems and political

00:26:22.140 --> 00:26:25.820
understandings and laws that govern financial
institutions.

00:26:25.820 --> 00:26:30.730
All of this materially affects human well
being and there are right and wrong answers

00:26:30.730 --> 00:26:35.990
to how those things will have consequences
in our lives.

00:26:35.990 --> 00:26:42.220
But the moment you're talking about human
well being, you are of necessity talking about

00:26:42.220 --> 00:26:46.780
changes in states and the function of the
human brain.

00:26:46.780 --> 00:26:51.630
So I would argue the mind sciences have a
kind of a privileged role to play here and

00:26:51.630 --> 00:26:58.780
that morality at some level is an undeveloped
branch of neuroscience and psychology and

00:26:58.780 --> 00:27:02.340
the sciences that treat our experience.

00:27:02.340 --> 00:27:12.120
Because any change in our experience is we
know being realized in the brain, and it is

00:27:12.120 --> 00:27:18.260
impressively constrained by the facts at the
level of the brain.

00:27:18.260 --> 00:27:24.130
And so what I suggest to you is the moment
you realize that there is a fact space both

00:27:24.130 --> 00:27:31.010
actual and potential that governs human value
and value of any kind, then I'm asking you

00:27:31.010 --> 00:27:38.810
to visualize what I'm calling a moral landscape
that has peaks and valleys where different

00:27:38.810 --> 00:27:43.510
possible ways of being are realized.

00:27:43.510 --> 00:27:47.001
And, one thing to notice is that there are
many peaks, very likely.

00:27:47.001 --> 00:27:51.150
There are probably many ways to be more or
less equivalently happy.

00:27:51.150 --> 00:27:56.710
There are probably many ways to organize a
human community that could be quite distinct,

00:27:56.710 --> 00:28:01.860
but nonetheless, allow for the same kind of
human flourishing.

00:28:01.860 --> 00:28:03.660
Now, why isn't this a problem?

00:28:03.660 --> 00:28:08.060
Why doesn't this erode any sort of objectivity
here?

00:28:08.060 --> 00:28:13.420
Well, think of how we think about -- and again
there are many different, obviously not just

00:28:13.420 --> 00:28:15.910
two, there are many different peaks.

00:28:15.910 --> 00:28:18.860
Think of how we think about food.

00:28:18.860 --> 00:28:23.690
No one would ever be tempted to argue that
there's one right food to eat.

00:28:23.690 --> 00:28:28.650
But there is a right or wrong answer to the
question of is this healthy food.

00:28:28.650 --> 00:28:32.020
There's a real distinction between food and
poison.

00:28:32.020 --> 00:28:37.390
There are many, many things we can eat that
are healthy to eat, that are appropriately

00:28:37.390 --> 00:28:39.230
called food.

00:28:39.230 --> 00:28:40.230
There are exceptions here.

00:28:40.230 --> 00:28:44.500
Some people are allergic to peanuts and will
die if they eat peanuts.

00:28:44.500 --> 00:28:51.490
But we can understand all of this within a
rational discussion about chemistry and human

00:28:51.490 --> 00:28:52.490
biology.

00:28:52.490 --> 00:28:59.410
And no one would ever -- the fact that the
set of all things that are food is still essentially

00:28:59.410 --> 00:29:04.390
open ended and that never tempts someone to
say there are no right and wrong answers to

00:29:04.390 --> 00:29:07.890
questions of human nutrition.

00:29:07.890 --> 00:29:13.230
So to with a, you can throw out an analogy
to a game like chess.

00:29:13.230 --> 00:29:18.020
It bothers people that certain moral precepts
admit of exceptions.

00:29:18.020 --> 00:29:20.700
So you take a precept like don't lie.

00:29:20.700 --> 00:29:23.960
Right, is don't lie a good moral precept?

00:29:23.960 --> 00:29:25.600
It's right most of the time, say.

00:29:25.600 --> 00:29:27.240
But there are exceptions.

00:29:27.240 --> 00:29:34.310
And people take this, the fact of the exceptions
to suggest, "Well then there is no real objective

00:29:34.310 --> 00:29:35.900
morality regarding lying."

00:29:35.900 --> 00:29:40.400
Well, don't lose your queen is a good precept
to take in chess.

00:29:40.400 --> 00:29:44.980
If you want to play winning chess, it's something
to keep in mind certainly most of the time.

00:29:44.980 --> 00:29:47.470
But obviously there are exceptions.

00:29:47.470 --> 00:29:51.890
There are moments where losing your queen
is the only good move, or a brilliant move.

00:29:51.890 --> 00:29:55.490
Chess is a domain of absolute objectivity.

00:29:55.490 --> 00:30:00.220
We could in principle if not in practice diagram
every possibly chess game.

00:30:00.220 --> 00:30:09.420
And it is true to say that a move is a good
move or a bad move in chess which brings us

00:30:09.420 --> 00:30:12.820
to moments of moral diversity.

00:30:12.820 --> 00:30:19.980
We are in a world where we must confront different
answers to questions of morality.

00:30:19.980 --> 00:30:25.510
Not everyone sees that don't lose your queen
is a good principle in this particular chess

00:30:25.510 --> 00:30:26.510
game.

00:30:26.510 --> 00:30:30.870
So you have someone like Sayyid Qutub, every
Jihadist's favorite philosopher.

00:30:30.870 --> 00:30:33.330
Certainly Osama Bin Laden's favorite philosopher.

00:30:33.330 --> 00:30:40.760
He lived in the United States in for six months
in 1949 in Greely, Colorado, and formed a

00:30:40.760 --> 00:30:43.860
lasting impression of American culture.

00:30:43.860 --> 00:30:49.180
He wrote that "the American girl is well acquainted
with her body's seductive capacity.

00:30:49.180 --> 00:30:53.360
She knows it lies in the face, and in expressive
eyes and thirsty lips.

00:30:53.360 --> 00:30:57.410
She knows seductiveness lies in the round
breasts, the full buttocks and in the shapely

00:30:57.410 --> 00:30:59.280
thighs, sleek legs.

00:30:59.280 --> 00:31:01.080
She shows all of this and does not hide it."

00:31:01.080 --> 00:31:07.850
I mean it seems to me never before have we
had one man's sexual frustrations so obviously

00:31:07.850 --> 00:31:10.860
informing his philosophy.

00:31:10.860 --> 00:31:15.180
And he is reported to have died a virgin.

00:31:15.180 --> 00:31:21.760
In any case, looking at images of the time,
we can feel his pain.

00:31:21.760 --> 00:31:29.560
But, this is the genius that has given us
this present instance of moral diversity.

00:31:29.560 --> 00:31:32.480
And this is to take one variable among many.

00:31:32.480 --> 00:31:39.570
What to do with women's sexuality, the problem,
the great problem of female sexuality.

00:31:39.570 --> 00:31:42.700
This is one answer to that question.

00:31:42.700 --> 00:31:49.620
This is obviously reasonably common throughout
the Muslim world.

00:31:49.620 --> 00:31:56.050
This is an instance in Iraq among Shiites.

00:31:56.050 --> 00:32:00.820
When you think of morality in terms of human
well being, when you think of values in terms

00:32:00.820 --> 00:32:05.630
of human well being, you can ask yourself,
what are the chances that this is a -- represents

00:32:05.630 --> 00:32:07.240
a peak on the moral landscape?

00:32:07.240 --> 00:32:13.630
What are the chances that this is a good way
to maximize human flourishing?

00:32:13.630 --> 00:32:19.200
Notice this is not what we do in Western academic
circles and intellectual circles at the moment.

00:32:19.200 --> 00:32:23.730
I can assure you that if you go to a scientific
conference, and you say something derogatory

00:32:23.730 --> 00:32:29.960
about this, you have staked out a very edgy
position from the point of view of secular

00:32:29.960 --> 00:32:32.850
western intellectual life.

00:32:32.850 --> 00:32:36.140
You have made a very controversial statement.

00:32:36.140 --> 00:32:42.750
It is widely believed, as far as I can tell
universally believed in academic circles that

00:32:42.750 --> 00:32:50.310
while we may not like this, while we might
want to say this is wrong in Boston or Palo

00:32:50.310 --> 00:32:57.430
Alto, who are we to say that the proud denizens
of an ancient culture can't force their wives

00:32:57.430 --> 00:32:59.060
and daughters to live in cloth bags?

00:32:59.060 --> 00:33:05.460
Who are we to say it's wrong to beat them,
or throw battery acid in their faces or kill

00:33:05.460 --> 00:33:08.910
them if they decline the privilege of living
like this?

00:33:08.910 --> 00:33:16.210
I mean I can't tell you what sort of bizarre
collisions I've had in academic circles saying

00:33:16.210 --> 00:33:21.390
something derogatory about life under the
Taliban.

00:33:21.390 --> 00:33:27.440
In any case, to say, to notice rather obviously
that this is not a way to maximize human well

00:33:27.440 --> 00:33:33.770
being is not to say that we in our own culture
have struck the perfect balance.

00:33:33.770 --> 00:33:34.770
That's not entailed.

00:33:34.770 --> 00:33:39.970
This is what it's like to go to a newsstand
these days.

00:33:39.970 --> 00:33:44.330
It may for some of the guys in the room, it
might require a degree in philosophy to figure

00:33:44.330 --> 00:33:46.930
out exactly what's wrong with this.

00:33:46.930 --> 00:33:48.360
[Laughter]

00:33:48.360 --> 00:33:49.760
But happily I have one.

00:33:49.760 --> 00:33:57.020
In any case, this is, have we struck the perfect
balance in our society?

00:33:57.020 --> 00:34:05.280
Is this the perfect expression of psychological
health with respect to the variable of female

00:34:05.280 --> 00:34:07.570
sexuality and youth and beauty?

00:34:07.570 --> 00:34:08.570
Perhaps not.

00:34:08.570 --> 00:34:15.039
Ok, there's a continuum here, again with respect
to only one variable where maybe we can find

00:34:15.039 --> 00:34:21.619
a place on this spectrum that represents greater
balance, where little girls and little boys

00:34:21.619 --> 00:34:30.950
can grow up sort of less confounded by the
prospect of becoming sexual adults.

00:34:30.950 --> 00:34:35.231
My point is, clearly the left is not the right
answer.

00:34:35.231 --> 00:34:43.289
I mean you ask yourself questions like is
this – is compulsory veiling a good way

00:34:43.289 --> 00:34:45.950
to raise confident and contented women?

00:34:45.950 --> 00:34:47.669
Does it raise more compassionate men?

00:34:47.669 --> 00:34:52.389
Does it improve the relationships between
boys and their mothers or girls and their

00:34:52.389 --> 00:34:53.389
fathers?

00:34:53.389 --> 00:35:01.089
I think any reasonable person, not confounded
by religious dogmatism would say very likely

00:35:01.089 --> 00:35:04.089
not.

00:35:04.089 --> 00:35:11.040
But we know that our moral intuitions are
actually not infallible.

00:35:11.040 --> 00:35:13.289
We know that they're prone to illusions.

00:35:13.289 --> 00:35:18.499
And I'll give you one instance of very clear
moral illusion.

00:35:18.499 --> 00:35:20.789
And this is why we need a scientific approach
to morality.

00:35:20.789 --> 00:35:22.960
We need to get behind our moral illusion.

00:35:22.960 --> 00:35:27.579
So if I asked you how much you would help
 -- how much money you would give a child

00:35:27.579 --> 00:35:33.490
in need and this is based on the work of Paul
Slovic who ran this experiment.

00:35:33.490 --> 00:35:36.680
People will give something near the limit
of their generosity.

00:35:36.680 --> 00:35:43.130
If I asked you how much compassion you feel,
you will express based on self report something

00:35:43.130 --> 00:35:49.059
near the limit of your compassion.

00:35:49.059 --> 00:35:53.650
If I asked you how much you would give to
help another child in need, now the girl's

00:35:53.650 --> 00:35:54.650
brother.

00:35:54.650 --> 00:36:00.519
Again, you'd give the same amount, and you
would self report the same level of compassion.

00:36:00.519 --> 00:36:04.990
But if I asked you in another circumstance
how much you would help to give -- how much

00:36:04.990 --> 00:36:12.730
you would give to children in need, both your
self report of compassion and your material

00:36:12.730 --> 00:36:16.319
generosity diminishes by about 20 to 25%.

00:36:16.319 --> 00:36:19.310
Now this is clearly non-normative.

00:36:19.310 --> 00:36:24.480
And if you care about a little girl, and you
care about her brother, you should care at

00:36:24.480 --> 00:36:28.569
least as much about the two of them.

00:36:28.569 --> 00:36:35.059
Your altruism should in some sense be additive.

00:36:35.059 --> 00:36:37.799
And it's not, it's actually quite the opposite.

00:36:37.799 --> 00:36:41.309
And the more you add, the more altruism diminishes.

00:36:41.309 --> 00:36:45.240
So that when you add enough, it just goes
to the floor.

00:36:45.240 --> 00:36:50.609
And this accounts for what Slovic has termed
'genocide neglect' which is something we're

00:36:50.609 --> 00:36:51.619
all familiar with.

00:36:51.619 --> 00:36:56.779
It's very difficult to care about a genocide.

00:36:56.779 --> 00:36:58.150
Genocides are boring for some reason.

00:36:58.150 --> 00:37:02.579
I mean the biggest problems in human life
when you hear that a hundred thousand or two

00:37:02.579 --> 00:37:08.930
hundred thousand or a million people were
hacked to death with machetes in Rwanda, that

00:37:08.930 --> 00:37:11.180
barely makes the news.

00:37:11.180 --> 00:37:15.911
And yet, on the left, you may not be familiar
with this image – it's about 20 years old

00:37:15.911 --> 00:37:25.309
 -- but baby Jessica fell down a well, her
rescue dominated the news 24 hours a day until

00:37:25.309 --> 00:37:26.309
she was rescued.

00:37:26.309 --> 00:37:28.940
It was like four days of pulling her out of
this well.

00:37:28.940 --> 00:37:34.009
There was not a person who owned a television
who was watching anything else.

00:37:34.009 --> 00:37:46.109
So, this is literally an instance where a
cat stuck in a tree can trump the needless

00:37:46.109 --> 00:37:51.380
suffering and death of millions, based on
how we allocate our attentional resources.

00:37:51.380 --> 00:38:00.269
And so we are, we're clearly not well equipped
to pay attention to the problems that we know

00:38:00.269 --> 00:38:05.680
actually affect most lives in the greatest
ways.

00:38:05.680 --> 00:38:10.579
And so we need to find some way of getting
behind our failures of intuition.

00:38:10.579 --> 00:38:16.910
And we know, we have, this again does not
erode the objectivity of the moral space because

00:38:16.910 --> 00:38:20.099
we have very obvious failures in intuition
elsewhere.

00:38:20.099 --> 00:38:24.400
I mean this is just a visual illusion which
should work for most of you.

00:38:24.400 --> 00:38:31.130
But if you are normally sighted, you will
almost certainly see the tower on the right

00:38:31.130 --> 00:38:34.359
to be leaning further on the right than the
tower on the left.

00:38:34.359 --> 00:38:37.630
But these are identical photos.

00:38:37.630 --> 00:38:39.099
It's a visual illusion.

00:38:39.099 --> 00:38:46.759
The existence of visual illusions allows us
to understand something about our visual system.

00:38:46.759 --> 00:38:51.819
The existence of moral illusions I would argue
should allow us to understand something about

00:38:51.819 --> 00:38:55.380
our judgments of value.

00:38:55.380 --> 00:39:02.440
Clearly when it's important to see the world
correctly, we manage to work around the limits

00:39:02.440 --> 00:39:06.130
of our visual system.

00:39:06.130 --> 00:39:15.890
Clearly we need to find some way of legislating
and developing social and political mechanisms

00:39:15.890 --> 00:39:22.490
that enshrines our better judgment and our
real moral wisdom, and leaves us no longer

00:39:22.490 --> 00:39:25.640
vulnerable to our moment to moment failures
of moral intuition.

00:39:25.640 --> 00:39:34.710
And so in closing, I would just say that it
seems to me that one of the critical things

00:39:34.710 --> 00:39:41.499
we need to do now as a species really is come
up with a way of talking about the most important

00:39:41.499 --> 00:39:48.080
questions in human life, talking about the
space of morality and human values in a way

00:39:48.080 --> 00:39:50.299
that truly transcends culture.

00:39:50.299 --> 00:39:56.769
So that just as there's no such thing as Christian
physics and Muslim algebra, there's no such

00:39:56.769 --> 00:39:58.690
thing as Christian and Muslim morality.

00:39:58.690 --> 00:40:04.849
We're just talking about human flourishing,
and all the variables that influence it.

00:40:04.849 --> 00:40:05.849
Thank you very much.

00:40:05.849 --> 00:40:07.950
[Applause]

00:40:07.950 --> 00:40:10.650
[pause]

00:40:10.650 --> 00:40:20.030
Jed: If we have questions, I'm sure Sam would
be happy to answer them.

00:40:20.030 --> 00:40:22.410
Sam: Do you want me to call on people or?

00:40:22.410 --> 00:40:23.430
Jed: Sure.

00:40:23.430 --> 00:40:26.970
&gt;&gt; Hey, thanks so much for coming out.

00:40:26.970 --> 00:40:33.579
I thought you did a really good job showing
how we can use more scientific method to maximize

00:40:33.579 --> 00:40:36.119
a value function like with your moral landscape.

00:40:36.119 --> 00:40:42.720
However, I think you completely dodged the
issue of where do you get that value function

00:40:42.720 --> 00:40:43.720
from.

00:40:43.720 --> 00:40:44.720
You seemed…

00:40:44.720 --> 00:40:45.720
&gt;&gt;Sam: Right

00:40:45.720 --> 00:40:51.210
&gt;&gt; to assume that maximizing happiness for
the most people is the value function.

00:40:51.210 --> 00:40:56.700
And I think, I mean I'm not disagreeing with
that, but I think that you've dodged the philosophical

00:40:56.700 --> 00:40:57.700
underpinning that…

00:40:57.700 --> 00:40:58.700
&gt;&gt;Sam: Right right.

00:40:58.700 --> 00:40:59.700
&gt;&gt; that it seemed like you were going to address.

00:40:59.700 --> 00:41:05.210
&gt;&gt;Sam: Well it's -- there are many wrinkles
there as you suggest.

00:41:05.210 --> 00:41:13.749
It's not obvious how you aggregate happiness
claims and whose opinion trumps others.

00:41:13.749 --> 00:41:20.009
How do you compare the one person's headache,
or the headache of a million people to the

00:41:20.009 --> 00:41:25.089
broken arms of five people, say?

00:41:25.089 --> 00:41:28.960
There's mysteries there as to how you, what
trumps what.

00:41:28.960 --> 00:41:33.641
There's also, when you talk about population
ethics, there are real problems in how do

00:41:33.641 --> 00:41:42.009
you just add up utility function so that -- if
you were gonna say, I don't know if you're

00:41:42.009 --> 00:41:43.519
familiar with the work of Derek Parfit, the
philosopher.

00:41:43.519 --> 00:41:51.749
But he's done some very brilliant work on
just the paradoxes that trying to aggregate

00:41:51.749 --> 00:41:55.119
utility coughs up.

00:41:55.119 --> 00:42:00.710
For instance, if you're gonna talk about just
positive experience, if that's -- if just

00:42:00.710 --> 00:42:05.549
more positive experience is the way you want
to -- what you want to privilege, then you

00:42:05.549 --> 00:42:14.109
should prefer a world of trillions of beings
that have lives that are only barely worth

00:42:14.109 --> 00:42:19.799
living, so a world of seven billion of us
living in perfect ecstasy.

00:42:19.799 --> 00:42:22.720
Because there's just more positivity net.

00:42:22.720 --> 00:42:23.930
So that clearly doesn't work.

00:42:23.930 --> 00:42:28.470
So then people want to say, well there's -- maybe
you want average happiness.

00:42:28.470 --> 00:42:29.999
You want to raise the average.

00:42:29.999 --> 00:42:34.009
Well if all you want to do is raise the average,
then you should kill all the unhappy people

00:42:34.009 --> 00:42:35.009
tonight.

00:42:35.009 --> 00:42:39.490
And maybe kill everyone except the one happiest
person, and then you will have raised the

00:42:39.490 --> 00:42:41.749
average, and there's just one happy person
left.

00:42:41.749 --> 00:42:45.460
Clearly average is not the right metric.

00:42:45.460 --> 00:42:48.739
So there are issues here.

00:42:48.739 --> 00:42:54.839
My point however is that -- and this probably
speaks to the core of your questions -- we

00:42:54.839 --> 00:43:00.710
can't get confused between answers in practice
and answers in principle.

00:43:00.710 --> 00:43:05.880
Just because there may not always be clear
ways to resolve these issues in practice doesn't

00:43:05.880 --> 00:43:07.809
mean there aren't right answers.

00:43:07.809 --> 00:43:13.890
If I asked you how many people on earth were
bitten by a mosquito in the last 60 seconds,

00:43:13.890 --> 00:43:17.089
it is obvious we don't have the answer to
that question, and we will never have the

00:43:17.089 --> 00:43:18.130
answer to that question.

00:43:18.130 --> 00:43:23.440
It's also obvious the question is well posed
and has a simple numerical answer.

00:43:23.440 --> 00:43:29.839
So there's a difference between there just
being no facts there to be known and there's

00:43:29.839 --> 00:43:32.460
 -- it's just being hard to know them.

00:43:32.460 --> 00:43:35.180
&gt;&gt; I think I -- maybe I mis-phrased.

00:43:35.180 --> 00:43:41.549
The, I think the core you missed is you tried
to put -- posit this as an alternative to

00:43:41.549 --> 00:43:44.339
values based on a religion and morals based
on it where…

00:43:44.339 --> 00:43:45.339
&gt;&gt;Sam: Right

00:43:45.339 --> 00:43:48.940
&gt;&gt; the value system is handed down from on
high and these things are good and these things

00:43:48.940 --> 00:43:50.549
are bad.

00:43:50.549 --> 00:43:57.160
However, you seem to just posit that maximum
happiness, if that were measurable is the

00:43:57.160 --> 00:44:00.089
value we should be seeking to achieve.

00:44:00.089 --> 00:44:02.539
&gt;&gt;Sam: Well one thing I said.

00:44:02.539 --> 00:44:07.799
&gt;&gt; And what's your -- what -- philosophically
if you're trying to establish morality without

00:44:07.799 --> 00:44:13.869
a higher being, what is your basis for saying
that the value function is maximum -- like

00:44:13.869 --> 00:44:14.869
in the game of chess.

00:44:14.869 --> 00:44:15.869
&gt;&gt;Sam: Right.

00:44:15.869 --> 00:44:17.940
&gt;&gt; We can solve the game of chess given that
you don't want to be checkmated.

00:44:17.940 --> 00:44:18.940
&gt;&gt;Sam: Right.

00:44:18.940 --> 00:44:22.549
&gt;&gt; However, if you don't have that goal, like
that goal has to be assumed.

00:44:22.549 --> 00:44:27.859
So you have to assume that happiness is good
for people or is the good that should be achieved.

00:44:27.859 --> 00:44:33.150
Sam: Well no, I think that's a, that's a good
question.

00:44:33.150 --> 00:44:38.779
That actually speaks to this notion of a naturalistic
fallacy.

00:44:38.779 --> 00:44:43.039
G. E. Moore, this philosopher, gave us this
idea of a naturalistic fallacy.

00:44:43.039 --> 00:44:50.739
He said that whenever you attempt to find
good in the world as a kind of natural property,

00:44:50.739 --> 00:44:54.999
it's always open to this further question,
well is that really good?

00:44:54.999 --> 00:44:59.299
So what you're saying to me is I want to maximize
human happiness.

00:44:59.299 --> 00:45:02.839
There's a posi -- there's a way to look at
that and stand outside and say, but is maximizing

00:45:02.839 --> 00:45:09.160
human happiness really good and that's called
Moore's open question argument.

00:45:09.160 --> 00:45:15.890
I think the moment you see that, when you
unpack what is actually being said there,

00:45:15.890 --> 00:45:22.619
what that doubt actually means, I think it's
clear that you are talking about -- that it

00:45:22.619 --> 00:45:27.190
doesn't work for a well being, that it doesn't
work for the well being of conscious creatures.

00:45:27.190 --> 00:45:33.559
'Cause what you're asking is if I say maximizing
well being is the basis for good and you say,

00:45:33.559 --> 00:45:38.160
but is that really good -- , what you're really
asking is -- is that instance of well being

00:45:38.160 --> 00:45:42.789
obstructive of some deeper well being that
you don't know about.

00:45:42.789 --> 00:45:46.130
And so my value function is truly open-ended.

00:45:46.130 --> 00:45:50.920
The challenge is not to -- I mean well being
is like health.

00:45:50.920 --> 00:45:56.470
It's a loose concept that is nonetheless and
indispensible concept.

00:45:56.470 --> 00:45:57.470
&gt;&gt; [Inaudible]

00:45:57.470 --> 00:46:01.829
&gt;&gt;Sam: No I'm saying that whatever well being
is altogether.

00:46:01.829 --> 00:46:05.560
Ok let's say there are frontiers of well being
we haven't discovered, as I think there are.

00:46:05.560 --> 00:46:07.089
&gt;&gt; You're assuming though.

00:46:07.089 --> 00:46:09.410
&gt;&gt;Sam: I'm assuming that there's nothing

00:46:09.410 --> 00:46:10.410
&gt;&gt; [Inaudible]

00:46:10.410 --> 00:46:15.910
&gt;&gt;Sam: Well, one thing I'm noticing is that
anyone who says they have an alternate version

00:46:15.910 --> 00:46:22.430
of value, their version is always parasitic
on some notion of well being anyway.

00:46:22.430 --> 00:46:26.430
So the jihadist who blows himself up in a
crowd of infidels, right?

00:46:26.430 --> 00:46:30.499
That seems to be like the ultimate repudiation
of my way of thinking and what's worse for

00:46:30.499 --> 00:46:33.849
your well being than strapping on the vest
and blowing yourself up?

00:46:33.849 --> 00:46:39.040
But when you look at what he's doing, he has
a story, and his story is he's gonna wind

00:46:39.040 --> 00:46:41.109
up in paradise for all eternity.

00:46:41.109 --> 00:46:43.619
He's gonna get seventy of his relatives in
there.

00:46:43.619 --> 00:46:47.539
He's gonna further the Islamification of the
earth.

00:46:47.539 --> 00:46:54.599
All of these reduced to notions of the good
and the notions of maximizing well being.

00:46:54.599 --> 00:47:00.079
Getting to paradise and getting your family
there too and helping the right religion spread

00:47:00.079 --> 00:47:04.330
on the face of the earth is the ultimate way
of trying to safe guard human well being.

00:47:04.330 --> 00:47:06.079
&gt;&gt;[Inaudible]

00:47:06.079 --> 00:47:15.809
&gt;&gt;Sam: Well, I've never, I've never encountered
an intelligible alternative.

00:47:15.809 --> 00:47:19.480
And if you're gonna say, 'Well listen, here's
the -- I've got a black box here which has

00:47:19.480 --> 00:47:21.190
the alternative, right.'

00:47:21.190 --> 00:47:30.309
This is a version of value that has nothing
to do with the effect on any possible conscious

00:47:30.309 --> 00:47:31.339
creature.

00:47:31.339 --> 00:47:36.279
OK, it has nothing to do with changes in state,
in consciousness now or in the future.

00:47:36.279 --> 00:47:39.809
But this is the real version of value.

00:47:39.809 --> 00:47:46.099
It seems to me you have by definition a version
of value that can't be of interest to anyone.

00:47:46.099 --> 00:47:47.339
&gt;&gt; [Inaudible]

00:47:47.339 --> 00:47:56.259
&gt;&gt;Sam: I mean, no -- anything that is conscious
can only be interested in possible, actual

00:47:56.259 --> 00:48:01.229
or possible changes in consciousness for them
or for someone or something else.

00:48:01.229 --> 00:48:04.839
And if you're gonna say, well I've got this
thing over here that doesn't show up in any

00:48:04.839 --> 00:48:08.769
of that space actually or possibly.

00:48:08.769 --> 00:48:14.529
It seems to me that's probably the least interesting
thing in the world, because it can't possibly

00:48:14.529 --> 00:48:19.779
affect anything that anyone can possibly notice.

00:48:19.779 --> 00:48:25.900
So the moment you notice it, it's consciousness,
and it's changes.

00:48:25.900 --> 00:48:32.339
And all I'm saying is, what I've done is I
haven't answered the questions of ethics.

00:48:32.339 --> 00:48:35.680
I'm not claiming to have said, ok here's what's
right and wrong.

00:48:35.680 --> 00:48:40.579
I'm just saying here's the direction in which
we can have a truly open- ended conversation

00:48:40.579 --> 00:48:43.859
where we discover frontiers of human flourishing.

00:48:43.859 --> 00:48:47.660
And not just human flourishing, the flourishing
of anything that can flourish.

00:48:47.660 --> 00:48:53.269
So if you guys build a computer that is conscious,
or that we think is conscious, all of a sudden

00:48:53.269 --> 00:48:56.400
we have an ethical conversation about how
we should treat our computers.

00:48:56.400 --> 00:49:01.789
If our computers suffer when we turn them
off, then we have ethical obligation with

00:49:01.789 --> 00:49:04.279
respect to our computers.

00:49:04.279 --> 00:49:06.170
I don't think anyone is expecting that anytime
soon,

00:49:06.170 --> 00:49:13.509
In any case, all the hard work is still to
be done is just -- the moment, it seems to

00:49:13.509 --> 00:49:18.680
me the moment you notice you're talking about
well being, then very different things start

00:49:18.680 --> 00:49:19.680
to happen.

00:49:19.680 --> 00:49:24.050
Then you can't argue that gay marriage is
the most important thing we should be talking

00:49:24.050 --> 00:49:30.579
about in the political space unless you have
an argument that gay marriage really is gonna

00:49:30.579 --> 00:49:32.549
create immense suffering.

00:49:32.549 --> 00:49:33.930
No one has that argument.

00:49:33.930 --> 00:49:38.700
Everyone just says this is wrong, God doesn't
like it so we're gonna burn 90% of our political

00:49:38.700 --> 00:49:40.140
oxygen talking about that.

00:49:40.140 --> 00:49:43.280
&gt;&gt;Jed: I think there's a question in the back.

00:49:43.280 --> 00:49:50.650
&gt;&gt; So yeah, so I guess just to kind of take
a slightly different perspective on this,

00:49:50.650 --> 00:49:52.259
on the question that was just asked.

00:49:52.259 --> 00:49:53.259
&gt;&gt;Sam: Yep.

00:49:53.259 --> 00:49:57.579
&gt;&gt; So the thing about science that's kind
of interesting is it excels in the descriptive.

00:49:57.579 --> 00:50:02.900
Mainly because usua -- in most sciences they'll
have hard physical sciences that you think

00:50:02.900 --> 00:50:03.900
of.

00:50:03.900 --> 00:50:11.910
The prime fitting function, the fitness function
or the, you know, optimizing function is basically

00:50:11.910 --> 00:50:12.910
kind of impartial.

00:50:12.910 --> 00:50:15.670
In most cases it's nature itself, right?

00:50:15.670 --> 00:50:20.099
So all you're trying to do is to discover
what's already there, and you have a really

00:50:20.099 --> 00:50:24.849
good way of testing which is tested against
the data that you collect from nature…

00:50:24.849 --> 00:50:25.849
&gt;&gt;Sam: Right.

00:50:25.849 --> 00:50:26.880
&gt;&gt; And you see if you're right or wrong.

00:50:26.880 --> 00:50:33.999
It's a natural, naturally given sort of like
a judge of whether you did it wrong or whether

00:50:33.999 --> 00:50:36.650
you're off base.

00:50:36.650 --> 00:50:39.859
Similar thing can be seen with a lot of games
like chess, right?

00:50:39.859 --> 00:50:44.880
Where you have a set of rules that's well
defined and whether you made the right move

00:50:44.880 --> 00:50:49.319
or not, or whether you won or not, it's not
really up to anybody's judgment, its…

00:50:49.319 --> 00:50:50.319
&gt;&gt;Sam: Right

00:50:50.319 --> 00:50:51.579
&gt;&gt; as long as you agree to those rules that's
there.

00:50:51.579 --> 00:50:57.150
Same thing with mathematics, as long as you
agree on the axioms up front of exactly what

00:50:57.150 --> 00:51:00.420
kind of a system you're playing with, then
everything is well defined from there on out.

00:51:00.420 --> 00:51:04.650
Then, you know unless of course there's issues
with the axioms themselves with Godel and

00:51:04.650 --> 00:51:05.650
stuff.

00:51:05.650 --> 00:51:09.240
But you know, once you set things up, that
system is self contained and…

00:51:09.240 --> 00:51:10.240
&gt;&gt;Sam: Right.

00:51:10.240 --> 00:51:11.240
&gt;&gt; enclosed, right?

00:51:11.240 --> 00:51:15.799
The problem with ethics it seems to me is
that -- and I think this gets to what he was

00:51:15.799 --> 00:51:27.069
saying earlier is that you're kind of a -- there's
no single agreed upon universally agreed upon

00:51:27.069 --> 00:51:31.279
set --like function, ethics function to maximize,
right?

00:51:31.279 --> 00:51:34.920
So the function itself is sort of like a matter's
kind of question.

00:51:34.920 --> 00:51:37.170
That's up for grabs, right?

00:51:37.170 --> 00:51:38.170
&gt;&gt;Sam: Right

00:51:38.170 --> 00:51:41.970
&gt;&gt; So we'll never really know, or maybe there
is a way to know, but what's to say that if

00:51:41.970 --> 00:51:44.319
you say OK, well science is going to figure
this out.

00:51:44.319 --> 00:51:52.579
We're going to say that some notion of well
being that will kind of tease out in the future.

00:51:52.579 --> 00:51:56.489
What's to say that's any better, or it's not
a religion that's comparable to Christianity

00:51:56.489 --> 00:51:57.749
or Islam or anything else.

00:51:57.749 --> 00:52:03.440
Where instead of setting up a god, you set
up a well being function, right?

00:52:03.440 --> 00:52:04.440
&gt;&gt;Sam: Ok, well.

00:52:04.440 --> 00:52:05.440
&gt;&gt;And that's the thing that you worship.

00:52:05.440 --> 00:52:09.810
At the end of the day you're not really, you're
kind of putting up a science, but it's not

00:52:09.810 --> 00:52:13.059
really fully scientific in the same kind of
a sense.

00:52:13.059 --> 00:52:18.900
You're using scientific methods, but the principle
on which you're actually trying to operate

00:52:18.900 --> 00:52:28.089
the machinery of scientific inquiry itself
could be based on a more dogmatic or kind

00:52:28.089 --> 00:52:29.579
of religious kind of ambiguity.

00:52:29.579 --> 00:52:32.589
&gt;&gt;Sam: Right, OK, that's a very well expressed
concern.

00:52:32.589 --> 00:52:41.599
I think you have again fallen into this double
standard that I was trying to expose.

00:52:41.599 --> 00:52:48.319
Based on intuitions that morality and well
being and value are different from the rest

00:52:48.319 --> 00:52:49.369
of scientific fact.

00:52:49.369 --> 00:52:58.489
So again, the only thing I can do is try to
nudge you with analogies and, for instance,

00:52:58.489 --> 00:53:01.190
I just brought up the analogy to human health.

00:53:01.190 --> 00:53:04.230
Notice you don't have this intuition about
human health.

00:53:04.230 --> 00:53:06.559
You wouldn't say well who's to say what human
health is?

00:53:06.559 --> 00:53:14.630
There is probably your health and my health,
they may be completely incommensurable.

00:53:14.630 --> 00:53:16.890
Cancer is cancer.

00:53:16.890 --> 00:53:21.900
It's cancer here, and it's cancer in the highlands
of New Guinea, and it's cancer whether people

00:53:21.900 --> 00:53:23.200
have heard of cancer.

00:53:23.200 --> 00:53:29.670
Now it's not that two culturally contingent
conceptions of health don't affect our experience

00:53:29.670 --> 00:53:30.670
of being sick.

00:53:30.670 --> 00:53:37.390
It's like cancer having the word cancer mean
so much in this society affects people when

00:53:37.390 --> 00:53:41.229
they get cancer in a way that it's probably
non-normative.

00:53:41.229 --> 00:53:46.299
In any case, there's a biology of human health
that we are trying to discover.

00:53:46.299 --> 00:53:49.180
Granted, it's not like chess, the goal isn't
predefined.

00:53:49.180 --> 00:53:56.289
So it's open ended, and in fact if we can
mettle with our biology in ways that completely

00:53:56.289 --> 00:54:03.979
transform the possibilities of physical health,
then physical health is truly undefined.

00:54:03.979 --> 00:54:10.660
If someone like Aubrey de Grey is right, the
biogerontologist who thinks that death isn't

00:54:10.660 --> 00:54:14.749
aging, it's just an engineering problem that
admits of a full solution.

00:54:14.749 --> 00:54:19.119
If he's right, then we should be able to live
indefinitely.

00:54:19.119 --> 00:54:24.211
And therefore our current conception of health
which is more or less something like if you're

00:54:24.211 --> 00:54:28.299
80 years old and can walk around without much
pain, you're healthy.

00:54:28.299 --> 00:54:32.910
If you can expect to be 80 and walk around
without pain, you're healthy.

00:54:32.910 --> 00:54:38.589
Well, if Aubrey de Grey is right, we should
be able to jog a marathon at age 1,000.

00:54:38.589 --> 00:54:42.819
And it's a completely different conception
of health, and yet each one of those conceptions

00:54:42.819 --> 00:54:45.640
is still objective.

00:54:45.640 --> 00:54:50.039
It's still, there's still, it's still, we're
still talking about a space of right and wrong

00:54:50.039 --> 00:54:53.989
answers and scientific understandings of causality.

00:54:53.989 --> 00:54:59.900
And what I'm saying to you is that forget
about words like morality and ethics, and

00:54:59.900 --> 00:55:04.329
just talk about psychological and social flourishing.

00:55:04.329 --> 00:55:09.779
These are facts about -- to speak of humans
only now.

00:55:09.779 --> 00:55:11.829
They're facts about the human brain.

00:55:11.829 --> 00:55:16.339
Whatever I do, whatever happens to me affects
my brain.

00:55:16.339 --> 00:55:21.770
I can only affect you by affecting your brain
in terms of your experience.

00:55:21.770 --> 00:55:27.650
And there is, this is all fantastically complicated
and culture is involved, but culture again

00:55:27.650 --> 00:55:32.240
is being run on our brains and affecting our
brains and being instantiated only at the

00:55:32.240 --> 00:55:35.160
level of the brain if it's showing up at all.

00:55:35.160 --> 00:55:41.319
So that a more maturing science of the mind,
a maturing science that they can really describe

00:55:41.319 --> 00:55:51.109
how positive and negative changes happen in
human experience will of necessity discourage

00:55:51.109 --> 00:55:57.582
right and wrong answer of what is good and
what is bad.

00:55:57.582 --> 00:56:02.229
Anyway, I hope that addresses the point, it's
not -- this is the subject of my next book,

00:56:02.229 --> 00:56:07.200
and obviously it's not, I can't deal with
each little wrinkle in the space of an hour,

00:56:07.200 --> 00:56:13.009
but I hope to over the course of 300 pages.

00:56:13.009 --> 00:56:14.400
&gt;&gt; My question is…

00:56:14.400 --> 00:56:15.400
&gt;&gt;Sam: Wait…

00:56:15.400 --> 00:56:16.489
&gt;&gt; My question now.

00:56:16.489 --> 00:56:19.530
You're getting variations on the same question
over and over again.

00:56:19.530 --> 00:56:22.119
You're getting a lot of variations on the
same question.

00:56:22.119 --> 00:56:28.069
It seems to me you did a really good job of
demonstrating that it would be very wonderful

00:56:28.069 --> 00:56:32.109
if we could have a universal morality that
we all agreed on.

00:56:32.109 --> 00:56:38.390
What I didn't see is that you did the same
level of job of convincing me that there is

00:56:38.390 --> 00:56:44.069
a universal morality that you can put forth
that you can get us all to agree on.

00:56:44.069 --> 00:56:50.109
For example take the pictures of women you
had.

00:56:50.109 --> 00:56:53.960
When you've done this at academic conferences,
you've wound up with heated discussions, and

00:56:53.960 --> 00:56:59.150
I'm guessing you didn't wind up convincing
the other people who disagreed with you that

00:56:59.150 --> 00:57:02.480
your sense of what was right was the way that
they should be looking at the world.

00:57:02.480 --> 00:57:04.469
&gt;&gt;Sam: Right.

00:57:04.469 --> 00:57:10.570
&gt;&gt;Now, speaking personally, when I look at
my own morality, I truly believe I have a

00:57:10.570 --> 00:57:15.739
built in ability to perceive and react to
morality.

00:57:15.739 --> 00:57:20.650
And when I ask why, and I look into the research
that exists on it, there's research in evolution

00:57:20.650 --> 00:57:26.619
on biological underpinnings from evolution
theory as to why I would have that.

00:57:26.619 --> 00:57:33.019
And indeed, you can find all sorts of research
on altruism, on through kin selection you

00:57:33.019 --> 00:57:34.019
can find all sorts of reasons…

00:57:34.019 --> 00:57:35.019
&gt;&gt;Sam: Right, right.

00:57:35.019 --> 00:57:36.029
&gt;&gt; why we have been built into these response.

00:57:36.029 --> 00:57:42.099
But the same research that is suggestion causes
for a biological underpinning that causes

00:57:42.099 --> 00:57:47.759
me to feel moral feelings also explain why
there should be between different social groups

00:57:47.759 --> 00:57:48.759
xenophobia.

00:57:48.759 --> 00:57:55.440
There is no scientifically from an evolutionary
perspective -- there's no difference between

00:57:55.440 --> 00:57:58.970
able to feel morality and xenophobia towards
outsiders.

00:57:58.970 --> 00:57:59.970
&gt;&gt;Sam: Right.

00:57:59.970 --> 00:58:03.299
&gt;&gt; They're explained by the same phenomenon.

00:58:03.299 --> 00:58:04.299
&gt;&gt;Sam: Okay.

00:58:04.299 --> 00:58:08.589
&gt;&gt;So what I don't see that you're able to
get past that.

00:58:08.589 --> 00:58:11.839
I don't see you're able to produce a morality
that's going to convince people that people

00:58:11.839 --> 00:58:12.839
are going to buy into.

00:58:12.839 --> 00:58:15.009
Sam: OK, great question.

00:58:15.009 --> 00:58:18.519
Two points I want to pick up on.

00:58:18.519 --> 00:58:24.710
First you have to distinguish between -- I'm
not arguing that morality is based on evolution.

00:58:24.710 --> 00:58:29.839
I'm not arguing that our current notion of
human well being and flourishing and all of

00:58:29.839 --> 00:58:35.260
our thinking about that is in any way tied
to Darwinian principles because clearly most

00:58:35.260 --> 00:58:37.509
of what we care about now is not.

00:58:37.509 --> 00:58:43.300
If you're giving your children eye glasses
or wearing sun screen, you're not disposed

00:58:43.300 --> 00:58:46.859
to live in the world that your genes have
made for you.

00:58:46.859 --> 00:58:53.009
And there are many things that we have, that
have been selected for like out group violence

00:58:53.009 --> 00:58:58.991
and xenophobia that clearly are a main obstacle
to human flourishing at this moment.

00:58:58.991 --> 00:59:03.770
We have to get -- rape could have paid dividends
to our ancestors is a good strategy to get

00:59:03.770 --> 00:59:05.809
your genes into the next generation.

00:59:05.809 --> 00:59:10.869
No one's going to argue that rape is therefore
morally necessary.

00:59:10.869 --> 00:59:15.690
So there's this separation between evolution
and intelligent discussion about human flourishing.

00:59:15.690 --> 00:59:22.339
And evolution simply can't see what we care
about because we haven't evolved to have conversations

00:59:22.339 --> 00:59:23.339
like this.

00:59:23.339 --> 00:59:29.279
We haven't evolved to perfect democracies,
we haven't evolved to build safer airplanes.

00:59:29.279 --> 00:59:32.650
We've flown the perch that evolution has built
for us.

00:59:32.650 --> 00:59:39.960
And we have as you say these hard wired judgments
that inform our moral life.

00:59:39.960 --> 00:59:42.430
People find certain things disgusting.

00:59:42.430 --> 00:59:47.650
And that kind of disgust circuitry plays into
their moral judgments.

00:59:47.650 --> 00:59:53.589
The question is given what we are, how do
we maximize human well being?

00:59:53.589 --> 01:00:02.200
And that question I'm arguing subsumes all
the talk we should be engaging around right

01:00:02.200 --> 01:00:04.650
and wrong and good and evil.

01:00:04.650 --> 01:00:10.430
Now I'll tell you the kind of -- your opening
question reminded me of the kind thing I do

01:00:10.430 --> 01:00:12.090
get at a scientific conference.

01:00:12.090 --> 01:00:19.960
For instance, talking about compulsory veiling,
I said very much like I've said here, we know

01:00:19.960 --> 01:00:26.239
that compulsory veiling is not a way of maximizing
human well being.

01:00:26.239 --> 01:00:29.640
Someone else at the conference, another presenter
at the conference said, "That's just your

01:00:29.640 --> 01:00:31.710
opinion. How can you prove that?"

01:00:31.710 --> 01:00:36.539
I said, well I think morality reduces to human
well being and this is obviously not a way

01:00:36.539 --> 01:00:37.660
of maximizing human well being.

01:00:37.660 --> 01:00:39.450
She said, "Well it's just your opinion."

01:00:39.450 --> 01:00:42.559
I said, "Well let's make it easier.

01:00:42.559 --> 01:00:48.519
Let's say we found a culture that was just
removing the eyeballs of every third child,

01:00:48.519 --> 01:00:49.989
right.

01:00:49.989 --> 01:00:54.200
Would you then admit that we had found a culture
that was not maximizing human well being?"

01:00:54.200 --> 01:00:57.869
And she said, "Well it would depend on why
they were doing it."

01:00:57.869 --> 01:01:07.700
Now understand this is a person who has a
PhD in biology and a PhD in philosophy and

01:01:07.700 --> 01:01:12.710
whose area of expertise is on the forensic
use of science and all the ethical issues

01:01:12.710 --> 01:01:13.710
involved.

01:01:13.710 --> 01:01:18.559
And she had just given a talk on how troubled
she was that we might be using lie detection

01:01:18.559 --> 01:01:24.930
technology on captured terrorists because
this would be a violation of cognitive liberty

01:01:24.930 --> 01:01:29.609
because she had very fine grained moral intuitions
about what is wrong to do to people, right.

01:01:29.609 --> 01:01:35.660
And I'm asking if we found a culture that
were removing the eyeballs of children, it

01:01:35.660 --> 01:01:36.900
would depend on why they were doing it.

01:01:36.900 --> 01:01:39.329
I said, "Well let's say they were doing it
for religious reasons.

01:01:39.329 --> 01:01:44.269
They have a scripture which says, every third
should walk in darkness or such nonsense."

01:01:44.269 --> 01:01:48.049
She said, "Well then you could never say that
they're wrong."

01:01:48.049 --> 01:01:54.079
This is not -- that is not a minority view
in science and academia at this moment.

01:01:54.079 --> 01:02:02.019
It seems to me we are hamstrung by this, this,
this politically correct dogma which suggests

01:02:02.019 --> 01:02:05.809
that we have to pretend to know so little
about human well being.

01:02:05.809 --> 01:02:11.359
We have to pretend to know so little about
how people flourish that we can say absolutely

01:02:11.359 --> 01:02:13.849
nothing in the face of moral diversity.

01:02:13.849 --> 01:02:19.320
That all we can do is just take everyone's
word for this is one flavor of morality, this

01:02:19.320 --> 01:02:20.400
is another flavor.

01:02:20.400 --> 01:02:25.289
They're all equally viable, they're all equally
dignified.

01:02:25.289 --> 01:02:30.380
And there's just no way we're ever gonna fuse
our cognitive horizons or our moral horizons

01:02:30.380 --> 01:02:31.539
on this subject.

01:02:31.539 --> 01:02:35.039
Whereas we're aspiring to fuse it on every
other subject.

01:02:35.039 --> 01:02:42.719
We talk about human psychology and genetics
and physics and then it's transcultural and

01:02:42.719 --> 01:02:45.839
transnational and there's just one space to
talk.

01:02:45.839 --> 01:02:50.640
But if you're going to talk about human well
being, we know nothing and we'll never know

01:02:50.640 --> 01:02:53.289
anything in principal.

01:02:53.289 --> 01:03:00.240
That, it seems to me is just, one it's just
profoundly unlikely to be true given that

01:03:00.240 --> 01:03:02.849
it's all happening at the level of the brain.

01:03:02.849 --> 01:03:07.220
And two, it's a recipe for just the continued
shattering of our world.

01:03:07.220 --> 01:03:09.820
&gt;&gt; That's not what I'm trying to say.

01:03:09.820 --> 01:03:13.160
I agree with you -- just not at the level.

01:03:13.160 --> 01:03:17.630
However there's lots of arguments that there
are many people like that.

01:03:17.630 --> 01:03:18.630
&gt;&gt;Sam: Right.

01:03:18.630 --> 01:03:23.420
&gt;&gt;You're not going to create the breaking
of universal ground.

01:03:23.420 --> 01:03:29.849
&gt;&gt;Sam: Well we don't have to convince every
 -- first, I know we're out of time, but this

01:03:29.849 --> 01:03:30.849
is okay.

01:03:30.849 --> 01:03:32.180
This is great, by the way.

01:03:32.180 --> 01:03:41.279
I don't take my adversarial stance as anything
other than appreciation, because I love this.

01:03:41.279 --> 01:03:42.279
[pause]

01:03:42.279 --> 01:03:45.859
It seems to me that we overstate the lack
of consensus because there actually is a lot

01:03:45.859 --> 01:03:49.140
of consensus on our most important moral intuitions.

01:03:49.140 --> 01:03:53.259
I mean you take something like -- so there's
two things.

01:03:53.259 --> 01:03:57.289
One is consensus doesn’t really matter ultimately
when you're talking about truth.

01:03:57.289 --> 01:04:01.329
It's possible for everyone to be wrong, it's
possible for one person to be right and to

01:04:01.329 --> 01:04:02.329
never be recognized.

01:04:02.329 --> 01:04:04.079
This is true everywhere.

01:04:04.079 --> 01:04:08.829
It's true in physics, it's true in information
processing and it's gotta be true in questions

01:04:08.829 --> 01:04:11.509
of human well being.

01:04:11.509 --> 01:04:15.519
But the truth is we have a consensus in morality
that we don't have elsewhere.

01:04:15.519 --> 01:04:21.380
So if I walk out on the street and I ask people,
"Do you think the passage of time varies with

01:04:21.380 --> 01:04:23.950
velocity?"

01:04:23.950 --> 01:04:25.479
Time slows down the faster you go.

01:04:25.479 --> 01:04:31.329
Well that's just special relativity, but most
people aren't gonna believe that, right?

01:04:31.329 --> 01:04:37.329
If I go out there and say, "Do you think human
beings and lobsters have a common ancestor?

01:04:37.329 --> 01:04:38.739
That's just evolution."

01:04:38.739 --> 01:04:43.469
But we know how many people don't believe
that, and on a good day, 25% of our neighbors

01:04:43.469 --> 01:04:45.769
believe that.

01:04:45.769 --> 01:04:52.440
If I go out there and say, "Do you think it's
good to be kind to strangers?

01:04:52.440 --> 01:04:56.280
Do you think it's good to tell the truth most
of the time? Do you think it's good to be

01:04:56.280 --> 01:04:57.280
kind to children?

01:04:57.280 --> 01:05:03.519
Those are massively well subscribed belief
systems.

01:05:03.519 --> 01:05:09.019
So what I would argue is that our core moral
intuitions, what moves us is actually quite

01:05:09.019 --> 01:05:10.519
similar from culture to culture.

01:05:10.519 --> 01:05:15.760
And the thing that we don't have, and the
thing that, the real challenge is we have

01:05:15.760 --> 01:05:23.910
 -- people are using the same morality, by
and large -- things like veiling notwithstanding.

01:05:23.910 --> 01:05:29.619
They're using the same kind of morality, but
they've trimmed down their moral circle based

01:05:29.619 --> 01:05:31.680
on some us and them ideology.

01:05:31.680 --> 01:05:34.089
So that there's an in group and there's an
out group.

01:05:34.089 --> 01:05:38.359
There's an in group that they care about to
which their morality applies.

01:05:38.359 --> 01:05:42.869
So it's good to be kind to these children,
but we can kill these other children because

01:05:42.869 --> 01:05:45.180
they're not really people.

01:05:45.180 --> 01:05:52.390
And so this is how you get the mystery of
how under the Third Reich, you have perfectly

01:05:52.390 --> 01:05:59.940
normal people willing to gas and kill unlimited
numbers of other people in their day job.

01:05:59.940 --> 01:06:02.930
And they go home and they still love their
children, and they love their pets and they

01:06:02.930 --> 01:06:06.160
listen to Wagner and they have normal lives.

01:06:06.160 --> 01:06:09.730
I mean there's no way that all the people
who were involved in the Third Reich were

01:06:09.730 --> 01:06:11.819
psychopaths.

01:06:11.819 --> 01:06:16.369
This is the horror of that particular instance.

01:06:16.369 --> 01:06:22.540
And it's the horror of any time you see mass
numbers of people victimizing other people.

01:06:22.540 --> 01:06:30.430
But what allows that to happen is this sense
of certain people are not people.

01:06:30.430 --> 01:06:31.920
So we have to expand the circle.

01:06:31.920 --> 01:06:39.690
What we don't have to do is somehow convince
people of a radically different morality.

01:06:39.690 --> 01:06:48.920
Modulate a few things like what to do about
women's sexuality and whether women should

01:06:48.920 --> 01:06:49.920
be taught to read.

01:06:49.920 --> 01:06:59.539
There are cultures that are pretty -- have
some strange ideas about how to best set up

01:06:59.539 --> 01:07:00.539
their societies.

01:07:00.539 --> 01:07:11.420
But, for the most part, nobody thinks that
being terrible to your in group is what constitutes

01:07:11.420 --> 01:07:13.089
a moral life.

01:07:13.089 --> 01:07:14.229
So we need to broaden the in group.

01:07:14.229 --> 01:07:18.239
&gt;&gt; So a question that I would have.

01:07:18.239 --> 01:07:19.680
Well first of all a statement.

01:07:19.680 --> 01:07:26.029
And that is it seems that you share some common
ground about maybe some of the dangers of

01:07:26.029 --> 01:07:30.190
moral relativism with the current Catholic
pope.

01:07:30.190 --> 01:07:32.789
I don't know if anyone's suggested that to
you before.

01:07:32.789 --> 01:07:36.700
&gt;&gt;Sam: Well no, but I actually suggested that
early on.

01:07:36.700 --> 01:07:41.609
The irony is that the people who -- the only
people who agree with me and think there are

01:07:41.609 --> 01:07:46.800
right answers to moral questions are the religious
demagogues who think they have those answers

01:07:46.800 --> 01:07:49.910
because they got them from a voice in a whirlwind.

01:07:49.910 --> 01:07:55.710
I mean that's the -- and so I would argue
they're right for the wrong reason.

01:07:55.710 --> 01:08:03.760
&gt;&gt; So I mean, I guess a question is is if
we, if the goal of your talk and maybe the

01:08:03.760 --> 01:08:07.160
goal of I guess your mission is really –

01:08:07.160 --> 01:08:14.400
It seems that it's something along the lines
of is it possible to get people more engaged

01:08:14.400 --> 01:08:19.849
with having like an active kind of moral I
guess inner dialogue.

01:08:19.849 --> 01:08:24.210
And then externalize that and have it with
others.

01:08:24.210 --> 01:08:29.119
And that's going to be at least some portion
of what you want to do.

01:08:29.119 --> 01:08:35.190
&gt;&gt;Sam: Yeah, well I want to break down the
illusion that there is actually no dialogue

01:08:35.190 --> 01:08:39.210
to have that can lean anywhere worth going.

01:08:39.210 --> 01:08:47.420
And that's we have this sense that we just
have to respect and tolerate difference, radical

01:08:47.420 --> 01:08:49.409
difference here.

01:08:49.409 --> 01:08:52.040
In fact we have to tolerate intolerance.

01:08:52.040 --> 01:08:54.330
We have to tolerate violent intolerance.

01:08:54.330 --> 01:08:58.389
So you know, if a cartoon controversy, there's
riots.

01:08:58.389 --> 01:09:02.429
People rioting by hundreds of thousands over
the earth.

01:09:02.429 --> 01:09:03.429
People are dying.

01:09:03.429 --> 01:09:06.750
The cartoonist Kurt Westergaard, I don't know
if you know this in Denmark.

01:09:06.750 --> 01:09:11.150
The guy who drew the most provocative of the
cartoons -- provo -- not provocative at all,

01:09:11.150 --> 01:09:13.380
it was a guy with a bomb shaped turban.

01:09:13.380 --> 01:09:18.630
But, you know, he's being hunted in his own
country.

01:09:18.630 --> 01:09:21.609
A guy showed up in his living room with an
ax the other night.

01:09:21.609 --> 01:09:26.109
And literally every person with the name Kurt
Westergaard in Denmark, there's like 87 of

01:09:26.109 --> 01:09:30.509
them now need round the clock protection.

01:09:30.509 --> 01:09:38.339
We are very patient with this kind of conception
of differing conception of what constitutes

01:09:38.339 --> 01:09:39.339
morality.

01:09:39.339 --> 01:09:43.259
There are these anti-blasphemy laws trying
to make their way through the UN at the moment.

01:09:43.259 --> 01:09:48.199
So it's going to be illegal, someone like
me could be -- get a knock on the door for

01:09:48.199 --> 01:09:53.560
the unpleasant things he says about religion.

01:09:53.560 --> 01:09:58.000
It seems to me, we need to, the moment we
start talking about how human beings really

01:09:58.000 --> 01:10:02.380
flourish, we can cut through a lot of this.

01:10:02.380 --> 01:10:07.090
The moment we get, we're no longer confused
by words like morality and we just simply

01:10:07.090 --> 01:10:12.400
talk about psychological health, social health,
physical health et cetera.

01:10:12.400 --> 01:10:14.341
&gt;&gt; Yeah, I had a question.

01:10:14.341 --> 01:10:19.230
I recently read a book by Edward O. Wilson
 – 'Consilience', where he made the argument

01:10:19.230 --> 01:10:27.760
that science needs to encroach on the areas
of arts and some other areas in curriculum.

01:10:27.760 --> 01:10:30.090
And the scientific approach can be applied
to those things.

01:10:30.090 --> 01:10:37.349
And I'm wondering if the inevitable belief
or goal is that science will basically be

01:10:37.349 --> 01:10:39.719
intrinsic to every avenue of human life.

01:10:39.719 --> 01:10:46.429
Be it something like you were talking about
now like ethics, to something that today exists

01:10:46.429 --> 01:10:48.450
completely devoid or outside of science.

01:10:48.450 --> 01:10:51.719
Will that inevitably be rolled under the blanket
of science?

01:10:51.719 --> 01:10:56.310
And will we have answers for you know the
things that we don't think that we can right

01:10:56.310 --> 01:10:57.610
now, through science?

01:10:57.610 --> 01:11:04.090
&gt;&gt;Sam: Yeah, yeah, well, it's not that we're
always gonna consult the scientist or scan

01:11:04.090 --> 01:11:09.190
our brains to make, to decide whether we want
to go get some ice cream.

01:11:09.190 --> 01:11:12.440
The desire for ice cream is something that's
happening at the level of the brain.

01:11:12.440 --> 01:11:17.659
We can understand it with greater precision
at the level of the brain.

01:11:17.659 --> 01:11:24.849
Even if we understood it perfectly, that's
still not going to change our experience necessarily

01:11:24.849 --> 01:11:28.739
of having ice cream or wanting ice cream or
getting ice cream.

01:11:28.739 --> 01:11:35.550
So there's practically speaking at the level
of how we live and fall in love and what attracts

01:11:35.550 --> 01:11:42.100
our attention in any moment a complete scientific
understanding of all those processes, should

01:11:42.100 --> 01:11:43.100
it be available.

01:11:43.100 --> 01:11:50.380
Isn't it going to just keep us looking at
brain scans and keep us out of living our

01:11:50.380 --> 01:11:51.380
ordinary lives?

01:11:51.380 --> 01:11:54.130
That's not the way science works.

01:11:54.130 --> 01:11:59.610
I think there are interesting ways in which
understanding things scientifically could

01:11:59.610 --> 01:12:02.409
change our actual experience.

01:12:02.409 --> 01:12:08.260
So, for instance, you know if [sigh].

01:12:08.260 --> 01:12:15.349
I mean we have this, we use words like "love"
say in many different contexts.

01:12:15.349 --> 01:12:22.261
And we say, "I love my wife, I love my child,
I love my dog, I potentially love other people

01:12:22.261 --> 01:12:28.190
who I haven't met yet, I love ice cream."

01:12:28.190 --> 01:12:30.030
We have different shades of meaning there.

01:12:30.030 --> 01:12:35.380
Now, if we understood all of these -- if I
could put you in the perfect brain scanner

01:12:35.380 --> 01:12:40.860
and interrogated your brain as you went through
all those different experiences, we might

01:12:40.860 --> 01:12:47.030
find that some of those experiences are quite
similar or quite different and line up in

01:12:47.030 --> 01:12:51.840
ways with other experiences that would be
rather counter intuitive.

01:12:51.840 --> 01:12:53.440
And so that maybe we're using the wrong word.

01:12:53.440 --> 01:12:58.780
And maybe were actually not noticing what
we really are feeling in certain circumstances.

01:12:58.780 --> 01:13:05.239
And this is not a brain scan analogy, but
for instance people use words like embarrassment

01:13:05.239 --> 01:13:08.610
and humiliation almost interchangeably.

01:13:08.610 --> 01:13:15.070
But when there's been some work done on embarrassment
and humiliation, these social emotions, and

01:13:15.070 --> 01:13:17.460
it turns out there's a difference between
embarrassment and humiliation.

01:13:17.460 --> 01:13:23.570
If I told you a story about a prior embarrassment
of mine right now.

01:13:23.570 --> 01:13:27.690
It's gonna be a story that's gonna make you
laugh very likely.

01:13:27.690 --> 01:13:34.860
If I tell you a story where I was humiliated,
genuinely humiliated, you might laugh, but

01:13:34.860 --> 01:13:37.630
you're gonna be uncomfortable and you're gonna
be ready to change the subject.

01:13:37.630 --> 01:13:41.840
Now that's a shade of difference.

01:13:41.840 --> 01:13:48.610
This is a way in which our social emotions
kind of translate into discursive inter-subjective

01:13:48.610 --> 01:13:50.199
space.

01:13:50.199 --> 01:13:54.219
The point is, this is something you might
not know anything about, but it's still true.

01:13:54.219 --> 01:13:58.320
So you could have gone through your whole
life telling embarrassing stories, and telling

01:13:58.320 --> 01:14:05.550
humiliating stories and sort of being vaguely
aware of a difference in your audience, and

01:14:05.550 --> 01:14:11.530
in you, but thinking the embarrassment and
humiliation were the same thing.

01:14:11.530 --> 01:14:19.469
And so, I think we could become much better
observers of our inner lives with new concepts.

01:14:19.469 --> 01:14:27.320
And that doesn't mean that science somehow
is gonna be this -- overwhelm every other

01:14:27.320 --> 01:14:32.199
kind of talk where we'll talk in terms of
neurotransmitters and not use words like love

01:14:32.199 --> 01:14:33.199
and happiness.

01:14:33.199 --> 01:14:38.820
&gt;&gt; I was thinking more of like a ubiquitous
accomplice to some of these other understandings.

01:14:38.820 --> 01:14:42.349
Science just always having some input in these
other areas.

01:14:42.349 --> 01:14:45.699
&gt;&gt;Sam: Yeah, I'm a fan of the notion of Consilience.

01:14:45.699 --> 01:14:50.679
I don't think that book has necessarily aged
so well in every regard.

01:14:50.679 --> 01:14:56.690
But the notion that there are actually no
real boundaries between knowledge domains,

01:14:56.690 --> 01:14:57.690
I agree with.

01:14:57.690 --> 01:15:03.860
I think the boundaries are there by virtue
of bookkeeping and university architecture

01:15:03.860 --> 01:15:05.770
and just shortages of time.

01:15:05.770 --> 01:15:13.440
I mean the fact that you can't -- it takes
too much time to specialize in any one area,

01:15:13.440 --> 01:15:15.099
to specialize in every area.

01:15:15.099 --> 01:15:19.260
And knowledge is doubling every three years
or five years in the sciences.

01:15:19.260 --> 01:15:23.489
So if you knew everything today, three to
five years from now you know exactly half

01:15:23.489 --> 01:15:24.940
of everything.

01:15:24.940 --> 01:15:35.440
So that aside I think, there is just one space
of facts to know and ways to talk about them

01:15:35.440 --> 01:15:43.179
and beliefs to have them.

01:15:43.179 --> 01:15:44.729
Yeah?

01:15:44.729 --> 01:15:50.170
&gt;&gt; Does anyone on VC have any questions, anyone
left?

01:15:50.170 --> 01:15:52.140
No.

01:15:52.140 --> 01:15:58.619
All right, great, well thanks a lot Sam.

01:15:58.619 --> 01:16:01.659
Sam: Yeah, thank you.

01:16:01.659 --> 01:16:02.419
[Applause]

