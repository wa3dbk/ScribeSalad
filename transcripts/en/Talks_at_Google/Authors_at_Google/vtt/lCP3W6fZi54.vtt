WEBVTT
Kind: captions
Language: en

00:00:02.050 --> 00:00:07.860
[applause]
&gt;&gt;Tim Harford: Thank you very much Cynthia.

00:00:07.860 --> 00:00:09.269
Thanks everyone for coming.

00:00:09.269 --> 00:00:15.019
I know there are lots of things going on on
campus that are interesting and distracting.

00:00:15.019 --> 00:00:18.890
So I appreciate you taking the trouble to
turn out and listen to me.

00:00:18.890 --> 00:00:23.589
One of the messages of the book "Adapt" is
that we should experiment in trying new things.

00:00:23.589 --> 00:00:25.880
And that's the way that we solve complex problems.

00:00:25.880 --> 00:00:28.490
So let me start with a little experiment.

00:00:28.490 --> 00:00:29.849
Or at least testing the water.

00:00:29.849 --> 00:00:32.710
There are three things that I could talk to
you about today.

00:00:32.710 --> 00:00:37.640
I could focus on Chapter 1 of the book which
is about how we solve problems in a complex

00:00:37.640 --> 00:00:38.920
world.

00:00:38.920 --> 00:00:44.780
I could talk about Chapter 3 of the book which
is how we nurture innovations that matter.

00:00:44.780 --> 00:00:49.739
Or I could talk about Chapter 6 in the book
which is how we prevent financial meltdowns.

00:00:49.739 --> 00:00:54.090
So Chapter 1, problem solving in a complex
world.

00:00:54.090 --> 00:00:56.429
Chapter 2, nurturing innovations that matter.

00:00:56.429 --> 00:00:57.800
Chapter 3 preventing financial meltdown.

00:00:57.800 --> 00:00:59.700
I just want a quick show of hands.

00:00:59.700 --> 00:01:02.420
Who would prefer Chapter 1?

00:01:02.420 --> 00:01:05.409
"Problem solving in a complex world?"

00:01:05.409 --> 00:01:09.280
Okay, who would prefer Chapter 3?

00:01:09.280 --> 00:01:12.590
"Nurturing innovations that matter?"

00:01:12.590 --> 00:01:14.880
Who would prefer Chapter 6?

00:01:14.880 --> 00:01:17.770
"Preventing financial meltdowns."

00:01:17.770 --> 00:01:21.550
[laughter]
&gt;&gt;Harford: You are so East Coast.

00:01:21.550 --> 00:01:25.570
[laughter]
&gt;&gt;Harford: So okay well it was kind of even.

00:01:25.570 --> 00:01:31.600
Last night I spoke in Seattle and I asked
the same question and people, it was also

00:01:31.600 --> 00:01:32.600
kind even.

00:01:32.600 --> 00:01:34.910
And I talked about nurturing innovations that
matter.

00:01:34.910 --> 00:01:42.360
So forgive me if purely to keep me you know
suitably inexperienced and capable of failure

00:01:42.360 --> 00:01:43.590
I talk about the other subjects.

00:01:43.590 --> 00:01:45.360
I talk about problem solving in a complex
world.

00:01:45.360 --> 00:01:46.960
Since I think it was pretty much 50-50.

00:01:46.960 --> 00:01:51.360
So why do I say the world's complex?

00:01:51.360 --> 00:01:57.280
Let me start by telling the story of one of
my countrymen, a gentleman called, Thomas

00:01:57.280 --> 00:02:00.950
Thwaites
Who set himself a very difficult task.

00:02:00.950 --> 00:02:02.350
Thomas Thwaites wanted to make a toaster.

00:02:02.350 --> 00:02:07.600
He wanted to make a toaster that was the equivalent
of a seven dollar toaster he could buy on

00:02:07.600 --> 00:02:08.600
Main Street.

00:02:08.600 --> 00:02:13.540
And, I'm not talking about making a toaster
from a toaster kit.

00:02:13.540 --> 00:02:20.380
I mean, imagine this guy you know dressed
only in a loincloth armed with a penknife.

00:02:20.380 --> 00:02:23.580
Ready to build a toaster from raw materials.

00:02:23.580 --> 00:02:26.380
To dig the iron from out of the earth.

00:02:26.380 --> 00:02:30.620
To carve the wood that goes into all good
toasters from the tree.

00:02:30.620 --> 00:02:37.430
Whatever, to produce from raw materials this
pretty straightforward inexpensive consumer

00:02:37.430 --> 00:02:38.590
product.

00:02:38.590 --> 00:02:40.670
It turns out this is a pretty difficult project.

00:02:40.670 --> 00:02:46.300
So the first thing he did was to buy a seven
dollar toaster and take it apart.

00:02:46.300 --> 00:02:51.120
And he discovered that a toaster actually
contains over 400 components and subcomponents.

00:02:51.120 --> 00:02:53.240
It contains a number of different materials.

00:02:53.240 --> 00:02:59.260
It contains iron, nickel, copper, mica which
is a sort of slate like material that you

00:02:59.260 --> 00:03:00.770
wrap the heating element around.

00:03:00.770 --> 00:03:02.850
Plastic, plastic's very important.

00:03:02.850 --> 00:03:09.490
If you didn't have plastic, how would you
have the beautiful sleek looking toaster casing?

00:03:09.490 --> 00:03:12.420
There's also the whole electrocution issue.

00:03:12.420 --> 00:03:13.880
It's kind of important.

00:03:13.880 --> 00:03:17.290
So it's a hugely complex problem, so where
does he start?

00:03:17.290 --> 00:03:19.030
Okay I'm gonna get iron.

00:03:19.030 --> 00:03:21.940
So he's English.

00:03:21.940 --> 00:03:26.970
Great Britain is a postindustrial country,
we don't actually have any iron mines anymore.

00:03:26.970 --> 00:03:32.050
But he called a place and he said I'm trying
to make a toaster, can I come in.

00:03:32.050 --> 00:03:37.569
So he visited this museum, it used to be an
iron mine now it's simply a museum of iron

00:03:37.569 --> 00:03:38.569
mining.

00:03:38.569 --> 00:03:43.320
And they very kindly gave him a bunch of iron
ore to fill.

00:03:43.320 --> 00:03:45.880
He had one of these roll-on suitcases.

00:03:45.880 --> 00:03:48.400
So he filled that with iron ore.

00:03:48.400 --> 00:03:53.620
So then he had to turn iron ore into iron.

00:03:53.620 --> 00:03:59.069
Well, I don't know, maybe somebody here knows
how you do that, but I'm not too clear.

00:03:59.069 --> 00:04:02.530
So the first experiment there was he had this
big trashcan.

00:04:02.530 --> 00:04:04.610
He had a leaf blower.

00:04:04.610 --> 00:04:06.070
He had barbecue coals.

00:04:06.070 --> 00:04:09.880
He's trying to use the leaf blower to sort
of blow air over the barbecue coals, get them

00:04:09.880 --> 00:04:10.880
as hot as possible.

00:04:10.880 --> 00:04:12.670
To try and smelt this iron.

00:04:12.670 --> 00:04:14.750
That didn't work.

00:04:14.750 --> 00:04:21.299
He then discovered, there was a fairly recent
patent for a new process to smelt iron.

00:04:21.299 --> 00:04:27.059
And it turns out that you can smelt iron in
a microwave.

00:04:27.059 --> 00:04:28.520
I do have the photos.

00:04:28.520 --> 00:04:32.210
I should probably say I have the photos of
the second microwave.

00:04:32.210 --> 00:04:34.639
[laughter]
&gt;&gt;Harford: The first microwave didn't survive

00:04:34.639 --> 00:04:35.639
the experience.

00:04:35.639 --> 00:04:36.639
[laughter]
&gt;&gt;Harford: But he did manage do the iron.

00:04:36.639 --> 00:04:39.370
So then he just sort of went on with this
sort of process.

00:04:39.370 --> 00:04:42.449
You'll have notice by the way, there was already
a compromise.

00:04:42.449 --> 00:04:49.139
The purity of that initial vision, remember,
just to make the toaster with your bare hands

00:04:49.139 --> 00:04:50.539
or maybe a Swiss Army knife.

00:04:50.539 --> 00:04:52.280
And now he's using a microwave.

00:04:52.280 --> 00:04:57.330
A microwave is clearly a more expensive complex
product than a toaster.

00:04:57.330 --> 00:05:00.320
So there were some issues there, but let's
pass on.

00:05:00.320 --> 00:05:02.460
And we'll come back to them.

00:05:02.460 --> 00:05:03.460
So plastic.

00:05:03.460 --> 00:05:04.930
Where does plastic come from?

00:05:04.930 --> 00:05:05.930
Petroleum.

00:05:05.930 --> 00:05:07.780
Where does petroleum come from?

00:05:07.780 --> 00:05:10.990
BP, they got loads of it.

00:05:10.990 --> 00:05:13.129
They spill it everywhere.

00:05:13.129 --> 00:05:21.319
So he called BP and he said "Could I please
take a trip out to an oil rig?

00:05:21.319 --> 00:05:25.870
I'll bring my own can, I'd like some crude
oil I'm gonna make some plastic."

00:05:25.870 --> 00:05:27.300
They said no, I don't know why they said no.

00:05:27.300 --> 00:05:30.680
You know some reason.

00:05:30.680 --> 00:05:35.699
He did discover though there is a way of making
a kind of plastic from potato starch.

00:05:35.699 --> 00:05:37.139
So he did that.

00:05:37.139 --> 00:05:43.180
The trouble is, it's edible, so he lost half
of it to mold and the other half to snails.

00:05:43.180 --> 00:05:48.889
And he finally got his plastic by just scavenging
some plastics from somewhere and melting it.

00:05:48.889 --> 00:05:51.330
So again, he's kind of cheating.

00:05:51.330 --> 00:05:57.210
The copper, he got from the water from a disused
copper mine by electrolysis.

00:05:57.210 --> 00:06:00.400
So that's a fairly modern technique.

00:06:00.400 --> 00:06:01.550
And the nickel, you wanna guess?

00:06:01.550 --> 00:06:03.749
Where do you get nickel from?

00:06:03.749 --> 00:06:08.169
[laughter]
&gt;&gt;Harford: Absolutely, you buy a Canadian

00:06:08.169 --> 00:06:10.009
commemorative dollar.

00:06:10.009 --> 00:06:13.389
It's 99.99% nickel.

00:06:13.389 --> 00:06:14.990
And there's your nickel.

00:06:14.990 --> 00:06:16.050
Very easy.

00:06:16.050 --> 00:06:22.070
So he's making these compromises with his
original vision.

00:06:22.070 --> 00:06:27.229
But you know, he said to me, "You know Tim,
I realize if you, if it was just you, and

00:06:27.229 --> 00:06:31.719
you are just trying to make a toaster all
by yourself.

00:06:31.719 --> 00:06:35.029
You could spend your whole life and you still
wouldn't get that."

00:06:35.029 --> 00:06:37.409
Turns out it's basically an impossible problem.

00:06:37.409 --> 00:06:42.770
And the toaster he eventually produced I don't
know how to describe it.

00:06:42.770 --> 00:06:46.870
You know when you're a bit younger, it was
your birthday.

00:06:46.870 --> 00:06:51.339
You might ask your Mom to do you a birthday
cake with a special shape.

00:06:51.339 --> 00:06:53.789
So for me it was a ladybug.

00:06:53.789 --> 00:06:55.050
Okay?

00:06:55.050 --> 00:06:58.580
Just me, no one else ever got a birthday cake
and a special shape?

00:06:58.580 --> 00:07:03.990
So okay imagine that you're getting your Mom
to produce you a specially shaped birthday

00:07:03.990 --> 00:07:04.990
cake.

00:07:04.990 --> 00:07:05.990
Or your dad, I'm not you know I'm modern.

00:07:05.990 --> 00:07:07.969
I'm not judging.

00:07:07.969 --> 00:07:12.210
So your Mom is producing this birthday cake.

00:07:12.210 --> 00:07:16.759
And imagine you said "I want it in the shape
of a toaster Mom."

00:07:16.759 --> 00:07:19.029
And imagine that your Mom did that.

00:07:19.029 --> 00:07:22.580
And imagine that your Mom was also very very
drunk.

00:07:22.580 --> 00:07:25.341
[laughter]
&gt;&gt;Harford: That's kind of what Thomas Thwaites

00:07:25.341 --> 00:07:33.190
got with this sort of oozing dripping congealed
plastic coating on this toaster.

00:07:33.190 --> 00:07:39.800
And he said to me, you know when I plug it
into a battery it does get warm.

00:07:39.800 --> 00:07:43.430
But I am not sure what's gonna happen when
I plug it into the mains.

00:07:43.430 --> 00:07:45.199
So he had a big exhibition.

00:07:45.199 --> 00:07:47.669
He showed all the different things he had
done.

00:07:47.669 --> 00:07:48.669
All the different experiments.

00:07:48.669 --> 00:07:53.229
All the different items of equipment he done
to produce his toaster.

00:07:53.229 --> 00:07:57.139
At the end of the exhibition they had a few
drinks and he plugged the toaster into the

00:07:57.139 --> 00:07:58.139
mains.

00:07:58.139 --> 00:08:01.439
2 seconds later the toaster was toast.

00:08:01.439 --> 00:08:11.460
And I tell this story because it's worth pausing
a moment to think about the tremendous complexity

00:08:11.460 --> 00:08:14.060
of the economy that surrounds us.

00:08:14.060 --> 00:08:16.839
And therefore the society that surrounds us.

00:08:16.839 --> 00:08:22.710
A pretty simple product like a toaster is
actually far beyond the capability of any

00:08:22.710 --> 00:08:25.999
one person.

00:08:25.999 --> 00:08:30.360
It's produced instead by a decentralized team
effort.

00:08:30.360 --> 00:08:36.199
So the copper from the toaster might come
from say the Chuquicamata mine in Chile.

00:08:36.199 --> 00:08:40.250
Where there's this guy who drives these gigantic
trucks you know.

00:08:40.250 --> 00:08:42.199
You couldn't fit one into this room.

00:08:42.199 --> 00:08:44.540
Huge huge trucks full of copper ore.

00:08:44.540 --> 00:08:47.560
And he just goes around and around and around
this huge opencast mine.

00:08:47.560 --> 00:08:52.050
As he's driving with his copper in the back
of his truck.

00:08:52.050 --> 00:08:54.230
Maybe it's going to the toaster.

00:08:54.230 --> 00:08:56.230
Maybe it's gonna make the casing of a bullet.

00:08:56.230 --> 00:08:57.960
He doesn't know, he doesn't need to know.

00:08:57.960 --> 00:09:01.230
He's just doing his part in that team effort.

00:09:01.230 --> 00:09:03.550
That decentralized team effort.

00:09:03.550 --> 00:09:06.290
And there are so many products.

00:09:06.290 --> 00:09:11.690
So a reasonable educated guess in a ancestral
society.

00:09:11.690 --> 00:09:12.690
A hunter gatherer society.

00:09:12.690 --> 00:09:15.430
The kind of society where our brains evolved.

00:09:15.430 --> 00:09:19.870
There might have been two or 300 distinct
products.

00:09:19.870 --> 00:09:23.930
If you know this kind of flint knife, that
kind of flint knife.

00:09:23.930 --> 00:09:26.779
This kind of loincloth, that kind of loincloth.

00:09:26.779 --> 00:09:27.990
There's not a lot going on.

00:09:27.990 --> 00:09:32.569
There's some interesting and complex challenges,
but not very many products in this economy.

00:09:32.569 --> 00:09:38.600
So anybody want to guess how many products
are on sale in Starbucks.

00:09:38.600 --> 00:09:42.459
Typical branch of Starbucks
&gt;&gt;female audience member #1: 60?

00:09:42.459 --> 00:09:43.459
&gt;&gt;Harford: 60.

00:09:43.459 --> 00:09:50.930
Ok, so Starbucks, that makes a hunter gatherer
society five times more complex than a Starbucks.

00:09:50.930 --> 00:09:52.540
Let's have a guess.

00:09:52.540 --> 00:09:55.600
Put your hands up if you think there are more
than 60.

00:09:55.600 --> 00:10:00.209
Hands up if you think there are fewer than
60.

00:10:00.209 --> 00:10:04.370
Okay so we've got one at 60, we've got I think
one say fewer than 60.

00:10:04.370 --> 00:10:08.800
Alright let's have a higher estimate than
60 then since most of you think it's more

00:10:08.800 --> 00:10:09.800
than 60.

00:10:09.800 --> 00:10:12.199
&gt;&gt;male audience member #1: 1000
&gt;&gt;Harford: 1000

00:10:12.199 --> 00:10:14.629
Okay so hands up if you think it's more than
1000.

00:10:14.629 --> 00:10:19.190
Hands up if you think it's fewer than 1000.

00:10:19.190 --> 00:10:22.240
Okay so it was good were kind of between 60
and 1000.

00:10:22.240 --> 00:10:23.470
Good, well done.

00:10:23.470 --> 00:10:28.760
Turns out according to Starbucks there are
85,000 products on sale in a typical Starbucks.

00:10:28.760 --> 00:10:29.882
&gt;&gt;female audience member #2: On sale?

00:10:29.882 --> 00:10:31.170
&gt;&gt;Harford: On sale in a typical Starbucks.

00:10:31.170 --> 00:10:33.339
I mean, they get to cheat right, because it's
combinatorial.

00:10:33.339 --> 00:10:36.820
I mean every different squirt of goop creates
a different product.

00:10:36.820 --> 00:10:37.981
But let's cheat a bit less.

00:10:37.981 --> 00:10:39.149
Let's think about Wal-Mart.

00:10:39.149 --> 00:10:42.690
Okay, they can't create a new product by sort
of adding marshmallows.

00:10:42.690 --> 00:10:46.930
Number of products on sale in a typical Walmart
is about 100,000.

00:10:46.930 --> 00:10:49.740
And the number of products, distinct products.

00:10:49.740 --> 00:10:53.199
By which I mean product that you'd need a
different barcode for each product.

00:10:53.199 --> 00:10:54.199
Okay?

00:10:54.199 --> 00:10:56.269
So distinctive types of product.

00:10:56.269 --> 00:11:00.149
You change the color of the jeans, or you
change the cut, or you change the size and

00:11:00.149 --> 00:11:02.970
you've got a different product.

00:11:02.970 --> 00:11:04.360
How many different barcodes would you need?

00:11:04.360 --> 00:11:06.300
How many different products in the Bay area?

00:11:06.300 --> 00:11:08.300
Anyone want to guess?

00:11:08.300 --> 00:11:11.019
There's a guy who's thought about this quite
hard.

00:11:11.019 --> 00:11:13.660
Eric Beinhocker at McKinsey, he's pretty smart.

00:11:13.660 --> 00:11:15.379
Any guess?

00:11:15.379 --> 00:11:17.100
6 million.

00:11:17.100 --> 00:11:18.420
Okay let's put hands up.

00:11:18.420 --> 00:11:21.020
More than 6 million?

00:11:21.020 --> 00:11:23.629
Fewer than 6 million?

00:11:23.629 --> 00:11:24.750
Okay and most people have no idea, that's
fair enough.

00:11:24.750 --> 00:11:27.740
[laughter]
&gt;&gt;Harford: It is more than 6 million.

00:11:27.740 --> 00:11:29.670
It's actually more than 6 billion.

00:11:29.670 --> 00:11:31.500
You're out by about three orders of magnitude.

00:11:31.500 --> 00:11:33.080
It's about 10 billion.

00:11:33.080 --> 00:11:35.120
Distinct products and services on sale in
the Bay Area.

00:11:35.120 --> 00:11:40.890
And it has more types of products and there
are people I suspect.

00:11:40.890 --> 00:11:43.160
That's the complexity of the economy that
surrounds us.

00:11:43.160 --> 00:11:46.430
Now if I were, if I were just in my economist
mode.

00:11:46.430 --> 00:11:47.940
And this was a stage.

00:11:47.940 --> 00:11:54.009
I would say, "Wow the economy is very complicated
and very impressive."

00:11:54.009 --> 00:11:56.050
And it's decentralized.

00:11:56.050 --> 00:11:59.930
Barack Obama doesn't run it.

00:11:59.930 --> 00:12:01.439
Bill Gates doesn't run it.

00:12:01.439 --> 00:12:02.439
Wall Street doesn't run it.

00:12:02.439 --> 00:12:03.439
Nobody runs it.

00:12:03.439 --> 00:12:05.459
It's a decentralized system.

00:12:05.459 --> 00:12:08.959
No one's in control, and it produces these
amazing things.

00:12:08.959 --> 00:12:12.319
We get toasters for seven dollars.

00:12:12.319 --> 00:12:15.770
You could never make that in your whole life
if you try.

00:12:15.770 --> 00:12:18.949
You could devote your entire life to making
a toaster you still wouldn't do it.

00:12:18.949 --> 00:12:21.670
And this is the complexity of the economy
that surrounds us.

00:12:21.670 --> 00:12:27.240
And it's magnificent, and it's wonderful,
and let's leave it at that shall we?

00:12:27.240 --> 00:12:29.189
And just thumbs up for the market.

00:12:29.189 --> 00:12:32.100
And, you know there's a point there.

00:12:32.100 --> 00:12:33.899
There really is a point.

00:12:33.899 --> 00:12:35.939
And yet.

00:12:35.939 --> 00:12:42.930
Does anybody in this room think that the world
is currently perfect?

00:12:42.930 --> 00:12:47.009
Okay, no votes.

00:12:47.009 --> 00:12:48.200
We have problems.

00:12:48.200 --> 00:12:50.860
We have some serious problems facing us.

00:12:50.860 --> 00:12:56.379
I think that we have a problem with the kind
of innovation that we produce.

00:12:56.379 --> 00:12:59.269
I think there's certain kinds of innovation
we're very good at producing.

00:12:59.269 --> 00:13:01.000
I think there are certain others.

00:13:01.000 --> 00:13:06.730
A lot of medical innovations, we still don't
have that HIV vaccine that President Reagan's

00:13:06.730 --> 00:13:10.519
Health Secretary promised us back in 1984.

00:13:10.519 --> 00:13:16.089
We still don't have that cost competitive
clean energy system we've been sort of talking

00:13:16.089 --> 00:13:17.699
about for the last 30 years.

00:13:17.699 --> 00:13:20.590
I mean, I understand you did do your bit this
morning well done.

00:13:20.590 --> 00:13:23.639
But we haven't solved that yet.

00:13:23.639 --> 00:13:25.680
We have innovation problems.

00:13:25.680 --> 00:13:30.040
We have environmental problems, severe environmental
problems.

00:13:30.040 --> 00:13:32.790
There are wars.

00:13:32.790 --> 00:13:36.110
You may have noticed some minor disruption
on Wall Street recently.

00:13:36.110 --> 00:13:39.170
You know we've got problems.

00:13:39.170 --> 00:13:42.060
And that's just, that's just in the Western
world.

00:13:42.060 --> 00:13:44.360
Let alone Sub-Saharan Africa.

00:13:44.360 --> 00:13:47.910
So, these are big problems.

00:13:47.910 --> 00:13:56.269
And Thomas Thwaites' toaster is, because it's
a symbol of the sophistication of our economy

00:13:56.269 --> 00:14:03.310
and our society it is also a symbol of the
hurdles and obstacles that lie in wait for

00:14:03.310 --> 00:14:06.940
people who want to change it and make it better.

00:14:06.940 --> 00:14:10.470
And that's the challenge I want to talk to
you about today.

00:14:10.470 --> 00:14:14.670
Now, I think the world's only gonna become
more complex.

00:14:14.670 --> 00:14:20.740
And I think the way we tend to think about
these problems is not necessarily terribly

00:14:20.740 --> 00:14:22.540
helpful.

00:14:22.540 --> 00:14:26.190
So we tend to be very focused on a leadership
model.

00:14:26.190 --> 00:14:30.060
We can find the right leader with the right
ideas.

00:14:30.060 --> 00:14:34.610
You know these problems would be solved.

00:14:34.610 --> 00:14:41.162
And Barack Obama is not going to solve all
our problems and he knows he's not gonna solve

00:14:41.162 --> 00:14:42.162
all our problems.

00:14:42.162 --> 00:14:46.420
I loved his first speech to the White House
press corps after he was elected President.

00:14:46.420 --> 00:14:51.090
He sort of mocked the expectations that everybody
had of him.

00:14:51.090 --> 00:14:58.000
And he said, " I'm very proud of the things
we've achieved in my first hundred days but

00:14:58.000 --> 00:15:02.540
I now want to talk to you about what I propose
to achieve in my second hundred days."

00:15:02.540 --> 00:15:08.829
"And my second hundred days I will design
and build a library devoted to the achievements

00:15:08.829 --> 00:15:10.089
of my first hundred days."

00:15:10.089 --> 00:15:13.319
[laughter]
Harford: "And my second hundred days will

00:15:13.319 --> 00:15:17.810
be so successful, they will be completed in
only 72 days."

00:15:17.810 --> 00:15:21.000
"And on the 73rd day I will rest."

00:15:21.000 --> 00:15:23.259
So he was mocking these expectations.

00:15:23.259 --> 00:15:27.480
And in his autobiography he says change doesn't
come from the top.

00:15:27.480 --> 00:15:30.490
Change comes from a mobilized grassroots.

00:15:30.490 --> 00:15:34.550
And the reason that he said that is in a world
where there are 10 billion products in the

00:15:34.550 --> 00:15:38.759
Bay Area, there are 100,000 products in a
Wal-Mart.

00:15:38.759 --> 00:15:43.139
Where any one of those products would be as
complex as a toaster or much more complex

00:15:43.139 --> 00:15:44.199
than a toaster.

00:15:44.199 --> 00:15:47.810
Where we don't really understand how it all
fits together.

00:15:47.810 --> 00:15:52.240
Where no one person can track how it's all
going, how it all works.

00:15:52.240 --> 00:15:58.519
He understands that there are limits to top-down
solutions to our problems.

00:15:58.519 --> 00:16:05.610
And you might say well fine, no one man or
it usually is a man, no one woman, no one

00:16:05.610 --> 00:16:08.730
person is gonna be able to provide the leadership
to get us through this.

00:16:08.730 --> 00:16:11.819
But maybe with the right expert advice.

00:16:11.819 --> 00:16:16.180
With smart enough people, they could just
figure out solutions to these problems.

00:16:16.180 --> 00:16:19.740
And I think, clearly that is true in certain
spirited endeavor.

00:16:19.740 --> 00:16:23.471
But I think in most of the problems that really
interest us the social problems, the problems

00:16:23.471 --> 00:16:24.990
of Social Science.

00:16:24.990 --> 00:16:30.079
A Social Science expertise has a limited track
record.

00:16:30.079 --> 00:16:35.410
I know that Philip Tetlock the psychologist
has come here and spoken at Google.

00:16:35.410 --> 00:16:40.939
If you didn't see him, you should check out
his talk on Authors@Google.

00:16:40.939 --> 00:16:48.529
Tetlock is a fascinating researcher who has
wrestled for 25 years with the question of

00:16:48.529 --> 00:16:51.790
expert judgment in the Social Sciences.

00:16:51.790 --> 00:16:56.380
And to cut a tremendous, wonderful story short.

00:16:56.380 --> 00:17:03.190
What Tetlock did to test out the question
of expert judgment in Social Sciences was

00:17:03.190 --> 00:17:07.740
to round up experts of every field in the
Social Sciences.

00:17:07.740 --> 00:17:17.620
From academia and more practical people, diplomats,
journalists, spies, policy wonks, think tankers.

00:17:17.620 --> 00:17:22.370
And ask, and there were economists, sociologists,
anthropologists, political scientists, historians.

00:17:22.370 --> 00:17:26.630
He would ask them to make forecasts.

00:17:26.630 --> 00:17:28.020
About the future of the world.

00:17:28.020 --> 00:17:30.340
In all its guises.

00:17:30.340 --> 00:17:33.050
Economic forecast, political forecasts.

00:17:33.050 --> 00:17:34.950
Forecast about their area of expertise.

00:17:34.950 --> 00:17:36.730
Forecasts outside their area of expertise.

00:17:36.730 --> 00:17:38.200
Short-term and long-term.

00:17:38.200 --> 00:17:41.170
The point is, these forecasts were all quantifiable.

00:17:41.170 --> 00:17:45.430
What Tetlock wanted to do was what we so rarely
do.

00:17:45.430 --> 00:17:51.540
Which was to come back later and call people
on what they had actually predicted.

00:17:51.540 --> 00:17:56.110
And what he found in a nutshell was, you might
as well have asked an orangutan because they

00:17:56.110 --> 00:17:59.940
would have done just as good a job as any
of these experts.

00:17:59.940 --> 00:18:05.380
And he found certain patterns in the data
about who gives really bad forecasts and who

00:18:05.380 --> 00:18:07.330
give slightly better forecast.

00:18:07.330 --> 00:18:11.640
But basically, experts can't forecast it doesn't
matter what field you're talking about.

00:18:11.640 --> 00:18:13.240
In the Social Sciences.

00:18:13.240 --> 00:18:17.410
Now at this point, a lot of people have said,
'cause Tetlock's work has become quite famous.

00:18:17.410 --> 00:18:20.500
"Well that just goes to show, you can't trust
the experts.

00:18:20.500 --> 00:18:22.550
You know, do it yourself."

00:18:22.550 --> 00:18:24.910
Well I'm not convinced about this.

00:18:24.910 --> 00:18:34.360
I mean I'm not, if I ever need say heart surgery
I am not going to propose that I just ask

00:18:34.360 --> 00:18:37.030
my wife to do it.

00:18:37.030 --> 00:18:39.910
You know I'm gonna ask a heart surgeon.

00:18:39.910 --> 00:18:42.130
Tomorrow I'm flying to Toronto.

00:18:42.130 --> 00:18:44.540
I would like the pilot to be an expert.

00:18:44.540 --> 00:18:45.540
Yeah?

00:18:45.540 --> 00:18:48.440
It's not, it's simply not good enough to say
do it yourself experts are useless.

00:18:48.440 --> 00:18:51.160
It's not really a statement about the nature
of expertise.

00:18:51.160 --> 00:18:54.690
It's a statement about the complexity of the
world that we can't forecast it.

00:18:54.690 --> 00:18:56.970
There are always gonna be surprises.

00:18:56.970 --> 00:19:02.610
We can make plans, we can consult experts
to try and solve these problems that I'm talking

00:19:02.610 --> 00:19:04.150
about.

00:19:04.150 --> 00:19:07.670
And we will constantly be surprised.

00:19:07.670 --> 00:19:09.830
So fine.

00:19:09.830 --> 00:19:11.200
How do we solve problems then?

00:19:11.200 --> 00:19:13.460
How do we solve complex problems?

00:19:13.460 --> 00:19:17.810
Well one possibility is to think about a problem
that I think we have nailed.

00:19:17.810 --> 00:19:20.380
And to look at how it's been solved.

00:19:20.380 --> 00:19:24.300
And I think a problem that we've fixed is
the problem of material affluence.

00:19:24.300 --> 00:19:27.530
We certainly fixed that problem here at Mountain
View.

00:19:27.530 --> 00:19:30.830
And I think we've basically fixed that problem
in the Western world.

00:19:30.830 --> 00:19:33.240
And it's a problem that's not easy to fix.

00:19:33.240 --> 00:19:38.660
It's a problem that defeated feudalism; it's
a problem that defeated Soviet Union and Communist

00:19:38.660 --> 00:19:39.750
China.

00:19:39.750 --> 00:19:44.320
It's a problem that human societies have been
wrestling with for you know 25,000 years or

00:19:44.320 --> 00:19:45.320
so.

00:19:45.320 --> 00:19:49.220
Providing just enough stuff to keep people
happy.

00:19:49.220 --> 00:19:55.360
Clothes to wear, place to sleep, food to eat,
and we've solved it.

00:19:55.360 --> 00:19:56.820
And think about the toaster.

00:19:56.820 --> 00:19:59.730
This is not a problem to trivialize.

00:19:59.730 --> 00:20:02.140
It's a very very hard problem.

00:20:02.140 --> 00:20:03.140
Okay.

00:20:03.140 --> 00:20:04.660
How did we solve it?

00:20:04.660 --> 00:20:12.250
Well you could say we solved it, we solved
it with a big reliance on private businesses.

00:20:12.250 --> 00:20:15.330
Okay so, what's the trick?

00:20:15.330 --> 00:20:19.260
So I've asked a number of private business
people about this and they say well the reason

00:20:19.260 --> 00:20:23.350
that private business solved problem so well
is because people who work for private businesses

00:20:23.350 --> 00:20:24.610
are very very smart.

00:20:24.610 --> 00:20:26.130
Especially me.

00:20:26.130 --> 00:20:29.500
And I'm not so sure about that.

00:20:29.500 --> 00:20:34.270
I mean I could understand if you read business
week or Forbes and Fortune they will tell

00:20:34.270 --> 00:20:36.410
you that businesses are run by very smart
people.

00:20:36.410 --> 00:20:37.820
And that's why they do amazing things.

00:20:37.820 --> 00:20:41.620
And they'll tell you about the new CEO of
this company or that company and how clever

00:20:41.620 --> 00:20:43.200
they are.

00:20:43.200 --> 00:20:47.680
And then of course half the time they get
sacked three years later with a huge payoff

00:20:47.680 --> 00:20:51.560
having totally failed to do anything of any
consequence.

00:20:51.560 --> 00:20:56.580
That's actually not the problem-solving algorithm
at work.

00:20:56.580 --> 00:20:57.580
What is the problem?

00:20:57.580 --> 00:20:58.860
Is not hire smart people.

00:20:58.860 --> 00:21:00.320
That's just experts all over again.

00:21:00.320 --> 00:21:01.970
What is the problem-solving algorithm?

00:21:01.970 --> 00:21:04.860
Well here's a clue.

00:21:04.860 --> 00:21:12.720
In 1982 Tom Peters who since became a huge
larger-than-life management guru.

00:21:12.720 --> 00:21:16.681
Published a book called "In search of excellence."

00:21:16.681 --> 00:21:20.020
And the book was a huge business bestseller.

00:21:20.020 --> 00:21:25.150
It was about the 43 most excellent companies
in America.

00:21:25.150 --> 00:21:27.590
And what we can all learn from them.

00:21:27.590 --> 00:21:32.540
So we learn from their marketing,
their advertising, their human resources policy.

00:21:32.540 --> 00:21:39.740
You know, how do they run their businesses
and what can the rest of the world learn from

00:21:39.740 --> 00:21:43.900
these 43 excellent American businesses?

00:21:43.900 --> 00:21:45.570
Fine.

00:21:45.570 --> 00:21:50.550
Three years later, Business Week had a cover
story.

00:21:50.550 --> 00:21:55.700
"Oops, Who's Excellent Now?"

00:21:55.700 --> 00:22:01.870
And almost a third of those excellent companies
were in financial trouble just three years

00:22:01.870 --> 00:22:03.150
later.

00:22:03.150 --> 00:22:07.430
I would love to turn this into a story about
how Tom Peters is a silly man.

00:22:07.430 --> 00:22:10.152
But it's not really a story about how Tom
Peters is a silly man.

00:22:10.152 --> 00:22:12.200
It's a story about failure in business.

00:22:12.200 --> 00:22:14.070
It's ubiquitous.

00:22:14.070 --> 00:22:18.280
We go all the way back to the Johannes Gutenberg.

00:22:18.280 --> 00:22:20.220
He's really cool again suddenly.

00:22:20.220 --> 00:22:25.650
He's sort of the symbol of you know web two,
web three or wherever we're up to these days.

00:22:25.650 --> 00:22:31.920
The invention of the movable type printing
press.

00:22:31.920 --> 00:22:36.180
So Gutenberg invents, in a way he invents
the modern world.

00:22:36.180 --> 00:22:39.600
By making it possible to print books.

00:22:39.600 --> 00:22:44.460
And he creates this fantastic object, the
42 line Bible.

00:22:44.460 --> 00:22:45.770
The Gutenberg Bible.

00:22:45.770 --> 00:22:47.470
Only a few copies out there exist.

00:22:47.470 --> 00:22:52.320
And it's this beautiful printed Bible.

00:22:52.320 --> 00:22:59.200
That many people regard as one of the most
remarkable books in the history of Western

00:22:59.200 --> 00:23:02.040
civilization.

00:23:02.040 --> 00:23:11.360
What is not often commented on is that Gutenberg's
Bible bankrupted Johannes Gutenberg.

00:23:11.360 --> 00:23:12.360
He got into debt.

00:23:12.360 --> 00:23:15.220
He got into an argument with his business
partner.

00:23:15.220 --> 00:23:16.500
And that was it.

00:23:16.500 --> 00:23:17.500
He was gone.

00:23:17.500 --> 00:23:20.160
He was a failure.

00:23:20.160 --> 00:23:22.020
In many ways.

00:23:22.020 --> 00:23:25.550
He was a success as far as we're all concerned.

00:23:25.550 --> 00:23:29.400
But in his own life he failed as a business
person.

00:23:29.400 --> 00:23:34.800
And it turns out; actually printing Bibles
is not necessarily what you want to do.

00:23:34.800 --> 00:23:39.320
Logically you would think, I developed this
fantastic new technology.

00:23:39.320 --> 00:23:41.060
You can print books.

00:23:41.060 --> 00:23:43.190
What is the greatest book in the world?

00:23:43.190 --> 00:23:44.760
The Bible.

00:23:44.760 --> 00:23:45.760
That's the name you know.

00:23:45.760 --> 00:23:46.760
It means "the book."

00:23:46.760 --> 00:23:49.480
I will print the Bible.

00:23:49.480 --> 00:23:56.080
It turns out people don't want that kind of
you know off-the-shelf GMO of cookie-cutter

00:23:56.080 --> 00:23:57.080
Bible.

00:23:57.080 --> 00:24:02.800
They want a beautiful organic hand stitched
monk crafted illuminated Bible.

00:24:02.800 --> 00:24:04.870
So it's not a good business model.

00:24:04.870 --> 00:24:09.840
And the early printing industry suffered despite
the fact it should be an amazing fast-growing

00:24:09.840 --> 00:24:10.840
industry.

00:24:10.840 --> 00:24:13.520
Should've been the Silicon Valley of the day.

00:24:13.520 --> 00:24:17.160
It suffered tremendously high failure rates.

00:24:17.160 --> 00:24:18.160
Enormously high.

00:24:18.160 --> 00:24:23.520
Does anyone want to guess what it was that
the printing industry eventually figured out

00:24:23.520 --> 00:24:26.230
was the business model that would work?

00:24:26.230 --> 00:24:30.760
&gt;&gt;male audience member #2: A novel?

00:24:30.760 --> 00:24:32.080
&gt;&gt;Harford: No it wasn't a novel.

00:24:32.080 --> 00:24:33.080
Newspapers?

00:24:33.080 --> 00:24:35.120
A lot of people say newspapers, it's not newspapers.

00:24:35.120 --> 00:24:37.450
&gt;&gt;female audience member #3: Tabloids?

00:24:37.450 --> 00:24:40.810
It's not, it's closer, it's getting closer
but it's still not very close.

00:24:40.810 --> 00:24:41.810
Sorry?

00:24:41.810 --> 00:24:42.810
&gt;&gt;male audience member #3: Propaganda?

00:24:42.810 --> 00:24:43.810
&gt;&gt;male audience member #4: Advertisements?

00:24:43.810 --> 00:24:45.480
&gt;&gt;Harford: Neither advertisements nor propaganda.

00:24:45.480 --> 00:24:46.480
But both are closer.

00:24:46.480 --> 00:24:47.920
&gt;&gt;female audience member #4: Pamphlets?

00:24:47.920 --> 00:24:49.530
&gt;&gt;Harford: They were a kind of pamphlet.

00:24:49.530 --> 00:24:52.250
They were papal indulgences.

00:24:52.250 --> 00:24:57.100
Okay, so it's a certificate from the Pope
that gets you into heaven earlier.

00:24:57.100 --> 00:25:02.870
It's like a little letter to St. Peter which
you buy and its great business for the medieval

00:25:02.870 --> 00:25:05.150
Catholic Church.

00:25:05.150 --> 00:25:08.360
And you think about it, you think of course
that is the perfect thing.

00:25:08.360 --> 00:25:11.550
You set up your printing press once and you're
good to go.

00:25:11.550 --> 00:25:13.000
You can stamp these things out.

00:25:13.000 --> 00:25:17.250
You just need a signature from a Catholic
official, or a seal.

00:25:17.250 --> 00:25:19.750
No one really cares that they're not properly
handwritten.

00:25:19.750 --> 00:25:21.960
It doesn't matter.

00:25:21.960 --> 00:25:26.220
What matters is that they have spiritual value
and financial value.

00:25:26.220 --> 00:25:30.200
And that was the early business model of the
printing industry.

00:25:30.200 --> 00:25:35.310
Having just stumbled through most of the suggestions
that you came up with.

00:25:35.310 --> 00:25:40.300
So it's not always obvious where success in
business is gonna come from.

00:25:40.300 --> 00:25:42.730
And failure rates are very high.

00:25:42.730 --> 00:25:48.500
And despite these failure rates, we have solved
this problem of material affluence.

00:25:48.500 --> 00:25:52.250
Actually I would say not despite these failure
rates, because of these failure rates

00:25:52.250 --> 00:25:58.760
There's actually some very interesting studies
showing that corporate turnover, by which

00:25:58.760 --> 00:25:59.760
I mean.

00:25:59.760 --> 00:26:05.540
So you look at the top 10 largest employees
in a country and how often do employees drop

00:26:05.540 --> 00:26:08.980
off that list and are they replaced by other
companies.

00:26:08.980 --> 00:26:11.700
That's positively related to economic growth.

00:26:11.700 --> 00:26:13.890
And productivity growth.

00:26:13.890 --> 00:26:16.500
And it seems to be causal.

00:26:16.500 --> 00:26:23.020
Because, you look at turnover in say 1970,
that turn and that's a good predictor of economic

00:26:23.020 --> 00:26:25.010
growth throughout the 1970s.

00:26:25.010 --> 00:26:29.750
You look at turn in 1980, you're comparing
one country with another, that's a good prediction

00:26:29.750 --> 00:26:32.370
of economic growth throughout the 1980s.

00:26:32.370 --> 00:26:38.050
So I said despite this failure we've solved
the material affluence problem.

00:26:38.050 --> 00:26:41.900
I would say we've solved the material affluence
problem because of this failure.

00:26:41.900 --> 00:26:44.630
Because it's an evolutionary system.

00:26:44.630 --> 00:26:46.890
It's a trial and error system.

00:26:46.890 --> 00:26:50.640
It's a trial and error system that is extremely
robust in the face of failure.

00:26:50.640 --> 00:26:55.640
You can have 50 failures.

00:26:55.640 --> 00:27:01.151
And if one of the successes is, you can have
one success and if it's General Electric that's

00:27:01.151 --> 00:27:02.270
fine.

00:27:02.270 --> 00:27:04.920
That's good odds.

00:27:04.920 --> 00:27:08.570
So I think these trial and error mechanisms
are very important.

00:27:08.570 --> 00:27:11.030
The market is one.

00:27:11.030 --> 00:27:13.900
The scientific method is another.

00:27:13.900 --> 00:27:17.650
Again you can have a lot of theoretical failures
, you can have a lot of experimental failures,

00:27:17.650 --> 00:27:21.170
but you will get your way towards progress.

00:27:21.170 --> 00:27:25.520
And one success makes up for a lot of failures.

00:27:25.520 --> 00:27:29.140
So this is how I think problems are solved
in a complex world.

00:27:29.140 --> 00:27:31.220
Through trial and error.

00:27:31.220 --> 00:27:37.030
The problem is psychologically, organizationally
politically, this is a message a lot of people

00:27:37.030 --> 00:27:38.940
find very difficult to accept.

00:27:38.940 --> 00:27:43.570
Think about the incentives for politicians.

00:27:43.570 --> 00:27:48.920
So I said a moment ago in a well-functioning
market you have 50 failures, one success,

00:27:48.920 --> 00:27:50.160
that's fine.

00:27:50.160 --> 00:27:51.160
Think about politics.

00:27:51.160 --> 00:27:55.220
Give me a politician, 50 things can be going
right.

00:27:55.220 --> 00:27:59.220
You have one embarrassing problem.

00:27:59.220 --> 00:28:02.480
One policy failure of any description.

00:28:02.480 --> 00:28:06.810
You know what the agenda for the next election
campaign is gonna be.

00:28:06.810 --> 00:28:10.870
The media will talk about your failure; your
opponents will talk about your failure.

00:28:10.870 --> 00:28:16.310
And so while in robust trial and error systems
we say well were happy to have 50 failures

00:28:16.310 --> 00:28:21.000
for one success in political systems it's
absolutely the reverse.

00:28:21.000 --> 00:28:24.630
50 successes don't necessarily make up for
one failure.

00:28:24.630 --> 00:28:26.950
So politicians have very different incentives.

00:28:26.950 --> 00:28:30.390
The basic incentive is, don't ever do anything.

00:28:30.390 --> 00:28:35.540
And if you do do something, for goodness sake
don't ever measure whether you'll succeed

00:28:35.540 --> 00:28:36.540
or not.

00:28:36.540 --> 00:28:38.670
Don't define targets.

00:28:38.670 --> 00:28:41.740
Don't specify what is needed to be qualified
as a success.

00:28:41.740 --> 00:28:44.920
And above all, do not evaluate.

00:28:44.920 --> 00:28:48.470
Because an awful lot of stuff goes wrong.

00:28:48.470 --> 00:28:50.720
Many things fail in a complex world.

00:28:50.720 --> 00:28:55.090
And well goodness me the last thing you want
to do is to actually create data that could

00:28:55.090 --> 00:29:00.340
enable one of your opponents to say that you
had certifiably produced a failure.

00:29:00.340 --> 00:29:04.550
And I said that's a problem that affects politics.

00:29:04.550 --> 00:29:07.390
I think it affects organizations in a broader
sense.

00:29:07.390 --> 00:29:10.660
So it's an office politics problem as well
as a politics from.

00:29:10.660 --> 00:29:16.350
In the book I talk about how the U.S. Army
adapted basically an impossible situation

00:29:16.350 --> 00:29:19.130
in Iraq with a failing strategy from the top.

00:29:19.130 --> 00:29:24.480
And it was the guys much further down who
could see what was going on, could see the

00:29:24.480 --> 00:29:27.810
failures and tried to improvise more effective
tactics.

00:29:27.810 --> 00:29:33.290
And what's fascinating is that once they did
that, the people at the top of the Army still

00:29:33.290 --> 00:29:34.400
didn't want to know.

00:29:34.400 --> 00:29:36.030
But their peers did want to know.

00:29:36.030 --> 00:29:39.910
Their peers were hungry for information about
what was working.

00:29:39.910 --> 00:29:45.910
And so you had counterinsurgency tips being
passed around between the majors and the colonels

00:29:45.910 --> 00:29:48.090
and captains in Iraq.

00:29:48.090 --> 00:29:50.810
You know like a naughty magazine amongst schoolboys.

00:29:50.810 --> 00:29:55.810
[Whispering] Don't tell the guys up there,
but this is pretty good stuff you know.

00:29:55.810 --> 00:30:00.130
This work in Tal Afa you should try it in
Al Anbar province.

00:30:00.130 --> 00:30:04.990
And that's how better counterinsurgency tactics
spread around the Army.

00:30:04.990 --> 00:30:10.130
Because we just don't have the incentives
for the hierarchy to experiment.

00:30:10.130 --> 00:30:13.000
It's not just a hierarchical problem.

00:30:13.000 --> 00:30:14.520
I think it's a personal problem.

00:30:14.520 --> 00:30:18.620
It's a personal problem that manifests itself
in hierarchies.

00:30:18.620 --> 00:30:20.770
Manifests itself in policies.

00:30:20.770 --> 00:30:23.180
And it also manifests itself in our lives.

00:30:23.180 --> 00:30:26.350
So you understand the manifestation in politics
of this.

00:30:26.350 --> 00:30:28.520
You know we don't like uncertainty.

00:30:28.520 --> 00:30:32.510
We like somebody to tell us that he knows
or she knows what's going on.

00:30:32.510 --> 00:30:38.470
I lived in the states during the Bush-Kerry
Presidential election campaign.

00:30:38.470 --> 00:30:40.340
You may remember that election campaign.

00:30:40.340 --> 00:30:46.281
It was effectively fought between the guy
who could make up mind and the guy who couldn't

00:30:46.281 --> 00:30:48.730
make up its mind.

00:30:48.730 --> 00:30:54.090
And the people who wanted to defend the guy
who could make up his mind, the defense was,

00:30:54.090 --> 00:30:56.090
no he can make up his mind.

00:30:56.090 --> 00:31:02.540
Nobody ever said "Well complex problem maybe
you should be changing your mind."

00:31:02.540 --> 00:31:04.570
In the UK.

00:31:04.570 --> 00:31:09.130
The two most successful postwar politicians
are Margaret Thatcher and Tony Blair.

00:31:09.130 --> 00:31:10.970
Between them they won six general elections.

00:31:10.970 --> 00:31:13.880
They won three each.

00:31:13.880 --> 00:31:17.190
So this is the equivalent, I know it's not
constitutionally possible, it's the equivalency

00:31:17.190 --> 00:31:20.210
of winning three presidential elections.

00:31:20.210 --> 00:31:26.470
So these two people had as much election success
between them as President Reagan, President

00:31:26.470 --> 00:31:28.370
Clinton, and President George W. Bush put
together.

00:31:28.370 --> 00:31:31.470
So those are pretty effective political operators.

00:31:31.470 --> 00:31:35.020
You know what one of Margaret Thatcher's most
famous statements?

00:31:35.020 --> 00:31:41.030
"You turn if you want to, the lady's not for
turning, I can't turn around."

00:31:41.030 --> 00:31:43.070
One of Blair's most famous political statements.

00:31:43.070 --> 00:31:47.190
"I don't have a reverse gear."

00:31:47.190 --> 00:31:50.830
Okay so I'd like to sell you a car, it doesn't
turn, it doesn't reverse.

00:31:50.830 --> 00:31:51.910
You want it?
[laughter]

00:31:51.910 --> 00:31:53.740
&gt;&gt;Harford: No you don't.

00:31:53.740 --> 00:31:56.250
But you want the politician, it seems that
we do.

00:31:56.250 --> 00:31:59.190
We like that expression of certainty.

00:31:59.190 --> 00:32:03.750
We don't like a politician who says I don't
know, is complex.

00:32:03.750 --> 00:32:07.220
You know, we might have a good idea, but we're
gonna need to test it out.

00:32:07.220 --> 00:32:08.990
We're gonna need to experiment.

00:32:08.990 --> 00:32:12.790
We may have to fail 50 times before we get
one success, but it'll be worth it.

00:32:12.790 --> 00:32:13.840
Stick with me.

00:32:13.840 --> 00:32:16.470
Oh is anybody still there?

00:32:16.470 --> 00:32:18.260
It's a problem, it's a problem.

00:32:18.260 --> 00:32:20.430
We have this difficulty.

00:32:20.430 --> 00:32:29.810
And I was quite struck by the fact that in
the UK perhaps the most important Social Scientist

00:32:29.810 --> 00:32:34.150
of the last decade turns out to be a celebrity
chef.

00:32:34.150 --> 00:32:36.340
So, and he's an accidental Social Scientist.

00:32:36.340 --> 00:32:40.790
So Jamie Oliver, I know Jamie's trying to
make it big here in the US now.

00:32:40.790 --> 00:32:46.120
So Jamie a few years ago was a hugely successful
celebrity chef.

00:32:46.120 --> 00:32:52.720
Launches this campaign for better school food.

00:32:52.720 --> 00:32:57.160
Now okay, I want you to think about something
horrible for a moment.

00:32:57.160 --> 00:32:58.160
School food.

00:32:58.160 --> 00:32:59.630
English food.

00:32:59.630 --> 00:33:03.660
[laughter]
&gt;&gt;Harford: English school food.

00:33:03.660 --> 00:33:06.340
[laughter]
&gt;&gt;Harford: It's not good.

00:33:06.340 --> 00:33:10.690
So Jamie's campaigning to improve the situation.

00:33:10.690 --> 00:33:12.220
And he has this big TV show.

00:33:12.220 --> 00:33:18.570
And you know he teaches the staff at the schools
how to teach, or how to cook all this you

00:33:18.570 --> 00:33:19.820
know great fresh stuff.

00:33:19.820 --> 00:33:26.620
And he tries to convince the kids to stop
eating sort of emulsified high-fat awful foods.

00:33:26.620 --> 00:33:29.750
And chugging down sugary fizzy drinks.

00:33:29.750 --> 00:33:32.210
And start eating something a bit healthier.

00:33:32.210 --> 00:33:34.280
But before he does this.

00:33:34.280 --> 00:33:36.300
In preparation for this campaign.

00:33:36.300 --> 00:33:38.950
He teams up with the London Borough of Greenwich.

00:33:38.950 --> 00:33:43.170
This is a big sort of chunk of London.

00:33:43.170 --> 00:33:44.820
Several hundred thousand people.

00:33:44.820 --> 00:33:50.560
And he convinces the educational authority
there to change the menus in all the schools.

00:33:50.560 --> 00:33:56.280
He says, "I'm gonna redesign your menus and
I'm gonna mobilize resources for you."

00:33:56.280 --> 00:33:58.270
"And I'm gonna help train the staff."

00:33:58.270 --> 00:33:59.270
"And it's gonna be great."

00:33:59.270 --> 00:34:02.290
But this is all basically happening in Greenwich
it's not happening anywhere else.

00:34:02.290 --> 00:34:06.160
There's no TV campaign it's all pretty much
under the radar.

00:34:06.160 --> 00:34:07.990
And then he makes his TV show.

00:34:07.990 --> 00:34:12.840
And this one school in Greenwich has TV cameras
everywhere and massive disruption.

00:34:12.840 --> 00:34:17.429
Every other school in Greenwich has basically
just had this exogenous shock dropped in there.

00:34:17.429 --> 00:34:19.500
Jamie Oliver's menus.

00:34:19.500 --> 00:34:21.060
So the food is better.

00:34:21.060 --> 00:34:25.980
For no reason other than just Jamie happened
to come along and pick Greenwich.

00:34:25.980 --> 00:34:29.570
And the food hasn't changed anywhere else
in London; it's only changed in Greenwich.

00:34:29.570 --> 00:34:30.800
Suddenly these kids are eating salads.

00:34:30.800 --> 00:34:36.560
And they don't know what's hit them.

00:34:36.560 --> 00:34:42.440
Then a couple of economists come along and
they say, "Jamie kind of created a controlled

00:34:42.440 --> 00:34:43.440
trial there."

00:34:43.440 --> 00:34:47.830
I mean it wasn't a proper sort of full year
double-blind randomized controlled trial.

00:34:47.830 --> 00:34:50.179
But it was, it was pretty good.

00:34:50.179 --> 00:34:54.110
He basically took London and he carved out
an area and he said "We're gonna change the

00:34:54.110 --> 00:34:55.110
menus there.

00:34:55.110 --> 00:34:58.700
There's no reason why we changed the menus
there rather than anywhere else."

00:34:58.700 --> 00:35:02.640
Observationally there's no obvious difference
between Greenwich and anywhere else.

00:35:02.640 --> 00:35:06.090
So economists came along and said "Well what
difference did it make?"

00:35:06.090 --> 00:35:14.630
And although the data was imperfect and uncertain
the evidence seems to be well fewer authorized

00:35:14.630 --> 00:35:15.630
absences.

00:35:15.630 --> 00:35:18.500
Authorized absences basically, a kid gets
sick.

00:35:18.500 --> 00:35:21.530
So less illness.

00:35:21.530 --> 00:35:24.610
Higher scores in maths, higher scores in reading.

00:35:24.610 --> 00:35:28.490
Kids are basically able to concentrate better,
they're a bit smarter.

00:35:28.490 --> 00:35:32.660
Now the British Prime Minister at the time
and the leader of the Opposition at the time

00:35:32.660 --> 00:35:37.050
both fell over themselves to say what a wonderful
guy Jamie Oliver was and what a wonderful

00:35:37.050 --> 00:35:38.140
idea this was.

00:35:38.140 --> 00:35:43.220
And I find that pretty exasperating.

00:35:43.220 --> 00:35:50.970
Tony Blair praising Jamie Oliver had been
the Prime Minister for eight years.

00:35:50.970 --> 00:35:56.740
It wasn't a particularly radical idea, it
existed in theory for a couple of decades

00:35:56.740 --> 00:36:02.530
that maybe nutrition has an effect on childhood
outcomes and childhood learning.

00:36:02.530 --> 00:36:04.500
He could've run that experiment.

00:36:04.500 --> 00:36:06.210
He could've run that experiment properly.

00:36:06.210 --> 00:36:09.000
In fact he could've run 100 experiments.

00:36:09.000 --> 00:36:11.770
He could've run 1000 experiments.

00:36:11.770 --> 00:36:14.390
But he chose not to do so.

00:36:14.390 --> 00:36:17.030
And why, I don't know.

00:36:17.030 --> 00:36:19.940
Maybe the idea of experimenting on the children.

00:36:19.940 --> 00:36:24.090
Maybe the idea that he basically, he thought
he knew the answer.

00:36:24.090 --> 00:36:26.100
The god-complex in medics.

00:36:26.100 --> 00:36:29.940
With medics who believe they know the answer.

00:36:29.940 --> 00:36:35.340
But slowly but surely we've come to realize
you need to run experiments.

00:36:35.340 --> 00:36:36.700
One of the heroes of the book.

00:36:36.700 --> 00:36:40.710
And there was, basically every chapter in
the book has a hero and the reason every chapter

00:36:40.710 --> 00:36:50.710
has a hero is because it turns out experimenting,
trying something new, taking risks is whether

00:36:50.710 --> 00:36:57.940
you're a colonel in Iraq, or your choreographer,
or you are doing research into gene therapy.

00:36:57.940 --> 00:36:59.240
It's extremely difficult.

00:36:59.240 --> 00:37:00.880
You're gonna get a lot of hassle.

00:37:00.880 --> 00:37:02.040
You're not gonna get much support.

00:37:02.040 --> 00:37:06.100
You need to be very brave, very stubborn to
do this kind of thing.

00:37:06.100 --> 00:37:07.810
That's why, there's a hero.

00:37:07.810 --> 00:37:11.670
One of the heroes in the book is a doctor
called Archie Cochrane.

00:37:11.670 --> 00:37:16.890
Who later, his name has been given to this
amazing organization called the Cochrane Collaboration

00:37:16.890 --> 00:37:21.690
which pulls together information about basically
all the information we have about all the

00:37:21.690 --> 00:37:23.130
medical treatments out there.

00:37:23.130 --> 00:37:26.300
Evaluated and put together in a systematic
fashion.

00:37:26.300 --> 00:37:29.860
So we really have the best possible information
about what medical treatments work and what

00:37:29.860 --> 00:37:30.970
don't.

00:37:30.970 --> 00:37:37.710
But Cochrane who also smuggled vitamins into
a prisoner of war camp in World War II because

00:37:37.710 --> 00:37:38.990
he was a prisoner.

00:37:38.990 --> 00:37:43.860
The other prisoners, they're all dying of
something and he didn't know what.

00:37:43.860 --> 00:37:48.700
So he managed to smuggle in vitamins and run
a randomized trial in the prisoner of war

00:37:48.700 --> 00:37:49.720
camp.

00:37:49.720 --> 00:37:53.860
Then go to the German running the camp with
his graphs and say.

00:37:53.860 --> 00:37:56.820
And actually it turns out what these men actually
need is Marmite.

00:37:56.820 --> 00:37:58.020
It contains vitamin B-12.

00:37:58.020 --> 00:38:03.130
It's a sort of yeast extract, it looks like
crude oil.

00:38:03.130 --> 00:38:06.840
And although the relations in that camp were
unbelievably bad between the prisoners and

00:38:06.840 --> 00:38:07.840
guards.

00:38:07.840 --> 00:38:12.340
The guards, one of the young guards who was
a doctor said, "It's a war crime if we don't

00:38:12.340 --> 00:38:15.150
respond to this evidence."

00:38:15.150 --> 00:38:16.800
"This cannot be denied."

00:38:16.800 --> 00:38:20.290
"The evidence that's come from this trial."

00:38:20.290 --> 00:38:24.570
"And you have to supply these men with vitamins
or you are murdering them."

00:38:24.570 --> 00:38:28.460
And the next day, the vitamins turned up at
the camp.

00:38:28.460 --> 00:38:30.900
Evidence has a tremendous power.

00:38:30.900 --> 00:38:35.830
But one of the things that Cochrane did to
emphasize the importance of running experiments

00:38:35.830 --> 00:38:37.750
and running trials was he.

00:38:37.750 --> 00:38:39.290
This was after the war.

00:38:39.290 --> 00:38:46.690
He tried to get his colleagues who were running
cardiac recuperation wings to see whether

00:38:46.690 --> 00:38:53.430
maybe patients who had cardiac surgery maybe
should be recuperating at home.

00:38:53.430 --> 00:38:58.350
And they all said this is tremendously unethical,
you can't do this, you're gonna to kill people.

00:38:58.350 --> 00:39:00.170
And they managed to shut down the trial.

00:39:00.170 --> 00:39:03.210
And he managed to get it open in a different
city.

00:39:03.210 --> 00:39:05.970
So he's running this trial.

00:39:05.970 --> 00:39:11.050
He calls all the doctors together around the
table and he says, "Well gentlemen I have

00:39:11.050 --> 00:39:12.050
some early results."

00:39:12.050 --> 00:39:16.030
"They're not statistically significant, but
I think we can see which way the wind is blowing."

00:39:16.030 --> 00:39:24.670
"And it turns out that the patients who are
recuperating at home seem to be more likely

00:39:24.670 --> 00:39:25.670
to die."

00:39:25.670 --> 00:39:26.670
"It's excess mortality there."

00:39:26.670 --> 00:39:30.690
"We can't be sure of this because it's too
early."

00:39:30.690 --> 00:39:33.800
And there's this huge hubbub and they all
said, "We always that you are completely unethical

00:39:33.800 --> 00:39:37.320
you need to shut this trial down at once you're
killing people."

00:39:37.320 --> 00:39:39.590
And he let them carry on for a bit.

00:39:39.590 --> 00:39:43.770
And he said, "Oh well that's very interesting
because I just swapped the two tables and

00:39:43.770 --> 00:39:46.990
it turns out your cardiac wings are the ones
that seems to be killing people."

00:39:46.990 --> 00:39:48.200
"Should we shut them down now?"

00:39:48.200 --> 00:39:51.750
"Or do you want to wait until we finish the
experiment?

00:39:51.750 --> 00:39:55.640
He understood that these experiments produce
a lot of data.

00:39:55.640 --> 00:39:59.610
So we've mostly won that fight in medicine.

00:39:59.610 --> 00:40:04.210
We've hardly begun to wage that fight in economic
policy.

00:40:04.210 --> 00:40:06.119
In criminal justice.

00:40:06.119 --> 00:40:07.410
In education.

00:40:07.410 --> 00:40:08.840
To run randomized trials.

00:40:08.840 --> 00:40:13.100
They produce a tremendous amount of information.

00:40:13.100 --> 00:40:17.350
But you know the book isn't just about these
formal trials, it's about all the different

00:40:17.350 --> 00:40:20.119
institutions we use to run experiments.

00:40:20.119 --> 00:40:23.850
Formal experimentation and informal experimentation.

00:40:23.850 --> 00:40:26.210
In the end though we find this tough.

00:40:26.210 --> 00:40:31.040
Look at the psychological evidence about how
we feel about failure.

00:40:31.040 --> 00:40:33.700
We're very sensitive to it.

00:40:33.700 --> 00:40:38.530
Even a small failure we, we put disproportionate
weight on it.

00:40:38.530 --> 00:40:40.260
We go into a fit of denial.

00:40:40.260 --> 00:40:42.860
Which is why these randomized trials are so
powerful.

00:40:42.860 --> 00:40:46.650
We, there's a failure going on, but we refuse
to admit that there's a denial.

00:40:46.650 --> 00:40:50.770
I interviewed poker players for the book among
many other people.

00:40:50.770 --> 00:40:55.900
And they told me at the poker table what's
really dangerous is immediately after you've

00:40:55.900 --> 00:41:00.180
had a failure at the table you then start
taking risks, 'cause you want to get your

00:41:00.180 --> 00:41:01.619
money back.

00:41:01.619 --> 00:41:05.760
So you respond to failure in a very unconstructive
ways.

00:41:05.760 --> 00:41:10.090
It's why the old clich where you should
learn from your mistakes is a clich.

00:41:10.090 --> 00:41:12.850
We keep saying learn from your mistakes, learn
from your mistakes.

00:41:12.850 --> 00:41:13.850
Why do we keep saying it?

00:41:13.850 --> 00:41:17.030
Because we don't learn from our mistakes,
we find it very hard.

00:41:17.030 --> 00:41:19.500
So that's what the book is about.

00:41:19.500 --> 00:41:23.400
It's a recognition that we have complex problems.

00:41:23.400 --> 00:41:28.540
That they are too hard to solve from a purely
theoretical basis.

00:41:28.540 --> 00:41:30.960
It's not that failure is desirable.

00:41:30.960 --> 00:41:33.170
Failure sucks, you know.

00:41:33.170 --> 00:41:35.140
It's that failure is going to happen.

00:41:35.140 --> 00:41:37.280
It's inevitable in a complex world.

00:41:37.280 --> 00:41:45.310
And the sooner that we get used to that in
our personal lives as voters, as employees.

00:41:45.310 --> 00:41:51.920
And above all the sooner were able to develop
institutions capable of experimenting.

00:41:51.920 --> 00:41:55.320
Capable of engaging in trial and error.

00:41:55.320 --> 00:41:59.080
Whether it's very tightly controlled or whether
it's very loose.

00:41:59.080 --> 00:42:00.950
The sooner were able to do that.

00:42:00.950 --> 00:42:02.510
The sooner we'll be able to solve problems
in a complex world.

00:42:02.510 --> 00:42:03.510
I'm very happy to take questions, but thank
you all for listening.

00:42:03.510 --> 00:42:04.510
[applause]
So a question here?

00:42:04.510 --> 00:42:05.510
&gt;&gt;male audience member #5: Thank you very
much.

00:42:05.510 --> 00:42:06.510
I wanted to ask you a question regarding the
psychology of people.

00:42:06.510 --> 00:42:07.510
'Cause it seems like you're setting up framework
that's theoretical, very rational.

00:42:07.510 --> 00:42:08.510
But at the end it's gonna be human beings
that are operating it.

00:42:08.510 --> 00:42:13.520
And so there are two examples of psychology
that I think would impede the ability to do

00:42:13.520 --> 00:42:14.520
this.

00:42:14.520 --> 00:42:15.520
Cannamen proved in his studies that people
value losses twice as much as the gains.

00:42:15.520 --> 00:42:16.520
Right?

00:42:16.520 --> 00:42:18.850
So there's a bias to loss avoidance.

00:42:18.850 --> 00:42:19.850
Right?

00:42:19.850 --> 00:42:24.360
They're not viewed as equal.

00:42:24.360 --> 00:42:42.440
The other thing is people presented with a
great deal of choice, they don't actually

00:42:42.440 --> 00:42:43.440
enjoy it.

00:42:43.440 --> 00:42:44.440
It actually causes unhappiness.

00:42:44.440 --> 00:42:45.440
When they have more choice.

00:42:45.440 --> 00:42:46.440
So giving them six flavors is actually better
than 30 flavors.

00:42:46.440 --> 00:43:12.070
'Cause they always feel like, I could've picked
a better flavor.

00:43:12.070 --> 00:43:13.390
And if there's six, I can easily sample, I
can't sample all 30 or 100 or 100,000 products

00:43:13.390 --> 00:43:14.390
or whatever it is, right?

00:43:14.390 --> 00:43:15.390
And so, you're talking about running many
many many experiments.

00:43:15.390 --> 00:43:16.390
How many experiments can I really run?

00:43:16.390 --> 00:43:17.390
How many choices can I really have?

00:43:17.390 --> 00:43:18.390
If I track infinity experiments, I can't possibly
deal with it, right?

00:43:18.390 --> 00:43:19.390
And then there's a near infinity of losses
that I'll suffer in all the failures, right?

00:43:19.390 --> 00:43:20.390
So you know loss avoidance.

00:43:20.390 --> 00:43:21.390
So just thinking that these two examples of
human psychology that are well proven right?

00:43:21.390 --> 00:43:29.970
Would tend to lead you down paths where you
really won't be able to do a whole lot of

00:43:29.970 --> 00:43:30.970
experiments.

00:43:30.970 --> 00:43:45.430
Because you don't want to suffer the losses
and you don't want to deal with the complexity

00:43:45.430 --> 00:43:49.560
of the choices.

00:43:49.560 --> 00:43:54.150
&gt;&gt;Harford: I half agree with you.

00:43:54.150 --> 00:43:57.840
So I certainly agree with the point about
loss aversion which is something that I catered

00:43:57.840 --> 00:44:02.780
to at the end of the talk emphasizing that
we do.

00:44:02.780 --> 00:44:05.170
We seem to significantly overweigh losses.

00:44:05.170 --> 00:44:08.170
Maybe from an evolutionary point of view that
used to be rational.

00:44:08.170 --> 00:44:12.900
But in our comfortable sort of modern world
that's not rational and we need to figure

00:44:12.900 --> 00:44:14.350
out ways to deal with that.

00:44:14.350 --> 00:44:19.580
I don't accept the result on excess choice.

00:44:19.580 --> 00:44:20.750
Okay?

00:44:20.750 --> 00:44:22.760
It's not robust.

00:44:22.760 --> 00:44:25.000
There are lots of studies disagreeing with
this.

00:44:25.000 --> 00:44:29.200
Benjamin Scheibehenne recently published a
systematic review of this.

00:44:29.200 --> 00:44:31.960
And found on average no effect.

00:44:31.960 --> 00:44:33.430
We don't understand that result very well.

00:44:33.430 --> 00:44:39.220
And I think just intuitively, we all get very
excited about this idea that choice is bad

00:44:39.220 --> 00:44:41.260
and choices demotivate and choice distracts.

00:44:41.260 --> 00:44:44.530
But Wal-Mart is still doing fine, Starbucks
offer 85,000 products.

00:44:44.530 --> 00:44:46.820
I mean there's clearly something.

00:44:46.820 --> 00:44:49.570
There's something there, but there's something
wrong as well.

00:44:49.570 --> 00:44:53.110
&gt;&gt;male audience member #5: Brand availability.

00:44:53.110 --> 00:44:54.290
&gt;&gt;Harford: Well.

00:44:54.290 --> 00:44:57.150
There are various ways that this choice is
mediated.

00:44:57.150 --> 00:45:01.790
But my point is, well actually it does make
a larger point about the value of experimentation.

00:45:01.790 --> 00:45:05.500
Which is, actually we need very good systems
for replicating experiments.

00:45:05.500 --> 00:45:08.980
Because you get experiment like the "choice
is bad" experiment.

00:45:08.980 --> 00:45:13.940
Which is a very creative and professionally
run experiment.

00:45:13.940 --> 00:45:16.810
It's all above board, it's all very rigorous
and peer-reviewed.

00:45:16.810 --> 00:45:19.960
But you have to replicate, and it turns out
this one is hard to replicate.

00:45:19.960 --> 00:45:22.700
And that happens a lot.

00:45:22.700 --> 00:45:27.080
Your bigger point I think is this can be overwhelming.

00:45:27.080 --> 00:45:29.610
We don't like taking gambles.

00:45:29.610 --> 00:45:36.620
And in order to be effective, we need to take
a lot of gambles.

00:45:36.620 --> 00:45:39.840
So, on a personal basis, that's absolutely
true.

00:45:39.840 --> 00:45:45.330
I mean I argue that we probably should take
more risks in our personal lives than we do.

00:45:45.330 --> 00:45:49.580
We have such fun with, college students have
a great time because they are experimenting

00:45:49.580 --> 00:45:51.620
and failing in a safe place.

00:45:51.620 --> 00:45:53.640
Where those experiments though matter.

00:45:53.640 --> 00:45:57.080
And then you, you know you quit college and
you get to your first job.

00:45:57.080 --> 00:46:02.690
And I think many people have the experience
of suddenly trying really hard not to fail.

00:46:02.690 --> 00:46:03.690
And then suddenly it's miserable.

00:46:03.690 --> 00:46:05.050
It should be just like college right?

00:46:05.050 --> 00:46:09.790
You got new colleagues, new surroundings,
new city, new ideas.

00:46:09.790 --> 00:46:16.020
It should be just as fun as college, but actually
its failure reverse instead of failure friendly.

00:46:16.020 --> 00:46:19.130
So I think we maybe should experiment more
than we do in our personalized.

00:46:19.130 --> 00:46:21.550
But that's almost an afterthought in the book.

00:46:21.550 --> 00:46:23.400
The book is about building systems to experiment.

00:46:23.400 --> 00:46:25.810
And we have systems that experiment.

00:46:25.810 --> 00:46:27.290
Markets are a very good system for experimentation.

00:46:27.290 --> 00:46:29.290
I'm not pro-market nut.

00:46:29.290 --> 00:46:31.130
But markets do experiment.

00:46:31.130 --> 00:46:34.860
And one of the reasons that you've got this
huge diversity.

00:46:34.860 --> 00:46:39.040
Entrepreneurs don't view themselves as carrying
out 100,000 experiments; they might just carry

00:46:39.040 --> 00:46:40.040
out one.

00:46:40.040 --> 00:46:41.040
They may be delusional.

00:46:41.040 --> 00:46:43.530
I mean there's good reason to believe that
many entrepreneurs are delusional about their

00:46:43.530 --> 00:46:45.360
chances of success.

00:46:45.360 --> 00:46:48.590
But socially that's fine, we ride off that
experiment.

00:46:48.590 --> 00:46:51.030
So those experiments that are going on.

00:46:51.030 --> 00:46:55.270
So some the themes in the book are about taking
that market process which we know is pretty

00:46:55.270 --> 00:46:56.460
effective.

00:46:56.460 --> 00:46:59.090
And directing it to more socially useful uses.

00:46:59.090 --> 00:47:02.430
Can we direct those market processes to reducing
carbon emissions?

00:47:02.430 --> 00:47:07.480
Can we direct those market processes to producing
vaccines for the poor?

00:47:07.480 --> 00:47:08.590
And the scientific method to.

00:47:08.590 --> 00:47:13.920
So I talk about how to fund scientist, or
how to run an organization in a way where

00:47:13.920 --> 00:47:16.980
you are supporting people in taking risks.

00:47:16.980 --> 00:47:19.380
And I'll just give you one example.

00:47:19.380 --> 00:47:22.040
This is a classic example from economic history.

00:47:22.040 --> 00:47:27.940
One of the most important inventions in the
economic history was Limited Liability Company.

00:47:27.940 --> 00:47:31.140
Basically it means that if your company goes
bankrupt.

00:47:31.140 --> 00:47:36.619
There's a limit to how far shareholders and
creditors can come after you personally.

00:47:36.619 --> 00:47:41.869
Many economic historians think this was hugely
important in the development of modern Capitalism.

00:47:41.869 --> 00:47:43.090
But what is it?

00:47:43.090 --> 00:47:45.530
A system for reducing the downside of failure
and encouraging people to take risks.

00:47:45.530 --> 00:47:46.530
Because socially, those risks are useful.

00:47:46.530 --> 00:47:47.530
&gt;&gt;male audience member #6: So I like to irritate
people who don't believe in evolution by asking

00:47:47.530 --> 00:48:16.020
them rather their difficulty is with death,
with sex or the idea that children take after

00:48:16.020 --> 00:48:27.160
their parents.

00:48:27.160 --> 00:48:38.610
You seem to be telling us today that death
is actually something we should accept and

00:48:38.610 --> 00:48:39.610
embrace, and sex is something we should have
more of.

00:48:39.610 --> 00:48:40.610
And I was wondering if you could tell us more
about the mechanisms whereby children take

00:48:40.610 --> 00:48:41.610
after their parents.

00:48:41.610 --> 00:48:46.046
Is it the biological evolution in fact, the
big driver in the long term is that fine tuning

00:48:46.046 --> 00:48:47.046
different mechanisms to enhance themselves
[Inaudible]

00:48:47.046 --> 00:48:48.046
&gt;&gt;Harford: That's a very good question, and
of course we all should be having more sex,

00:48:48.046 --> 00:48:49.046
I think we all know that.

00:48:49.046 --> 00:48:50.770
So the evolutionary metaphor I think is probably
more than metaphor, I think it's a proper

00:48:50.770 --> 00:48:56.560
analogy that's very useful for understanding
how markets work.

00:48:56.560 --> 00:49:03.840
What's essential to evolution is, and I'm
not a biologist so I'm not gonna give any

00:49:03.840 --> 00:49:04.840
lessons on this.

00:49:04.840 --> 00:49:06.440
The variation in selection.

00:49:06.440 --> 00:49:09.600
There are lots of stuff, lots of different
stuff.

00:49:09.600 --> 00:49:14.870
And then some mechanisms for getting rid of
the bad stuff and having more the good stuff.

00:49:14.870 --> 00:49:17.380
We know that's a very powerful algorithm in
biology.

00:49:17.380 --> 00:49:20.310
And it potentially is a very powerful how
the algorithm outside biology,

00:49:20.310 --> 00:49:24.320
I talk about the work of Karl Sims who's probably
better known these days as the guy who did

00:49:24.320 --> 00:49:27.970
the special effects for Spiderman and Lord
of the Rings and Titanic.

00:49:27.970 --> 00:49:31.530
Originally he was programming evolution, really
cool evolution in digital environments.

00:49:31.530 --> 00:49:36.770
If you go onto YouTube and type Karl Sims
virtual creatures you see some cool stuff

00:49:36.770 --> 00:49:42.450
that he was programming nearly 20 years ago.

00:49:42.450 --> 00:49:44.530
In markets.

00:49:44.530 --> 00:49:46.460
So where does the variation come from?

00:49:46.460 --> 00:49:48.000
Well it comes from entrepreneurs.

00:49:48.000 --> 00:49:49.900
It also comes from middle managers.

00:49:49.900 --> 00:49:53.930
Basically anybody in an organization was a
new idea for a new way to do things.

00:49:53.930 --> 00:49:56.210
It can come from customer suggestions.

00:49:56.210 --> 00:49:59.170
It could also come, it could be technological
as an input into economy.

00:49:59.170 --> 00:50:00.450
So it can come from scientist.

00:50:00.450 --> 00:50:02.750
It can come from research labs.

00:50:02.750 --> 00:50:06.480
So there's no shortage of variation in well-functioning
economy.

00:50:06.480 --> 00:50:10.860
In Wall Street, what you have is it turns
out everybody taking the same multi-trillion

00:50:10.860 --> 00:50:12.170
dollar bet at the same time.

00:50:12.170 --> 00:50:14.270
So we don't have sufficient variation on Wall
Street.

00:50:14.270 --> 00:50:17.570
But generally markets create variation.

00:50:17.570 --> 00:50:20.070
Where does the selection mechanism come from?

00:50:20.070 --> 00:50:23.240
Well bankruptcy is a pretty good one.

00:50:23.240 --> 00:50:28.580
If you don't close down the bad idea, you
know I'm gonna open a stuffed puppy shop okay.

00:50:28.580 --> 00:50:33.810
Yeah, if the market doesn't buy on the stuffed
puppies then you're gonna close 'em down or

00:50:33.810 --> 00:50:38.300
you're gonna change what you do and if you
don't the bankruptcy courts soon will.

00:50:38.300 --> 00:50:41.000
What's the propagation mechanism, well there
are various ones.

00:50:41.000 --> 00:50:47.030
So companies don't have sex, but companies
do merge.

00:50:47.030 --> 00:50:51.910
Takeover other companies and rollout their
ideas inside those other companies.

00:50:51.910 --> 00:50:54.160
They grow organically.

00:50:54.160 --> 00:50:58.330
You know you just have more and more chains
of a particular retail store.

00:50:58.330 --> 00:50:59.880
They just get copied.

00:50:59.880 --> 00:51:03.740
You have a good idea, other people will try
to copy the idea.

00:51:03.740 --> 00:51:07.600
And employees leave and set up their own organizations.

00:51:07.600 --> 00:51:09.850
So you've got a variation mechanism.

00:51:09.850 --> 00:51:11.020
You've got a selection mechanism.

00:51:11.020 --> 00:51:12.260
You've got a propagation mechanism.

00:51:12.260 --> 00:51:14.270
As it's an evolutionary environment.

00:51:14.270 --> 00:51:16.290
Just a final thought.

00:51:16.290 --> 00:51:21.190
It's a very interesting work by economist
Paul Ormerod.

00:51:21.190 --> 00:51:25.100
Examining corporate extinctions and comparing
them to biological extinctions.

00:51:25.100 --> 00:51:27.700
And actually the patterns are extremely similar.

00:51:27.700 --> 00:51:31.200
They both, if you sort of arrange them properly
they both follow a power law.

00:51:31.200 --> 00:51:35.840
And Ormerod's conclusion, I don't think this
is proven but I think it's strongly suggested

00:51:35.840 --> 00:51:38.440
is we know evolution is a blind process.

00:51:38.440 --> 00:51:40.050
There's no foresight.

00:51:40.050 --> 00:51:43.170
Species don't decide a direction in which
to evolve.

00:51:43.170 --> 00:51:46.130
It's just purely the variation selection.

00:51:46.130 --> 00:51:50.850
Ormerod reckons that that is probably largely
true of economic organizations to.

00:51:50.850 --> 00:51:55.980
No matter how much we pay our CEOs, they're
basically just experimenting pretty much randomly

00:51:55.980 --> 00:51:58.320
and succeeding or failing pretty much randomly.

00:51:58.320 --> 00:52:01.560
That's not proven but I think it's pretty
nicely suggested.

00:52:01.560 --> 00:52:05.060
So do we have time for one more question?

00:52:05.060 --> 00:52:07.770
You gonna have to ask me the question after
this Cynthia.

00:52:07.770 --> 00:52:11.360
Thanks very much everybody for listening.

00:52:11.360 --> 00:52:12.400
[applause]

