WEBVTT
Kind: captions
Language: en

00:00:00.240 --> 00:00:02.082
JAKE: He wrote the
high-performance browser

00:00:02.082 --> 00:00:03.540
networking book
for O'Reilly, which

00:00:03.540 --> 00:00:07.050
is also available for free
in the links on his website.

00:00:07.050 --> 00:00:08.600
If the internet is
a series of tubes,

00:00:08.600 --> 00:00:11.096
then this is one of the
world's greatest plumbers.

00:00:11.096 --> 00:00:12.470
Hands together
for Ilya Grigorik.

00:00:12.470 --> 00:00:15.820
[APPLAUSE]

00:00:15.820 --> 00:00:18.334
ILYA GRIGORIK: All
right, thanks, Jake.

00:00:18.334 --> 00:00:20.250
All right, so we're going
to talk a little bit

00:00:20.250 --> 00:00:23.130
about optimizing network
performance and specifically

00:00:23.130 --> 00:00:25.610
some of the things that we've
been doing on the Chrome team

00:00:25.610 --> 00:00:28.450
for helping deliver better apps.

00:00:28.450 --> 00:00:32.080
And I guess the first
thing that we should ask

00:00:32.080 --> 00:00:33.910
is, does it matter, right?

00:00:33.910 --> 00:00:35.750
What's the problem
we're trying to solve?

00:00:35.750 --> 00:00:38.550
And Tony Gentilcore, who's
actually somewhere here

00:00:38.550 --> 00:00:41.140
in the room, ran a
number of different tests

00:00:41.140 --> 00:00:43.070
over the last couple
of months, where

00:00:43.070 --> 00:00:46.250
he's been kind of deep
diving into where do we

00:00:46.250 --> 00:00:46.890
spend our time.

00:00:46.890 --> 00:00:48.940
Like when we try to
render a web page, what

00:00:48.940 --> 00:00:50.210
are the bottlenecks today?

00:00:50.210 --> 00:00:52.212
And he has a series
of these posts

00:00:52.212 --> 00:00:54.170
on Blink-dev if you guys
are interested in kind

00:00:54.170 --> 00:00:56.200
of low-level guts
of how Blink works

00:00:56.200 --> 00:00:58.100
and in Chrome kind
of end to end.

00:00:58.100 --> 00:01:00.730
But one test to me stood
out, in particular.

00:01:00.730 --> 00:01:03.769
And this is a test where we took
the top 1 million Alexa sites

00:01:03.769 --> 00:01:05.560
and just ran them
through Chrome and looked

00:01:05.560 --> 00:01:06.810
at where do we spend our time?

00:01:06.810 --> 00:01:09.970
Like in terms of the
actual main Blink thread,

00:01:09.970 --> 00:01:11.370
where is the time going?

00:01:11.370 --> 00:01:14.980
And the big takeaway here
is that, approximately 70%

00:01:14.980 --> 00:01:17.164
of the time, we're
just basically idling

00:01:17.164 --> 00:01:18.080
on the network, right?

00:01:18.080 --> 00:01:20.370
That's that big chunk
right here in the blue.

00:01:20.370 --> 00:01:23.246
And then after that, you have
all of your usual offenders,

00:01:23.246 --> 00:01:25.370
things like, well, we've
got to get the JavaScript,

00:01:25.370 --> 00:01:28.904
we've got to paint pixels,
and all the rest, do layouts.

00:01:28.904 --> 00:01:30.570
So this should not
be surprising, right?

00:01:30.570 --> 00:01:32.590
This is specifically
for the first page load.

00:01:32.590 --> 00:01:34.034
There's a very
different profile,

00:01:34.034 --> 00:01:35.450
of course, once
the page is loaded

00:01:35.450 --> 00:01:37.020
and you're interacting
with the page.

00:01:37.020 --> 00:01:38.430
That's a different problem.

00:01:38.430 --> 00:01:41.555
But this, in part,
is one big problem

00:01:41.555 --> 00:01:42.680
that we're trying to solve.

00:01:42.680 --> 00:01:46.932
Like how do we make this blue
part smaller or just go faster?

00:01:46.932 --> 00:01:49.140
So there's two takeaways
that you can take from this.

00:01:49.140 --> 00:01:53.390
One is, page loads in
network are a problem, right?

00:01:53.390 --> 00:01:56.130
That's 70% of loading
the page today.

00:01:56.130 --> 00:02:00.510
But the good news is that if we
can do anything to the network

00:02:00.510 --> 00:02:02.880
stack in terms of improving
that latency and improving

00:02:02.880 --> 00:02:05.660
performance, it's going to have
a significant impact on how

00:02:05.660 --> 00:02:06.850
we experience the web.

00:02:06.850 --> 00:02:09.889
So even small fractional
wins in this space

00:02:09.889 --> 00:02:13.770
will, in fact, have
huge performance impact.

00:02:13.770 --> 00:02:15.930
So kind of with that in
mind, what I wanted to do

00:02:15.930 --> 00:02:19.280
is actually take a look
at some of the things

00:02:19.280 --> 00:02:21.280
that we've been working
on internally in Chrome.

00:02:21.280 --> 00:02:22.904
This is kind of
looking under the hood.

00:02:22.904 --> 00:02:24.530
This is not perhaps
something that you

00:02:24.530 --> 00:02:27.104
would be, as a developer,
looking at APIs

00:02:27.104 --> 00:02:28.770
or trying to figure
out how to optimize.

00:02:28.770 --> 00:02:31.030
This is the kind of stuff
that Chrome does internally.

00:02:31.030 --> 00:02:34.480
But we have a very dedicated
and awesome performance team

00:02:34.480 --> 00:02:35.510
working on this stuff.

00:02:35.510 --> 00:02:37.270
And I wanted to highlight
some of the wins

00:02:37.270 --> 00:02:41.290
that we had over the last year
and also kind of essentially

00:02:41.290 --> 00:02:42.760
so you know what
we're working on

00:02:42.760 --> 00:02:46.460
and also highlight the
potential areas for improvement

00:02:46.460 --> 00:02:47.492
in the future.

00:02:47.492 --> 00:02:48.950
And after that,
we're going to look

00:02:48.950 --> 00:02:51.180
at some of the new
additions, specifically,

00:02:51.180 --> 00:02:52.910
kind of low-level
network plumbing

00:02:52.910 --> 00:02:54.660
stuff that we support
in Chrome, so things

00:02:54.660 --> 00:02:58.340
like SPDY, some notes about
QUIC, and other things.

00:02:58.340 --> 00:03:00.760
And then finally we'll talk
about measurements, right?

00:03:00.760 --> 00:03:02.385
Of course, performance
is the big theme

00:03:02.385 --> 00:03:04.056
throughout this entire event.

00:03:04.056 --> 00:03:06.180
And we want to make sure
that we give you the tools

00:03:06.180 --> 00:03:10.190
to measure performance
in the best way possible.

00:03:10.190 --> 00:03:13.670
You should be able to measure
anything you need in the stack.

00:03:13.670 --> 00:03:17.090
So first, let's actually
do a quick survey.

00:03:17.090 --> 00:03:19.020
This is going to be kind
of all over the map,

00:03:19.020 --> 00:03:21.380
but I want to
highlight a few things.

00:03:21.380 --> 00:03:26.380
First, in Chrome 26, we landed
the new asynchronous DNS

00:03:26.380 --> 00:03:29.610
resolver, which is kind of
low-level plumbing stuff,

00:03:29.610 --> 00:03:32.410
so we're no longer relying
on the operating system DNS

00:03:32.410 --> 00:03:32.910
resolver.

00:03:32.910 --> 00:03:35.940
We actually have our own.

00:03:35.940 --> 00:03:39.960
Today, it's available on
Windows, Mac, and Chrome

00:03:39.960 --> 00:03:42.930
OS, so this is
not yet on mobile.

00:03:42.930 --> 00:03:44.370
Hopefully, it will be.

00:03:44.370 --> 00:03:46.775
So why did we want to do this?

00:03:46.775 --> 00:03:48.900
Well, first of all, it
gives us a lot more control.

00:03:48.900 --> 00:03:51.810
We can do a lot
smarter strategies

00:03:51.810 --> 00:03:54.190
for high resolve names
and other things.

00:03:54.190 --> 00:03:56.730
And here's some
performance numbers

00:03:56.730 --> 00:04:01.100
in terms of what we've seen
since we've landed M26.

00:04:01.100 --> 00:04:03.410
It took us a couple of tries
to actually kind of get

00:04:03.410 --> 00:04:05.390
the performance numbers
as good as they are.

00:04:05.390 --> 00:04:07.265
But you can see that
there's significant wins

00:04:07.265 --> 00:04:08.200
across the board.

00:04:08.200 --> 00:04:10.920
And for things like
Chrome OS, we've

00:04:10.920 --> 00:04:14.736
reduced the DNS resolution
time significantly, 36%.

00:04:14.736 --> 00:04:16.110
And not only that,
but we're also

00:04:16.110 --> 00:04:18.130
measuring the resolve
plus TCP connect.

00:04:18.130 --> 00:04:20.545
And you can see that there
are wins across the board.

00:04:20.545 --> 00:04:22.670
And of course, some of
these are platform specific.

00:04:22.670 --> 00:04:24.310
Some platforms just
do a better job

00:04:24.310 --> 00:04:27.150
of implementing their DNS
resolvers in the first place.

00:04:27.150 --> 00:04:29.502
But the cool thing is
that we can actually now

00:04:29.502 --> 00:04:30.960
kind of take control
now that we've

00:04:30.960 --> 00:04:32.770
got the basic plumbing working.

00:04:32.770 --> 00:04:35.110
We can take control
and do smarter things.

00:04:35.110 --> 00:04:38.650
So, for example, we can
raise different resolutions

00:04:38.650 --> 00:04:40.520
for IPv6 and IPv4.

00:04:40.520 --> 00:04:42.620
We are now actually
doing adaptive retry,

00:04:42.620 --> 00:04:45.790
so we actually remember
which DNS servers we've used.

00:04:45.790 --> 00:04:50.970
So we can do a better job of
making these resolutions faster

00:04:50.970 --> 00:04:52.680
in the future.

00:04:52.680 --> 00:04:56.810
And this is definitely a
space for a lot of improvement

00:04:56.810 --> 00:05:00.795
and also kind of subtle things
like providing better user

00:05:00.795 --> 00:05:02.790
error pages, right?

00:05:02.790 --> 00:05:05.430
Before you would just
get a failed timeout

00:05:05.430 --> 00:05:06.401
from DNS resolution.

00:05:06.401 --> 00:05:08.150
I mean, you just kind
of like, we give up.

00:05:08.150 --> 00:05:08.816
We have no idea.

00:05:08.816 --> 00:05:11.290
We can't give any useful
feedback to the user.

00:05:11.290 --> 00:05:12.800
Now we can go
much, much further.

00:05:12.800 --> 00:05:13.950
So that's pretty cool.

00:05:13.950 --> 00:05:18.050
Moving on, in M27, we landed
this big and important

00:05:18.050 --> 00:05:20.080
improvement, which is we
completely rewrote how

00:05:20.080 --> 00:05:21.540
we schedule resources.

00:05:21.540 --> 00:05:24.150
It's one thing for us
to get the HTML bytes.

00:05:24.150 --> 00:05:25.541
We then discovered
the resources.

00:05:25.541 --> 00:05:27.790
And then we need to figure
out how do we schedule them

00:05:27.790 --> 00:05:30.620
efficiently on the wire,
like we care about JavaScript

00:05:30.620 --> 00:05:33.070
before images and other things.

00:05:33.070 --> 00:05:37.620
And the big change that we've
done in there, in M27, is we

00:05:37.620 --> 00:05:40.150
replaced that scheduler.

00:05:40.150 --> 00:05:43.090
And we also started focusing
on perceived performance.

00:05:43.090 --> 00:05:45.090
So instead of just measuring
the page load time,

00:05:45.090 --> 00:05:47.500
we started measuring
things like speed index.

00:05:47.500 --> 00:05:50.480
So what kind of optimizations
we can do in Resource Scheduler

00:05:50.480 --> 00:05:51.590
to improve speed index.

00:05:51.590 --> 00:05:55.970
In fact, we've made decisions
where we've intentionally

00:05:55.970 --> 00:05:59.740
chosen speed index over
page load time, or unload.

00:05:59.740 --> 00:06:01.420
So there are changes
that have gone

00:06:01.420 --> 00:06:04.840
in where we've regressed,
in some cases, on load time.

00:06:04.840 --> 00:06:06.820
But we've improved
speed index, because we

00:06:06.820 --> 00:06:08.760
think that perceived
performance, getting

00:06:08.760 --> 00:06:13.140
useful pixels on the screen,
is a win for the user.

00:06:13.140 --> 00:06:16.350
And one interesting
takeaway from this work

00:06:16.350 --> 00:06:20.730
that was done in M27 was that
we realized that a lot of pages

00:06:20.730 --> 00:06:22.970
were actually competing for
bandwidth unnecessarily.

00:06:22.970 --> 00:06:25.350
So they were trying to
download too many things.

00:06:25.350 --> 00:06:28.770
We've gotten so good at charting
our assets that it's actually

00:06:28.770 --> 00:06:31.220
backfiring on a lot of sites.

00:06:31.220 --> 00:06:34.800
So, in particular, one
big interesting change

00:06:34.800 --> 00:06:38.490
that went in in that iteration
was that the new scheduler

00:06:38.490 --> 00:06:40.950
would only download up
to 10 images in parallel.

00:06:40.950 --> 00:06:43.610
So, for example, if you
have a gallery of images,

00:06:43.610 --> 00:06:45.800
you have let's say 30
of them on the page,

00:06:45.800 --> 00:06:48.640
and you sharded them
in 20 different ways,

00:06:48.640 --> 00:06:51.322
we would not open more than
10 connections at once.

00:06:51.322 --> 00:06:52.780
Because we found
that that actually

00:06:52.780 --> 00:06:56.190
hurts performance in most cases.

00:06:56.190 --> 00:06:59.070
So if you're developing
your site today,

00:06:59.070 --> 00:07:01.940
Chrome will limit you
to 10 image downloads.

00:07:01.940 --> 00:07:05.270
But in other browsers,
you'll still have no problem.

00:07:05.270 --> 00:07:08.670
I'm not sure what exact
scheduling algorithms

00:07:08.670 --> 00:07:10.470
they're using, but
perhaps something you

00:07:10.470 --> 00:07:11.790
should consider on your site.

00:07:11.790 --> 00:07:16.110
There is such thing as
oversharding your site.

00:07:16.110 --> 00:07:18.600
Later in M28, speaking
of perceived performance,

00:07:18.600 --> 00:07:22.970
we've also improved the SPDY
performance quite a bit.

00:07:22.970 --> 00:07:26.037
So the change here is
actually pretty awesome

00:07:26.037 --> 00:07:27.620
and pretty trivial
in that now that we

00:07:27.620 --> 00:07:29.030
have control over the
Resource Scheduler

00:07:29.030 --> 00:07:30.770
we said, look, if
you're using SPDY,

00:07:30.770 --> 00:07:33.530
we have a much better way
to schedule resources, which

00:07:33.530 --> 00:07:34.550
is we know the priority.

00:07:34.550 --> 00:07:36.620
We can send that
priority to the server.

00:07:36.620 --> 00:07:38.250
The server can do
the right thing.

00:07:38.250 --> 00:07:41.429
So we won't delay any
resource scheduling

00:07:41.429 --> 00:07:43.970
on the client, which is kind of
this like this fake latency--

00:07:43.970 --> 00:07:46.540
not fake, unnecessary
latency that we're otherwise

00:07:46.540 --> 00:07:47.500
introducing.

00:07:47.500 --> 00:07:50.330
So if you're using SPDY,
this is a nice performance

00:07:50.330 --> 00:07:52.100
win because it allows
us once again to get

00:07:52.100 --> 00:07:55.420
those pixels visible
earlier on the screen.

00:07:55.420 --> 00:07:58.490
So if you haven't
already, I definitely

00:07:58.490 --> 00:08:01.620
encourage you to look
into playing with SPDY.

00:08:01.620 --> 00:08:04.500
So if you're using Apache, you
can sell them on SPDY EngineX,

00:08:04.500 --> 00:08:06.810
and other server are
supported as well.

00:08:06.810 --> 00:08:10.610
And actually, we'll come back
to SPDY a little bit later.

00:08:10.610 --> 00:08:14.150
In M30, there's been
yet more improvements

00:08:14.150 --> 00:08:16.470
to the Resource Scheduler.

00:08:16.470 --> 00:08:19.290
We keep improving
and iterating on all

00:08:19.290 --> 00:08:20.740
of these different strategies.

00:08:20.740 --> 00:08:24.430
One interesting kind of takeaway
that we had in this iteration

00:08:24.430 --> 00:08:27.130
was that we actually
started distinguishing

00:08:27.130 --> 00:08:30.350
between optimizing for the
popular sites versus sites

00:08:30.350 --> 00:08:31.300
in the tail.

00:08:31.300 --> 00:08:32.960
There's different
ways that sites

00:08:32.960 --> 00:08:35.600
are constructed in terms of
kind of patterns that they use,

00:08:35.600 --> 00:08:37.780
how they lay out the
resources, and all the rest.

00:08:37.780 --> 00:08:41.010
And this iteration,
in particular,

00:08:41.010 --> 00:08:43.409
actually helped
quite a bit in terms

00:08:43.409 --> 00:08:47.440
of accelerating the
sites in the long tail.

00:08:47.440 --> 00:08:49.460
And if you think about
a 10% improvement

00:08:49.460 --> 00:08:51.390
in firing the
onload, this is just

00:08:51.390 --> 00:08:55.500
like one Chrome m
revision, it's huge.

00:08:55.500 --> 00:08:59.720
That's a 10% win in onload and
a 9% improvement in speed index.

00:08:59.720 --> 00:09:01.850
So there's just faster
pixels on the screen.

00:09:01.850 --> 00:09:04.110
So these are impressive numbers.

00:09:04.110 --> 00:09:07.780
And I think what's most exciting
for me is if we look forward,

00:09:07.780 --> 00:09:10.560
based on the work that we
have in the pipeline now,

00:09:10.560 --> 00:09:14.770
and project it a little bit,
we see significant improvements

00:09:14.770 --> 00:09:16.670
that we can still make
to these algorithms.

00:09:16.670 --> 00:09:20.820
So right now, at least based on
the current code that we have,

00:09:20.820 --> 00:09:26.060
you can expect more wins
rolling out to our users.

00:09:26.060 --> 00:09:27.967
So this is great.

00:09:27.967 --> 00:09:30.050
As far as I'm concerned,
this is free performance.

00:09:30.050 --> 00:09:31.837
Like the apps,
it's the same apps,

00:09:31.837 --> 00:09:33.670
they're just rendering
faster, because we're

00:09:33.670 --> 00:09:35.240
doing a better job
of how we schedule

00:09:35.240 --> 00:09:37.080
those resources in Chrome.

00:09:37.080 --> 00:09:39.480
So that's pretty exciting.

00:09:39.480 --> 00:09:45.010
Another huge win that's coming
and that's available on Android

00:09:45.010 --> 00:09:47.650
today is what we're
calling the "simple Cache".

00:09:47.650 --> 00:09:50.650
So one of the problems
that we realized

00:09:50.650 --> 00:09:53.460
that we had on Android
and mobile phones,

00:09:53.460 --> 00:09:57.560
in particular, is that in order
for us to dispatch a network

00:09:57.560 --> 00:10:00.060
request, we actually had to do
a number of different context

00:10:00.060 --> 00:10:00.560
switches.

00:10:00.560 --> 00:10:03.150
Like we would go from the main
threads to an I/O thread to

00:10:03.150 --> 00:10:04.480
we'd do another jump.

00:10:04.480 --> 00:10:09.100
We would always do a check
on the file system, which

00:10:09.100 --> 00:10:11.220
in itself can take
quite a bit of time.

00:10:11.220 --> 00:10:14.540
And the idea behind Simple Cache
is to try to simplify that,

00:10:14.540 --> 00:10:17.880
as the name implies,
to the extent

00:10:17.880 --> 00:10:21.610
that we can, and ideally, avoid
any context switches ongoing

00:10:21.610 --> 00:10:22.500
to disk.

00:10:22.500 --> 00:10:24.260
So that should help
quite a bit in terms

00:10:24.260 --> 00:10:28.130
of the actual performance
of the Simple Cache.

00:10:28.130 --> 00:10:29.920
And here's some early numbers.

00:10:29.920 --> 00:10:31.910
These look very, very good.

00:10:31.910 --> 00:10:34.360
The blue line on the
bottom is the original,

00:10:34.360 --> 00:10:37.364
and what you see
here is the latency.

00:10:37.364 --> 00:10:39.530
So you kind of had this
like long tail distribution,

00:10:39.530 --> 00:10:41.320
where basically every
request incurred

00:10:41.320 --> 00:10:43.590
a minimum of several
milliseconds.

00:10:43.590 --> 00:10:45.230
But then you had
this long tail, where

00:10:45.230 --> 00:10:48.790
it wasn't atypical for a
request to take 50 milliseconds

00:10:48.790 --> 00:10:50.402
before we could
even dispatch it.

00:10:50.402 --> 00:10:52.360
Because we had to kind
of do a couple of thread

00:10:52.360 --> 00:10:55.030
hops and then check
disk, or check

00:10:55.030 --> 00:10:58.740
Flash, in this case, and
kind of bubble that back up.

00:10:58.740 --> 00:11:00.685
With the new Simple
Cache, basically we

00:11:00.685 --> 00:11:02.060
can just complete
it immediately,

00:11:02.060 --> 00:11:03.320
most of the requests.

00:11:03.320 --> 00:11:06.190
Every once in a while, we
still have some delays,

00:11:06.190 --> 00:11:09.100
but this is the
type of line where

00:11:09.100 --> 00:11:12.020
you want to see on all of
your performance charts.

00:11:12.020 --> 00:11:16.730
And this is quite amazing
because once we have the Simple

00:11:16.730 --> 00:11:20.200
Cache, based on
our measurements,

00:11:20.200 --> 00:11:22.794
this has improved all
HTTP transfers, the speed

00:11:22.794 --> 00:11:24.460
of these transfers,
in terms of the time

00:11:24.460 --> 00:11:26.110
from the first
request byte that we

00:11:26.110 --> 00:11:28.850
want to send to
completion by 10%, which,

00:11:28.850 --> 00:11:31.500
if you think about
it, is massive, right?

00:11:31.500 --> 00:11:33.620
And not only that,
but in M31 we're

00:11:33.620 --> 00:11:36.860
seeing 7% page load
time improvement.

00:11:36.860 --> 00:11:39.200
So this is simply eliminating
that extra latency

00:11:39.200 --> 00:11:42.190
at the beginning of
each and every request.

00:11:42.190 --> 00:11:45.337
And once again, there's
more work going into M32,

00:11:45.337 --> 00:11:47.420
and we hope that we can
improve this even further.

00:11:47.420 --> 00:11:50.425
So this is huge,
and this will be

00:11:50.425 --> 00:11:53.590
an awesome win for
mobile browsers.

00:11:53.590 --> 00:11:56.100
And then finally, one of
the last things that we've

00:11:56.100 --> 00:11:58.234
started iterating towards
the end of the year here,

00:11:58.234 --> 00:12:00.400
and something that I'm
really, really excited about,

00:12:00.400 --> 00:12:05.412
is focusing on improving the
speculative optimizations

00:12:05.412 --> 00:12:06.620
that we already do in Chrome.

00:12:06.620 --> 00:12:10.140
We do a lot of speculative
optimization as it is today.

00:12:10.140 --> 00:12:12.527
But now we're also looking
at how do we refine these?

00:12:12.527 --> 00:12:14.110
How do we expose the
right primitives,

00:12:14.110 --> 00:12:15.693
and how do we make
better use of them?

00:12:15.693 --> 00:12:17.860
One example is something
like prefetch, right?

00:12:17.860 --> 00:12:21.010
So if you're familiar
with a link rel=prefetch,

00:12:21.010 --> 00:12:22.870
what it allows you
to say is, hey,

00:12:22.870 --> 00:12:25.177
I will need this resource
perhaps on the next page.

00:12:25.177 --> 00:12:26.760
That could be an
HTML page, that could

00:12:26.760 --> 00:12:29.390
be a CSS file, an
image, what have you.

00:12:29.390 --> 00:12:30.960
Please fetch this
for me, such that I

00:12:30.960 --> 00:12:33.920
don't have to fetch that,
or I can just fetch it out

00:12:33.920 --> 00:12:36.850
of the cache when the
user initiates that load.

00:12:36.850 --> 00:12:39.720
One of the gotchas there
was, if that request did not

00:12:39.720 --> 00:12:41.680
complete in time for
the next navigation,

00:12:41.680 --> 00:12:42.620
it would get canceled.

00:12:42.620 --> 00:12:44.300
So you kind of incur
the double download

00:12:44.300 --> 00:12:46.480
and it just didn't make sense.

00:12:46.480 --> 00:12:49.410
So, for example, we have
this new patch that's in.

00:12:49.410 --> 00:12:52.640
It's not available in Canary
yet, but it's coming soon,

00:12:52.640 --> 00:12:54.740
called detachable prefetch,
which will actually

00:12:54.740 --> 00:12:57.890
keep the prefetch alive even
as you navigate away, such

00:12:57.890 --> 00:12:59.910
that you can still make
use of that resource

00:12:59.910 --> 00:13:01.549
once you get to
your destination.

00:13:01.549 --> 00:13:02.590
So that's pretty awesome.

00:13:02.590 --> 00:13:06.130
And this will also apply to
other things like prerenders

00:13:06.130 --> 00:13:08.750
and other types of improvements.

00:13:08.750 --> 00:13:10.060
So this is pretty cool.

00:13:10.060 --> 00:13:12.120
And this is how,
basically, it looks.

00:13:12.120 --> 00:13:16.360
Chrome allows you to actually
dynamically create these hints.

00:13:16.360 --> 00:13:19.280
So, for example, if, let's
say, the user initiates

00:13:19.280 --> 00:13:21.790
some sort of an action, like
they click on the Checkout

00:13:21.790 --> 00:13:23.552
button or they click
on Add To Cart button

00:13:23.552 --> 00:13:26.010
and you know that they're going
to go to the checkout page,

00:13:26.010 --> 00:13:29.492
at that moment you can actually
inject one of these link

00:13:29.492 --> 00:13:30.950
elements and say,
hey, I would like

00:13:30.950 --> 00:13:34.220
you to prefetch that asset
for me, because now I

00:13:34.220 --> 00:13:35.380
know I will need it.

00:13:35.380 --> 00:13:38.220
And vice versa, you can
actually delete this element out

00:13:38.220 --> 00:13:41.570
of the DOM, and we will
cancel the prefetch as well.

00:13:41.570 --> 00:13:44.110
So you can dynamically
script how and basically

00:13:44.110 --> 00:13:46.730
drive Chrome to do these
prefetches for you.

00:13:46.730 --> 00:13:48.380
So this is pretty cool stuff.

00:13:48.380 --> 00:13:50.890
And I think this
is a place where

00:13:50.890 --> 00:13:54.730
we can do a lot more
in the future as well.

00:13:54.730 --> 00:13:57.290
So that's a little bit about
kind of the low-level guts

00:13:57.290 --> 00:13:59.450
and improvements in Chrome.

00:13:59.450 --> 00:14:01.930
Now let's take a look
at some of the protocols

00:14:01.930 --> 00:14:03.650
that we've been working on.

00:14:03.650 --> 00:14:08.110
So back in 2009, roughly,
actually four years ago

00:14:08.110 --> 00:14:10.480
almost on the dot,
we announced our work

00:14:10.480 --> 00:14:13.240
on SPDY or initial
efforts around SPDY.

00:14:13.240 --> 00:14:15.510
And since then we've gone,
I think, quite a long way.

00:14:15.510 --> 00:14:18.900
We've had several iterations
of the protocol itself, so v2,

00:14:18.900 --> 00:14:20.000
v3, 3.1.

00:14:20.000 --> 00:14:21.810
Now we're working on Version 4.

00:14:21.810 --> 00:14:23.900
And that actually
became the foundation

00:14:23.900 --> 00:14:26.080
of HTTP 2.0, which
is pretty exciting.

00:14:26.080 --> 00:14:29.950
And HTTP 2.0 work in itself
is progressing quite rapidly,

00:14:29.950 --> 00:14:31.760
and I'm really
excited about that.

00:14:31.760 --> 00:14:36.240
So today we actually have
both SPDY and HTTP 2.0 support

00:14:36.240 --> 00:14:39.110
in Chrome, although HTTP
2.0 is under a flag.

00:14:39.110 --> 00:14:40.040
But it is there.

00:14:40.040 --> 00:14:41.810
It's something that
we're iterating on.

00:14:41.810 --> 00:14:44.265
And then once HTTP 2.0-- I
know this is a common question.

00:14:44.265 --> 00:14:47.960
Once HTTP 2.0 is marked
as ready, as a standard,

00:14:47.960 --> 00:14:49.760
we'll just switch
over to HTTP 2.0.

00:14:49.760 --> 00:14:52.940
So think of SPDY as kind of like
an experimental ground for us

00:14:52.940 --> 00:14:55.670
to try different ideas
and feed them back

00:14:55.670 --> 00:14:57.260
into the HTTP 2.0 spec, right?

00:14:57.260 --> 00:14:59.230
So like it'd be great
if we had this feature.

00:14:59.230 --> 00:15:01.250
Let's go and try and
implement that feature.

00:15:01.250 --> 00:15:04.270
We try it, and we
discover the rough edges,

00:15:04.270 --> 00:15:07.760
and then we kind of feed
that back into HTTP 2.0.

00:15:07.760 --> 00:15:09.790
So earlier in the
year, we actually

00:15:09.790 --> 00:15:14.040
deployed SPDY 3.1 across
all of our Google servers

00:15:14.040 --> 00:15:16.240
and, of course, added
support in Chrome.

00:15:16.240 --> 00:15:18.800
Firefox also supports SPDY v3.1.

00:15:18.800 --> 00:15:21.340
And here's some numbers.

00:15:21.340 --> 00:15:23.490
We've never released
this before,

00:15:23.490 --> 00:15:25.450
but these are the
performance numbers

00:15:25.450 --> 00:15:29.460
that we see for SPDY across some
of the major Google properties,

00:15:29.460 --> 00:15:32.954
and these are consistent across
all the different Google sites.

00:15:32.954 --> 00:15:35.370
So you're kind of looking at
the right order of magnitude,

00:15:35.370 --> 00:15:40.460
anywhere between 20 to 40 to
50% improvement in latency as

00:15:40.460 --> 00:15:42.720
compared to HTTPS.

00:15:42.720 --> 00:15:45.510
And in some cases,
we're actually-- so even

00:15:45.510 --> 00:15:49.690
despite the fact that we have
these extra handshake round

00:15:49.690 --> 00:15:52.340
trips and all the rest
in CLS, oftentimes

00:15:52.340 --> 00:15:55.240
we actually end up going
faster than just vanilla HTTP

00:15:55.240 --> 00:15:58.640
as well, which is,
of course, the point

00:15:58.640 --> 00:16:00.816
of this whole exercise
to begin with.

00:16:00.816 --> 00:16:01.940
So this is really exciting.

00:16:01.940 --> 00:16:05.774
And I guess the important bit
here is also that not only is

00:16:05.774 --> 00:16:08.440
it helping the median, which is,
of course, what we like to see,

00:16:08.440 --> 00:16:10.950
but it's also consistently
helping all of our users,

00:16:10.950 --> 00:16:14.085
the ones on fast connections,
and especially so for the ones

00:16:14.085 --> 00:16:15.960
that are ion the slow
connections or the ones

00:16:15.960 --> 00:16:18.550
with the high RTT times,
which is especially

00:16:18.550 --> 00:16:21.740
relevant for things like mobile,
where RTTs are definitely

00:16:21.740 --> 00:16:22.540
higher.

00:16:22.540 --> 00:16:23.940
So this is really exciting.

00:16:23.940 --> 00:16:26.030
This is very promising.

00:16:26.030 --> 00:16:28.700
And I hope that this will help
kind of drive the HTTP 2.0

00:16:28.700 --> 00:16:30.860
adoption as well.

00:16:30.860 --> 00:16:32.400
So if you haven't
looked at SPDY,

00:16:32.400 --> 00:16:34.370
I definitely encourage
you to do so.

00:16:34.370 --> 00:16:36.932
There are modules for
virtually every popular server

00:16:36.932 --> 00:16:38.765
out there today that
you can enable and just

00:16:38.765 --> 00:16:41.600
play with, enable
it on your site.

00:16:41.600 --> 00:16:44.300
And there's also
commercial support for it

00:16:44.300 --> 00:16:48.120
as well, so F5, Akamai,
and others support SPDY.

00:16:48.120 --> 00:16:49.990
So that's pretty cool.

00:16:49.990 --> 00:16:53.330
And as I mentioned, we
also do have HTTP 2.0.

00:16:53.330 --> 00:16:56.070
If you're curious, if
you want to play with it,

00:16:56.070 --> 00:16:58.610
we do have HTTP 2.0
support under a flag.

00:16:58.610 --> 00:17:00.970
So you can actually
enable that and then

00:17:00.970 --> 00:17:02.860
run it against
your local server.

00:17:02.860 --> 00:17:05.500
I think the only big
public site that supports

00:17:05.500 --> 00:17:08.033
HTTP 2.0 today is twitter.com.

00:17:08.033 --> 00:17:10.329
So in theory, you
can test it on that.

00:17:10.329 --> 00:17:14.099
But there are also
open source servers

00:17:14.099 --> 00:17:16.859
that speak HTTP 2.0 today
that you can play with.

00:17:16.859 --> 00:17:20.290
So SPDY is kind of a production
version, if you will.

00:17:20.290 --> 00:17:22.760
HTTP 2.0 is coming soon
and hopefully, fingers

00:17:22.760 --> 00:17:26.950
crossed, sometime in 2014.

00:17:26.950 --> 00:17:30.120
So that's SPDY.

00:17:30.120 --> 00:17:33.192
You may have caught the
wind of some other protocol

00:17:33.192 --> 00:17:35.400
that we started working on
earlier in the year, which

00:17:35.400 --> 00:17:38.290
is QUIC, which is Quick
UDP Internet Connections.

00:17:38.290 --> 00:17:40.840
And the idea here is
actually to kind of take

00:17:40.840 --> 00:17:44.000
what we've done with SPDY
and go one step beyond.

00:17:44.000 --> 00:17:47.340
And this was actually our intent
right at the very beginning

00:17:47.340 --> 00:17:49.610
when we started
thinking of SPDY.

00:17:49.610 --> 00:17:51.030
But it was just
too much of a leap

00:17:51.030 --> 00:17:54.850
to change both the protocol,
kind of the application

00:17:54.850 --> 00:17:56.770
protocol, and the
transfer protocols.

00:17:56.770 --> 00:17:59.310
So we kind of decoupled those,
and QUIC is basically that.

00:17:59.310 --> 00:18:03.650
We're trying to go one
step further and say, well,

00:18:03.650 --> 00:18:05.590
could we build a
better transport

00:18:05.590 --> 00:18:07.890
for HTTP traffic,
period, on top of UDP?

00:18:07.890 --> 00:18:11.300
Could we experiment
with new ideas?

00:18:11.300 --> 00:18:14.460
The core premise of this stuff
is it's all about latency.

00:18:14.460 --> 00:18:16.790
We're trying to eliminate
latency everywhere we can.

00:18:16.790 --> 00:18:19.590
So can we eliminate
extra round trips

00:18:19.590 --> 00:18:22.560
to establish the secure tunnel?

00:18:22.560 --> 00:18:24.310
Can we do better
congestion control?

00:18:24.310 --> 00:18:25.820
What if we do packet pacing?

00:18:25.820 --> 00:18:27.840
What if we do forward
error correction?

00:18:27.840 --> 00:18:29.910
What can we do to
innovate in the space

00:18:29.910 --> 00:18:33.590
to help reduce the page
load times on the web?

00:18:33.590 --> 00:18:35.809
And there's a lot of
interesting ideas.

00:18:35.809 --> 00:18:37.850
If you guys are curious
about this kind of stuff,

00:18:37.850 --> 00:18:39.190
we posted our design docs.

00:18:39.190 --> 00:18:41.980
And it's a very long doc.

00:18:41.980 --> 00:18:44.360
I encourage you to read
it and give us feedback.

00:18:44.360 --> 00:18:47.160
We have a Google group for that.

00:18:47.160 --> 00:18:49.370
And this question comes
up quite frequently,

00:18:49.370 --> 00:18:51.690
which is, like,
what's the point?

00:18:51.690 --> 00:18:53.670
What are you trying to do here?

00:18:53.670 --> 00:18:55.360
And the answer is very simple.

00:18:55.360 --> 00:18:59.246
We just want to make faster
internet for everybody to use.

00:18:59.246 --> 00:19:01.120
And there are two ways
that this will happen.

00:19:01.120 --> 00:19:03.520
One is we end up building
a really awesome protocol

00:19:03.520 --> 00:19:05.500
that everybody loves
and we take it to ITF.

00:19:05.500 --> 00:19:08.110
And just like with
HTTP 2.0 and SPDY,

00:19:08.110 --> 00:19:11.770
we work with the community and
kind of make that the standard.

00:19:11.770 --> 00:19:14.930
That's plausible and
maybe that will happen.

00:19:14.930 --> 00:19:17.830
The alternative route is, we
just experiment with QUIC.

00:19:17.830 --> 00:19:19.450
We experiment with
different ideas.

00:19:19.450 --> 00:19:22.240
And those ideas get adopted,
the good ones get adopted

00:19:22.240 --> 00:19:24.936
into existing protocol
stacks, like TCP and TLS.

00:19:24.936 --> 00:19:26.310
And actually we're
already seeing

00:19:26.310 --> 00:19:30.020
some of that, where based on our
experience with the encryption

00:19:30.020 --> 00:19:33.270
stuff in QUIC, the TLS
working group is looking

00:19:33.270 --> 00:19:34.960
at improvements
in terms of can we

00:19:34.960 --> 00:19:36.660
eliminate some
extra round trips.

00:19:36.660 --> 00:19:39.980
So in either case, the point
is, no matter which one of these

00:19:39.980 --> 00:19:41.790
happens, the users will win.

00:19:41.790 --> 00:19:42.910
We'll get faster internet.

00:19:42.910 --> 00:19:44.770
And that's our intent with QUIC.

00:19:44.770 --> 00:19:47.380
So that's pretty awesome.

00:19:47.380 --> 00:19:51.045
We don't have any benchmarks
for it as of today.

00:19:51.045 --> 00:19:53.670
We're still at a point where we
want to make sure that it works

00:19:53.670 --> 00:19:55.460
and it works correctly
before we start

00:19:55.460 --> 00:19:58.470
optimizing kind of all
the edges around it.

00:19:58.470 --> 00:20:01.050
But you can actually
play with QUIC today.

00:20:01.050 --> 00:20:03.156
We have it deployed
on Google servers,

00:20:03.156 --> 00:20:04.280
and you can also enable it.

00:20:04.280 --> 00:20:08.090
If you go into Chrome flags,
you can flip QUIC Support.

00:20:08.090 --> 00:20:10.290
And then you can, for
example, access YouTube,

00:20:10.290 --> 00:20:14.250
and you'll get served--
youtube.com or other Google

00:20:14.250 --> 00:20:16.950
service-- over UDP, over QUIC.

00:20:16.950 --> 00:20:19.880
And if you're curious, you can
dive into Chrome net internals

00:20:19.880 --> 00:20:21.880
and kind of look at
the actual protocol

00:20:21.880 --> 00:20:23.000
and all this other stuff.

00:20:23.000 --> 00:20:27.160
So if you're into kind of
low-level networking protocols,

00:20:27.160 --> 00:20:29.620
definitely a thing you want
to check out and play with.

00:20:29.620 --> 00:20:32.200
There's lots of interesting
ideas in the protocol.

00:20:34.717 --> 00:20:35.800
All right, shifting gears.

00:20:35.800 --> 00:20:37.730
Linus mentioned Chrome
data compression.

00:20:37.730 --> 00:20:40.250
This is something that we
launched early in the year.

00:20:40.250 --> 00:20:42.542
As you heard, it provides
roughly 50% data savings.

00:20:42.542 --> 00:20:44.750
That's kind of the average
number for a lot of users.

00:20:44.750 --> 00:20:48.030
It turns out there's a lot
of poorly compressed content

00:20:48.030 --> 00:20:49.300
on the web.

00:20:49.300 --> 00:20:52.240
People still forget to
gzip their content, which

00:20:52.240 --> 00:20:56.320
is one of the optimizations
that we apply for text, like

00:20:56.320 --> 00:20:56.970
[INAUDIBLE].

00:20:56.970 --> 00:20:58.870
And we also convert
all the images

00:20:58.870 --> 00:21:01.260
to IP, which provides
a significant savings.

00:21:01.260 --> 00:21:03.730
So this is a big benefit
to a lot of users.

00:21:03.730 --> 00:21:05.410
But one thing that
Linus didn't mention

00:21:05.410 --> 00:21:08.930
is that there are other
secondary benefits to that.

00:21:08.930 --> 00:21:11.770
Because we run over SPDY,
so between your phone

00:21:11.770 --> 00:21:14.220
and the Google server, it's
actually a SPDY connection.

00:21:14.220 --> 00:21:15.650
It's an encrypted connection.

00:21:15.650 --> 00:21:19.690
So I actually use Chrome
data compression in part

00:21:19.690 --> 00:21:22.120
for the data compression
part, but also

00:21:22.120 --> 00:21:24.970
partially to secure my browsing.

00:21:24.970 --> 00:21:28.674
Because when I enable this,
the secure traffic, if you're

00:21:28.674 --> 00:21:30.840
connecting to your bank,
for example, an HTTPS site,

00:21:30.840 --> 00:21:32.173
it will go directly to the site.

00:21:32.173 --> 00:21:33.510
So that traffic is encrypted.

00:21:33.510 --> 00:21:36.550
But if you're trying to connect
to some unencrypted site,

00:21:36.550 --> 00:21:40.010
it'll just flow basically
as it is on the wire.

00:21:40.010 --> 00:21:41.940
With Chrome data
compression, that

00:21:41.940 --> 00:21:45.770
goes through a secure tunnel,
so even if you're on a Starbucks

00:21:45.770 --> 00:21:49.110
Wi-Fi or whatever,
some unencrypted Wi-Fi

00:21:49.110 --> 00:21:53.160
and you're browsing around,
all of your data is encrypted.

00:21:53.160 --> 00:21:55.660
So that's really nice.

00:21:55.660 --> 00:21:59.100
And maybe one important thing
to highlight with Chrome data

00:21:59.100 --> 00:22:04.050
compression is, it is still
the full fidelity HTML5 web

00:22:04.050 --> 00:22:04.860
experience, right?

00:22:04.860 --> 00:22:07.550
We're not doing anything
to modify your site.

00:22:07.550 --> 00:22:09.670
We're not trying to
render it on the server.

00:22:09.670 --> 00:22:12.910
Like you have all of the
flexibility of JavaScript, CSS,

00:22:12.910 --> 00:22:15.590
and all the rest on your phone.

00:22:15.590 --> 00:22:17.340
That's where the
code gets executed.

00:22:17.340 --> 00:22:20.150
So we're just modifying and
optimizing some of the assets

00:22:20.150 --> 00:22:21.940
as they get delivered.

00:22:21.940 --> 00:22:25.140
Some common questions that I get
about Chrome data compression,

00:22:25.140 --> 00:22:27.790
something you should know, is
this is going through a proxy.

00:22:27.790 --> 00:22:29.800
So if you're developing
a site where you're

00:22:29.800 --> 00:22:33.420
relying on GoIP
functionality to customize

00:22:33.420 --> 00:22:36.422
the location to the user or
maybe serve relevant ads,

00:22:36.422 --> 00:22:38.130
you should be looking
for the X Forwarded

00:22:38.130 --> 00:22:40.110
For header, which
is the IP address

00:22:40.110 --> 00:22:44.670
of the client as forwarded
by the Chrome data proxy.

00:22:44.670 --> 00:22:47.800
And similarly, if
for whatever reason

00:22:47.800 --> 00:22:51.020
you absolutely want to make
sure that we don't do anything

00:22:51.020 --> 00:22:52.480
to your content,
you can actually

00:22:52.480 --> 00:22:54.780
opt out on a per-resource basis.

00:22:54.780 --> 00:22:57.160
If you add a no
transform header,

00:22:57.160 --> 00:23:00.000
it basically tells the
Chrome data proxy to just

00:23:00.000 --> 00:23:01.880
be hands off with that resource.

00:23:01.880 --> 00:23:04.100
So we won't
reoptimize that image,

00:23:04.100 --> 00:23:06.860
or we won't recompress
that text, or other things.

00:23:06.860 --> 00:23:12.100
So these are standard
kind of proxy directives.

00:23:12.100 --> 00:23:15.660
Chrome data compression
proxies supports it.

00:23:15.660 --> 00:23:18.840
So, just an FYI.

00:23:18.840 --> 00:23:20.890
Shifting gears, web sockets.

00:23:20.890 --> 00:23:22.520
This is really, really exciting.

00:23:22.520 --> 00:23:25.300
Do we have any web socket
developers in the room?

00:23:25.300 --> 00:23:26.280
Yes.

00:23:26.280 --> 00:23:27.260
Awesome.

00:23:27.260 --> 00:23:30.090
So web socket
compression is going

00:23:30.090 --> 00:23:34.200
to be live in M32, which
is a long overdue feature.

00:23:34.200 --> 00:23:35.960
One of the gotchas
with web sockets

00:23:35.960 --> 00:23:38.310
was that you could
transfer binary in text,

00:23:38.310 --> 00:23:42.260
but text would always
go as uncompressed

00:23:42.260 --> 00:23:44.040
in both directions.

00:23:44.040 --> 00:23:45.820
Now that we have
the spec up to date

00:23:45.820 --> 00:23:48.970
and we already have
the code in Chrome,

00:23:48.970 --> 00:23:53.100
you can actually negotiate
the deflate compression

00:23:53.100 --> 00:23:55.920
to apply in both directions,
and the server can selectively

00:23:55.920 --> 00:23:57.900
compress any given frame.

00:23:57.900 --> 00:23:59.790
And the client, as
of today, Chrome

00:23:59.790 --> 00:24:05.020
will compress every
single frame going out

00:24:05.020 --> 00:24:08.260
from your mobile device or
from your desktop device.

00:24:08.260 --> 00:24:10.350
And I'm not going to
go into details here,

00:24:10.350 --> 00:24:12.620
but we also, actually,
the spec provides

00:24:12.620 --> 00:24:14.680
a number of different
parameters to customize

00:24:14.680 --> 00:24:16.100
how the compression
will be done.

00:24:16.100 --> 00:24:18.805
For example, the size of the
sliding window, so essentially

00:24:18.805 --> 00:24:22.000
you can control the
resources used on your server

00:24:22.000 --> 00:24:24.422
and on your client,
plus some other flags.

00:24:24.422 --> 00:24:25.880
So this is really,
really exciting,

00:24:25.880 --> 00:24:30.740
because this has definitely been
a sore point for web sockets.

00:24:30.740 --> 00:24:33.936
We heard about WebRTC
and DataChannel.

00:24:33.936 --> 00:24:35.310
The way I think
about DataChannel

00:24:35.310 --> 00:24:38.690
is basically WebSocket,
but over UDP and P2P.

00:24:38.690 --> 00:24:41.570
So we can communicate
directly between devices.

00:24:41.570 --> 00:24:45.250
We don't have to go through
an intermediary like a server.

00:24:45.250 --> 00:24:49.420
And DataChannel and M31
has now officially switched

00:24:49.420 --> 00:24:51.150
to SCTP protocol.

00:24:51.150 --> 00:24:54.870
So previously we were
using RTP data channels,

00:24:54.870 --> 00:24:58.260
and that was the reason for
some of the incompatibilities

00:24:58.260 --> 00:24:59.830
with some of the other vendors.

00:24:59.830 --> 00:25:02.690
But as of M31, SCTP
is the default,

00:25:02.690 --> 00:25:07.150
and we will aggressively remove
support for RTP data channels.

00:25:07.150 --> 00:25:10.410
So if you're using
data channels today,

00:25:10.410 --> 00:25:12.210
this is something
you want to revisit.

00:25:12.210 --> 00:25:14.330
And if you're not familiar
with data channels,

00:25:14.330 --> 00:25:16.870
I encourage you to
check out the links.

00:25:16.870 --> 00:25:19.280
I'll post the slides
later for how this works

00:25:19.280 --> 00:25:20.290
and why this is awesome.

00:25:20.290 --> 00:25:23.640
Because it allows you
to define things like,

00:25:23.640 --> 00:25:26.180
fire-and-forget semantics,
don't retransmit.

00:25:26.180 --> 00:25:30.655
So it's a really nice transport
for doing low-latency data

00:25:30.655 --> 00:25:31.155
exchange.

00:25:33.900 --> 00:25:36.310
And then finally, let's talk
about measurements, right?

00:25:36.310 --> 00:25:38.860
So there's a lot of kind
of protocol improvements

00:25:38.860 --> 00:25:40.190
that are going on.

00:25:40.190 --> 00:25:42.730
But as we know, we need to
be able to measure things

00:25:42.730 --> 00:25:44.210
in order to improve them.

00:25:44.210 --> 00:25:46.630
So, of course, we're all
familiar with navigation

00:25:46.630 --> 00:25:47.810
timing, or I hope we are.

00:25:47.810 --> 00:25:50.220
Most of the people
here I expect would be.

00:25:50.220 --> 00:25:53.350
You can get detailed
low-level stats

00:25:53.350 --> 00:25:55.500
about how long did
each connection take

00:25:55.500 --> 00:25:58.440
in terms of DNS times, TCP
time, and all the other things.

00:25:58.440 --> 00:26:01.080
You can throw that into your
analytics solution here.

00:26:01.080 --> 00:26:02.870
I'm showing you Google
Analytics, which

00:26:02.870 --> 00:26:05.160
allows you to segment
this data to say, well,

00:26:05.160 --> 00:26:07.650
I want to look at my mobile
users versus desktop.

00:26:07.650 --> 00:26:10.750
You can segment it
by any other variable

00:26:10.750 --> 00:26:14.000
you define, like has a user
clicked the Checkout button,

00:26:14.000 --> 00:26:15.900
or have they
registered, et cetera.

00:26:15.900 --> 00:26:17.080
This is all great.

00:26:17.080 --> 00:26:20.000
One gotcha with this is this is
only for the main page, right?

00:26:20.000 --> 00:26:23.076
What about the other 85
resources or 100 resources

00:26:23.076 --> 00:26:24.200
that you have on your page?

00:26:24.200 --> 00:26:25.730
How are those performing?

00:26:25.730 --> 00:26:29.530
Well in Chrome, we have support
for resource timing, which

00:26:29.530 --> 00:26:32.660
gives you that same level of
access to all of the network

00:26:32.660 --> 00:26:35.240
metadata, or
timestamps, I should

00:26:35.240 --> 00:26:37.570
say, on a per-resource basis.

00:26:37.570 --> 00:26:40.920
So you can see here
that you can actually

00:26:40.920 --> 00:26:43.159
query for a specific
resource, like your JavaScript

00:26:43.159 --> 00:26:44.200
file that you're loading.

00:26:44.200 --> 00:26:45.991
Maybe you're loading
it from CDN and you're

00:26:45.991 --> 00:26:48.350
wondering how well
is my CDN performing.

00:26:48.350 --> 00:26:50.070
You can get your
real user measurement

00:26:50.070 --> 00:26:52.910
data for that specific
resource and then look up

00:26:52.910 --> 00:26:56.350
the time for DNS, TCP connect
time, total transfer time,

00:26:56.350 --> 00:26:57.300
et cetera.

00:26:57.300 --> 00:26:59.160
The only thing that
you need to be aware of

00:26:59.160 --> 00:27:02.930
is that the resource has to
manually opt in and allow

00:27:02.930 --> 00:27:04.516
the data to be
gathered to begin with.

00:27:04.516 --> 00:27:06.390
This is done for privacy
reasons to make sure

00:27:06.390 --> 00:27:11.010
that somebody can't just iterate
or recache and figure out

00:27:11.010 --> 00:27:14.120
where you've been in the
past, or something like it.

00:27:14.120 --> 00:27:17.300
So for your own resources
you need to add this header.

00:27:17.300 --> 00:27:19.810
And then if you're using
third party resources,

00:27:19.810 --> 00:27:23.000
if that origin is already
not providing this header,

00:27:23.000 --> 00:27:25.370
then you should
ask them to do so.

00:27:25.370 --> 00:27:31.580
Because here's one example where
I have a web font on my site.

00:27:31.580 --> 00:27:34.060
Web fonts delay when
the tech gets painted.

00:27:34.060 --> 00:27:37.865
So the question is,
how is-- in this case,

00:27:37.865 --> 00:27:38.740
this is a Google CDN.

00:27:38.740 --> 00:27:40.550
How is Google CDN
performing in terms

00:27:40.550 --> 00:27:41.990
of serving the actual font?

00:27:41.990 --> 00:27:43.430
Is it hurting my users?

00:27:43.430 --> 00:27:46.160
Well, now I can actually grab
that data from Resource Timing,

00:27:46.160 --> 00:27:49.200
just as I showed you
a few slides ago.

00:27:49.200 --> 00:27:51.330
And we can just pump that
into Google Analytics.

00:27:51.330 --> 00:27:53.495
Here you can see that I'm
tracking the DNS, TCP,

00:27:53.495 --> 00:27:54.820
and transfer times.

00:27:54.820 --> 00:27:57.380
And it turns out
that the fonts coming

00:27:57.380 --> 00:28:01.290
from Google CDN, at
least for my site,

00:28:01.290 --> 00:28:04.730
are being loaded in this case
within 150 milliseconds, which

00:28:04.730 --> 00:28:07.130
to me was an acceptable time.

00:28:07.130 --> 00:28:08.490
And that was fine for me.

00:28:08.490 --> 00:28:11.850
But you can now think about
using this sort of data

00:28:11.850 --> 00:28:13.730
to define third party SLAs.

00:28:13.730 --> 00:28:16.270
You rely on third party
widgets you can say, well,

00:28:16.270 --> 00:28:19.879
your widgets must load in x
amount of time, et cetera.

00:28:19.879 --> 00:28:21.920
You can actually track
this with Resource Timing,

00:28:21.920 --> 00:28:23.920
which is pretty awesome.

00:28:23.920 --> 00:28:27.200
So as a quick recap, we
covered a lot of ground.

00:28:27.200 --> 00:28:29.060
There's a new DNS
Resolver in Chrome,

00:28:29.060 --> 00:28:31.720
which is double-digit
performance improvement

00:28:31.720 --> 00:28:32.920
and actual DNS resolutions.

00:28:32.920 --> 00:28:34.579
And the new scheduler
is definitely

00:28:34.579 --> 00:28:36.120
something we're
really excited about.

00:28:36.120 --> 00:28:40.570
We've already seen huge
improvements there,

00:28:40.570 --> 00:28:42.680
10% and 20% improvement
in the actual speed

00:28:42.680 --> 00:28:44.340
index and page load times.

00:28:44.340 --> 00:28:47.250
The Simple Cache stuff
is a huge win on mobile,

00:28:47.250 --> 00:28:49.350
and I'm really excited
to have that out there.

00:28:49.350 --> 00:28:51.490
And then moving
forward, I'm hoping

00:28:51.490 --> 00:28:54.530
that we can make the preresolve
and prefetch and the prerender

00:28:54.530 --> 00:28:56.610
stuff much, much smarter.

00:28:56.610 --> 00:28:58.990
And you saw the
SPDY wins, right?

00:28:58.990 --> 00:29:01.890
So all of these things
are incremental, 10% here,

00:29:01.890 --> 00:29:02.620
20% there.

00:29:02.620 --> 00:29:04.078
Before you know
it, you're actually

00:29:04.078 --> 00:29:07.150
saving hundreds of milliseconds,
and sometimes seconds,

00:29:07.150 --> 00:29:09.310
for the user, which
is a huge win.

00:29:09.310 --> 00:29:11.850
And some of these things you
guys need to optimize for.

00:29:11.850 --> 00:29:14.215
These are the things where
you need to install SPDY,

00:29:14.215 --> 00:29:15.715
you need to configure
SPDY, you need

00:29:15.715 --> 00:29:18.920
to make sure that your stacks
are configured correctly.

00:29:18.920 --> 00:29:20.940
And in other cases,
it's just also doing

00:29:20.940 --> 00:29:23.120
a better job of scheduling
this kind of stuff.

00:29:23.120 --> 00:29:25.024
And then finally, if
you haven't already,

00:29:25.024 --> 00:29:26.440
I definitely
encourage you to look

00:29:26.440 --> 00:29:29.620
at things like Nav Timing, User
Timing, and Resource Timing.

00:29:29.620 --> 00:29:31.680
So I talked about
Resource Timing.

00:29:31.680 --> 00:29:35.230
User Timing allows you to
measure any chunk of code

00:29:35.230 --> 00:29:40.290
and just get high-resolution
time stamps for this

00:29:40.290 --> 00:29:43.030
is when I started, this is when
I ended, and beacon that back

00:29:43.030 --> 00:29:43.772
to your server.

00:29:43.772 --> 00:29:45.730
So all of these things
are supported in Chrome.

00:29:45.730 --> 00:29:50.620
And what you can measure,
you can optimize.

00:29:50.620 --> 00:29:56.170
So with that, I'll leave
you the link to the slides.

00:29:56.170 --> 00:29:57.780
Thank you.

