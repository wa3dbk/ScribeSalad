WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.420
[GOOGLE LOGO MUSIC]

00:00:03.390 --> 00:00:05.910
AMIT SOOD: I hope I
can get your attention

00:00:05.910 --> 00:00:08.710
at 6:30 PM this
evening for a talk

00:00:08.710 --> 00:00:11.610
that I hope will inspire,
entertain, and just

00:00:11.610 --> 00:00:13.293
be chaotic in general.

00:00:13.293 --> 00:00:15.210
We are going to try and
do quite a few things.

00:00:15.210 --> 00:00:17.097
We have a short amount of time.

00:00:17.097 --> 00:00:18.930
But, essentially, we're
going to talk to you

00:00:18.930 --> 00:00:22.560
about what Google is doing when
it comes to arts and culture.

00:00:22.560 --> 00:00:24.990
And for those of
you who know what

00:00:24.990 --> 00:00:27.237
Google Arts &amp; Culture is, great.

00:00:27.237 --> 00:00:29.820
For those of you who don't, I'm
going to keep it really short.

00:00:29.820 --> 00:00:30.990
My name is Amit Sood.

00:00:30.990 --> 00:00:34.260
I work in the London,
Paris offices of Google.

00:00:34.260 --> 00:00:37.610
And I'm joined on stage here
with my colleague Damien Henry.

00:00:37.610 --> 00:00:41.185
Damien is our head off our
experiments team based in Paris

00:00:41.185 --> 00:00:42.810
and responsible for
a lot of the things

00:00:42.810 --> 00:00:44.230
that I'm going to show you.

00:00:44.230 --> 00:00:46.530
And so if you don't like
something or like something,

00:00:46.530 --> 00:00:47.640
talk to Damien.

00:00:47.640 --> 00:00:50.040
I'm going to escape really
fast after the session.

00:00:50.040 --> 00:00:55.680
But being very brief, Google
Arts &amp; Culture started in 2011.

00:00:55.680 --> 00:00:58.320
And it's a non-profit
non-commercial division

00:00:58.320 --> 00:01:00.600
within the company that
essentially focuses

00:01:00.600 --> 00:01:03.510
on making arts and
all types of culture

00:01:03.510 --> 00:01:05.650
more accessible
using technology.

00:01:05.650 --> 00:01:09.600
So we've been working with
museums, foundations, archives,

00:01:09.600 --> 00:01:11.970
and artists for
now over 10 years,

00:01:11.970 --> 00:01:14.130
and essentially trying
to get more culture out

00:01:14.130 --> 00:01:16.997
there for everyone to
enjoy in different ways.

00:01:16.997 --> 00:01:19.080
And so today, I'm not going
to talk to you so much

00:01:19.080 --> 00:01:22.530
about what we do at Google
Arts &amp; Culture in the core.

00:01:22.530 --> 00:01:25.860
I'm going to talk to you what we
do with experiments, because we

00:01:25.860 --> 00:01:28.650
want to try and show
you a few cool ideas.

00:01:28.650 --> 00:01:32.040
So before I do that, I think
we're going to try and show you

00:01:32.040 --> 00:01:35.310
a short video that talks about
the main platform, which,

00:01:35.310 --> 00:01:36.840
by the way, you
can all download--

00:01:36.840 --> 00:01:38.610
it's just called
Google Arts &amp; Culture--

00:01:38.610 --> 00:01:42.480
that has now over 6 million
artifacts, artworks,

00:01:42.480 --> 00:01:45.240
and over tens of thousands
of curated exhibitions

00:01:45.240 --> 00:01:46.693
from museums around the world.

00:01:46.693 --> 00:01:49.110
So it's a short video to tell
you what you can do with it.

00:01:52.498 --> 00:01:54.918
[VIDEO PLAYBACK]

00:01:54.918 --> 00:01:57.338
[UPBEAT MUSIC]

00:02:50.766 --> 00:02:51.850
[END PLAYBACK]

00:02:51.850 --> 00:02:53.567
So that's our main job.

00:02:53.567 --> 00:02:55.150
We're not going to
talk about it much.

00:02:55.150 --> 00:02:57.190
We encourage you all
to enjoy the app,

00:02:57.190 --> 00:02:59.410
and essentially have
all the world's museums

00:02:59.410 --> 00:03:01.960
and cultural topics
easily accessible.

00:03:01.960 --> 00:03:03.610
What we want to talk
to you about today

00:03:03.610 --> 00:03:06.880
are a few of our recent
activities in the field of arts

00:03:06.880 --> 00:03:07.970
and culture.

00:03:07.970 --> 00:03:12.230
And this is going to go quite
fast, so try and stay up.

00:03:12.230 --> 00:03:15.230
But if you can find structure,
don't worry about it.

00:03:15.230 --> 00:03:17.462
It's just a bunch of
really important cool stuff

00:03:17.462 --> 00:03:18.670
that we're going to show you.

00:03:18.670 --> 00:03:21.560
So preserving cultural heritage.

00:03:21.560 --> 00:03:24.220
I think we decided to put this
at the start of the session

00:03:24.220 --> 00:03:27.310
given some of you might know
about the recent tragedies that

00:03:27.310 --> 00:03:31.240
have unfolded when
it comes to monuments

00:03:31.240 --> 00:03:34.635
and amazing, amazing
cultural landmarks.

00:03:34.635 --> 00:03:36.010
I'm not going to
name them, but I

00:03:36.010 --> 00:03:38.110
think we all are aware
of what's been going on.

00:03:38.110 --> 00:03:41.500
And so we've been working with a
partner called CyArk based here

00:03:41.500 --> 00:03:42.700
in San Francisco.

00:03:42.700 --> 00:03:45.640
CyArk has been one of
the leaders in capturing

00:03:45.640 --> 00:03:48.250
and preserving cultural
landmarks using

00:03:48.250 --> 00:03:51.200
cutting-edge drone technology
and photogrammetry.

00:03:51.200 --> 00:03:54.850
And this is, by the way, called
the Open Heritage Project.

00:03:54.850 --> 00:03:56.320
There's a lot of content here.

00:03:56.320 --> 00:03:58.995
More than enough for you
to spend a couple of weeks,

00:03:58.995 --> 00:04:01.120
so I don't have time to
take you through all of it.

00:04:01.120 --> 00:04:03.550
But the idea is to tell
stories about preservation.

00:04:03.550 --> 00:04:05.230
Why preservation is important.

00:04:05.230 --> 00:04:08.950
But to also make it easy
for developers and anyone

00:04:08.950 --> 00:04:10.990
interested in the
raw data of what

00:04:10.990 --> 00:04:14.870
it means to capture a cultural
landmark to experience it.

00:04:14.870 --> 00:04:18.430
So we're going to try and show
you one story of the Mexico

00:04:18.430 --> 00:04:19.425
City cathedral.

00:04:19.425 --> 00:04:20.800
I don't know how
many of you know

00:04:20.800 --> 00:04:22.270
about this amazing building.

00:04:22.270 --> 00:04:24.260
But after the
earthquake in Mexico,

00:04:24.260 --> 00:04:27.400
the Mexico government
invited CyArk, our partner,

00:04:27.400 --> 00:04:30.310
to come and preserve this,
so that in case anything

00:04:30.310 --> 00:04:34.030
ever happens, there is a
high-density point cloud

00:04:34.030 --> 00:04:37.180
photogrammetric model that
can be used for preservation

00:04:37.180 --> 00:04:38.380
and restoration.

00:04:38.380 --> 00:04:39.670
So this is a great story.

00:04:39.670 --> 00:04:40.840
You can enjoy it.

00:04:40.840 --> 00:04:44.380
But what's exciting
is models like these.

00:04:44.380 --> 00:04:48.760
And we have over 50
of them now have--

00:04:48.760 --> 00:04:50.360
it's going to load in a second.

00:04:50.360 --> 00:04:53.080
This is all live, by the way,
so we're taking a few risks.

00:04:53.080 --> 00:04:55.360
But hopefully, it will
be coming on soon.

00:04:55.360 --> 00:04:56.050
That's it.

00:04:56.050 --> 00:04:58.600
So that, by the
way, is the altar

00:04:58.600 --> 00:05:01.090
in the cathedral that
has been captured

00:05:01.090 --> 00:05:04.300
using drones that have
essentially allowed you to get

00:05:04.300 --> 00:05:09.130
very high-density information
on the entire structural nature

00:05:09.130 --> 00:05:10.570
of this altarpiece.

00:05:10.570 --> 00:05:12.310
And if you want to
really understand

00:05:12.310 --> 00:05:14.780
your perspective and the
view that you're getting,

00:05:14.780 --> 00:05:17.800
I'm just going to ask Damien
to tilt down so that you

00:05:17.800 --> 00:05:21.660
can see where you actually are.

00:05:21.660 --> 00:05:25.510
This is a possibility now with
the kind of digitization tools,

00:05:25.510 --> 00:05:26.965
the kind of work
our partners are

00:05:26.965 --> 00:05:30.370
doing that helps preserve
but also storytell

00:05:30.370 --> 00:05:31.930
about these amazing landmarks.

00:05:31.930 --> 00:05:35.090
We also have, for example,
one of my favorites,

00:05:35.090 --> 00:05:36.805
which is the Thomas
Jefferson Memorial.

00:05:36.805 --> 00:05:40.630
If Damien just goes
back to the homepage,

00:05:40.630 --> 00:05:43.780
I'll be able to very
quickly, as you go down here,

00:05:43.780 --> 00:05:45.010
you will see cities.

00:05:45.010 --> 00:05:46.960
You will see the
temples of Bagan.

00:05:46.960 --> 00:05:49.990
And you will also see
what I've been finding

00:05:49.990 --> 00:05:54.250
fascinating is the
fly-through of the Jefferson

00:05:54.250 --> 00:05:56.740
Memorial, which has been
now preserved, again,

00:05:56.740 --> 00:05:58.070
thanks to CyArk.

00:05:58.070 --> 00:06:00.280
So this is an example
of preservation.

00:06:00.280 --> 00:06:02.110
We have a few others
on the platform

00:06:02.110 --> 00:06:03.330
that you can experience.

00:06:03.330 --> 00:06:04.870
Damien can just fly
through, and you

00:06:04.870 --> 00:06:08.170
can start exploring this
monument like never before.

00:06:08.170 --> 00:06:09.670
Here's the main
news why we wanted

00:06:09.670 --> 00:06:12.820
to talk about this at
I/O, because CyArk has now

00:06:12.820 --> 00:06:17.890
agreed to opensource all this
data for anybody to download.

00:06:17.890 --> 00:06:20.740
And so, essentially, you just
have to go to the platform,

00:06:20.740 --> 00:06:22.990
apply, and you can
get the raw data

00:06:22.990 --> 00:06:25.270
and start manipulating
it, playing with it.

00:06:25.270 --> 00:06:27.250
We're already seeing
examples of developers

00:06:27.250 --> 00:06:28.750
around the world
who are actually

00:06:28.750 --> 00:06:32.420
finding new insights thanks
to these type of initiatives.

00:06:32.420 --> 00:06:35.950
So moving out of
preservation and moving

00:06:35.950 --> 00:06:39.760
into another area, which is
basically talking about what

00:06:39.760 --> 00:06:41.710
we do with institutions.

00:06:41.710 --> 00:06:43.360
And we wanted to
take two examples

00:06:43.360 --> 00:06:46.720
that we launched very recently,
just a couple of months ago.

00:06:46.720 --> 00:06:50.660
And how many of you
know who Vermeer is?

00:06:50.660 --> 00:06:51.160
OK.

00:06:51.160 --> 00:06:51.820
Not bad.

00:06:51.820 --> 00:06:53.800
Well, he was a great artist.

00:06:53.800 --> 00:06:55.810
Take it for granted, he was.

00:06:55.810 --> 00:06:58.090
And you can google it
later to verify it.

00:06:58.090 --> 00:07:02.830
But he was also an artist
whose works were very limited--

00:07:02.830 --> 00:07:05.840
only 36, I think-- and they're
spread all across the world.

00:07:05.840 --> 00:07:08.500
So there isn't
one Vermeer museum

00:07:08.500 --> 00:07:11.410
that you can go and experience
these amazing works.

00:07:11.410 --> 00:07:13.540
And you have CERN.

00:07:13.540 --> 00:07:16.150
I hope you all
know what CERN is.

00:07:16.150 --> 00:07:19.230
Hands up if you don't
know what CERN is?

00:07:19.230 --> 00:07:20.650
OK, everyone knows what CERN is.

00:07:20.650 --> 00:07:21.220
Great.

00:07:21.220 --> 00:07:23.960
So what do these two
places have in common?

00:07:23.960 --> 00:07:25.750
Both of them deal
with the problem

00:07:25.750 --> 00:07:29.050
of recreating an experience
in the physical world that's

00:07:29.050 --> 00:07:30.050
just not possible.

00:07:30.050 --> 00:07:32.410
So you can't go to
sun to experience

00:07:32.410 --> 00:07:33.940
the Big Bang for now.

00:07:33.940 --> 00:07:36.040
You can't go to
a Vermeer museum.

00:07:36.040 --> 00:07:38.380
And so here comes in
augmented reality.

00:07:38.380 --> 00:07:40.630
And we're going to show you
two experiments that we've

00:07:40.630 --> 00:07:43.835
launched live that
hopefully will work,

00:07:43.835 --> 00:07:45.710
because they're going
to do it live on stage.

00:07:45.710 --> 00:07:48.650
And these are public, so
you can download it as well.

00:07:48.650 --> 00:07:51.318
So the first one we're
going to try and show you.

00:07:51.318 --> 00:07:52.860
So, by the way, this
is the platform,

00:07:52.860 --> 00:07:54.360
the Google Arts &amp;
Culture platform--

00:07:54.360 --> 00:07:56.700
and I'm going to try
and go a little fast--

00:07:56.700 --> 00:08:00.750
which has daily amazing stories
from Van Gogh's, and a lot

00:08:00.750 --> 00:08:01.690
of other crazy stuff.

00:08:01.690 --> 00:08:03.690
I don't know if you know
what the art selfie is.

00:08:03.690 --> 00:08:04.570
Try it out.

00:08:04.570 --> 00:08:07.680
Over 100 million selfies have
been taken using this feature.

00:08:07.680 --> 00:08:09.260
But here's Meet Vermeer.

00:08:09.260 --> 00:08:12.840
So in partnership with
some amazing museums led

00:08:12.840 --> 00:08:15.000
by the Mauritshuis
in the Netherlands,

00:08:15.000 --> 00:08:17.840
and involving some other
great institutions,

00:08:17.840 --> 00:08:20.070
we brought all the
Vermeer pieces together

00:08:20.070 --> 00:08:22.380
on one platform in
high resolution.

00:08:22.380 --> 00:08:24.105
But then the challenge
was, that's great,

00:08:24.105 --> 00:08:26.730
but what if you actually wanted
to give the impression that you

00:08:26.730 --> 00:08:29.410
were walking through a
physical Vermeer museum?

00:08:29.410 --> 00:08:32.100
So we tried to experiment--
and this is an experiment.

00:08:32.100 --> 00:08:34.470
We launched the complete
works in augmented reality,

00:08:34.470 --> 00:08:36.960
and I'm going to
try and demo it now.

00:08:36.960 --> 00:08:42.110
And hopefully, it will
not be a disaster.

00:08:42.110 --> 00:08:44.680
So let me try and
find my surface.

00:08:44.680 --> 00:08:47.050
And we're just waiting
for the model to load.

00:08:47.050 --> 00:08:48.400
So great.

00:08:48.400 --> 00:08:51.130
So that's the Vermeer
museum, which can't actually

00:08:51.130 --> 00:08:53.350
exist in the physical world.

00:08:53.350 --> 00:08:55.360
And you can check out the model.

00:08:55.360 --> 00:08:56.710
You can pinch on it.

00:08:56.710 --> 00:08:58.780
And then you can
jump right into it.

00:08:58.780 --> 00:09:01.420
And this is now a Vermeer
museum in your house

00:09:01.420 --> 00:09:04.030
that you can walk up to the
"Girl with the Pearl Earring,"

00:09:04.030 --> 00:09:05.770
one of the most
iconic paintings.

00:09:05.770 --> 00:09:08.200
And you can get to
brushstroke-level details.

00:09:08.200 --> 00:09:09.490
You can move around.

00:09:09.490 --> 00:09:11.290
And as you walk
around, you can start

00:09:11.290 --> 00:09:13.030
discovering different rooms.

00:09:13.030 --> 00:09:15.250
You can start walking
through other galleries,

00:09:15.250 --> 00:09:18.730
other sections, and
essentially be in a-- oh.

00:09:18.730 --> 00:09:21.100
That was a bit too ambitious.

00:09:21.100 --> 00:09:23.380
But essentially,
back to reality.

00:09:23.380 --> 00:09:25.640
Now back to augmented reality.

00:09:25.640 --> 00:09:28.570
And as you can
see, you can start

00:09:28.570 --> 00:09:32.260
going to every single work
of his in high resolution,

00:09:32.260 --> 00:09:34.310
and start walking in
front of the paintings.

00:09:34.310 --> 00:09:38.890
So this is an idea how physical
galleries that can be created

00:09:38.890 --> 00:09:41.275
can be done through
augmented reality.

00:09:41.275 --> 00:09:43.150
I hope you enjoyed, and
you can play with it.

00:09:43.150 --> 00:09:44.567
By the way, you
can spend a couple

00:09:44.567 --> 00:09:46.120
of hours in that gallery.

00:09:46.120 --> 00:09:48.790
The next example I'm
going to show you

00:09:48.790 --> 00:09:51.220
is actually about a project
we launched a few months ago

00:09:51.220 --> 00:09:53.360
called Once Upon a Try.

00:09:53.360 --> 00:09:57.340
115 scientific institutions
bought on the same platform

00:09:57.340 --> 00:09:59.680
telling stories
about inventions.

00:09:59.680 --> 00:10:04.630
Amazing, great fun, but
no time to show it to you.

00:10:04.630 --> 00:10:08.260
But I'm going to show you one
component of that initiative.

00:10:08.260 --> 00:10:13.090
And this was about how do we
get people to enjoy, and also

00:10:13.090 --> 00:10:15.010
learn about the Big Bang.

00:10:15.010 --> 00:10:17.950
Something we all know, the
word, but we don't take the time

00:10:17.950 --> 00:10:19.700
to actually delve into it.

00:10:19.700 --> 00:10:24.280
And so this is app created with
CERN and published under CERN.

00:10:24.280 --> 00:10:26.890
And you can download it on
any of your different stores.

00:10:29.267 --> 00:10:30.850
I'm going to go back
to the beginning.

00:10:30.850 --> 00:10:31.517
[VIDEO PLAYBACK]

00:10:31.517 --> 00:10:35.000
- You're about to
experience the Big Bang--

00:10:35.000 --> 00:10:37.890
the moment a tiny speck
packed with energy

00:10:37.890 --> 00:10:42.870
suddenly expanded, giving
birth to space and time.

00:10:46.740 --> 00:10:50.160
To see the universe form,
stretch out your hand

00:10:50.160 --> 00:10:52.440
palm-up in front of your camera.

00:10:56.550 --> 00:10:57.310
Make a fist.

00:11:01.160 --> 00:11:02.120
Open your hand.

00:11:07.980 --> 00:11:10.170
Just a billionth of
a second has passed,

00:11:10.170 --> 00:11:12.210
and it's blisteringly hot--

00:11:12.210 --> 00:11:14.595
around 10 million
billion degrees.

00:11:18.828 --> 00:11:22.260
The energy of the Big
Bang has transformed

00:11:22.260 --> 00:11:26.670
into a thick soup of quarks,
electrons, neutrinos,

00:11:26.670 --> 00:11:28.003
and photons.

00:11:28.003 --> 00:11:28.920
Quarks and electrons--

00:11:28.920 --> 00:11:30.080
[PLAYBACK ENDS]

00:11:30.080 --> 00:11:31.720
AMIT SOOD: So I have to pause
because I don't have time

00:11:31.720 --> 00:11:33.095
to show you the
whole experience,

00:11:33.095 --> 00:11:36.040
but that's a 10-minute
augmented reality storytelling

00:11:36.040 --> 00:11:37.870
by Tilda Swinton
that really gets

00:11:37.870 --> 00:11:39.490
you to understand the Big Bang.

00:11:39.490 --> 00:11:43.960
And of course, if you are keen
on continuing the selfie trend

00:11:43.960 --> 00:11:47.480
and want to take something
called the star selfie to share

00:11:47.480 --> 00:11:48.370
with your friends.

00:11:48.370 --> 00:11:50.110
You can actually
start doing that.

00:11:50.110 --> 00:11:53.050
And now, I am a star selfie.

00:11:53.050 --> 00:11:55.120
So you get the idea with
what we're trying to do.

00:11:55.120 --> 00:11:58.700
Educate, but also create
something playful and fun.

00:11:58.700 --> 00:12:00.610
So I'm going to move
on now very quickly

00:12:00.610 --> 00:12:02.710
to another section which
we may have to skip,

00:12:02.710 --> 00:12:04.360
because I'm running out of time.

00:12:04.360 --> 00:12:08.120
But, essentially, what do
NASA and MoMA have in common?

00:12:08.120 --> 00:12:11.170
They both are amazing
abbreviations, I think.

00:12:11.170 --> 00:12:13.210
But they're also
great institutions.

00:12:13.210 --> 00:12:15.370
And what they have
in common is they

00:12:15.370 --> 00:12:18.370
both have used machine learning
in a very interesting way

00:12:18.370 --> 00:12:20.030
to essentially solve a problem.

00:12:20.030 --> 00:12:22.030
And I think we don't have
time to show you both,

00:12:22.030 --> 00:12:25.120
but maybe we'll show you the
NASA experiment very quickly.

00:12:25.120 --> 00:12:27.010
So NASA has a public
API that they've

00:12:27.010 --> 00:12:30.730
made public, which has
around 300,000 images or more

00:12:30.730 --> 00:12:33.160
of all the photographs
of missions

00:12:33.160 --> 00:12:36.310
and many other topics
that NASA has made public.

00:12:36.310 --> 00:12:39.700
But one of the challenges is
how to make sense of it all.

00:12:39.700 --> 00:12:42.770
How to make sense of such
a large visual archive.

00:12:42.770 --> 00:12:44.950
And so we created this
storytelling project

00:12:44.950 --> 00:12:46.870
that essentially
allows you to navigate

00:12:46.870 --> 00:12:49.090
through every single
mission photograph

00:12:49.090 --> 00:12:53.290
that NASA has ever released in a
storytelling way using clusters

00:12:53.290 --> 00:12:55.390
that have been tagged
using machine learning.

00:12:55.390 --> 00:12:58.200
And, essentially, these are
tags that allow you to navigate.

00:12:58.200 --> 00:13:00.070
So rather than navigating
through the image,

00:13:00.070 --> 00:13:02.000
you're navigating
through these clusters.

00:13:02.000 --> 00:13:04.318
So there are hundreds of
thousands of these clusters.

00:13:04.318 --> 00:13:06.110
I don't have time to
take you through them.

00:13:06.110 --> 00:13:08.930
But let's just
search for the Moon.

00:13:08.930 --> 00:13:10.473
And when you search
for the Moon,

00:13:10.473 --> 00:13:12.890
obviously, there are going to
be a large amount of images.

00:13:12.890 --> 00:13:17.200
But what we wanted to do was
create a simple way for you

00:13:17.200 --> 00:13:20.740
to enjoy each image and
the accompanying story.

00:13:20.740 --> 00:13:23.440
So this is a very
simple, lean back,

00:13:23.440 --> 00:13:25.480
you just have to sit
down, and the story

00:13:25.480 --> 00:13:29.410
will come on the right side
on what each image has--

00:13:29.410 --> 00:13:30.880
what role it has played.

00:13:30.880 --> 00:13:32.563
And of course, if
you want to just see

00:13:32.563 --> 00:13:34.480
all the images in a
visually stunning way that

00:13:34.480 --> 00:13:38.470
has been categorized, you
just click on the visual view,

00:13:38.470 --> 00:13:42.370
and then you have a beautiful,
beautiful, essentially, view

00:13:42.370 --> 00:13:44.030
of all these images.

00:13:44.030 --> 00:13:46.480
You can also find some
very strange words

00:13:46.480 --> 00:13:49.330
that you would wonder why
they are in the NASA API.

00:13:49.330 --> 00:13:52.450
But one of the words that
we found was lettuce.

00:13:52.450 --> 00:13:52.950
Lettuce.

00:13:52.950 --> 00:13:54.850
For all the
vegetarians out there,

00:13:54.850 --> 00:13:56.590
it's a very important thing.

00:13:56.590 --> 00:13:58.450
I eat a lot of lettuce.

00:13:58.450 --> 00:13:59.770
And we found lettuce.

00:13:59.770 --> 00:14:02.620
And essentially, we were
wondering, why has lettuce

00:14:02.620 --> 00:14:03.730
turned up in this archive?

00:14:03.730 --> 00:14:06.910
And it's because it's about
astronauts trying to grow,

00:14:06.910 --> 00:14:09.220
essentially, lettuce in space.

00:14:09.220 --> 00:14:12.190
And so you learn more about the
archive through, essentially,

00:14:12.190 --> 00:14:15.890
tags, and through, essentially,
understanding of these words.

00:14:15.890 --> 00:14:20.000
So you can spend a year
enjoying this experiment.

00:14:20.000 --> 00:14:21.850
So we're going to
move on very quickly

00:14:21.850 --> 00:14:25.390
and go to the next section,
which is to talk about--

00:14:25.390 --> 00:14:28.007
I've taken you through what
we do with institutions.

00:14:28.007 --> 00:14:30.340
I've taken you through what
we can do with a large photo

00:14:30.340 --> 00:14:31.632
archive using machine learning.

00:14:31.632 --> 00:14:33.298
And now I want to
talk to you about what

00:14:33.298 --> 00:14:35.650
we're doing with artists,
with certain collaborations

00:14:35.650 --> 00:14:36.700
that we've done.

00:14:36.700 --> 00:14:39.990
We have some that
we're launching today.

00:14:39.990 --> 00:14:41.440
That's in the next section.

00:14:41.440 --> 00:14:43.510
These are two examples
of things that

00:14:43.510 --> 00:14:46.552
are going to be actually
coming to you very soon

00:14:46.552 --> 00:14:48.010
and are in development,
but we want

00:14:48.010 --> 00:14:50.390
to show you both the examples.

00:14:50.390 --> 00:14:52.420
So the first one we're
going to show you

00:14:52.420 --> 00:14:56.020
is with an amazing artist
called Wayne McGregor.

00:14:56.020 --> 00:14:58.480
Wayne McGregor is
the current resident

00:14:58.480 --> 00:15:01.043
at the Royal Ballet in London.

00:15:01.043 --> 00:15:02.710
But he's also one of
the individuals who

00:15:02.710 --> 00:15:05.170
was responsible for
designing Harry Potter's

00:15:05.170 --> 00:15:08.230
movements in the movies,
and he has done a lot more.

00:15:08.230 --> 00:15:09.670
So google Wayne McGregor.

00:15:09.670 --> 00:15:11.410
And we worked with
Wayne McGregor

00:15:11.410 --> 00:15:13.690
to really tell a story
using machine learning,

00:15:13.690 --> 00:15:17.590
how machine learning can
inform his art, rather than

00:15:17.590 --> 00:15:18.500
the other way around.

00:15:18.500 --> 00:15:21.084
So let's watch this
very short video.

00:15:21.084 --> 00:15:23.519
[VIDEO PLAYBACK]

00:15:24.980 --> 00:15:27.415
[ATMOSPHERIC MUSIC]

00:15:33.605 --> 00:15:35.980
- One of the things that's
run through all of my practice

00:15:35.980 --> 00:15:39.470
has been a relationship
with technology.

00:15:39.470 --> 00:15:41.440
- So, when we started
working with Wayne,

00:15:41.440 --> 00:15:44.830
we were really interested
about movement prediction.

00:15:44.830 --> 00:15:47.590
We found a research
paper which [INAUDIBLE]

00:15:47.590 --> 00:15:49.540
and writing prediction.

00:15:49.540 --> 00:15:51.880
And we think, what
if we use that

00:15:51.880 --> 00:15:56.160
for predicting dance movement?

00:15:56.160 --> 00:16:01.250
We use the archive from
Wayne to train the algorithm

00:16:01.250 --> 00:16:04.840
so they can use these
data to generate movement.

00:16:09.010 --> 00:16:10.510
- When I'm with my
dancers normally,

00:16:10.510 --> 00:16:12.940
what I'm asking them to do
through their own creativity

00:16:12.940 --> 00:16:14.740
is make iterative
versions of an idea

00:16:14.740 --> 00:16:16.030
that I might have proposed.

00:16:16.030 --> 00:16:18.730
What this tool does
for each little moment

00:16:18.730 --> 00:16:21.790
is do 400,000
iterations of that.

00:16:21.790 --> 00:16:24.160
Yes, so the canvas
is way, way bigger.

00:16:24.160 --> 00:16:26.020
We had to gift the archive.

00:16:26.020 --> 00:16:28.960
And it was a huge archive--
thousands of hours of video

00:16:28.960 --> 00:16:29.920
to be analyzed.

00:16:29.920 --> 00:16:31.910
What this tool allows
us to do is go,

00:16:31.910 --> 00:16:34.520
OK, I'm starting
with this phrase.

00:16:34.520 --> 00:16:36.670
I would like the machine
learning tool, the AI

00:16:36.670 --> 00:16:41.560
to invent the next phrase,
but in the style of Jordan,

00:16:41.560 --> 00:16:43.840
or in the style of Jess.

00:16:43.840 --> 00:16:45.632
And then you can get
combinations of those.

00:16:45.632 --> 00:16:47.840
And then it's learning all
the time and feeding back.

00:16:47.840 --> 00:16:49.990
And so this iterative
version gives you

00:16:49.990 --> 00:16:52.872
all of these new possibilities
you couldn't have imagined.

00:16:52.872 --> 00:16:53.455
[END PLAYBACK]

00:16:53.455 --> 00:16:55.790
AMIT SOOD: So I hope
you are seeing a trend

00:16:55.790 --> 00:16:57.590
in this chaotic
presentation, which

00:16:57.590 --> 00:17:01.040
is that I'm trying to show you a
lot of different cultural ideas

00:17:01.040 --> 00:17:03.430
that can all benefit from
some of the technologies

00:17:03.430 --> 00:17:05.480
that we all have been
talking about here at I/O,

00:17:05.480 --> 00:17:06.633
and that was dance.

00:17:06.633 --> 00:17:09.050
And I'm going to show you a
very short clip, because we've

00:17:09.050 --> 00:17:11.720
got to screen the actual
movie a little later,

00:17:11.720 --> 00:17:15.200
but this was a collaboration
with an artist called Jenna

00:17:15.200 --> 00:17:18.069
Sutela, and the movie will be
screened by Kenric and Damien

00:17:18.069 --> 00:17:18.569
later.

00:17:18.569 --> 00:17:21.109
So this is just a teaser
of the behind the scenes.

00:17:21.109 --> 00:17:23.210
And this is really
something very opposite

00:17:23.210 --> 00:17:24.319
from the dance example.

00:17:24.319 --> 00:17:25.291
[VIDEO PLAYBACK]

00:17:25.291 --> 00:17:27.721
[WARPED VOICES]

00:17:32.170 --> 00:17:36.710
- "nimiia cÃ©tii" is an
audiovisual artwork based

00:17:36.710 --> 00:17:41.060
on machine learning,
teaching the machine to speak

00:17:41.060 --> 00:17:42.890
in tongues.

00:17:42.890 --> 00:17:45.770
So my name is
Jenna Sutela, and I

00:17:45.770 --> 00:17:49.250
work a lot with words,
sounds, and living materials,

00:17:49.250 --> 00:17:53.720
exploring biological and
computational systems.

00:17:53.720 --> 00:17:55.850
I'm working with
machine learning

00:17:55.850 --> 00:18:00.920
to generate a certain type of
glosso poetry based on Martian

00:18:00.920 --> 00:18:08.030
language by the French medium
Helene Smith in the late 1800s,

00:18:08.030 --> 00:18:11.070
and the movement of
Bacillus subtilis,

00:18:11.070 --> 00:18:13.700
or the nocto bacterium
that are also

00:18:13.700 --> 00:18:17.450
known as a test species in
spaceflight experimentation.

00:18:17.450 --> 00:18:22.670
Together, the bacteria as well
as these early Martian scripts,

00:18:22.670 --> 00:18:24.410
together with the
computer shaman,

00:18:24.410 --> 00:18:27.230
will create a new
language altogether.

00:18:27.230 --> 00:18:28.482
And the end result will be--

00:18:28.482 --> 00:18:29.065
[END PLAYBACK]

00:18:29.065 --> 00:18:30.860
AMIT SOOD: So I'm
going to end over there

00:18:30.860 --> 00:18:32.870
because I see you
all so entranced.

00:18:32.870 --> 00:18:35.130
The movie screens
after this session.

00:18:35.130 --> 00:18:38.330
So just remember the key
words, "a computer shaman."

00:18:38.330 --> 00:18:39.860
That's what she said, not me.

00:18:39.860 --> 00:18:45.170
So moving on very quickly now
to, what do we have new at I/O?

00:18:45.170 --> 00:18:48.170
Well, we have an
exciting next section.

00:18:48.170 --> 00:18:50.720
We're going to go a little fast
just so we get everything in.

00:18:50.720 --> 00:18:53.980
But I want to invite on stage--

00:18:53.980 --> 00:18:55.165
actually, no.

00:18:55.165 --> 00:18:56.540
Before I invite
on stage, we need

00:18:56.540 --> 00:19:00.220
to do one last demo that
Damien is going to do.

00:19:00.220 --> 00:19:03.480
We have launched today
an application developed

00:19:03.480 --> 00:19:07.065
with an artist called
Zach Lieberman and Molmol,

00:19:07.065 --> 00:19:09.390
a Brooklyn-based
artist collective.

00:19:09.390 --> 00:19:13.710
And they have been doing some
fascinating stuff on education,

00:19:13.710 --> 00:19:16.170
but also, when it comes
to augmented reality.

00:19:16.170 --> 00:19:19.530
So Zach came and did a residency
with us at the lab in Paris,

00:19:19.530 --> 00:19:21.150
and essentially
developed this app.

00:19:21.150 --> 00:19:22.890
And this app launched
this morning.

00:19:22.890 --> 00:19:24.450
It's available on
the Play Store,

00:19:24.450 --> 00:19:26.340
so please go download
it, play with it.

00:19:26.340 --> 00:19:28.240
It's quite crazy,
and it's out there.

00:19:28.240 --> 00:19:29.910
So what we're going
to do is perhaps

00:19:29.910 --> 00:19:32.790
show the video very
quickly, and then

00:19:32.790 --> 00:19:36.580
maybe try and demo the app live.

00:19:36.580 --> 00:19:37.450
[VIDEO PLAYBACK]

00:19:37.450 --> 00:19:38.950
- My name is Molmol.

00:19:38.950 --> 00:19:42.500
I am a artist, an
educator, and a researcher.

00:19:42.500 --> 00:19:44.730
And we have a studio together.

00:19:44.730 --> 00:19:46.300
- And my name is Zach Lieberman.

00:19:46.300 --> 00:19:48.280
I'm also an artist, an educator.

00:19:48.280 --> 00:19:51.680
And we're interested
in using technology

00:19:51.680 --> 00:19:55.360
that is code and electronics,
but to create artistic work.

00:19:55.360 --> 00:19:58.750
We're doing a residency here at
the Google Arts + Culture Lab.

00:19:58.750 --> 00:20:00.880
Our goal was to
create an app that

00:20:00.880 --> 00:20:03.820
allows you to capture
elements in the world,

00:20:03.820 --> 00:20:06.070
and then paint
with them in space.

00:20:06.070 --> 00:20:11.553
- We create a lot of interactive
installation that requires--

00:20:11.553 --> 00:20:12.136
[END PLAYBACK]

00:20:12.136 --> 00:20:15.500
AMIT SOOD: So now let's
show you the actual app.

00:20:15.500 --> 00:20:18.860
Damien is going to try
and demo it very quickly.

00:20:18.860 --> 00:20:20.350
So this is called Weird Cuts.

00:20:24.210 --> 00:20:26.745
He's essentially cutting
a bunch of weird things.

00:20:26.745 --> 00:20:27.870
Not that you all are weird.

00:20:27.870 --> 00:20:30.580
Well, I am.

00:20:30.580 --> 00:20:31.240
Perfect timing.

00:20:37.290 --> 00:20:40.370
And the idea is you
use these cuts--

00:20:40.370 --> 00:20:41.800
well, you don't do that.

00:20:41.800 --> 00:20:48.200
But we use these cuts to
create, essentially, art in AR.

00:20:48.200 --> 00:20:51.680
And that's the I/O logo there
done by Damien in a record 20

00:20:51.680 --> 00:20:52.711
seconds, so.

00:20:52.711 --> 00:20:55.540
[APPLAUSE]

00:20:55.540 --> 00:20:59.460
So download Weird Cats by
Zach Lieberman and Molmol.

00:20:59.460 --> 00:21:00.960
It's a lot of fun, trust me.

00:21:00.960 --> 00:21:04.380
Especially if you have kids,
it can be absolutely addictive.

00:21:04.380 --> 00:21:07.740
So moving on very
quickly to my next guest

00:21:07.740 --> 00:21:10.680
and the next experiment that
we want to launch today here

00:21:10.680 --> 00:21:12.390
at Google I/O, is
I want to welcome

00:21:12.390 --> 00:21:16.560
on stage the lovely Pinar,
who has flown in from Europe

00:21:16.560 --> 00:21:17.650
to join us.

00:21:17.650 --> 00:21:19.350
And we're going
to talk about what

00:21:19.350 --> 00:21:20.610
we've been doing with Pinar.

00:21:20.610 --> 00:21:21.110
Pinar.

00:21:21.110 --> 00:21:21.887
[APPLAUSE]

00:21:21.887 --> 00:21:22.970
PINAR DEMIRDAG: Thank you.

00:21:25.970 --> 00:21:32.080
AMIT SOOD: So rather than
me introducing who Pinar is,

00:21:32.080 --> 00:21:35.080
I'm going to let Pinar tell
you why she's at Google I/O,

00:21:35.080 --> 00:21:36.565
and what does she do?

00:21:36.565 --> 00:21:38.710
PINAR: Thank you.

00:21:38.710 --> 00:21:39.830
So I'm Pinar.

00:21:39.830 --> 00:21:40.960
I'm an artist.

00:21:40.960 --> 00:21:43.330
And, together with my
work partner, Viola,

00:21:43.330 --> 00:21:46.450
we have a studio together.

00:21:46.450 --> 00:21:51.580
Our main mission as creators is
to contribute to the progress

00:21:51.580 --> 00:21:54.460
of social justice.

00:21:54.460 --> 00:21:59.080
And we do this by using the
power and charm of visuals.

00:21:59.080 --> 00:22:03.170
Normally, usually, even though
we partner with technology

00:22:03.170 --> 00:22:05.140
and fashion companies
to make their products

00:22:05.140 --> 00:22:07.720
relevant for the
contemporary, this

00:22:07.720 --> 00:22:10.360
is the first time we are
collaborating with machine

00:22:10.360 --> 00:22:13.412
intelligence thanks
to the residency we

00:22:13.412 --> 00:22:14.950
did with Google Arts + Culture.

00:22:14.950 --> 00:22:15.580
AMIT SOOD: Yes.

00:22:15.580 --> 00:22:18.120
So Pinar came to us in Paris--

00:22:18.120 --> 00:22:20.800
to Damien, actually--
and she wanted

00:22:20.800 --> 00:22:22.767
to understand what we are doing.

00:22:22.767 --> 00:22:24.100
We showed her what we are doing.

00:22:24.100 --> 00:22:26.183
And I don't know how many
of you know who Alex is.

00:22:26.183 --> 00:22:29.740
Alex works in a team
here run by Blaise,

00:22:29.740 --> 00:22:31.690
who's going to join me
on stage in a second.

00:22:31.690 --> 00:22:35.090
And Alex is also the founder
of the DeepDream sequence.

00:22:35.090 --> 00:22:37.400
So if you move to the
next slide very quickly,

00:22:37.400 --> 00:22:39.130
maybe we can see--
these are your works.

00:22:39.130 --> 00:22:40.540
PINAR DEMIRDAG: It's insane.

00:22:40.540 --> 00:22:44.110
It's like, you cannot understand
what I felt at that very

00:22:44.110 --> 00:22:45.400
moment.

00:22:45.400 --> 00:22:50.170
A year and a half ago, when
we met Damien in Paris,

00:22:50.170 --> 00:22:52.240
he showed us the
discoveries of Alex.

00:22:52.240 --> 00:22:56.320
That you see on the top
floor, these patterns

00:22:56.320 --> 00:23:01.210
are made by machine intelligence
by a complex but simple system

00:23:01.210 --> 00:23:04.540
that can extract images
from the way machine

00:23:04.540 --> 00:23:08.200
can do visualizations,
feature visualizations.

00:23:08.200 --> 00:23:10.570
And the images that
you see on the bottom

00:23:10.570 --> 00:23:16.240
is our 10-year body of work
as fashion pattern creators.

00:23:16.240 --> 00:23:16.965
So--

00:23:16.965 --> 00:23:19.710
AMIT SOOD: So it's way before
DeepDream ever came on,

00:23:19.710 --> 00:23:24.010
Pinar was somehow already
ahead of the game.

00:23:24.010 --> 00:23:27.460
And that's a reassuring,
that a human was already

00:23:27.460 --> 00:23:29.072
in this sequence.

00:23:29.072 --> 00:23:31.030
So shall we go-- show
the next slide, and shall

00:23:31.030 --> 00:23:35.140
we show the different types
of things that you discovered.

00:23:35.140 --> 00:23:36.670
PINAR DEMIRDAG:
So what we did is

00:23:36.670 --> 00:23:40.090
that we met with Alex,
obviously, the genius.

00:23:40.090 --> 00:23:42.280
And I'm not a coder.

00:23:42.280 --> 00:23:43.580
I don't know how to code.

00:23:43.580 --> 00:23:45.970
So Alex had to do
something very simple,

00:23:45.970 --> 00:23:50.890
like a tool that has only few
parameters, that you basically

00:23:50.890 --> 00:23:52.570
place an input as an image.

00:23:52.570 --> 00:23:56.110
The input is in the small image
that you see in the corner.

00:23:56.110 --> 00:23:59.620
And then, according to your
quote-unquote aesthetic

00:23:59.620 --> 00:24:02.350
parameter, you can play
with the parameters

00:24:02.350 --> 00:24:04.240
and control the output.

00:24:04.240 --> 00:24:08.950
So our role here as artists
was to curate the ingredients,

00:24:08.950 --> 00:24:11.680
and guide the machine
and iterations,

00:24:11.680 --> 00:24:14.770
and stop and extract
images in the moment

00:24:14.770 --> 00:24:17.380
we found them beautiful.

00:24:17.380 --> 00:24:20.440
AMIT SOOD: And I think if
you see the next slide,

00:24:20.440 --> 00:24:21.910
I hope it's the one that-- yes.

00:24:21.910 --> 00:24:23.560
That's a fantastic
slide, because that

00:24:23.560 --> 00:24:25.097
talks about the original image?

00:24:25.097 --> 00:24:25.930
PINAR DEMIRDAG: Yes.

00:24:25.930 --> 00:24:29.080
So let me tell you.

00:24:29.080 --> 00:24:32.250
The images that you
have seen before--

00:24:32.250 --> 00:24:34.750
like the big image that you saw
on the screen, the pattern--

00:24:34.750 --> 00:24:37.460
is actually what you
see in the middle, what

00:24:37.460 --> 00:24:40.090
says DeepDream, the images
that DeepDream created.

00:24:40.090 --> 00:24:45.100
And what is on the very left
is the flower, the heart, which

00:24:45.100 --> 00:24:47.080
is the original input image.

00:24:47.080 --> 00:24:51.580
And what you see on the right is
the compositions that we made.

00:24:51.580 --> 00:24:54.750
So the images that
you see in the middle

00:24:54.750 --> 00:24:57.130
come back in the
original image--

00:24:57.130 --> 00:25:00.970
sorry, in the final artwork.

00:25:00.970 --> 00:25:04.210
You must understand that this
is an incredible moment for me

00:25:04.210 --> 00:25:08.500
because, normally, it's quite
a lot of an effort for me

00:25:08.500 --> 00:25:12.790
to create images that come
from different backgrounds.

00:25:12.790 --> 00:25:14.890
And artificial
machine intelligence

00:25:14.890 --> 00:25:16.450
was an amazing tool.

00:25:16.450 --> 00:25:20.110
First of all, it just
never gets tired.

00:25:20.110 --> 00:25:21.410
It runs all the time.

00:25:21.410 --> 00:25:22.540
It doesn't complain.

00:25:22.540 --> 00:25:24.730
It doesn't get sleepy like I do.

00:25:24.730 --> 00:25:29.320
And then it's like, it creates
these nonlinear images.

00:25:29.320 --> 00:25:30.280
Like, I'm a human.

00:25:30.280 --> 00:25:31.540
You know how I make images?

00:25:31.540 --> 00:25:33.910
I put something next
to another thing.

00:25:33.910 --> 00:25:34.840
I think linear.

00:25:34.840 --> 00:25:38.020
But this thing thinks recursive.

00:25:38.020 --> 00:25:40.610
So it creates things that
I've never seen before,

00:25:40.610 --> 00:25:42.140
and they're really beautiful.

00:25:42.140 --> 00:25:45.070
AMIT SOOD: And
where do you think

00:25:45.070 --> 00:25:47.890
this will go for you as an
artist, this collaboration?

00:25:47.890 --> 00:25:49.780
Where do you think
this will move towards?

00:25:49.780 --> 00:25:52.000
PINAR DEMIRDAG: Yes.

00:25:52.000 --> 00:25:53.200
I see two options.

00:25:53.200 --> 00:25:57.520
Well, first of all, if I'm
given like a golden ticket,

00:25:57.520 --> 00:26:02.480
I want to cover space rockets
for them to go to Mars.

00:26:02.480 --> 00:26:07.720
But pattern is something
really beautiful.

00:26:07.720 --> 00:26:12.490
It's a very volatile
surface, in the sense

00:26:12.490 --> 00:26:16.150
that all three-dimensional
objects carry a surface,

00:26:16.150 --> 00:26:19.190
so you can cover anything--
a phone cover, fashion, this

00:26:19.190 --> 00:26:19.690
and that.

00:26:22.390 --> 00:26:27.250
But what we want to
start with-- actually,

00:26:27.250 --> 00:26:29.110
can we go back to
the former one--

00:26:29.110 --> 00:26:30.320
is with an exhibition.

00:26:30.320 --> 00:26:34.390
Because what you have seen so
far is only beautiful prints.

00:26:34.390 --> 00:26:36.190
But we cultivated
so much knowledge

00:26:36.190 --> 00:26:38.780
about future visualization
through the process.

00:26:38.780 --> 00:26:42.160
For instance, when you place
a Buckminster Fuller molecule

00:26:42.160 --> 00:26:44.530
as an input-- you know,
the carbon molecule--

00:26:44.530 --> 00:26:48.590
in one go, it created a
snakeskin, and in another go,

00:26:48.590 --> 00:26:51.020
it created a turtle pattern.

00:26:51.020 --> 00:26:53.590
Another example, when
we placed a Nautilus--

00:26:53.590 --> 00:26:55.960
this spiral animal--

00:26:55.960 --> 00:26:59.680
and then when we placed
a DNA double string,

00:26:59.680 --> 00:27:01.015
it created the same output.

00:27:01.015 --> 00:27:04.300
So so much can be said
about the hidden patterns

00:27:04.300 --> 00:27:06.040
of our universe.

00:27:06.040 --> 00:27:10.720
And then the second
wish is to make

00:27:10.720 --> 00:27:15.370
technology sexy with fashion.

00:27:15.370 --> 00:27:18.370
We recently, as a studio, we
started making our own clothes

00:27:18.370 --> 00:27:20.420
that I am wearing right now.

00:27:20.420 --> 00:27:24.460
And like about artificial
intelligence, machine learning,

00:27:24.460 --> 00:27:28.210
I find it the natural next step
in the progress of humanity.

00:27:28.210 --> 00:27:30.420
But I'm afraid not
everybody sees the beauty

00:27:30.420 --> 00:27:31.750
that I see in it.

00:27:31.750 --> 00:27:36.160
And, as you know, fashion has
this, wow, fashion, glamor,

00:27:36.160 --> 00:27:38.210
this instant glamor effect.

00:27:38.210 --> 00:27:39.940
And I think artificial
intelligence

00:27:39.940 --> 00:27:41.140
can make use of it.

00:27:41.140 --> 00:27:42.310
AMIT SOOD: Yeah.

00:27:42.310 --> 00:27:44.620
I think it's a excellent
example where, not only have

00:27:44.620 --> 00:27:46.420
you co-curated,
but you also think

00:27:46.420 --> 00:27:48.740
about how to make it more
acceptable to the masses.

00:27:48.740 --> 00:27:49.990
PINAR DEMIRDAG: You are right.

00:27:49.990 --> 00:27:51.880
Also, it's a great
conversation opener.

00:27:51.880 --> 00:27:53.390
Like, what are you wearing?

00:27:53.390 --> 00:27:55.810
Oh, I'm wearing a collaboration
between artist and machine

00:27:55.810 --> 00:27:56.410
intelligence.

00:27:56.410 --> 00:27:57.520
And you?

00:27:57.520 --> 00:27:58.603
Just black?

00:27:58.603 --> 00:27:59.270
How interesting.

00:27:59.270 --> 00:28:01.180
AMIT SOOD: [CHUCKLES] Yeah.

00:28:01.180 --> 00:28:05.140
I think the way you
said it is perfect.

00:28:05.140 --> 00:28:07.310
A definite conversation opener.

00:28:07.310 --> 00:28:07.810
OK.

00:28:07.810 --> 00:28:10.428
So now we don't have a lot
of time, unfortunately,

00:28:10.428 --> 00:28:11.720
because we have a next section.

00:28:11.720 --> 00:28:14.137
But we're going to tell you
very quickly what's launching.

00:28:14.137 --> 00:28:16.850
So this is launching today,
this story, which is available.

00:28:16.850 --> 00:28:19.480
But what you can also
see is the actual tool

00:28:19.480 --> 00:28:22.840
that we are publicly making
available thanks to Alex.

00:28:22.840 --> 00:28:25.150
This is essentially
DeepDream, you could say,

00:28:25.150 --> 00:28:27.250
V2 based on the 2018 paper.

00:28:27.250 --> 00:28:29.050
It's not the 2014 version.

00:28:29.050 --> 00:28:31.240
And it's a little
less psychedelic.

00:28:31.240 --> 00:28:32.792
It's a bit more practical.

00:28:32.792 --> 00:28:34.750
And it has a lot of
variations that you can do.

00:28:34.750 --> 00:28:36.290
So this tool is now launched.

00:28:36.290 --> 00:28:37.560
It's available to anybody.

00:28:37.560 --> 00:28:39.550
Go in, put in any
image you want,

00:28:39.550 --> 00:28:42.400
and see what you can
collaborate with.

00:28:42.400 --> 00:28:43.820
I think we have one image--

00:28:43.820 --> 00:28:45.770
I don't know if we can
do it very quickly--

00:28:45.770 --> 00:28:50.242
which Damien took of me eating
my lunch, which I'm not sure--

00:28:50.242 --> 00:28:52.450
that's the only one I could
find that was copyright--

00:28:52.450 --> 00:28:54.850
I'm the copyright owner,
so I'm allowed to use it.

00:28:54.850 --> 00:28:55.510
It's me.

00:28:55.510 --> 00:28:57.680
So essentially,
if you take that,

00:28:57.680 --> 00:29:00.610
and if you try and
very quickly, live,

00:29:00.610 --> 00:29:06.530
see what the tool outputs,
it might take a second, but--

00:29:06.530 --> 00:29:07.030
so here.

00:29:07.030 --> 00:29:11.530
That's my lunch and me converted
into something quite abstract,

00:29:11.530 --> 00:29:12.410
quite interesting.

00:29:12.410 --> 00:29:15.070
But then you can start playing
with it with the toggles.

00:29:15.070 --> 00:29:18.710
So the tool is available
on g.co/artsexperiments.

00:29:18.710 --> 00:29:19.210
Yes.

00:29:19.210 --> 00:29:20.620
That's me and my gazpacho.

00:29:20.620 --> 00:29:23.270
So titled "Me and My Gazpacho."

00:29:23.270 --> 00:29:25.833
So thank you so much, Pinar,
for working with us on this.

00:29:25.833 --> 00:29:27.250
And thank you so
much to Alex, who

00:29:27.250 --> 00:29:29.230
can't be here, who was
an amazing collaborator

00:29:29.230 --> 00:29:30.610
on this project with Pinar.

00:29:30.610 --> 00:29:31.010
PINAR DEMIRDAG: Thank you.

00:29:31.010 --> 00:29:32.010
AMIT SOOD: Thanks a lot.

00:29:32.010 --> 00:29:33.745
[APPLAUSE]

00:29:37.050 --> 00:29:41.260
So, now, I'm going to be really
quick to introduce someone who

00:29:41.260 --> 00:29:43.090
requires a very
long introduction,

00:29:43.090 --> 00:29:45.040
but I'm going to try
and make it very fast.

00:29:45.040 --> 00:29:47.770
So I welcome on stage
Blaise, Blaise Aguera,

00:29:47.770 --> 00:29:51.400
who has been kind of like
an inspiration for us

00:29:51.400 --> 00:29:53.260
here at Google Arts
&amp; Culture because he

00:29:53.260 --> 00:29:56.470
has been doing this work
way before Google Arts

00:29:56.470 --> 00:29:57.430
&amp; Culture came along.

00:29:57.430 --> 00:30:00.160
And I think I have
this cards that I

00:30:00.160 --> 00:30:01.810
want to read out very quickly.

00:30:01.810 --> 00:30:04.060
But, basically, Blaise
leads a team at Google

00:30:04.060 --> 00:30:05.620
now focusing on
machine intelligence

00:30:05.620 --> 00:30:08.590
for mobile devices, both on
the research front as well

00:30:08.590 --> 00:30:09.670
as the new products.

00:30:09.670 --> 00:30:12.850
And the group works extensively
in deep neural nets for machine

00:30:12.850 --> 00:30:14.320
perception,
distributed learning,

00:30:14.320 --> 00:30:16.300
and agents, as well
as collaborating

00:30:16.300 --> 00:30:19.960
with cultural institutions
and academic institutions.

00:30:19.960 --> 00:30:23.270
Until 2014, distinguished
engineer at Microsoft,

00:30:23.270 --> 00:30:25.990
where you worked in
a variety of roles.

00:30:25.990 --> 00:30:29.260
And your TED talk,
which is something

00:30:29.260 --> 00:30:33.760
that any TED aspirant should
enjoy, around Sea Dragon

00:30:33.760 --> 00:30:36.670
and Photosynth in 2007
and 2012, and of course,

00:30:36.670 --> 00:30:38.200
Bing Maps in 2010.

00:30:38.200 --> 00:30:42.040
And in 2008, you were awarded
MIT's prestigious TR35.

00:30:42.040 --> 00:30:44.600
So we are very happy
to have you here.

00:30:44.600 --> 00:30:47.170
We are going to now get you
to talk about some of the work

00:30:47.170 --> 00:30:48.280
that you're doing.

00:30:48.280 --> 00:30:51.480
Maybe you can start talking
a little bit about just

00:30:51.480 --> 00:30:55.037
DeepDream, and what your team
is doing around this area.

00:30:55.037 --> 00:30:55.870
BLAISE AGUERA: Sure.

00:30:55.870 --> 00:30:58.160
Thank you so much for
having me up here, Amit.

00:30:58.160 --> 00:31:02.290
So we've been collaborating
with Google Arts &amp; Culture

00:31:02.290 --> 00:31:05.710
via a sister program
called Artists and Machine

00:31:05.710 --> 00:31:08.170
Intelligence for some years now.

00:31:08.170 --> 00:31:15.160
And the origins of DeepDream,
you've already alluded to.

00:31:15.160 --> 00:31:19.090
This was Alex Mordvintsev
originally doing experiments

00:31:19.090 --> 00:31:21.850
to try to understand
the neuroscience

00:31:21.850 --> 00:31:24.310
of artificial neural nets.

00:31:24.310 --> 00:31:29.350
When we first began to use
deep nets to understand images,

00:31:29.350 --> 00:31:32.350
they turned out to be much more
powerful than previous machine

00:31:32.350 --> 00:31:33.710
learning techniques.

00:31:33.710 --> 00:31:36.370
And he was trying
to visualize what

00:31:36.370 --> 00:31:39.670
they were doing on the inside,
to run them in reverse.

00:31:39.670 --> 00:31:45.153
And those visualizations
yielded these incredible

00:31:45.153 --> 00:31:45.820
hallucinogenic--

00:31:45.820 --> 00:31:48.250
AMIT SOOD: And that's not
all your team has been doing.

00:31:48.250 --> 00:31:51.220
There's been a lot of other
cultural engagements already

00:31:51.220 --> 00:31:53.998
influenced based on the research
that your team is actually

00:31:53.998 --> 00:31:54.540
doing, right?

00:31:54.540 --> 00:31:56.590
BLAISE AGUERA: That's right.

00:31:56.590 --> 00:32:02.230
So that really began the process
of thinking about deep nets

00:32:02.230 --> 00:32:05.800
as not only being able to
understand or analyze media,

00:32:05.800 --> 00:32:07.870
but also synthesize media.

00:32:07.870 --> 00:32:11.890
So where the Cultural
Institute had

00:32:11.890 --> 00:32:14.170
been using these
kind of technologies

00:32:14.170 --> 00:32:17.380
to do things like classify media
and allow you to search them,

00:32:17.380 --> 00:32:19.980
the next step was to
try and understand

00:32:19.980 --> 00:32:23.320
what happens when they
begin to synthesize media,

00:32:23.320 --> 00:32:24.730
and what kind of
new partnerships

00:32:24.730 --> 00:32:27.925
are possible with artists, as
Pinar was just demonstrating.

00:32:27.925 --> 00:32:28.993
AMIT SOOD: Exactly.

00:32:28.993 --> 00:32:33.770
And what has been like one
of your highlight projects

00:32:33.770 --> 00:32:36.560
from these cultural engagements?

00:32:36.560 --> 00:32:38.452
What has inspired you?

00:32:38.452 --> 00:32:40.990
BLAISE AGUERA: So I
brought a couple of slides,

00:32:40.990 --> 00:32:43.850
nothing so flashy as
what you've been showing.

00:32:43.850 --> 00:32:46.100
But there were a couple of
really interesting moments,

00:32:46.100 --> 00:32:49.990
I thought, at various points
in AMI's history so far.

00:32:49.990 --> 00:32:55.030
One of them was this
rather inglorious-looking

00:32:55.030 --> 00:32:59.860
little bubble camera, which
Ross Goodwin, one of our artist

00:32:59.860 --> 00:33:04.000
collaborators, drove
with Kenric McDowell

00:33:04.000 --> 00:33:08.470
around in this car that had
this camera mounted on it.

00:33:08.470 --> 00:33:14.793
And the camera was hooked up to
both an analysis and synthesis

00:33:14.793 --> 00:33:15.460
neural networks.

00:33:15.460 --> 00:33:18.910
Analysis in order to understand
what images were being seen.

00:33:18.910 --> 00:33:21.850
Synthesis in order
to generate poetry

00:33:21.850 --> 00:33:24.210
from the images that
were being seen.

00:33:24.210 --> 00:33:27.370
So the inputs are
coming from the image,

00:33:27.370 --> 00:33:32.740
and from GPS, and
from Foursquare API.

00:33:32.740 --> 00:33:37.840
And this journey, this road
trip that references on the road

00:33:37.840 --> 00:33:40.670
went through
industrial corridors

00:33:40.670 --> 00:33:45.580
in the US that are
suffering a certain degree

00:33:45.580 --> 00:33:47.590
of economic depression
at the moment.

00:33:47.590 --> 00:33:49.330
"Red and white
flags and the stars

00:33:49.330 --> 00:33:51.760
were like a curtain of
paper, like a broad stream

00:33:51.760 --> 00:33:53.050
of flowers."

00:33:53.050 --> 00:33:54.790
These kinds of lines come out.

00:33:54.790 --> 00:34:00.880
Or in Biloxi, Hard
Rock Hotel &amp; Casino

00:34:00.880 --> 00:34:03.790
Biloxi, "a hotel in
Biloxi, a high fisherman

00:34:03.790 --> 00:34:07.150
with a starry face, and a
stub of a coat on his face,

00:34:07.150 --> 00:34:09.639
and his shirt looking
boldly across his mouth."

00:34:09.639 --> 00:34:13.120
These sort of things
emerge from this network

00:34:13.120 --> 00:34:18.340
that has been trained on a large
corpus of 20th century poetry.

00:34:18.340 --> 00:34:22.030
And a little bit like
Pinar's experience,

00:34:22.030 --> 00:34:24.820
you start to get
a spooky feeling

00:34:24.820 --> 00:34:26.650
when you experience this.

00:34:26.650 --> 00:34:29.320
There's something going
on in the interaction

00:34:29.320 --> 00:34:33.190
between the corpora
of human art that

00:34:33.190 --> 00:34:36.480
has been made in the 20th
century, the environments

00:34:36.480 --> 00:34:38.909
that we've created
in the 20th and 21st,

00:34:38.909 --> 00:34:41.790
and the neural nets that we're
now able to partner with.

00:34:41.790 --> 00:34:43.650
AMIT SOOD: But can I
ask you a question?

00:34:43.650 --> 00:34:45.420
Because now we've
shown a few examples

00:34:45.420 --> 00:34:50.500
where people are co-creating
with an intelligent system.

00:34:50.500 --> 00:34:54.909
What does it actually mean
for you, both on an abstract,

00:34:54.909 --> 00:34:56.520
but also on a practical level?

00:34:56.520 --> 00:34:58.562
BLAISE AGUERA: Well, I
don't think that we really

00:34:58.562 --> 00:34:59.850
know yet where this all goes.

00:34:59.850 --> 00:35:01.392
And that's one of
the reasons that we

00:35:01.392 --> 00:35:04.140
thought it was so important
to begin these dialogues, not

00:35:04.140 --> 00:35:06.480
only with artists, but
also with philosophers,

00:35:06.480 --> 00:35:09.660
and critical theorists, and
all kinds of other disciplines,

00:35:09.660 --> 00:35:12.600
all sorts of other people.

00:35:12.600 --> 00:35:15.390
On the one hand,
art and technology

00:35:15.390 --> 00:35:17.430
have always been
very deeply enmeshed.

00:35:17.430 --> 00:35:20.070
And if we have this
idea about art,

00:35:20.070 --> 00:35:23.700
of it being somehow very pure
and devoid of technology,

00:35:23.700 --> 00:35:25.413
this is absolutely wrong.

00:35:25.413 --> 00:35:28.080
No matter whether you're looking
at aboriginal technologies that

00:35:28.080 --> 00:35:31.475
use dyes extracted from nature,
or you're looking at Henri

00:35:31.475 --> 00:35:32.850
Cartier-Bresson
and photography--

00:35:32.850 --> 00:35:33.540
AMIT SOOD: The printing press.

00:35:33.540 --> 00:35:35.165
BLAISE AGUERA: --or
the printing press,

00:35:35.165 --> 00:35:37.270
right, it's always been
a technological exercise.

00:35:37.270 --> 00:35:39.930
And often, when the
new technology comes--

00:35:39.930 --> 00:35:42.040
and photography is a
really good example--

00:35:42.040 --> 00:35:45.300
there's a little bit of a
moral panic of like, oh my god,

00:35:45.300 --> 00:35:46.990
what does this mean?

00:35:46.990 --> 00:35:49.800
But of course, in
the end, we're not

00:35:49.800 --> 00:35:51.520
really separate from technology.

00:35:51.520 --> 00:35:55.560
I feel like we're all part
of the same sociotechnical

00:35:55.560 --> 00:35:56.370
universe.

00:35:56.370 --> 00:36:00.020
AMIT SOOD: So this engagement
is critical, right?

00:36:00.020 --> 00:36:05.070
Like your group, apart from
this initiative on arts,

00:36:05.070 --> 00:36:08.250
your group is doing a lot of
other very big impactful things

00:36:08.250 --> 00:36:09.600
across Google.

00:36:09.600 --> 00:36:12.500
And I'm just curious, what--

00:36:12.500 --> 00:36:13.680
you are very busy.

00:36:13.680 --> 00:36:15.240
You have a lot of
stuff going on.

00:36:15.240 --> 00:36:17.880
But you still make
time out to focus

00:36:17.880 --> 00:36:20.190
on this kind of
collaboration with artists,

00:36:20.190 --> 00:36:21.390
thinkers, et cetera.

00:36:21.390 --> 00:36:23.988
And I want to know, what is
the benefit to tech companies?

00:36:23.988 --> 00:36:25.530
Why should tech
companies collaborate

00:36:25.530 --> 00:36:27.280
with this type of entities?

00:36:27.280 --> 00:36:30.270
BLAISE AGUERA: Well, we find
this engagement absolutely

00:36:30.270 --> 00:36:32.190
critical to all of our work.

00:36:32.190 --> 00:36:38.355
This isn't a sideshow,
or a 20% project for us.

00:36:38.355 --> 00:36:43.350
I feel like there's an
insularity to Silicon Valley

00:36:43.350 --> 00:36:44.670
culture.

00:36:44.670 --> 00:36:47.550
And we've seen some
of the downsides

00:36:47.550 --> 00:36:52.320
of that play out in recent
years along every dimension.

00:36:52.320 --> 00:36:53.780
It's geographic.

00:36:53.780 --> 00:36:55.560
Companies that are
based in Silicon Valley

00:36:55.560 --> 00:36:58.740
often don't understand what the
impacts and the consequences

00:36:58.740 --> 00:37:01.600
of technology are in
other places in the world.

00:37:01.600 --> 00:37:04.050
They don't have their
eyes open through the lens

00:37:04.050 --> 00:37:06.270
of other disciplines, and
other kinds of life ways,

00:37:06.270 --> 00:37:09.877
and other ways of
interacting with people

00:37:09.877 --> 00:37:10.710
and with technology.

00:37:10.710 --> 00:37:13.830
So for us, I just came back--

00:37:13.830 --> 00:37:19.410
Kenric and I were at the Strelka
Institute in Moscow for a week

00:37:19.410 --> 00:37:22.113
last week in discussion
with Benjamin Bratton, who

00:37:22.113 --> 00:37:24.030
is one of our artists
and machine intelligence

00:37:24.030 --> 00:37:28.020
collaborators, and an
urbanist, an urban theorist.

00:37:28.020 --> 00:37:30.510
And it was an extremely--

00:37:30.510 --> 00:37:33.750
this was an engagement
that we're bringing back

00:37:33.750 --> 00:37:36.187
into the lab and into our
work in a variety of very

00:37:36.187 --> 00:37:36.770
concrete ways.

00:37:36.770 --> 00:37:40.350
AMIT SOOD: So you are
finding practical nuggets

00:37:40.350 --> 00:37:43.460
that you can actually take
from these engagements

00:37:43.460 --> 00:37:46.950
and put it into the actual
larger technical world

00:37:46.950 --> 00:37:47.700
that you're doing.

00:37:47.700 --> 00:37:48.210
BLAISE AGUERA: Absolutely.

00:37:48.210 --> 00:37:48.990
AMIT SOOD: OK.

00:37:48.990 --> 00:37:51.465
And so obviously,
that means you want

00:37:51.465 --> 00:37:52.590
more of these interactions.

00:37:52.590 --> 00:37:53.400
BLAISE AGUERA: Yes.

00:37:53.400 --> 00:37:54.780
AMIT SOOD: You don't
want less of them, right?

00:37:54.780 --> 00:37:57.210
Because you want your main
work to be further enhanced.

00:37:57.210 --> 00:37:58.710
BLAISE AGUERA: We
want to keep going

00:37:58.710 --> 00:37:59.793
and to keep engaging, yes.

00:37:59.793 --> 00:38:02.370
AMIT SOOD: So to
do that, I heard

00:38:02.370 --> 00:38:05.250
that you and I and our teams
are going to announce something

00:38:05.250 --> 00:38:06.480
today.

00:38:06.480 --> 00:38:07.517
So why don't you--

00:38:07.517 --> 00:38:09.100
BLAISE AGUERA: How
did you know, Amit?

00:38:09.100 --> 00:38:11.183
AMIT SOOD: Well, because
we've been working on it.

00:38:11.183 --> 00:38:12.625
But here it is.

00:38:12.625 --> 00:38:14.380
You're going to
talk about thing.

00:38:14.380 --> 00:38:16.613
Damien?

00:38:16.613 --> 00:38:17.280
Please go ahead.

00:38:17.280 --> 00:38:17.865
Go ahead, please.

00:38:17.865 --> 00:38:18.657
BLAISE AGUERA: Yes.

00:38:18.657 --> 00:38:24.440
So this was another project
that I didn't have a chance.

00:38:24.440 --> 00:38:27.010
But I feel like we've already
shown maybe too many of these,

00:38:27.010 --> 00:38:28.810
so perhaps we should
skip straight to the--

00:38:28.810 --> 00:38:29.936
AMIT SOOD: I think we have
time if you want to do

00:38:29.936 --> 00:38:29.980
another example or two, yeah.

00:38:29.980 --> 00:38:31.438
BLAISE AGUERA: Do
we have a moment?

00:38:31.438 --> 00:38:34.660
Well, this was a really
beautiful project.

00:38:34.660 --> 00:38:37.450
So this is Ross
Goodwin's "The Road."

00:38:37.450 --> 00:38:40.960
This is Rafik Anadol's
"Archive Dreaming," which

00:38:40.960 --> 00:38:42.650
we were pretty excited by.

00:38:42.650 --> 00:38:46.750
He first did this
experiment in 2017

00:38:46.750 --> 00:38:49.100
with the SALT
Archive in Istanbul.

00:38:49.100 --> 00:38:51.800
So this is an example of
another very large art

00:38:51.800 --> 00:38:54.850
archive similar to the ones
that Damien was showing earlier.

00:38:54.850 --> 00:38:59.120
And he created an
environment that

00:38:59.120 --> 00:39:01.540
consisted of curved
screens and mirrors,

00:39:01.540 --> 00:39:06.880
and let you explore the archive
in a very rich interactive way.

00:39:06.880 --> 00:39:11.140
But also, Mike Tyka on
our team worked with him

00:39:11.140 --> 00:39:13.700
with synthetic networks similar
to what Pinar was showing.

00:39:13.700 --> 00:39:15.457
And so you could
both visualize--

00:39:15.457 --> 00:39:16.040
[END PLAYBACK]

00:39:16.040 --> 00:39:18.010
--the archive in a
variety of new ways,

00:39:18.010 --> 00:39:22.367
and also synthesize media
that look like they belong

00:39:22.367 --> 00:39:23.450
in the archive but didn't.

00:39:23.450 --> 00:39:24.820
AMIT SOOD: Yeah, and
visually very appealing.

00:39:24.820 --> 00:39:26.590
BLAISE AGUERA: And
visually quite intense.

00:39:26.590 --> 00:39:28.090
AMIT SOOD: And now
I think we should

00:39:28.090 --> 00:39:32.200
go to the grants program,
because in 28 seconds,

00:39:32.200 --> 00:39:33.160
the doors will open.

00:39:33.160 --> 00:39:36.470
BLAISE AGUERA: So in 24
seconds, the doors open,

00:39:36.470 --> 00:39:39.502
so let's go straight
to the grants program.

00:39:39.502 --> 00:39:40.960
AMIT SOOD: So this
is something new

00:39:40.960 --> 00:39:43.060
that we are announcing
this year at I/O 2019,

00:39:43.060 --> 00:39:44.560
and Blaise is going
to introduce it.

00:39:44.560 --> 00:39:48.340
BLAISE AGUERA: So we're doing
six grants over the coming

00:39:48.340 --> 00:39:51.340
year to artists.

00:39:51.340 --> 00:39:54.203
It's over five months.

00:39:54.203 --> 00:39:55.120
There's no commission.

00:39:55.120 --> 00:39:57.940
There's not a requirement for
any specific artistic output.

00:39:57.940 --> 00:40:01.480
But creative technologists
from Google--

00:40:01.480 --> 00:40:06.450
Damien, and Kenric, and
engineering help from Google--

00:40:06.450 --> 00:40:08.770
will work with those
artists and their practices

00:40:08.770 --> 00:40:12.755
to extend their thinking
with these new approaches

00:40:12.755 --> 00:40:13.630
and new technologies.

00:40:13.630 --> 00:40:14.255
AMIT SOOD: Yes.

00:40:14.255 --> 00:40:16.150
And this is a
formalization of the work

00:40:16.150 --> 00:40:18.240
that Blaise's team has
been doing for many years

00:40:18.240 --> 00:40:19.720
with the AMI project.

00:40:19.720 --> 00:40:23.590
And we are starting small,
and starting humbly.

00:40:23.590 --> 00:40:26.800
But we are hoping that these
grants will enable artists

00:40:26.800 --> 00:40:29.410
to come and work with people
like yourself and Kenric

00:40:29.410 --> 00:40:32.415
to essentially provide that
extra nugget for the work

00:40:32.415 --> 00:40:33.790
that you're already
doing, right?

00:40:33.790 --> 00:40:34.300
BLAISE AGUERA: Yeah.

00:40:34.300 --> 00:40:36.593
We've had wonderful engagements
for this kind of thing

00:40:36.593 --> 00:40:39.010
in past years, and now we're
formalizing it and scaling it

00:40:39.010 --> 00:40:39.595
up.

00:40:39.595 --> 00:40:40.060
So a wonderful partnership.

00:40:40.060 --> 00:40:40.852
AMIT SOOD: Perfect.

00:40:40.852 --> 00:40:44.030
So three new things
at I/O. Weird Cuts.

00:40:44.030 --> 00:40:47.110
DeepDream V2, call it
Infinite Patterns launched,

00:40:47.110 --> 00:40:49.060
and machine learning grants.

00:40:49.060 --> 00:40:51.460
So don't tell it was not enough.

00:40:51.460 --> 00:40:52.660
I hope that's enough.

00:40:52.660 --> 00:40:55.270
And plus all the
other stuff we threw.

00:40:55.270 --> 00:40:57.600
So thank you so much,
Blaise, for coming on.

00:40:57.600 --> 00:40:58.880
Thank you, Pinar.

00:40:58.880 --> 00:41:00.460
Thank you, Damien.

00:41:00.460 --> 00:41:05.890
And we are right on time,
so you guys can go and enjoy

00:41:05.890 --> 00:41:06.650
your evening.

00:41:06.650 --> 00:41:07.150
Bye-bye.

00:41:07.150 --> 00:41:08.320
Thank you.

00:41:08.320 --> 00:41:11.970
[MUSIC PLAYING]

