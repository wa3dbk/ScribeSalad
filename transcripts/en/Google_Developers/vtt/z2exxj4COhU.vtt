WEBVTT
Kind: captions
Language: en

00:00:02.860 --> 00:00:03.230
ALEX FAABORG: All right.

00:00:03.230 --> 00:00:03.950
Welcome and Good Morning.

00:00:03.950 --> 00:00:04.540
Thanks for coming.

00:00:04.540 --> 00:00:05.610
I'm Alex Faaborg.

00:00:05.610 --> 00:00:07.130
I'm a designer at Google.

00:00:07.130 --> 00:00:09.280
My background's in cognitive
science and machine learning.

00:00:09.280 --> 00:00:12.000
And at Google, I've worked on
Google Now and on Glass and on

00:00:12.000 --> 00:00:13.440
the Android platform.

00:00:13.440 --> 00:00:16.149
And giving design talks at
venues like I/O is really one

00:00:16.149 --> 00:00:18.080
of the favorite parts
of my job.

00:00:18.080 --> 00:00:21.320
I really enjoy doing it,
especially being able to

00:00:21.320 --> 00:00:22.610
talked audience of engineers.

00:00:22.610 --> 00:00:24.740
You guys are obviously smarter
than most people.

00:00:24.740 --> 00:00:26.360
It means I can move
very quickly.

00:00:26.360 --> 00:00:27.410
There's a lot of slides
in this talk.

00:00:27.410 --> 00:00:29.150
So we're going to
have to dive in.

00:00:29.150 --> 00:00:30.750
So how many of you
are engineers?

00:00:30.750 --> 00:00:31.240
Quick hands.

00:00:31.240 --> 00:00:31.780
Yep.

00:00:31.780 --> 00:00:33.400
All of you.

00:00:33.400 --> 00:00:34.580
Awesome.

00:00:34.580 --> 00:00:34.990
Makes sense.

00:00:34.990 --> 00:00:35.800
It's a tech conference.

00:00:35.800 --> 00:00:38.480
So you write great software.

00:00:38.480 --> 00:00:41.290
You make sure that your software
executes well or is

00:00:41.290 --> 00:00:45.120
interpreted well on a silicon
based processor.

00:00:45.120 --> 00:00:46.560
But that's really the
first time that your

00:00:46.560 --> 00:00:47.210
code is going to run.

00:00:47.210 --> 00:00:49.730
It's going to run it again
on another machine.

00:00:49.730 --> 00:00:51.780
So you start with the mechanical
computation, which

00:00:51.780 --> 00:00:52.890
is of this entire conference is

00:00:52.890 --> 00:00:54.270
about and is very important.

00:00:54.270 --> 00:00:55.420
But then there's
another phase.

00:00:55.420 --> 00:00:57.260
And that's the biological
computation that's happening

00:00:57.260 --> 00:00:58.370
right after.

00:00:58.370 --> 00:01:00.940
And this is really where your
code is actually being

00:01:00.940 --> 00:01:03.440
interpreted, is on
the user's mind.

00:01:03.440 --> 00:01:06.190
So the more you can understand
about both of these machines,

00:01:06.190 --> 00:01:08.520
the better software that
you're going to write.

00:01:08.520 --> 00:01:10.970
And it's important to focus on
some of the attributes of what

00:01:10.970 --> 00:01:13.220
we know about biological
computation.

00:01:13.220 --> 00:01:14.620
So a very quick overview
of the talk.

00:01:14.620 --> 00:01:16.520
Here's my very rough diagram.

00:01:16.520 --> 00:01:18.560
We're going to spend about
half the talk on vision.

00:01:18.560 --> 00:01:20.460
And then the second half the
talk we'll be focusing on

00:01:20.460 --> 00:01:23.620
attention emotion memory.

00:01:23.620 --> 00:01:25.150
Diving into vision--

00:01:25.150 --> 00:01:26.460
During the opening sequence
we went through a

00:01:26.460 --> 00:01:27.930
lot of optical illusions.

00:01:27.930 --> 00:01:29.730
Of course, no cognitive science
talk is complete

00:01:29.730 --> 00:01:31.520
without a few optical
illusions.

00:01:31.520 --> 00:01:33.240
This one is physiological.

00:01:33.240 --> 00:01:36.670
We're basically overloading your
rods, where the little

00:01:36.670 --> 00:01:38.785
white dots are popping
and becoming black.

00:01:38.785 --> 00:01:41.440
So this is basically just pure
hacking of hardware.

00:01:41.440 --> 00:01:43.000
But what's more interesting
is this one.

00:01:43.000 --> 00:01:44.420
This one is not physiological.

00:01:44.420 --> 00:01:47.190
This one's running on software,
where the lines

00:01:47.190 --> 00:01:48.490
appear to be slanted.

00:01:48.490 --> 00:01:48.910
They're not.

00:01:48.910 --> 00:01:50.010
They're horizontal.

00:01:50.010 --> 00:01:53.060
But nonetheless, your mind is
interpreting it because the

00:01:53.060 --> 00:01:55.640
very powerful video codec that
you have that's grabbing all

00:01:55.640 --> 00:01:58.480
this raw data is trying to do
certain optimizations based

00:01:58.480 --> 00:02:00.720
off of expected input in the
types of things you see in the

00:02:00.720 --> 00:02:01.760
real world.

00:02:01.760 --> 00:02:04.900
Another example is this one,
where it really looks like

00:02:04.900 --> 00:02:06.720
there's a gradient on the bar.

00:02:06.720 --> 00:02:07.690
The bar's a flat color.

00:02:07.690 --> 00:02:09.539
The gradient's only
in the background.

00:02:09.539 --> 00:02:12.310
And the reason for this effect
is what we're used to natural

00:02:12.310 --> 00:02:13.570
lighting environments.

00:02:13.570 --> 00:02:16.840
We're not used to this thing
being able to happen, where

00:02:16.840 --> 00:02:19.510
you can have a flat color
and a gradient into the

00:02:19.510 --> 00:02:20.450
background.

00:02:20.450 --> 00:02:22.970
So all of our evolution has been
optimized for the types

00:02:22.970 --> 00:02:25.400
of things that we're
likely to see.

00:02:25.400 --> 00:02:27.510
So it's taking short cuts.

00:02:27.510 --> 00:02:31.960
It's increasing the amount of
difference that you can very

00:02:31.960 --> 00:02:34.640
quickly see the edges
and changes in shape

00:02:34.640 --> 00:02:36.170
and changes in shape.

00:02:36.170 --> 00:02:38.710
So one of things we're great
at is edge detection.

00:02:38.710 --> 00:02:40.270
This is actually my favorite
optical illusions.

00:02:40.270 --> 00:02:41.910
It's called the Kansai
Triangle.

00:02:41.910 --> 00:02:43.980
And what's cool about this
is there's isn't actually

00:02:43.980 --> 00:02:45.540
triangle in the shot.

00:02:45.540 --> 00:02:48.760
But you perceive a right
triangle in the foreground.

00:02:48.760 --> 00:02:50.900
It's being created
out of nothing.

00:02:50.900 --> 00:02:53.250
And when you look at the edges,
you almost feel like

00:02:53.250 --> 00:02:56.800
you can see the shadow
on the edge, even

00:02:56.800 --> 00:02:58.280
though it's not there.

00:02:58.280 --> 00:03:00.710
Your mind is making assumptions
on the triangle

00:03:00.710 --> 00:03:02.410
being in the foreground.

00:03:02.410 --> 00:03:05.440
And that edge doesn't exist but
nonetheless you feel like

00:03:05.440 --> 00:03:07.670
you can see the shadow,
which is very strange.

00:03:07.670 --> 00:03:10.770
So a lot of other cognitive
scientists and designers, many

00:03:10.770 --> 00:03:13.500
years ago, came up with the
Gestalt Laws of Grouping.

00:03:13.500 --> 00:03:14.850
And this is something
that all designers

00:03:14.850 --> 00:03:16.520
will learn in school.

00:03:16.520 --> 00:03:18.940
And there's eight of
them for grouping.

00:03:18.940 --> 00:03:21.110
We only a little bit of time,
so we'll go through three of

00:03:21.110 --> 00:03:22.830
them specifically.

00:03:22.830 --> 00:03:24.570
First one's the Law
of Proximity.

00:03:24.570 --> 00:03:27.670
By introducing white space, you
perceive columns, instead

00:03:27.670 --> 00:03:29.980
of just the same number
of shapes.

00:03:29.980 --> 00:03:31.980
When it's uniform grade, you
just perceive all the shapes.

00:03:31.980 --> 00:03:33.430
But as soon as you have a little
bit of white space--

00:03:33.430 --> 00:03:35.620
your mind is very good at
finding patterns and assigning

00:03:35.620 --> 00:03:36.510
order to things.

00:03:36.510 --> 00:03:39.270
So you very quickly assign
that into three columns.

00:03:39.270 --> 00:03:41.220
So you don't have to draw boxes
around everything to

00:03:41.220 --> 00:03:41.940
create grouping.

00:03:41.940 --> 00:03:44.030
You can just use a little
bit of white space.

00:03:44.030 --> 00:03:45.550
So an obvious example
of this--

00:03:45.550 --> 00:03:47.470
Google search results.

00:03:47.470 --> 00:03:49.160
By introducing just a little bit
of white space in between

00:03:49.160 --> 00:03:51.410
the search results, it's very
easy for people to group those

00:03:51.410 --> 00:03:53.390
and chunk them into individual
results.

00:03:53.390 --> 00:03:55.535
Whereas if that white space
didn't exist, even though you

00:03:55.535 --> 00:03:58.070
have all the formatting cues--

00:03:58.070 --> 00:04:00.540
bold titles and the
blue underlines.

00:04:00.540 --> 00:04:01.260
Those things still exist.

00:04:01.260 --> 00:04:03.820
But it's still very hard to be
able to see that structure

00:04:03.820 --> 00:04:05.340
without the white space.

00:04:05.340 --> 00:04:08.080
Obvious analogy to writing
software is trying to look at

00:04:08.080 --> 00:04:09.890
code without white
space is hard.

00:04:09.890 --> 00:04:12.200
I mean, a computer can interpret
it just fine.

00:04:12.200 --> 00:04:13.852
In fact, white space is probably
wasting a little bit

00:04:13.852 --> 00:04:14.510
of bandwidth.

00:04:14.510 --> 00:04:17.860
But nonetheless for you as a
developer, you need that to

00:04:17.860 --> 00:04:19.110
see the structure.

00:04:21.070 --> 00:04:23.820
Another Gestalt Law of Grouping
is the Law of

00:04:23.820 --> 00:04:28.030
Closure, where we very quickly
complete forms.

00:04:28.030 --> 00:04:30.720
It's not actually full circle or
full square, but we quickly

00:04:30.720 --> 00:04:31.840
make it one.

00:04:31.840 --> 00:04:35.220
So again, you don't have to draw
boxes around everything.

00:04:35.220 --> 00:04:37.550
In the case of Android, just
having the little edges on the

00:04:37.550 --> 00:04:39.660
text field is enough for
your mind to mentally

00:04:39.660 --> 00:04:40.970
complete the box.

00:04:40.970 --> 00:04:42.130
You begin to see the box.

00:04:42.130 --> 00:04:43.680
And the box exists in your mind,
even though it wasn't

00:04:43.680 --> 00:04:44.930
literally drawn on the screen.

00:04:47.520 --> 00:04:48.700
Law of Similarity--

00:04:48.700 --> 00:04:50.760
here, instead of columns,
we're seeing row.

00:04:50.760 --> 00:04:52.870
And the only thing we changed
was level of contrast of some

00:04:52.870 --> 00:04:53.860
of the objects.

00:04:53.860 --> 00:04:55.270
But the rows pop out.

00:04:55.270 --> 00:04:56.380
And it doesn't have
to contrast.

00:04:56.380 --> 00:04:59.930
It could also be shape,
where seeing stars

00:04:59.930 --> 00:05:02.030
versus circles, where--

00:05:02.030 --> 00:05:03.780
the rows really pop
out at you.

00:05:03.780 --> 00:05:06.940
And we this in Gmail, where--
in this case, columns.

00:05:06.940 --> 00:05:08.940
You have a column of check boxes
and column of starring

00:05:08.940 --> 00:05:11.600
messages and a column of
priority, where it's very easy

00:05:11.600 --> 00:05:14.020
to then visually scan down that
column, even though the

00:05:14.020 --> 00:05:15.430
spacing is all uniform.

00:05:15.430 --> 00:05:17.940
It's otherwise just a grid.

00:05:17.940 --> 00:05:19.990
So those are all things
that are innate,

00:05:19.990 --> 00:05:21.640
that apply to everyone.

00:05:21.640 --> 00:05:24.830
There's also some aspects of
layout that are cultural, that

00:05:24.830 --> 00:05:26.250
you pick up over time.

00:05:26.250 --> 00:05:29.670
One of the most basic one of
these is reading right to left

00:05:29.670 --> 00:05:31.100
versus left to right.

00:05:31.100 --> 00:05:33.150
This is very important for the
structure of your application.

00:05:33.150 --> 00:05:35.190
It's not just about the text,
but it's about the logical

00:05:35.190 --> 00:05:38.660
flow of the application, where
the meaning of a switch being

00:05:38.660 --> 00:05:41.970
on versus off should actually
be inverted, if it's

00:05:41.970 --> 00:05:43.460
horizontal switch.

00:05:43.460 --> 00:05:46.540
I should note-- the back
button is wrong.

00:05:46.540 --> 00:05:48.140
As I was a taking the screen
shot, I realize this.

00:05:48.140 --> 00:05:50.060
We'll fix that.

00:05:50.060 --> 00:05:53.190
But the notion of back is
opposite, if you're used to

00:05:53.190 --> 00:05:55.880
reading right to left, instead
of left to right.

00:05:55.880 --> 00:05:57.740
And this applies to really know
the whole structure of

00:05:57.740 --> 00:05:59.200
your application.

00:05:59.200 --> 00:06:00.730
And things like going
up in the hierarchy.

00:06:00.730 --> 00:06:02.090
In the action bar,
we see that.

00:06:02.090 --> 00:06:03.190
We didn't do that correctly.

00:06:03.190 --> 00:06:06.960
Or even things like the Settings
button being sort of

00:06:06.960 --> 00:06:09.250
peripheral to activating a
keyboard in this sense--

00:06:09.250 --> 00:06:10.470
there's a certain flow to it.

00:06:10.470 --> 00:06:13.130
And that flow should
be reversed.

00:06:13.130 --> 00:06:16.340
So a whole new topic related to
vision-- peripheral vision.

00:06:16.340 --> 00:06:19.920
Let's say we have an underground
testing facility,

00:06:19.920 --> 00:06:23.000
where we do studies on people,
of course for science.

00:06:23.000 --> 00:06:25.090
And we keep people isolated.

00:06:25.090 --> 00:06:25.990
So we don't about
the studies are.

00:06:25.990 --> 00:06:28.430
So they don't know any idea what
the study is going in.

00:06:28.430 --> 00:06:30.800
But we give you this
test chamber.

00:06:30.800 --> 00:06:32.770
And we ask you to go
into the room.

00:06:32.770 --> 00:06:33.920
So you go in.

00:06:33.920 --> 00:06:36.800
And bam-- tiger.

00:06:36.800 --> 00:06:37.950
That's the only test.

00:06:37.950 --> 00:06:40.190
Basically, we're just monitoring
how long it takes

00:06:40.190 --> 00:06:42.330
you to realize that there's
a tiger in front of you.

00:06:42.330 --> 00:06:45.730
And it's going to be about 190
milliseconds to recognize that

00:06:45.730 --> 00:06:48.310
tiger that we very carefully
set on the podium.

00:06:48.310 --> 00:06:49.850
It's probably hard to get
him to stay there.

00:06:49.850 --> 00:06:50.890
And of course, he
then kills you.

00:06:50.890 --> 00:06:52.680
But that's not part
of the test.

00:06:52.680 --> 00:06:53.375
That part's arbitrary.

00:06:53.375 --> 00:06:55.890
And it's up to the tiger.

00:06:55.890 --> 00:06:58.820
So let's run another study.

00:06:58.820 --> 00:07:01.320
At this point, subjects are
kind of talking, say these

00:07:01.320 --> 00:07:02.470
chamber's are no good.

00:07:02.470 --> 00:07:03.615
So you go in.

00:07:03.615 --> 00:07:04.790
There's nothing.

00:07:04.790 --> 00:07:07.330
Once again, bam-- tiger.

00:07:07.330 --> 00:07:10.305
And what's interesting about
this is you'll see this tiger

00:07:10.305 --> 00:07:12.020
in 80 milliseconds.

00:07:12.020 --> 00:07:15.380
We've actually evolved to have
faster peripheral vision for

00:07:15.380 --> 00:07:18.240
detecting motion in objects
because of tigers.

00:07:18.240 --> 00:07:22.800
There's a very legitimate for
this is all the people who had

00:07:22.800 --> 00:07:25.720
vision that was uniform,
between central and

00:07:25.720 --> 00:07:27.180
peripheral, they'll get
killed by tigers and

00:07:27.180 --> 00:07:28.340
the rest of us survived.

00:07:28.340 --> 00:07:31.540
And we're very good at seeing
movement and change in our

00:07:31.540 --> 00:07:32.410
peripheral vision.

00:07:32.410 --> 00:07:34.000
It's highly tuned for that.

00:07:34.000 --> 00:07:35.510
So what's this have to do
with interface design?

00:07:35.510 --> 00:07:38.320
Obviously, we don't exist in
environments where we have a

00:07:38.320 --> 00:07:39.390
lot of predators anymore.

00:07:39.390 --> 00:07:41.390
We're all information workers.

00:07:41.390 --> 00:07:43.890
But nonetheless, you can use
this in your design.

00:07:43.890 --> 00:07:45.990
So let's say that I'm
modifying this

00:07:45.990 --> 00:07:47.180
product-to-plan document.

00:07:47.180 --> 00:07:49.170
And then my PM shows up.

00:07:49.170 --> 00:07:50.640
And this is his actual
at avatar

00:07:50.640 --> 00:07:52.530
picture up in the corner--

00:07:52.530 --> 00:07:55.290
of the tiger, tying
it all together.

00:07:55.290 --> 00:07:57.110
And what's interesting about
this is it's actually easier

00:07:57.110 --> 00:07:59.290
for me to see that notification
of him arriving

00:07:59.290 --> 00:08:01.830
in the document, when that's
being cued off of my

00:08:01.830 --> 00:08:04.080
peripheral vision, verses if it
happened right in front of

00:08:04.080 --> 00:08:05.800
me as an editing text
and things.

00:08:05.800 --> 00:08:09.330
So that same effect of grabbing
the user's attention

00:08:09.330 --> 00:08:10.090
of notification--

00:08:10.090 --> 00:08:12.640
it's actually easier
in their periphery.

00:08:12.640 --> 00:08:14.900
So another new topic
related to vision--

00:08:14.900 --> 00:08:16.860
geons and object recognition.

00:08:16.860 --> 00:08:19.670
So we recognize a lot of
objects in the world.

00:08:19.670 --> 00:08:21.920
We're constantly encountering
new objects.

00:08:21.920 --> 00:08:24.040
There's millions, potentially
billions of them.

00:08:24.040 --> 00:08:27.150
So the question is how do we
actually store all of this in

00:08:27.150 --> 00:08:28.590
our own software?

00:08:28.590 --> 00:08:30.820
And this is some of the
most recent research.

00:08:30.820 --> 00:08:32.860
The idea is that we have a core

00:08:32.860 --> 00:08:34.980
vocabulary geometric objects.

00:08:34.980 --> 00:08:36.679
And people argue about
the exact number

00:08:36.679 --> 00:08:38.230
of how many it is.

00:08:38.230 --> 00:08:40.260
But people are gravitating
towards there

00:08:40.260 --> 00:08:42.070
maybe being 24 of them.

00:08:42.070 --> 00:08:43.309
And even just 24--

00:08:43.309 --> 00:08:45.210
any three of them, you could
create greater than 306

00:08:45.210 --> 00:08:47.210
billion combinations.

00:08:47.210 --> 00:08:49.340
So that's robust enough that
it could be working.

00:08:49.340 --> 00:08:51.340
But basically the idea is when
you look at an object, you

00:08:51.340 --> 00:08:54.080
immediately break it down into
the geons that it contains.

00:08:54.080 --> 00:08:55.930
And then you use that
to do the look up of

00:08:55.930 --> 00:08:57.090
which object it is.

00:08:57.090 --> 00:08:59.800
So here you got cylinder
and the curved candle.

00:08:59.800 --> 00:09:01.730
You do that look up and
say, oh, it's a cup.

00:09:01.730 --> 00:09:04.510
And this applies to even more
complicated objects, where, as

00:09:04.510 --> 00:09:06.320
you're perceiving it, you're
constantly just breaking it

00:09:06.320 --> 00:09:08.750
down into the various core
geometric objects and then

00:09:08.750 --> 00:09:10.360
using that for recognition.

00:09:10.360 --> 00:09:12.040
So what's interesting
about this--

00:09:12.040 --> 00:09:12.970
not exactly tigers.

00:09:12.970 --> 00:09:17.330
But you will recognize the
silhouette, the basic geometry

00:09:17.330 --> 00:09:20.420
of the shape, faster than you'll
recognize an icon that

00:09:20.420 --> 00:09:23.230
is more photo-realistic
or rendered.

00:09:23.230 --> 00:09:25.630
Now it's a very small
difference.

00:09:25.630 --> 00:09:27.240
So you might have been able
to perceive it as

00:09:27.240 --> 00:09:28.890
you're watching yourself.

00:09:28.890 --> 00:09:31.120
But nonetheless it's kind of
interesting that, if you

00:09:31.120 --> 00:09:34.150
really care about speed and
subtlety and having a truly

00:09:34.150 --> 00:09:37.810
optimized design, these sort of
silhouette, basic geometry

00:09:37.810 --> 00:09:40.580
shapes actually do recognize
faster for the user.

00:09:40.580 --> 00:09:43.120
And this is also--

00:09:43.120 --> 00:09:45.310
there's a lot of aesthetic
reasons why you might want to

00:09:45.310 --> 00:09:46.640
use one versus the other.

00:09:46.640 --> 00:09:48.350
For instance, on the Android
home screen, where we can't

00:09:48.350 --> 00:09:51.410
control the background, we opt
for using the more rendered

00:09:51.410 --> 00:09:53.760
icons because they have better
contrast on variety of

00:09:53.760 --> 00:09:54.890
backgrounds.

00:09:54.890 --> 00:09:57.970
But also on Android, the hollow
icon set is entirely

00:09:57.970 --> 00:10:01.420
this flat icon style, in part
due to aesthetics and also in

00:10:01.420 --> 00:10:03.310
part due to this recognition.

00:10:03.310 --> 00:10:05.280
So you can very quickly
spot things in here--

00:10:05.280 --> 00:10:08.110
camera or joystick or battery.

00:10:08.110 --> 00:10:10.030
As soon as you see these things,
you very immediately

00:10:10.030 --> 00:10:12.220
know what they are.

00:10:12.220 --> 00:10:14.170
So another type of object
recognition we do is facial

00:10:14.170 --> 00:10:14.860
recognition.

00:10:14.860 --> 00:10:16.380
And this is actually done
on a completely

00:10:16.380 --> 00:10:18.110
separate hardware path.

00:10:18.110 --> 00:10:19.890
You're not looking at someone's
face and breaking it

00:10:19.890 --> 00:10:21.270
down into various geometric
objects.

00:10:21.270 --> 00:10:24.320
You have an entirely separate
set of hardware in your mind

00:10:24.320 --> 00:10:27.720
that's purely dedicated
recognizing faces.

00:10:27.720 --> 00:10:30.850
So let's take you into
another test chamber.

00:10:30.850 --> 00:10:32.330
At this point, you're
really worried.

00:10:32.330 --> 00:10:35.540
And you go in, and you think,
oh my god, it's

00:10:35.540 --> 00:10:37.200
full stock-art people.

00:10:37.200 --> 00:10:38.970
And they're all walking
towards me--

00:10:38.970 --> 00:10:40.140
even worse than tigers.

00:10:40.140 --> 00:10:43.220
And in this test, it is
all stock-art people.

00:10:43.220 --> 00:10:46.980
And they're kind of
creepy perfection.

00:10:46.980 --> 00:10:49.000
But there's one person and
who's actually a friend.

00:10:49.000 --> 00:10:51.420
And the test is how quickly do
you see your friend as all

00:10:51.420 --> 00:10:52.920
these people walk towards you.

00:10:52.920 --> 00:10:54.260
And you'll see them
very quickly.

00:10:54.260 --> 00:10:56.270
You've probably have already
about perceived this at the

00:10:56.270 --> 00:10:58.050
conference, where various people
conference-- you're

00:10:58.050 --> 00:10:59.810
seeing a lot of cases,
obviously.

00:10:59.810 --> 00:11:01.740
But you'll quickly spot these
people that you know.

00:11:01.740 --> 00:11:03.440
You might not remember their
name, which is a whole

00:11:03.440 --> 00:11:04.350
different thing.

00:11:04.350 --> 00:11:07.130
But you'll definitely know that
you recognize them as

00:11:07.130 --> 00:11:09.190
someone that you've
met before.

00:11:09.190 --> 00:11:11.390
And you're able to do this by
taking in all the faces

00:11:11.390 --> 00:11:13.650
simultaneously, which is
also very interesting.

00:11:13.650 --> 00:11:16.830
You're not having to do a very
linear scan between each face

00:11:16.830 --> 00:11:17.950
to process it.

00:11:17.950 --> 00:11:19.830
This is all just happening in
the background, on the full

00:11:19.830 --> 00:11:21.050
visual field.

00:11:21.050 --> 00:11:24.490
So in terms of implications
for interface design--

00:11:24.490 --> 00:11:27.270
if you're looking to see a
particular email came in from

00:11:27.270 --> 00:11:29.970
say James or Ruth, with this
type of design you're going to

00:11:29.970 --> 00:11:32.080
have to do when your scan
down the list and

00:11:32.080 --> 00:11:33.360
read each of the names.

00:11:33.360 --> 00:11:36.430
But if we start using faces,
then you can get that effect

00:11:36.430 --> 00:11:38.130
of all the hardware that
we had built for facial

00:11:38.130 --> 00:11:39.130
recognition.

00:11:39.130 --> 00:11:41.290
So for instance, the
Glass Timeline--

00:11:41.290 --> 00:11:43.410
as you're browsing through it,
you can very quickly find

00:11:43.410 --> 00:11:45.250
particular pieces of information
because of those

00:11:45.250 --> 00:11:46.070
pictures of faces.

00:11:46.070 --> 00:11:47.980
So if you're looking for a
lunch appointment, you'll

00:11:47.980 --> 00:11:50.610
recognize Richard there and
you'll see a very quickly.

00:11:50.610 --> 00:11:54.060
And you don't have to do that
scan as you would for text.

00:11:54.060 --> 00:11:55.600
So any new topic related
to vision--

00:11:55.600 --> 00:11:57.480
perceived affordances.

00:11:57.480 --> 00:11:59.620
Every single time people talk
about perceived affordances,

00:11:59.620 --> 00:12:01.360
they talk about doorknobs.

00:12:01.360 --> 00:12:03.340
I'm starting to think that maybe
people think it's only

00:12:03.340 --> 00:12:03.950
about doorknobs.

00:12:03.950 --> 00:12:07.210
So we'll do a whole
new example.

00:12:07.210 --> 00:12:08.170
So again, test chamber.

00:12:08.170 --> 00:12:09.220
And yeah, there's
not a doorknob.

00:12:09.220 --> 00:12:10.440
That's not the test.

00:12:10.440 --> 00:12:12.030
You have to go through door.

00:12:12.030 --> 00:12:13.990
And the way you figure out how
to go through the door is a

00:12:13.990 --> 00:12:16.410
perceived affordance because you
see the physics of how the

00:12:16.410 --> 00:12:17.520
thing's going to slide.

00:12:17.520 --> 00:12:19.160
But you go into the
test chamber.

00:12:19.160 --> 00:12:21.990
And there's pieces of trash
on the ground floor or

00:12:21.990 --> 00:12:22.780
some type of object.

00:12:22.780 --> 00:12:24.090
And what we're trying
to figure is,

00:12:24.090 --> 00:12:26.210
do you recycle correctly?

00:12:26.210 --> 00:12:27.900
And the answer is, usually no.

00:12:27.900 --> 00:12:29.770
People are actually pretty
lazy about this.

00:12:29.770 --> 00:12:30.270
They're busy.

00:12:30.270 --> 00:12:31.860
They're thinking about
other things.

00:12:31.860 --> 00:12:33.000
They just look at all
the trash cans and

00:12:33.000 --> 00:12:34.380
just throw it in one.

00:12:34.380 --> 00:12:37.430
What's interesting, though, is
if you change the trash cans

00:12:37.430 --> 00:12:40.350
to have slots that match roughly
the types of objects

00:12:40.350 --> 00:12:42.840
that should go in them,
recycling actually goes up

00:12:42.840 --> 00:12:45.730
34%, or correct recycling.

00:12:45.730 --> 00:12:48.520
Because, as you're holding a
piece of paper, you just sort

00:12:48.520 --> 00:12:51.150
of think, yes that is where
I should put this.

00:12:51.150 --> 00:12:53.230
And you slide it in.

00:12:53.230 --> 00:12:55.090
And you're doing this processing
very quickly, just

00:12:55.090 --> 00:12:57.250
as you look at a doorknob, you
make immediate inferences

00:12:57.250 --> 00:12:58.600
about its physics, on if
you're supposed to

00:12:58.600 --> 00:13:00.310
push or pull it.

00:13:00.310 --> 00:13:02.140
So an image that, of course,
had been circling around

00:13:02.140 --> 00:13:04.370
inside of Google--

00:13:04.370 --> 00:13:06.960
Sometimes hiring the smartest
people isn't enough, where,

00:13:06.960 --> 00:13:10.410
no, the milk jug is
not compostable.

00:13:10.410 --> 00:13:12.290
But I would argue, first of
all, they were probably

00:13:12.290 --> 00:13:14.180
thinking about a very hard
computer science problem as

00:13:14.180 --> 00:13:15.180
they did this.

00:13:15.180 --> 00:13:17.100
And secondly, based on perceived
affordances, that

00:13:17.100 --> 00:13:19.940
was the correct slot for
something milk jug sized.

00:13:19.940 --> 00:13:21.540
They were doing all
that processing.

00:13:21.540 --> 00:13:22.920
They just weren't reading
any signs or

00:13:22.920 --> 00:13:24.230
really paying attention.

00:13:24.230 --> 00:13:26.350
And these types of perceived
affordances obviously have a

00:13:26.350 --> 00:13:27.770
lot of impact in the
physical world for

00:13:27.770 --> 00:13:29.270
doors and trash cans.

00:13:29.270 --> 00:13:31.180
But they also have an impact
in the virtual world, with

00:13:31.180 --> 00:13:34.670
things like buttons, sliders,
where can see the physics of

00:13:34.670 --> 00:13:36.630
the object as you
just take it in.

00:13:36.630 --> 00:13:39.360
And it immediately visually
conveys to you how you

00:13:39.360 --> 00:13:40.790
interact with it--

00:13:40.790 --> 00:13:44.360
on and off switches, or even a
check box that can or cannot

00:13:44.360 --> 00:13:47.030
contain a check inside of it.

00:13:47.030 --> 00:13:50.700
So another topic about vision--
color deficiency.

00:13:50.700 --> 00:13:52.630
So most of us in the room
have three cones--

00:13:52.630 --> 00:13:54.630
tri-chromatic vision.

00:13:54.630 --> 00:13:56.600
And some of us in the room will
have two cones, where you

00:13:56.600 --> 00:14:00.080
could-- most commonly, you'll
lose either the perception of

00:14:00.080 --> 00:14:01.220
red or perception of green.

00:14:01.220 --> 00:14:04.310
It's also possible to
lose perception of

00:14:04.310 --> 00:14:06.780
blue, although that's--

00:14:06.780 --> 00:14:07.430
its more rare--

00:14:07.430 --> 00:14:08.600
Tritanopia.

00:14:08.600 --> 00:14:13.630
So there's a general the
misconception that when you're

00:14:13.630 --> 00:14:15.420
colorblind, you actually
perceive the world in

00:14:15.420 --> 00:14:17.430
monochrome, which is not true.

00:14:17.430 --> 00:14:19.726
It's much more common to only
lose one of your cones through

00:14:19.726 --> 00:14:21.090
a mutation.

00:14:21.090 --> 00:14:23.130
And there's also a general
perception that you shouldn't

00:14:23.130 --> 00:14:26.130
use red-green differences
in your interface.

00:14:26.130 --> 00:14:29.580
So let's look at an interface it
uses red-green differences.

00:14:29.580 --> 00:14:31.920
And we can very easily simulate
what this appears for

00:14:31.920 --> 00:14:35.540
someone of Deuteranopia or
Protanopia or Tritanopia.

00:14:35.540 --> 00:14:39.280
And the reason it works is
there's more than just color

00:14:39.280 --> 00:14:39.830
in the values.

00:14:39.830 --> 00:14:41.690
You also have the level
of contrast.

00:14:41.690 --> 00:14:43.720
So even though you're losing
that red-green difference,

00:14:43.720 --> 00:14:46.500
you're having very clear
contrast differences.

00:14:46.500 --> 00:14:48.420
So instead of just making
assumptions on which covers

00:14:48.420 --> 00:14:49.430
you should or shouldn't use.

00:14:49.430 --> 00:14:51.640
It's better to just run them
through filters, your

00:14:51.640 --> 00:14:53.810
interface, see what it actually
looks like for people

00:14:53.810 --> 00:14:55.650
in that population set,
make sure things

00:14:55.650 --> 00:14:57.380
are working out OK.

00:14:57.380 --> 00:15:00.610
And there's a lot of-- if go
online and just search for it.

00:15:00.610 --> 00:15:03.740
There's a lot SVG filters that
you can apply to an image to

00:15:03.740 --> 00:15:04.510
see the change.

00:15:04.510 --> 00:15:05.870
There's a java application
that you can

00:15:05.870 --> 00:15:07.410
download to do it locally.

00:15:07.410 --> 00:15:08.400
Or if you have Photoshop--

00:15:08.400 --> 00:15:09.430
amazingly enough, it's actually

00:15:09.430 --> 00:15:11.470
in the menu of Photoshop.

00:15:11.470 --> 00:15:13.530
As I was researching this,
I was kind of surprised.

00:15:13.530 --> 00:15:14.850
I had never seen this before.

00:15:14.850 --> 00:15:17.220
You can just go to View, Proof
Set Up, and actually--

00:15:17.220 --> 00:15:18.220
unfortunately for
the people with

00:15:18.220 --> 00:15:20.320
Tritanopia, they aren't included.

00:15:20.320 --> 00:15:23.180
But [INAUDIBLE] very easy if you
have Photoshop to quickly

00:15:23.180 --> 00:15:24.540
check out an interface.

00:15:24.540 --> 00:15:26.980
And what's sort of interesting
is a mutation causes you to

00:15:26.980 --> 00:15:29.940
have two cones versus three.

00:15:29.940 --> 00:15:31.280
But you can also have
a mutation it

00:15:31.280 --> 00:15:33.150
gives you four cones--

00:15:33.150 --> 00:15:37.070
tetrachromats that have
superhuman color vision, which

00:15:37.070 --> 00:15:39.930
is really cool because each
cone gives you about 100

00:15:39.930 --> 00:15:40.770
ranges of color.

00:15:40.770 --> 00:15:43.620
So we all have about a million
colors that we can perceive.

00:15:43.620 --> 00:15:46.760
Tetrachromats can perceive 100
million colors because of

00:15:46.760 --> 00:15:48.320
their fourth cone.

00:15:48.320 --> 00:15:51.250
And this is also extremely
common in other species.

00:15:51.250 --> 00:15:53.890
Birds, for instance, all
have four cones.

00:15:53.890 --> 00:15:55.120
The fact that we have
three primary

00:15:55.120 --> 00:15:56.750
colors is kind of arbitrary.

00:15:56.750 --> 00:15:58.480
If we were a society of
birds, we would have

00:15:58.480 --> 00:15:59.820
four primary colors.

00:15:59.820 --> 00:16:02.190
Birds can perceive ultraviolet
light.

00:16:02.190 --> 00:16:03.830
There's no design implication
here.

00:16:03.830 --> 00:16:05.120
It's just cool.

00:16:05.120 --> 00:16:06.470
So moving on--

00:16:06.470 --> 00:16:09.570
colors and culture.

00:16:09.570 --> 00:16:10.450
This is not innate.

00:16:10.450 --> 00:16:13.610
It's something that's
learned over time.

00:16:13.610 --> 00:16:15.940
Concepts like to red, at least
in the West, are usually

00:16:15.940 --> 00:16:17.330
pretty negative.

00:16:17.330 --> 00:16:21.420
Red tape, in the red, these
types of phrases.

00:16:21.420 --> 00:16:22.640
Whereas in Japan,
red is actually

00:16:22.640 --> 00:16:24.160
very celebratory color.

00:16:24.160 --> 00:16:26.450
It has connotations
of lanterns and

00:16:26.450 --> 00:16:28.140
festivals and happiness.

00:16:28.140 --> 00:16:30.120
Of course, their stop signs are
still red for consistency.

00:16:30.120 --> 00:16:31.870
I guess those are more
celebratory stop signs.

00:16:31.870 --> 00:16:34.630
But they've a very
advanced culture.

00:16:34.630 --> 00:16:37.610
But it's important to sort of
think about the various

00:16:37.610 --> 00:16:39.770
implications of the colors
that you're choosing.

00:16:39.770 --> 00:16:41.120
But that's not true
for all colors.

00:16:41.120 --> 00:16:42.880
Other colors are
more universal.

00:16:42.880 --> 00:16:45.510
For instance, gold
is universal and

00:16:45.510 --> 00:16:46.210
not just as a color.

00:16:46.210 --> 00:16:48.670
But it's sort of universal
in the universe.

00:16:48.670 --> 00:16:51.090
And this has implications on
Android design, where we use

00:16:51.090 --> 00:16:54.590
gold to mean the
monetary value.

00:16:54.590 --> 00:16:59.000
This of course localizes very
well to pirates as well.

00:16:59.000 --> 00:17:00.940
So let's go on Selective
Visual Variables--

00:17:00.940 --> 00:17:02.550
another test chamber.

00:17:02.550 --> 00:17:03.870
Now this is a great
test chamber.

00:17:03.870 --> 00:17:06.609
This is a test chamber that you
actually get to go into.

00:17:06.609 --> 00:17:09.670
And the winners will get
Android plushies.

00:17:09.670 --> 00:17:13.450
So hopefully you'll win.

00:17:13.450 --> 00:17:14.430
The task is--

00:17:14.430 --> 00:17:17.730
I'm going to show you a range
of letters and numbers.

00:17:17.730 --> 00:17:20.540
And the first person to
correctly shout out how many

00:17:20.540 --> 00:17:23.150
red letters or numbers
there are, just red

00:17:23.150 --> 00:17:25.060
shapes total, wins.

00:17:25.060 --> 00:17:26.290
And I'll time you.

00:17:26.290 --> 00:17:28.870
So--

00:17:28.870 --> 00:17:30.462
we'll see how long
this takes you.

00:17:30.462 --> 00:17:30.920
All right.

00:17:30.920 --> 00:17:32.170
Begin.

00:17:35.776 --> 00:17:37.930
[AUDIENCE SHOUTING ANSWERS]

00:17:37.930 --> 00:17:39.720
21 over here.

00:17:39.720 --> 00:17:41.140
Who was the person
who said 21?

00:17:41.140 --> 00:17:41.952
You?

00:17:41.952 --> 00:17:42.360
All right.

00:17:42.360 --> 00:17:45.885
There you go.

00:17:45.885 --> 00:17:48.150
Sorry, Angela's going to
help me hand it out.

00:17:48.150 --> 00:17:49.130
OK.

00:17:49.130 --> 00:17:49.990
Let's try again.

00:17:49.990 --> 00:17:52.960
And that took about
15 seconds.

00:17:52.960 --> 00:17:53.380
All right.

00:17:53.380 --> 00:17:58.178
Your next task is how
many G's are there.

00:17:58.178 --> 00:18:09.002
[AUDIENCE SHOUTING ANSWERS]

00:18:09.002 --> 00:18:09.500
All right.

00:18:09.500 --> 00:18:10.995
16.

00:18:10.995 --> 00:18:11.695
Who is--

00:18:11.695 --> 00:18:13.300
Who's the person who
said 16 over here?

00:18:13.300 --> 00:18:13.630
Yep.

00:18:13.630 --> 00:18:15.720
You're right.

00:18:15.720 --> 00:18:17.920
OK.

00:18:17.920 --> 00:18:22.070
That took you about 20 seconds
and there were less of them.

00:18:22.070 --> 00:18:24.530
And you were all shouting out
completely random numbers were

00:18:24.530 --> 00:18:27.222
not accurate at all.

00:18:27.222 --> 00:18:30.760
So the implication for this is
that color is a selective

00:18:30.760 --> 00:18:32.980
visual variable, while
shape is not.

00:18:32.980 --> 00:18:34.660
In computer science
terms, you can per

00:18:34.660 --> 00:18:37.190
color in constant time.

00:18:37.190 --> 00:18:39.010
Going back to the spread.

00:18:39.010 --> 00:18:41.740
As you look at it, the color's
all coming in, just as you can

00:18:41.740 --> 00:18:43.830
do face recognition
constant time.

00:18:43.830 --> 00:18:47.550
Whereas for shape, you're having
to do a very clear

00:18:47.550 --> 00:18:48.990
linear scan-- look this shape.

00:18:48.990 --> 00:18:49.315
Is it a G?

00:18:49.315 --> 00:18:49.680
No.

00:18:49.680 --> 00:18:50.400
Move onto the next.

00:18:50.400 --> 00:18:50.885
Is it a G?

00:18:50.885 --> 00:18:52.120
No.

00:18:52.120 --> 00:18:55.310
So this is an important effect
for your interfaces, this type

00:18:55.310 --> 00:18:57.950
of visual processing, that if
someone's looking for shapes

00:18:57.950 --> 00:19:00.320
they're going to have to
do that linear scan.

00:19:00.320 --> 00:19:02.790
So the implication for
Google search--

00:19:02.790 --> 00:19:08.880
by using color for title and
then also for the domain, the

00:19:08.880 --> 00:19:12.980
full URL, you're able to then
very quickly in your mind to

00:19:12.980 --> 00:19:15.320
do a selective--

00:19:15.320 --> 00:19:16.860
it's sort of filtering
on that color and

00:19:16.860 --> 00:19:18.020
then scan just those.

00:19:18.020 --> 00:19:20.260
And you can pop to them, just
as you're popping tall with

00:19:20.260 --> 00:19:21.730
the red letters,
counting them.

00:19:21.730 --> 00:19:25.720
So if you're looking, for
instance, for berkeley.edu,

00:19:25.720 --> 00:19:29.040
you can say, not it, it, without
having to read any of

00:19:29.040 --> 00:19:30.700
the other information.

00:19:30.700 --> 00:19:32.110
That covers vision.

00:19:32.110 --> 00:19:34.956
Let's dive into the attention,
emotion, and memory.

00:19:34.956 --> 00:19:37.250
First, we'll talk
about attention.

00:19:37.250 --> 00:19:38.740
This is an fMRI machine.

00:19:38.740 --> 00:19:40.380
And what's really amazing about
this machine is we can

00:19:40.380 --> 00:19:43.390
actually look at the minds and
see how it's operating on a

00:19:43.390 --> 00:19:44.740
physiological level.

00:19:44.740 --> 00:19:45.990
And this is how we
know everything

00:19:45.990 --> 00:19:47.380
about how mind works.

00:19:47.380 --> 00:19:51.850
So very, very, rough, high level
overview of the mind--

00:19:51.850 --> 00:19:54.320
you have working memory and
you have long term memory.

00:19:54.320 --> 00:19:57.780
And that's a super
simplification.

00:19:57.780 --> 00:20:00.930
And now to make a bad analogy on
top of the simplification--

00:20:00.930 --> 00:20:04.440
working memory is kind of like
a clipboard on the computer.

00:20:04.440 --> 00:20:05.920
You store things there
for a moment.

00:20:05.920 --> 00:20:07.470
And then you're done
with them.

00:20:07.470 --> 00:20:09.830
Whereas long term memory is a
little bit more like storage.

00:20:09.830 --> 00:20:11.870
Now there's a lot of ways in
that it's not like storage.

00:20:11.870 --> 00:20:15.120
In fact, when you access your
memories you also modify them.

00:20:15.120 --> 00:20:18.170
So read and write are tied
together, which is one of the

00:20:18.170 --> 00:20:21.240
reasons that memory is so
unreliable, unlike a computer,

00:20:21.240 --> 00:20:24.070
where you're able to read
without writing to the file.

00:20:24.070 --> 00:20:26.875
Also sleeping is kind of like
defragmenting your hard drive.

00:20:26.875 --> 00:20:28.940
But this is rough analogy.

00:20:28.940 --> 00:20:32.700
So what's important about
working memory is the user is

00:20:32.700 --> 00:20:34.440
going to be strong things their
working memory as they

00:20:34.440 --> 00:20:35.830
go throughout their day--

00:20:35.830 --> 00:20:37.510
various things that they're
working on, software they're

00:20:37.510 --> 00:20:39.110
writing, variables--

00:20:39.110 --> 00:20:40.340
any number of things.

00:20:40.340 --> 00:20:43.700
And then if they receive an
interruption what happens is

00:20:43.700 --> 00:20:45.800
the interruption captures
their attention and the

00:20:45.800 --> 00:20:47.840
working memory fades away.

00:20:47.840 --> 00:20:50.790
So you wouldn't write software
that was actively deleting the

00:20:50.790 --> 00:20:52.380
contents of the clipboard,
right?

00:20:52.380 --> 00:20:54.120
You obviously care
about data loss.

00:20:54.120 --> 00:20:56.150
But when you create interruptive
notifications,

00:20:56.150 --> 00:20:56.900
that's what you're doing.

00:20:56.900 --> 00:20:59.070
You're deleting the clipboard
of the user's minds.

00:20:59.070 --> 00:21:02.390
And this is why interruptions
can be so dangerous and cause

00:21:02.390 --> 00:21:04.610
people to be very ineffective
throughout their day, if

00:21:04.610 --> 00:21:06.510
they're constantly getting
email toasts and they're

00:21:06.510 --> 00:21:08.500
running around putting
out fires.

00:21:08.500 --> 00:21:09.890
You're doing a lot of thrashing

00:21:09.890 --> 00:21:10.700
on the user's thread.

00:21:10.700 --> 00:21:13.680
And they're losing a lot of
data, as the thing that they

00:21:13.680 --> 00:21:14.930
were storing was lost.

00:21:17.530 --> 00:21:20.000
So another aspect related to
working memory is chunking.

00:21:20.000 --> 00:21:21.950
Basically what we're doing here
is because you're working

00:21:21.950 --> 00:21:24.200
memory so limited in size,
you're putting things on it

00:21:24.200 --> 00:21:25.745
and then taking them
off quickly.

00:21:25.745 --> 00:21:28.150
So I was trying to find an
example in Google products--

00:21:28.150 --> 00:21:29.880
a little bit hard because we
don't have a lot of serial

00:21:29.880 --> 00:21:30.600
numbers or anything.

00:21:30.600 --> 00:21:33.340
But for two factor
authentication, when you have

00:21:33.340 --> 00:21:36.400
a recovery password, we
chunk it, based off

00:21:36.400 --> 00:21:37.930
of four letter sequences.

00:21:37.930 --> 00:21:39.860
So it's easier for you
to then write it in.

00:21:39.860 --> 00:21:40.930
If we didn't have
these spaces, it

00:21:40.930 --> 00:21:41.740
would be very difficult.

00:21:41.740 --> 00:21:44.020
You'd be grabbing as much as you
could possibly store and

00:21:44.020 --> 00:21:46.340
then going back and trying to
find where you left off.

00:21:46.340 --> 00:21:48.780
More commonly you see this
of credit card numbers.

00:21:48.780 --> 00:21:51.540
If you ever create an
application that doesn't let

00:21:51.540 --> 00:21:53.980
the user enter spaces on a
credit card number, you're a

00:21:53.980 --> 00:21:56.190
very bad developer.

00:21:56.190 --> 00:21:59.165
Also, if you actually generate
an error because they entered

00:21:59.165 --> 00:22:01.310
spaces, you're just a
horrifically bad developer.

00:22:01.310 --> 00:22:03.690
So please, please,
don't do that.

00:22:03.690 --> 00:22:05.300
It doesn't matter how
smart the user is.

00:22:05.300 --> 00:22:06.410
They could be brilliant.

00:22:06.410 --> 00:22:09.010
They still have a limited
working memory, as we all do.

00:22:09.010 --> 00:22:13.490
And we rely on, in this case,
Gestalt Proximity with the

00:22:13.490 --> 00:22:16.010
white space, for being able to
grab the various chunks and

00:22:16.010 --> 00:22:17.650
move them over.

00:22:17.650 --> 00:22:21.590
In other aspects related to
memory is interruptions and

00:22:21.590 --> 00:22:23.560
the concept of flow.

00:22:23.560 --> 00:22:25.645
So as the user is holding
their working memory and

00:22:25.645 --> 00:22:28.500
they're doing these creative
tasks, if they're really

00:22:28.500 --> 00:22:30.660
focused they can get into this
particular psychological state

00:22:30.660 --> 00:22:32.390
called flow.

00:22:32.390 --> 00:22:33.390
It has a few attributes.

00:22:33.390 --> 00:22:34.860
Usually have a very clear
goal when you're

00:22:34.860 --> 00:22:36.130
doing creative work.

00:22:36.130 --> 00:22:37.250
You're very focused.

00:22:37.250 --> 00:22:39.200
You're receiving constant
feedback.

00:22:39.200 --> 00:22:41.240
And this also affects your
perception of time, when some

00:22:41.240 --> 00:22:43.450
people report that time almost
seems to stand still when

00:22:43.450 --> 00:22:45.280
they're in this state, whereas
other people report that time

00:22:45.280 --> 00:22:46.890
goes extremely quickly.

00:22:46.890 --> 00:22:49.200
So, for instance, when you're
playing a musical instrument,

00:22:49.200 --> 00:22:51.130
if you're very good instrument,
you're not

00:22:51.130 --> 00:22:53.100
actually thinking about the
sort of physicality of the

00:22:53.100 --> 00:22:53.900
instrument itself.

00:22:53.900 --> 00:22:55.540
You're just creating music.

00:22:55.540 --> 00:22:58.250
Or perhaps a more common
example-- if you're playing a

00:22:58.250 --> 00:23:01.080
video game, you don't think
about the controller.

00:23:01.080 --> 00:23:03.720
You get lost in the narrative
of the game and you start to

00:23:03.720 --> 00:23:05.770
have the world kind
of fade away.

00:23:05.770 --> 00:23:06.700
Same with reading a book.

00:23:06.700 --> 00:23:08.950
You to think about turning the
pages, just sort of lost in

00:23:08.950 --> 00:23:09.920
the narrative of the book.

00:23:09.920 --> 00:23:11.640
And, of course, same with
writing software, where you're

00:23:11.640 --> 00:23:14.310
not really thinking about all
the tools you're using.

00:23:14.310 --> 00:23:16.440
You're thinking about the
creative endeavor of writing

00:23:16.440 --> 00:23:17.550
the software.

00:23:17.550 --> 00:23:21.220
And what's important is when
you create interactive

00:23:21.220 --> 00:23:24.160
notification, you're not just
deleting the working memory,

00:23:24.160 --> 00:23:25.610
you're also pulling
them out of flow.

00:23:25.610 --> 00:23:27.750
And it can actually take quite
some time for them to get back

00:23:27.750 --> 00:23:30.580
into the psychological state.

00:23:30.580 --> 00:23:32.930
So another topic related to
attention is line length and

00:23:32.930 --> 00:23:33.980
reading speed.

00:23:33.980 --> 00:23:35.360
There've been a lot of
studies on this.

00:23:35.360 --> 00:23:37.800
So if you have very lines of
text, people can consume

00:23:37.800 --> 00:23:39.650
information faster.

00:23:39.650 --> 00:23:41.510
So for instance, Google News
here, as you're reading these

00:23:41.510 --> 00:23:43.940
headlines you can fly through
them because you don't have to

00:23:43.940 --> 00:23:45.570
do a break onto the next one.

00:23:45.570 --> 00:23:49.110
However, if you ask people what
they prefer, they say

00:23:49.110 --> 00:23:50.960
they prefer shorter lines.

00:23:50.960 --> 00:23:53.530
So it's this, are we force
feeding them information or

00:23:53.530 --> 00:23:55.990
not argument, where, yes,
they're are more efficient and

00:23:55.990 --> 00:23:57.440
optimal with long lines.

00:23:57.440 --> 00:23:59.060
But it's not as comfortable.

00:23:59.060 --> 00:24:02.420
So you see an application like
Currents on Android, which is

00:24:02.420 --> 00:24:03.740
a new news reading app.

00:24:03.740 --> 00:24:06.325
By having very short lines of
text, it becomes a more casual

00:24:06.325 --> 00:24:08.320
and browsable interface.

00:24:08.320 --> 00:24:12.920
And it's not as intense as
reading these very long ones.

00:24:12.920 --> 00:24:14.745
So moving over into emotion--

00:24:14.745 --> 00:24:17.050
one of the first aspects
of emotion is trust.

00:24:17.050 --> 00:24:22.980
And just as we're designed to
recognize tigers very quickly,

00:24:22.980 --> 00:24:26.510
we're also designed to make
trust decisions very quickly

00:24:26.510 --> 00:24:29.590
because we evolved in a state
where we had to decide, is

00:24:29.590 --> 00:24:30.750
this thing going to kill me?

00:24:30.750 --> 00:24:32.360
Can I eat this thing?

00:24:32.360 --> 00:24:33.990
These were very basic
decisions.

00:24:33.990 --> 00:24:36.080
We had to them very quickly.

00:24:36.080 --> 00:24:37.350
We don't have to make them
quickly anymore, but

00:24:37.350 --> 00:24:40.220
nonetheless these first
impressions start to stick,

00:24:40.220 --> 00:24:42.190
where you're choosing a bank.

00:24:42.190 --> 00:24:44.880
And you look at this bank and
you think, well they clearly

00:24:44.880 --> 00:24:47.060
been around for a while, perhaps
a few centuries, based

00:24:47.060 --> 00:24:49.450
off of that column.

00:24:49.450 --> 00:24:52.150
And if it gets really windy,
like my money's not going to

00:24:52.150 --> 00:24:54.610
blow over, because it's
very, very sturdy.

00:24:54.610 --> 00:24:55.730
So this is probably good bank.

00:24:55.730 --> 00:24:58.180
And maybe it's a horrendously
corrupt bank.

00:24:58.180 --> 00:25:01.230
But you form of these immediate
trust decisions.

00:25:01.230 --> 00:25:03.630
This comes into play in the
virtual world as well.

00:25:03.630 --> 00:25:05.290
Let's say you're writing
financial software.

00:25:05.290 --> 00:25:06.880
And the user has to decide
which of these two

00:25:06.880 --> 00:25:08.130
applications they trust.

00:25:10.520 --> 00:25:12.870
And they don't know anything
else, like the developer could

00:25:12.870 --> 00:25:16.220
be brilliant and also indie
and not corrupt at all and

00:25:16.220 --> 00:25:18.770
writing really good stuff
with Money Pro

00:25:18.770 --> 00:25:21.150
using Comic Sans and--

00:25:21.150 --> 00:25:23.580
versus this one, where it's a
3D render and has little bit

00:25:23.580 --> 00:25:24.000
of texture.

00:25:24.000 --> 00:25:25.120
And it's just a great icon.

00:25:25.120 --> 00:25:27.710
And what's interesting is once
you formed that decision on

00:25:27.710 --> 00:25:30.510
which one you trust, then as
we give you additional

00:25:30.510 --> 00:25:34.030
information, you start to tell
yourself these made up stories

00:25:34.030 --> 00:25:36.580
to try to justify your
original assumption.

00:25:36.580 --> 00:25:39.740
So we say, well look Money Pro's
got four stars, whereas

00:25:39.740 --> 00:25:41.390
this one only one.

00:25:41.390 --> 00:25:43.850
You say, well yeah but maybe
this one didn't work on all

00:25:43.850 --> 00:25:44.940
the devices.

00:25:44.940 --> 00:25:46.200
Those people are just
mad because they

00:25:46.200 --> 00:25:47.600
couldn't have its greatness.

00:25:47.600 --> 00:25:48.940
Or maybe it's really
expensive.

00:25:48.940 --> 00:25:49.690
I haven't looked at
the price yet.

00:25:49.690 --> 00:25:50.500
And they're just mad.

00:25:50.500 --> 00:25:52.530
So you start to create these
theories, even though we've

00:25:52.530 --> 00:25:54.140
given you evidence that,
not, that one's better.

00:25:54.140 --> 00:25:56.220
You've already made your
initial trust decision.

00:25:56.220 --> 00:25:59.590
So the obvious implication
here is first impressions

00:25:59.590 --> 00:26:02.400
matter a lot, especially for
interfaces like an app store,

00:26:02.400 --> 00:26:05.070
where people are very quickly
choosing one amongst others.

00:26:05.070 --> 00:26:09.040
It's very worthwhile to invest
in your application icon and

00:26:09.040 --> 00:26:14.140
create that very first
impression, to be very solid.

00:26:14.140 --> 00:26:16.130
So text and culture--

00:26:16.130 --> 00:26:19.040
not innate but learned
over time.

00:26:19.040 --> 00:26:22.840
Obviously, we think about
threads and exceptions and all

00:26:22.840 --> 00:26:25.870
this terminology and jargon
of software development.

00:26:25.870 --> 00:26:28.380
It's important to think about
the environment the user's in.

00:26:28.380 --> 00:26:31.140
If you create a dialogue box
that says, this application

00:26:31.140 --> 00:26:32.960
has performed an illegal
operation.

00:26:32.960 --> 00:26:35.520
You don't actually know the
geopolitical environment that

00:26:35.520 --> 00:26:36.200
the user's in.

00:26:36.200 --> 00:26:37.910
This might actually scare
them quite a bit.

00:26:37.910 --> 00:26:39.760
So please don't do that.

00:26:39.760 --> 00:26:41.420
Another great one is,

00:26:41.420 --> 00:26:44.860
unfortunately, earth has crashed.

00:26:44.860 --> 00:26:47.030
I was trying to crash Google
Earth to get that one.

00:26:47.030 --> 00:26:48.860
And I couldn't crash it.

00:26:48.860 --> 00:26:51.890
But, it does exist,
that dialog.

00:26:51.890 --> 00:26:54.820
Jumping over into memory,
off of attention--

00:26:54.820 --> 00:26:55.850
talking a little bit
about learning.

00:26:55.850 --> 00:26:59.300
So again, we have working memory
and long term memory.

00:26:59.300 --> 00:27:02.360
And the task here is to transfer
something that's just

00:27:02.360 --> 00:27:05.440
in the very transitory,
ephemeral working memory into

00:27:05.440 --> 00:27:06.180
your long term memory.

00:27:06.180 --> 00:27:07.470
And once we've done that
transfer, you've

00:27:07.470 --> 00:27:08.670
learned this new thing.

00:27:08.670 --> 00:27:09.910
And there's two ways
to do that.

00:27:09.910 --> 00:27:11.450
The first is to associate
it with something

00:27:11.450 --> 00:27:12.560
they already know.

00:27:12.560 --> 00:27:15.540
If you can form that linkage,
it'll transfer very quickly.

00:27:15.540 --> 00:27:17.720
And then if they don't have that
linkage yet, the second

00:27:17.720 --> 00:27:19.710
way to do it is through
repetition.

00:27:19.710 --> 00:27:23.100
So let's look at an example
in interface design.

00:27:23.100 --> 00:27:25.280
One of the things the users
immediately have to get used

00:27:25.280 --> 00:27:27.350
to on an Android is that all
their apps are in a separate

00:27:27.350 --> 00:27:28.850
place, whereas the
home screen is a

00:27:28.850 --> 00:27:30.830
customizable home for them.

00:27:30.830 --> 00:27:32.810
So we need to tell them
your apps are here.

00:27:32.810 --> 00:27:35.440
If you to get to one of your
apps, hit this button.

00:27:35.440 --> 00:27:36.877
This was a screen that
we rolled out

00:27:36.877 --> 00:27:37.660
in Ice Cream Sandwich.

00:27:37.660 --> 00:27:38.700
It actually doesn't
work very well.

00:27:38.700 --> 00:27:40.990
And reason for that is they
realized that they're blocked,

00:27:40.990 --> 00:27:42.270
so they don't read anything
and they just

00:27:42.270 --> 00:27:44.570
hit OK really quickly.

00:27:44.570 --> 00:27:45.430
There's no repetition.

00:27:45.430 --> 00:27:46.250
We only told them once.

00:27:46.250 --> 00:27:48.610
It wasn't linked to anything
there ready know.

00:27:48.610 --> 00:27:49.780
So they start to play
with the phone.

00:27:49.780 --> 00:27:52.160
And then they say, well
where are my apps?

00:27:52.160 --> 00:27:54.310
Then they proceed to hit
everything until they

00:27:54.310 --> 00:27:55.760
finally find it.

00:27:55.760 --> 00:27:58.450
So an alternative design
could be--

00:27:58.450 --> 00:28:00.950
we can't really to something
they know, so just repetition.

00:28:00.950 --> 00:28:04.420
If we just had this refrain for
the first number of times

00:28:04.420 --> 00:28:07.430
saying, all your apps are here,
that would start to set

00:28:07.430 --> 00:28:09.400
in after just a couple
of times.

00:28:09.400 --> 00:28:10.810
Or after they'd hit the Control,
then we'd stop

00:28:10.810 --> 00:28:11.270
showing it.

00:28:11.270 --> 00:28:12.450
By doing this--

00:28:12.450 --> 00:28:16.740
it's not as loud or as broad
as that intrusive,

00:28:16.740 --> 00:28:19.455
interruptive flow that
we initially had.

00:28:19.455 --> 00:28:21.660
But this would actually
perform better.

00:28:21.660 --> 00:28:24.860
It performs better because
of the repetition.

00:28:24.860 --> 00:28:26.570
Now if you're linking to
something that the user are

00:28:26.570 --> 00:28:30.840
already knows, it's OK to just
have a single reference that

00:28:30.840 --> 00:28:32.100
they might ignore.

00:28:32.100 --> 00:28:33.920
So for instance, let's say
you've already use the

00:28:33.920 --> 00:28:35.110
commenting system a lot.

00:28:35.110 --> 00:28:38.350
And now we say, you can also
chat with document

00:28:38.350 --> 00:28:38.920
collaborators.

00:28:38.920 --> 00:28:41.230
It's an adaptation of
something you've

00:28:41.230 --> 00:28:42.270
already been using.

00:28:42.270 --> 00:28:45.230
Here, because it links to that
existing knowledge, this'll

00:28:45.230 --> 00:28:46.960
perform pretty well, even
though it's just

00:28:46.960 --> 00:28:50.320
that one time interface.

00:28:50.320 --> 00:28:55.140
So another aspect of learning is
recognition versus recall.

00:28:55.140 --> 00:28:58.740
Now the classic example is the
command line versus graphical

00:28:58.740 --> 00:29:01.290
interface, where the command
line's very difficult because

00:29:01.290 --> 00:29:03.600
you have to, in your own memory,
remember all the

00:29:03.600 --> 00:29:06.320
commands are and access
them over time.

00:29:06.320 --> 00:29:06.850
And--

00:29:06.850 --> 00:29:08.580
it's actually a little bit more
complicated than that.

00:29:08.580 --> 00:29:08.950
That's true.

00:29:08.950 --> 00:29:09.860
But there's more going on.

00:29:09.860 --> 00:29:11.720
And essentially what we're
doing is cognitive load

00:29:11.720 --> 00:29:14.500
balancing, where in order
of difficulty,

00:29:14.500 --> 00:29:16.490
recall is very difficult.

00:29:16.490 --> 00:29:18.950
Visual targeting is moderately
difficult.

00:29:18.950 --> 00:29:20.970
And then movement
is very easy.

00:29:20.970 --> 00:29:24.200
So if we look at a variety of
interfaces, a command line

00:29:24.200 --> 00:29:26.330
versus the graphical interface,
the graphical

00:29:26.330 --> 00:29:28.370
interface is going to perform
better because it's mostly the

00:29:28.370 --> 00:29:30.200
visual targeting and movement.

00:29:30.200 --> 00:29:32.020
I can remember that there
are alignment tools.

00:29:32.020 --> 00:29:33.720
I can't remember what
they all are.

00:29:33.720 --> 00:29:38.040
But I'm able to look there and
say, oh OK, a line left, and

00:29:38.040 --> 00:29:39.090
hit that button.

00:29:39.090 --> 00:29:41.500
So it's a interplay between me
and the interface, where I'm

00:29:41.500 --> 00:29:42.460
remembering some things.

00:29:42.460 --> 00:29:44.340
It's remembering other
things for me.

00:29:44.340 --> 00:29:46.860
And it's able to augment my
memory because it's being

00:29:46.860 --> 00:29:48.140
shown graphically.

00:29:48.140 --> 00:29:50.610
And then the visual targeting
is a little bit of work.

00:29:50.610 --> 00:29:54.000
Interestingly, the voice
interfaces are, at least in

00:29:54.000 --> 00:29:56.970
terms of cognitive load, more
similar to a command line.

00:29:56.970 --> 00:29:59.870
The pulsing mic is kind of the
new blinking cursor because

00:29:59.870 --> 00:30:01.620
you have to remember, like for
instance what all the Android

00:30:01.620 --> 00:30:03.640
Voice Actions are.

00:30:03.640 --> 00:30:04.500
And--

00:30:04.500 --> 00:30:06.896
can anyone name all Android
Voice Actions?

00:30:06.896 --> 00:30:07.750
Yeah.

00:30:07.750 --> 00:30:12.330
So that's still, in the recall,
very high cognitive

00:30:12.330 --> 00:30:14.240
load category.

00:30:14.240 --> 00:30:16.740
And then also interestingly is
we're seeing interfaces that

00:30:16.740 --> 00:30:18.690
are in some ways just
about movement.

00:30:18.690 --> 00:30:20.690
So like invoking Google Now,
once you've learned that

00:30:20.690 --> 00:30:24.340
behavior, you don't even have
to do any visual targeting.

00:30:24.340 --> 00:30:26.380
You're just swiping directly
up off the bottom of the

00:30:26.380 --> 00:30:27.150
screen to do it.

00:30:27.150 --> 00:30:29.260
So it's in many ways one of the
easiest interfaces because

00:30:29.260 --> 00:30:32.480
it's only on that third track,
which was the easiest.

00:30:32.480 --> 00:30:35.000
Also swiping through the
timeline on Glass-- you're not

00:30:35.000 --> 00:30:36.900
doing very much visual targeting
because it's such

00:30:36.900 --> 00:30:38.450
low information density.

00:30:38.450 --> 00:30:40.860
And you just have the single
cards in the timeline.

00:30:40.860 --> 00:30:45.360
And you're just doing the gross
motor skills of Swipe or

00:30:45.360 --> 00:30:46.560
Accelerometer looking.

00:30:46.560 --> 00:30:49.200
So those are very easy
interfaces, at least in terms

00:30:49.200 --> 00:30:51.150
of cognitive load.

00:30:51.150 --> 00:30:53.640
Another topic I want to talk
about with learning is the

00:30:53.640 --> 00:30:55.710
notion of learning
with examples.

00:30:55.710 --> 00:30:58.360
Now, often people say, well,
we need to create this

00:30:58.360 --> 00:31:00.270
interface in this particular
way because it's similar to

00:31:00.270 --> 00:31:01.340
this other product
that exists.

00:31:01.340 --> 00:31:04.460
And users aren't going
to use it otherwise.

00:31:04.460 --> 00:31:06.660
That's not entirely true.

00:31:06.660 --> 00:31:08.130
You can show the user
an example of

00:31:08.130 --> 00:31:09.330
how something works.

00:31:09.330 --> 00:31:10.870
And now it's consistent.

00:31:10.870 --> 00:31:14.210
Their futures experiences are
consistent with that example.

00:31:14.210 --> 00:31:15.470
So they've effectively
learned it.

00:31:15.470 --> 00:31:17.090
People are pretty smart.

00:31:17.090 --> 00:31:19.380
So you're able to actually
create innovative software

00:31:19.380 --> 00:31:21.980
that changes things from the
existing marketplace and

00:31:21.980 --> 00:31:22.780
playing field.

00:31:22.780 --> 00:31:25.220
You just have to bring people
up to speed on why you made

00:31:25.220 --> 00:31:26.280
this changes.

00:31:26.280 --> 00:31:28.320
So a couple examples of this--

00:31:28.320 --> 00:31:31.300
in 2006, the notion of
the end of files.

00:31:31.300 --> 00:31:33.080
Obviously, people are very
used to the file system.

00:31:33.080 --> 00:31:35.380
They're used to attaching
things, sending them around.

00:31:35.380 --> 00:31:36.350
That's kind of broken.

00:31:36.350 --> 00:31:39.170
So how do you get this huge
marketplace that is very sort

00:31:39.170 --> 00:31:40.820
of set in the consistency
of how files

00:31:40.820 --> 00:31:42.490
operate into a new model?

00:31:42.490 --> 00:31:44.810
And the answers is you just
lay out a very quick

00:31:44.810 --> 00:31:47.320
argument for it.

00:31:47.320 --> 00:31:48.540
MALE SPEAKER: Meet Sam.

00:31:48.540 --> 00:31:50.850
Sam is the editor of a
neighborhood newsletter called

00:31:50.850 --> 00:31:52.020
The Oak Tree View.

00:31:52.020 --> 00:31:54.390
She works with local writers who
like to publish articles

00:31:54.390 --> 00:31:55.240
in the newsletter.

00:31:55.240 --> 00:31:58.350
Sam loves her job but often
feels frustrated when time is

00:31:58.350 --> 00:32:00.290
wasted managing all
the 'articles.

00:32:00.290 --> 00:32:01.690
It's a familiar problem.

00:32:01.690 --> 00:32:04.190
Each month, writers send her
draft articles as email

00:32:04.190 --> 00:32:05.040
attachments.

00:32:05.040 --> 00:32:07.510
She reviews them and sends
them back with comments.

00:32:07.510 --> 00:32:10.050
One article might create six
different versions of the same

00:32:10.050 --> 00:32:12.510
file, not to mention the
countless emails.

00:32:12.510 --> 00:32:15.230
Sam often feels buried by all
the email attachments.

00:32:15.230 --> 00:32:17.794
She finds it hard to track all
the versions being sent to her

00:32:17.794 --> 00:32:18.650
from the writers.

00:32:18.650 --> 00:32:21.260
As the deadline looms,
frustration rises.

00:32:21.260 --> 00:32:22.860
Something has to give.

00:32:22.860 --> 00:32:25.860
Sam decides to try something
new, Google Docs.

00:32:25.860 --> 00:32:27.110
Here's what happens.

00:32:27.110 --> 00:32:30.110
First, she visits the Google
Docs page and creates a free

00:32:30.110 --> 00:32:31.110
Google account.

00:32:31.110 --> 00:32:32.140
She logs in.

00:32:32.140 --> 00:32:34.570
And because some articles were
already written, she uploads

00:32:34.570 --> 00:32:36.600
the current drafts right
from her computer.

00:32:36.600 --> 00:32:38.930
With a snap, Google
Docs turns offline

00:32:38.930 --> 00:32:41.190
articles into online versions.

00:32:41.190 --> 00:32:43.310
Now all she needs to do is
invite the writers to

00:32:43.310 --> 00:32:45.650
collaborate on the documents.

00:32:45.650 --> 00:32:47.710
ALEX FAABORG: So there, you lay
out a very simple problem.

00:32:47.710 --> 00:32:49.060
You show the solution.

00:32:49.060 --> 00:32:49.870
Sam is sad.

00:32:49.870 --> 00:32:51.190
Sam has too many files.

00:32:51.190 --> 00:32:53.260
And people are able to very
quickly then adapt to that new

00:32:53.260 --> 00:32:55.130
model because they
have been able to

00:32:55.130 --> 00:32:56.570
learn from that example.

00:32:56.570 --> 00:32:58.720
It's not the case that you
have to be consistent.

00:32:58.720 --> 00:33:01.920
Looking at another example--

00:33:01.920 --> 00:33:03.120
2012, 2013--

00:33:03.120 --> 00:33:04.830
The notion of predictive
assistance.

00:33:04.830 --> 00:33:06.890
When we were working on Google
Now, we were worried about--

00:33:06.890 --> 00:33:08.800
it's going to be really hard
to explain this to people

00:33:08.800 --> 00:33:10.130
because people are so
used to search,

00:33:10.130 --> 00:33:11.020
especially with Google.

00:33:11.020 --> 00:33:12.650
People are extremely used to
search because Google such a

00:33:12.650 --> 00:33:13.800
search company.

00:33:13.800 --> 00:33:16.020
How do people wrap their head
around the notion of a product

00:33:16.020 --> 00:33:17.740
that's going to give them the
information that they need

00:33:17.740 --> 00:33:18.500
right when they need it?

00:33:18.500 --> 00:33:21.320
And the answer is you show them
a couple of very simple

00:33:21.320 --> 00:33:23.600
examples to lay out the
nature of the product.

00:33:23.600 --> 00:33:25.740
And from just those examples
they can start to extrapolate

00:33:25.740 --> 00:33:27.650
new use cases in
their own mind.

00:33:27.650 --> 00:33:29.770
So here's a quick spot we
created for Google Now.

00:33:29.770 --> 00:33:47.798
[MUSIC PLAYING]

00:33:47.798 --> 00:33:48.784
FEMALE SPEAKER 1: Bonjour.

00:33:48.784 --> 00:33:50.263
FEMALE SPEAKER 2: A fruit or
a vegetable, do you think?

00:33:50.263 --> 00:33:50.756
FEMALE SPEAKER 1: I don't know.

00:33:50.756 --> 00:33:53.714
I can ask.

00:33:53.714 --> 00:33:55.686
[SPEAKING IN FRENCH]

00:33:55.686 --> 00:33:58.644
MALE SPEAKER 2: It's a fish.

00:33:58.644 --> 00:33:59.670
FEMALE SPEAKER 2: Oh.

00:33:59.670 --> 00:34:02.530
ALEX FAABORG: So three
very short examples--

00:34:02.530 --> 00:34:03.560
and I'm only showing
a clip of it.

00:34:03.560 --> 00:34:04.890
But from that, you can
understand the

00:34:04.890 --> 00:34:05.620
nature of the product.

00:34:05.620 --> 00:34:08.610
And we're finding when we told
people, so this thing is going

00:34:08.610 --> 00:34:09.969
to predict the information
you need.

00:34:09.969 --> 00:34:11.960
They would look back
and say, OK what?

00:34:11.960 --> 00:34:13.070
That makes no sense.

00:34:13.070 --> 00:34:16.260
But if we said, you're standing
on a train platform.

00:34:16.260 --> 00:34:17.790
You want to know when the next
train's going to come.

00:34:17.790 --> 00:34:19.679
So you go in it, and the
schedule's already there.

00:34:19.679 --> 00:34:21.199
They say, oh that's
pretty cool.

00:34:21.199 --> 00:34:24.050
From the example they're able
to then grapple onto

00:34:24.050 --> 00:34:24.560
[INAUDIBLE]

00:34:24.560 --> 00:34:26.179
and then imagine
other examples.

00:34:26.179 --> 00:34:29.280
That was act one of laying
out this notion of

00:34:29.280 --> 00:34:30.350
this augmented reality.

00:34:30.350 --> 00:34:32.320
Of course, act two is then
saying to people.

00:34:32.320 --> 00:34:33.558
And it's going to augment
your vision.

00:34:33.558 --> 00:34:35.510
[MUSIC PLAYING]

00:34:35.510 --> 00:34:36.974
MALE SPEAKER 3: After this
bridge, first exit.

00:34:36.974 --> 00:34:38.224
MALE SPEAKER 4: Woo hoo.

00:34:41.366 --> 00:34:41.854
MALE SPEAKER 5: Hurry up.

00:34:41.854 --> 00:34:43.820
A12, right there.

00:34:43.820 --> 00:34:45.540
ALEX FAABORG: So this product
is great for when you're

00:34:45.540 --> 00:34:50.300
running down escalators is
the consistent notion.

00:34:50.300 --> 00:34:52.190
Because we're showing people
being so busy that's also

00:34:52.190 --> 00:34:54.400
important for the
predictiveness, where they

00:34:54.400 --> 00:34:55.989
don't even have time
to quickly look up

00:34:55.989 --> 00:34:56.690
their flight details.

00:34:56.690 --> 00:34:57.655
They need to get the gate.

00:34:57.655 --> 00:34:58.820
And it's right there.

00:34:58.820 --> 00:35:02.665
So what's important here is
that consistency is--

00:35:02.665 --> 00:35:03.215
[MIC FEEDBACK]

00:35:03.215 --> 00:35:03.893
Sorry.

00:35:03.893 --> 00:35:08.530
It's making noise against
my phone.

00:35:08.530 --> 00:35:10.690
Consistency is not critical.

00:35:10.690 --> 00:35:12.780
It really bothers me that
that's one of usability

00:35:12.780 --> 00:35:14.590
heuristics that people
focus on.

00:35:14.590 --> 00:35:16.700
You do not need to build
products that are identical to

00:35:16.700 --> 00:35:18.190
what exists in the
marketplace.

00:35:18.190 --> 00:35:21.120
What you can do is you can have
innovation and teaching.

00:35:21.120 --> 00:35:23.630
And people are smart, like you
don't have to design for the

00:35:23.630 --> 00:35:25.020
first-run interaction.

00:35:25.020 --> 00:35:26.930
You can bring people up
to speed over time.

00:35:26.930 --> 00:35:28.220
And they're going to understand
your product.

00:35:28.220 --> 00:35:30.210
And you can create interesting
products that aren't just

00:35:30.210 --> 00:35:31.850
leveraging what's already in
the marketplace for the

00:35:31.850 --> 00:35:33.750
purpose of usability.

00:35:33.750 --> 00:35:35.730
So the final topic I want
to focus on is the

00:35:35.730 --> 00:35:37.950
perception of time.

00:35:37.950 --> 00:35:40.590
So interesting example
here-- just looking

00:35:40.590 --> 00:35:43.201
at a progress bar.

00:35:43.201 --> 00:35:45.755
In this case, it's a pretty
simple progress bar.

00:35:48.570 --> 00:35:50.090
We look at another one.

00:35:50.090 --> 00:35:51.080
This one it slows down.

00:35:51.080 --> 00:35:54.940
You're like, come on, come
on-- and then finishes.

00:35:54.940 --> 00:35:59.280
Versus the final one, where
it starts out OK.

00:35:59.280 --> 00:36:01.200
And then it speeds up
towards the end.

00:36:01.200 --> 00:36:04.320
And of course, all these
progress bars are taking the

00:36:04.320 --> 00:36:05.395
same amount of time
to complete.

00:36:05.395 --> 00:36:07.710
But what's interesting is we're
actually really bad at

00:36:07.710 --> 00:36:09.090
gauging how long
something took.

00:36:09.090 --> 00:36:11.740
We don't really have an
internal chronometer.

00:36:11.740 --> 00:36:14.490
What we're doing is we're
perceiving the process of time

00:36:14.490 --> 00:36:15.870
based off of change.

00:36:15.870 --> 00:36:18.170
So something that speeds up
towards the end, is actually

00:36:18.170 --> 00:36:20.240
going to appear faster than
something that slows down

00:36:20.240 --> 00:36:21.780
towards the end, even if
the overall amount

00:36:21.780 --> 00:36:22.910
of time is the same.

00:36:22.910 --> 00:36:24.550
And they're been a lot
of studies on this.

00:36:24.550 --> 00:36:27.600
In fact other products, have
had slow progress bars.

00:36:27.600 --> 00:36:30.755
And everyone complained that
file copying got slower, even

00:36:30.755 --> 00:36:33.350
though it was actually faster,
which is crazy.

00:36:33.350 --> 00:36:35.480
So it's important to know
these types of effects.

00:36:35.480 --> 00:36:38.910
They're can actually be a 10%
variance in how long something

00:36:38.910 --> 00:36:40.480
people think something's
going to take.

00:36:40.480 --> 00:36:42.730
Another example of this is if
you're working on something

00:36:42.730 --> 00:36:45.730
like the Web Layout engine,
where obviously there's a lot

00:36:45.730 --> 00:36:47.630
of people working very hard
at making that quickly.

00:36:47.630 --> 00:36:50.420
So your immediate assumption
could be, well we'll just do a

00:36:50.420 --> 00:36:52.270
layout as things come in.

00:36:52.270 --> 00:36:54.770
As soon as we have it, we show
to the screen, quick feedback,

00:36:54.770 --> 00:36:55.990
it's all going to be great.

00:36:55.990 --> 00:36:59.570
What's interesting is because we
we're so bad gauging time.

00:36:59.570 --> 00:37:03.280
And we only gauge time based off
of the individual changes

00:37:03.280 --> 00:37:05.560
and how many changes
there were.

00:37:05.560 --> 00:37:07.890
That will actually appear to
take longer than if you were

00:37:07.890 --> 00:37:10.520
just pause and then bring
everything in

00:37:10.520 --> 00:37:11.880
once you have it.

00:37:11.880 --> 00:37:15.205
Because we mentally chunk that
white space of before.

00:37:15.205 --> 00:37:17.620
And we don't really know
how long before was.

00:37:17.620 --> 00:37:19.550
We just know that, wow I
have my whole page now.

00:37:19.550 --> 00:37:21.580
And it came in very quickly.

00:37:21.580 --> 00:37:23.730
So there are all these aspects
of how we're perceiving time

00:37:23.730 --> 00:37:25.250
that come to play with the
performance of your

00:37:25.250 --> 00:37:27.920
applications and how you
can optimize for that.

00:37:27.920 --> 00:37:31.010
And our perception of time it's
kind of like an optical

00:37:31.010 --> 00:37:33.630
illusion, where we're not
perceiving reality.

00:37:33.630 --> 00:37:36.440
We're filtering everything
through our own hardware.

00:37:36.440 --> 00:37:38.940
And if you learn about our
hardware, and if you learn

00:37:38.940 --> 00:37:41.430
about the biological
computational machines that we

00:37:41.430 --> 00:37:44.110
are and that your software
actually runs on, you can

00:37:44.110 --> 00:37:45.190
write better software.

00:37:45.190 --> 00:37:47.020
And you'll be a better
engineer.

00:37:47.020 --> 00:37:49.610
So some quick recommended
reading, if you want to check

00:37:49.610 --> 00:37:50.190
out some books--

00:37:50.190 --> 00:37:53.050
Don Norman, famous cognitive
psychologist.

00:37:53.050 --> 00:37:55.810
Susan Weinschenk has a very
book came out recently.

00:37:55.810 --> 00:37:57.210
Also of course, all the
writing from the

00:37:57.210 --> 00:37:58.460
injury design team.

00:37:58.460 --> 00:38:00.970
And before you read those books,
you can spend your

00:38:00.970 --> 00:38:02.650
entire day learning
about design.

00:38:02.650 --> 00:38:04.570
This was the first session.

00:38:04.570 --> 00:38:06.520
In the same room, we'll
have three more

00:38:06.520 --> 00:38:08.180
sessions about design.

00:38:08.180 --> 00:38:09.700
And then if you head
over to Room 12.

00:38:09.700 --> 00:38:12.450
There's Android design
for UI developers.

00:38:12.450 --> 00:38:14.450
So now we can take some
quick questions.

00:38:14.450 --> 00:38:15.700
And thank you.

00:38:18.528 --> 00:38:23.786
[APPLAUSE]

00:38:23.786 --> 00:38:26.280
And I think very quick questions
because we have

00:38:26.280 --> 00:38:28.140
about a minute and a half--

00:38:28.140 --> 00:38:29.122
one question.

00:38:29.122 --> 00:38:30.086
[VOICES FROM THE AUDIENCE]

00:38:30.086 --> 00:38:31.050
Ah yeah.

00:38:31.050 --> 00:38:32.500
Sure.

00:38:32.500 --> 00:38:33.700
Thank you.

00:38:33.700 --> 00:38:34.160
All right.

00:38:34.160 --> 00:38:35.410
Thank you for coming.

