WEBVTT
Kind: captions
Language: en

00:00:06.011 --> 00:00:07.510
JOSH GORDON: Last
episode we trained

00:00:07.510 --> 00:00:10.500
in Image Classifier using
TensorFlow for Poets,

00:00:10.500 --> 00:00:13.552
and this time, we'll
write one using TF.Learn.

00:00:13.552 --> 00:00:15.010
The problem we'll
start on today is

00:00:15.010 --> 00:00:18.400
classifying handwritten
digits from the MNIST dataset,

00:00:18.400 --> 00:00:21.000
and writing a simple
classifier for these is often

00:00:21.000 --> 00:00:23.780
considered the Hello
World of computer vision.

00:00:23.780 --> 00:00:26.940
Now MNIST is a multi-class
classification problem.

00:00:26.940 --> 00:00:28.620
Given an image of
a digit, our job

00:00:28.620 --> 00:00:30.880
will be to predict
which one it is.

00:00:30.880 --> 00:00:32.900
I wrote an IPython
notebook for this episode,

00:00:32.900 --> 00:00:35.110
and you can find a link
to it in the description.

00:00:35.110 --> 00:00:37.630
And to make it easier for you
to configure your environment,

00:00:37.630 --> 00:00:39.630
I'll start with a quick
screencast of installing

00:00:39.630 --> 00:00:41.576
TensorFlow using Docker.

00:00:41.576 --> 00:00:43.450
First, here's an outline
of what we'll cover.

00:00:43.450 --> 00:00:45.158
I'll show you how to
download the dataset

00:00:45.158 --> 00:00:46.530
and visualize images.

00:00:46.530 --> 00:00:49.050
Next, we'll train a
classifier, evaluate it,

00:00:49.050 --> 00:00:51.911
and use it to make
predictions on new images.

00:00:51.911 --> 00:00:54.160
Then we'll visualize the
weights the classifier learns

00:00:54.160 --> 00:00:56.940
to gain intuition for how
it works under the hood.

00:00:56.940 --> 00:00:59.397
Let's start by
installing TensorFlow.

00:00:59.397 --> 00:01:00.980
You can find
installation instructions

00:01:00.980 --> 00:01:03.090
for Docker linked from
the Getting Started page

00:01:03.090 --> 00:01:06.020
on TensorFlow.org, and
I'll start this screencast

00:01:06.020 --> 00:01:08.480
assuming you've just finished
downloading and installing

00:01:08.480 --> 00:01:12.450
Docker itself but haven't
started installing TensorFlow.

00:01:12.450 --> 00:01:15.300
Starting from a fresh install
of Docker, the first thing to do

00:01:15.300 --> 00:01:17.540
is open the Docker
Quickstart terminal.

00:01:17.540 --> 00:01:20.040
And when this appears,
you'll see an IP address just

00:01:20.040 --> 00:01:21.280
below the whale.

00:01:21.280 --> 00:01:22.060
Copy it down.

00:01:22.060 --> 00:01:23.509
We'll need it later.

00:01:23.509 --> 00:01:25.050
Next, we'll launch
a Docker container

00:01:25.050 --> 00:01:26.810
with a TensorFlow image.

00:01:26.810 --> 00:01:28.670
The image is hosted
on Docker hub,

00:01:28.670 --> 00:01:30.810
and there's a link to
that in the description.

00:01:30.810 --> 00:01:33.580
The image contains TensorFlow
with all its dependencies

00:01:33.580 --> 00:01:35.880
properly configured,
and here's the command

00:01:35.880 --> 00:01:38.360
we'll use to download
and launch the image.

00:01:38.360 --> 00:01:41.574
But first, let's choose
the version we want.

00:01:41.574 --> 00:01:43.240
The versions are on
this page, and we'll

00:01:43.240 --> 00:01:44.850
use the latest release.

00:01:44.850 --> 00:01:47.420
Now we can copy-paste the
command into a terminal

00:01:47.420 --> 00:01:49.670
and add a colon with
the version number.

00:01:49.670 --> 00:01:51.700
If this is the first time
you've run the image,

00:01:51.700 --> 00:01:53.260
it'll be downloaded
automatically.

00:01:53.260 --> 00:01:56.257
And on subsequent runs,
it'll be cached locally.

00:01:56.257 --> 00:01:58.340
The image starts automatically,
and by default, it

00:01:58.340 --> 00:01:59.500
runs a notebook server.

00:01:59.500 --> 00:02:01.880
All that's left for us to
do is to open up a browser

00:02:01.880 --> 00:02:06.310
and point it to the IP we jotted
down earlier on port 8888.

00:02:06.310 --> 00:02:08.060
And now we have an
IPython notebook

00:02:08.060 --> 00:02:10.430
that we can experiment
with in our browser served

00:02:10.430 --> 00:02:11.549
by the container.

00:02:11.549 --> 00:02:14.090
You can find the notebook for
this episode in the description

00:02:14.090 --> 00:02:16.590
and upload it through the UI.

00:02:16.590 --> 00:02:17.090
OK.

00:02:17.090 --> 00:02:18.600
Now onto code.

00:02:18.600 --> 00:02:20.180
Here are the imports we'll use.

00:02:20.180 --> 00:02:22.670
I'll use matplotlib to display
images, and, of course,

00:02:22.670 --> 00:02:25.430
we'll use TF.Learn to
train the classifier.

00:02:25.430 --> 00:02:27.810
All of these are
installed with the image.

00:02:27.810 --> 00:02:30.200
Next, we'll download
the MNIST dataset,

00:02:30.200 --> 00:02:32.710
and we have a nice
one liner for that.

00:02:32.710 --> 00:02:35.080
The dataset contains
thousands of labeled images

00:02:35.080 --> 00:02:36.450
of handwritten digits.

00:02:36.450 --> 00:02:39.460
It's pre-divided into
train, which is 55,000,

00:02:39.460 --> 00:02:41.620
and test, which is 10,000.

00:02:41.620 --> 00:02:44.520
Let's visualize a few
of these to get a feel.

00:02:44.520 --> 00:02:47.380
This code displays an
image along with its label,

00:02:47.380 --> 00:02:49.280
and you might notice
I'm reshaping the image,

00:02:49.280 --> 00:02:52.050
and I'll explain why in a bit.

00:02:52.050 --> 00:02:54.480
The first image from the
testing set is a seven,

00:02:54.480 --> 00:02:57.760
and you can see the example
index as well as the label.

00:02:57.760 --> 00:02:59.660
Here's the second image.

00:02:59.660 --> 00:03:01.180
Now both of these
are clearly drawn,

00:03:01.180 --> 00:03:03.096
but there's a variety
of different handwriting

00:03:03.096 --> 00:03:04.300
samples in this dataset.

00:03:04.300 --> 00:03:06.990
Here's an image that's
harder to recognize.

00:03:06.990 --> 00:03:09.340
These images are low
resolution, just 28

00:03:09.340 --> 00:03:11.750
by 28 pixels in grayscale.

00:03:11.750 --> 00:03:14.250
Also note they're
properly segmented.

00:03:14.250 --> 00:03:17.760
That means each image
contains exactly one digit.

00:03:17.760 --> 00:03:20.050
Now let's talk about
the features we'll use.

00:03:20.050 --> 00:03:21.660
When we're working
with images, we

00:03:21.660 --> 00:03:23.770
use the raw pixels as features.

00:03:23.770 --> 00:03:25.560
That's because extracting
useful features

00:03:25.560 --> 00:03:28.360
from images, like textures
and shapes, is hard.

00:03:28.360 --> 00:03:31.770
Now a 28 by 28 image
has 784 pixels,

00:03:31.770 --> 00:03:34.117
so we have 784 features.

00:03:34.117 --> 00:03:36.200
And here, we're using the
flattened representation

00:03:36.200 --> 00:03:37.560
of the image.

00:03:37.560 --> 00:03:40.250
To flatten an image means to
convert it from a 2D array

00:03:40.250 --> 00:03:43.566
to a 1D array by unstacking
the rows and lining them up.

00:03:43.566 --> 00:03:45.190
That's why we had to
reshape this array

00:03:45.190 --> 00:03:47.260
to display it earlier.

00:03:47.260 --> 00:03:49.200
Now we can initialize
the classifier,

00:03:49.200 --> 00:03:51.590
and here, we'll use
a linear classifier.

00:03:51.590 --> 00:03:53.360
We'll provide two parameters.

00:03:53.360 --> 00:03:55.730
The first indicates how
many classes we have,

00:03:55.730 --> 00:03:58.660
and there are 10, one
for each type of digit.

00:03:58.660 --> 00:04:00.230
The second informs
the classifier

00:04:00.230 --> 00:04:02.270
about the features we'll use.

00:04:02.270 --> 00:04:04.730
Now I'll draw a quick diagram
of a linear classifier

00:04:04.730 --> 00:04:07.595
to give you a high level preview
of how it works under the hood.

00:04:07.595 --> 00:04:08.970
You could think
of the classifier

00:04:08.970 --> 00:04:11.280
as adding up the evidence
that the image is

00:04:11.280 --> 00:04:13.020
each type of digit.

00:04:13.020 --> 00:04:15.910
The input nodes are on the
top, represented by Xes,

00:04:15.910 --> 00:04:19.220
and the output nodes are on
the bottom represented by Ys.

00:04:19.220 --> 00:04:22.750
We have one input node for each
feature or pixel in the image

00:04:22.750 --> 00:04:24.340
and one output
node for each digit

00:04:24.340 --> 00:04:26.100
the image could represent.

00:04:26.100 --> 00:04:29.777
Here, we have 784
inputs and 10 outputs.

00:04:29.777 --> 00:04:31.610
I've just drawn a few
of them, so everything

00:04:31.610 --> 00:04:32.740
fits on the screen.

00:04:32.740 --> 00:04:35.240
Now the inputs and outputs
are fully connected,

00:04:35.240 --> 00:04:37.560
and each of these
edges has a weight.

00:04:37.560 --> 00:04:40.350
When we classify an image,
you can think of each pixel

00:04:40.350 --> 00:04:41.830
as going on a journey.

00:04:41.830 --> 00:04:44.130
First, it flows
into its input node,

00:04:44.130 --> 00:04:46.650
and next, it travels
along the edges.

00:04:46.650 --> 00:04:49.590
Along the way, it's multiplied
by the weight on the edge,

00:04:49.590 --> 00:04:51.650
and the output nodes
gather evidence

00:04:51.650 --> 00:04:55.750
that the image we're classifying
represents each type of digit.

00:04:55.750 --> 00:04:58.430
The more evidence we gather,
say on the eight output,

00:04:58.430 --> 00:05:01.060
the more likely it is
the image is an eight.

00:05:01.060 --> 00:05:03.160
And to calculate how
much evidence we have,

00:05:03.160 --> 00:05:06.250
we sum the value of the
pixel intensities multiplied

00:05:06.250 --> 00:05:07.430
by the weights.

00:05:07.430 --> 00:05:09.970
Then we can predict that the
image belongs to the output

00:05:09.970 --> 00:05:12.170
node with the most evidence.

00:05:12.170 --> 00:05:13.870
The important part
is the weights,

00:05:13.870 --> 00:05:15.420
and by setting them
properly, we can

00:05:15.420 --> 00:05:17.160
get accurate classifications.

00:05:17.160 --> 00:05:20.130
We begin with random weights,
then gradually adjust them

00:05:20.130 --> 00:05:21.510
towards better values.

00:05:21.510 --> 00:05:24.030
And this happens
inside the fit method.

00:05:24.030 --> 00:05:26.820
Once we have a trained
model, we can evaluate it.

00:05:26.820 --> 00:05:28.290
Using the evaluate
method, we see

00:05:28.290 --> 00:05:31.730
that it correctly classifies
about 90% of the test set.

00:05:31.730 --> 00:05:34.860
We can also make predictions
on individual images.

00:05:34.860 --> 00:05:37.400
Here's one that it correctly
classifies, and here's

00:05:37.400 --> 00:05:39.676
one that it gets wrong.

00:05:39.676 --> 00:05:41.800
Now I want to show you how
to visualize the weights

00:05:41.800 --> 00:05:43.520
the classifier learns.

00:05:43.520 --> 00:05:45.600
Here, positive weights
are drawn in red,

00:05:45.600 --> 00:05:48.650
and negative weights
are drawn in blue.

00:05:48.650 --> 00:05:50.440
So what do these
weights tell us?

00:05:50.440 --> 00:05:53.800
Well, to understand that,
I'll show four images of ones.

00:05:53.800 --> 00:05:55.480
They're all drawn
slightly differently,

00:05:55.480 --> 00:05:57.600
but take a look at
the middle pixel.

00:05:57.600 --> 00:06:00.390
Notice that it's filled
in on every image.

00:06:00.390 --> 00:06:02.290
When that pixel
is filled in, it's

00:06:02.290 --> 00:06:04.640
evidence that the image
we're looking at is a one,

00:06:04.640 --> 00:06:07.410
so we'd expect a
highway on that edge.

00:06:07.410 --> 00:06:09.270
Now let's take a
look at four zeros.

00:06:09.270 --> 00:06:11.450
Notice that the
middle pixel is empty.

00:06:11.450 --> 00:06:13.680
Although there's lots
of ways to draw zeros,

00:06:13.680 --> 00:06:15.330
if that middle
pixel is filled in,

00:06:15.330 --> 00:06:17.660
it's evidence against
the image being a zero,

00:06:17.660 --> 00:06:19.972
so we'd expect a negative
weight on the edge.

00:06:19.972 --> 00:06:21.680
And looking at the
images of the weights,

00:06:21.680 --> 00:06:23.940
we can almost see outlines
of the digits drawn

00:06:23.940 --> 00:06:25.935
in red for each class.

00:06:25.935 --> 00:06:28.060
We were able to visualize
these, because we started

00:06:28.060 --> 00:06:31.870
with 784 pixels, and we learned
10 weights for each, one

00:06:31.870 --> 00:06:33.350
for each type of digit.

00:06:33.350 --> 00:06:36.200
We then reshape the
weights into a 2D array.

00:06:36.200 --> 00:06:36.700
OK.

00:06:36.700 --> 00:06:37.489
That's it for now.

00:06:37.489 --> 00:06:39.530
Of course, there's lots
more to learn about this,

00:06:39.530 --> 00:06:41.615
and I put my favorite
links in the description.

00:06:41.615 --> 00:06:43.990
Coming up next time, we'll
experiment with deep learning,

00:06:43.990 --> 00:06:46.860
and I'll cover in more detail
what we introduced here today.

00:06:46.860 --> 00:06:49.760
Thanks very much for watching,
and I'll see you then.

00:06:49.760 --> 00:06:53.110
[MUSIC PLAYING]

